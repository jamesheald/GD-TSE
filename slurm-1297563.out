Launching a python run
Sun Sep 28 12:57:36 AM UTC 2025
Active conda env: /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/python3
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/pip
2025-09-28 00:57:47.666912: I external/xla/xla/pjrt/pjrt_api.cc:115] GetPjrtApi was found for cuda at /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/jax_plugins/xla_cuda12/xla_cuda_plugin.so
2025-09-28 00:57:47.666976: I external/xla/xla/pjrt/pjrt_api.cc:93] PJRT_Api is set for device type cuda
2025-09-28 00:57:47.670381: I external/xla/xla/pjrt/pjrt_api.cc:161] The PJRT plugin has PJRT API version 0.70. The framework PJRT API version is 0.70.
2025-09-28 00:57:47.874004: I external/xla/xla/service/service.cc:153] XLA service 0x5f9b1bbef690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-09-28 00:57:47.874022: I external/xla/xla/service/service.cc:161]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2025-09-28 00:57:47.885894: I external/xla/xla/pjrt/pjrt_c_api_client.cc:130] PjRtCApiClient created.
[CudaDevice(id=0)]
/nfs/nhome/live/jheald/jax_dt/train_dt.py:50: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path=cfg_path, config_name="config.yaml")
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
============================================================
start time: 25-09-28-00-57-49
============================================================
dataset path: data//relocate-expert-v1-fullnextstate.pkl
log csv save path: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/log.csv
[2025-09-28 00:57:50,059][OpenGL.acceleratesupport][INFO] - No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'
wandb: Currently logged in as: james-heald (james-gatsby) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /nfs/nhome/live/jheald/jax_dt/outputs/2025-09-28/00-57-48/wandb/run-20250928_005837-j012czr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run relocate-expert-v1-985440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/james-gatsby/jax_dt
wandb: üöÄ View run at https://wandb.ai/james-gatsby/jax_dt/runs/j012czr7
2025-09-28 00:58:39.636823: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 00:58:42.946373: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 232 bytes spill stores, 232 bytes spill loads

2025-09-28 00:58:44.256998: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 628 bytes spill stores, 492 bytes spill loads

2025-09-28 00:58:49.001725: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 2140 bytes spill stores, 1648 bytes spill loads

2025-09-28 00:58:49.245558: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 388 bytes spill stores, 296 bytes spill loads

2025-09-28 00:58:50.277263: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 80 bytes spill stores, 80 bytes spill loads

2025-09-28 00:58:52.787329: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 12 bytes spill stores, 12 bytes spill loads

2025-09-28 00:58:54.019328: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 16008 bytes spill stores, 16296 bytes spill loads

2025-09-28 00:58:54.735387: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 1016 bytes spill stores, 1016 bytes spill loads

2025-09-28 00:58:57.829093: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 5912 bytes spill stores, 5776 bytes spill loads

2025-09-28 00:58:58.615923: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 436 bytes spill stores, 436 bytes spill loads

============================================================
time elapsed: 0:01:16
train iter: 0
num of updates: 100
dynamics loss: 362632.12500

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/dynamics_model_100.pt
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = _fork_exec(
============================================================
time elapsed: 0:01:25
train iter: 1
num of updates: 200
dynamics loss: 362374.12500

============================================================
time elapsed: 0:01:28
train iter: 2
num of updates: 300
dynamics loss: 361995.59375

============================================================
time elapsed: 0:01:31
train iter: 3
num of updates: 400
dynamics loss: 361465.56250

============================================================
time elapsed: 0:01:34
train iter: 4
num of updates: 500
dynamics loss: 360738.06250

============================================================
time elapsed: 0:01:37
train iter: 5
num of updates: 600
dynamics loss: 359797.65625

============================================================
time elapsed: 0:01:40
train iter: 6
num of updates: 700
dynamics loss: 358565.06250

============================================================
time elapsed: 0:01:43
train iter: 7
num of updates: 800
dynamics loss: 357281.87500

============================================================
time elapsed: 0:01:46
train iter: 8
num of updates: 900
dynamics loss: 355958.28125

============================================================
time elapsed: 0:01:49
train iter: 9
num of updates: 1000
dynamics loss: 354116.37500

============================================================
time elapsed: 0:01:52
train iter: 10
num of updates: 1100
dynamics loss: 352194.93750

============================================================
time elapsed: 0:01:55
train iter: 11
num of updates: 1200
dynamics loss: 350299.59375

============================================================
time elapsed: 0:01:58
train iter: 12
num of updates: 1300
dynamics loss: 347948.93750

============================================================
time elapsed: 0:02:01
train iter: 13
num of updates: 1400
dynamics loss: 345720.50000

============================================================
time elapsed: 0:02:04
train iter: 14
num of updates: 1500
dynamics loss: 343151.34375

============================================================
time elapsed: 0:02:07
train iter: 15
num of updates: 1600
dynamics loss: 340521.40625

============================================================
time elapsed: 0:02:09
train iter: 16
num of updates: 1700
dynamics loss: 337549.62500

============================================================
time elapsed: 0:02:12
train iter: 17
num of updates: 1800
dynamics loss: 334451.53125

============================================================
time elapsed: 0:02:15
train iter: 18
num of updates: 1900
dynamics loss: 331242.96875

============================================================
time elapsed: 0:02:18
train iter: 19
num of updates: 2000
dynamics loss: 328067.87500

============================================================
time elapsed: 0:02:21
train iter: 20
num of updates: 2100
dynamics loss: 324501.43750

============================================================
time elapsed: 0:02:24
train iter: 21
num of updates: 2200
dynamics loss: 320934.75000

============================================================
time elapsed: 0:02:27
train iter: 22
num of updates: 2300
dynamics loss: 317115.00000

============================================================
time elapsed: 0:02:30
train iter: 23
num of updates: 2400
dynamics loss: 313338.34375

============================================================
time elapsed: 0:02:33
train iter: 24
num of updates: 2500
dynamics loss: 309313.53125

============================================================
time elapsed: 0:02:36
train iter: 25
num of updates: 2600
dynamics loss: 305254.09375

============================================================
time elapsed: 0:02:39
train iter: 26
num of updates: 2700
dynamics loss: 300905.15625

============================================================
time elapsed: 0:02:42
train iter: 27
num of updates: 2800
dynamics loss: 296674.12500

============================================================
time elapsed: 0:02:45
train iter: 28
num of updates: 2900
dynamics loss: 292124.81250

============================================================
time elapsed: 0:02:48
train iter: 29
num of updates: 3000
dynamics loss: 287594.12500

============================================================
time elapsed: 0:02:51
train iter: 30
num of updates: 3100
dynamics loss: 283032.81250

============================================================
time elapsed: 0:02:53
train iter: 31
num of updates: 3200
dynamics loss: 278290.87500

============================================================
time elapsed: 0:02:56
train iter: 32
num of updates: 3300
dynamics loss: 273460.62500

============================================================
time elapsed: 0:02:59
train iter: 33
num of updates: 3400
dynamics loss: 268630.28125

============================================================
time elapsed: 0:03:02
train iter: 34
num of updates: 3500
dynamics loss: 263657.37500

============================================================
time elapsed: 0:03:05
train iter: 35
num of updates: 3600
dynamics loss: 258803.56250

============================================================
time elapsed: 0:03:08
train iter: 36
num of updates: 3700
dynamics loss: 253758.34375

============================================================
time elapsed: 0:03:11
train iter: 37
num of updates: 3800
dynamics loss: 248600.87500

============================================================
time elapsed: 0:03:14
train iter: 38
num of updates: 3900
dynamics loss: 243608.48438

============================================================
time elapsed: 0:03:17
train iter: 39
num of updates: 4000
dynamics loss: 238328.78125

============================================================
time elapsed: 0:03:20
train iter: 40
num of updates: 4100
dynamics loss: 233271.46875

============================================================
time elapsed: 0:03:23
train iter: 41
num of updates: 4200
dynamics loss: 228207.32812

============================================================
time elapsed: 0:03:26
train iter: 42
num of updates: 4300
dynamics loss: 222960.96875

============================================================
time elapsed: 0:03:29
train iter: 43
num of updates: 4400
dynamics loss: 217908.04688

============================================================
time elapsed: 0:03:32
train iter: 44
num of updates: 4500
dynamics loss: 212761.15625

============================================================
time elapsed: 0:03:35
train iter: 45
num of updates: 4600
dynamics loss: 207712.78125

============================================================
time elapsed: 0:03:37
train iter: 46
num of updates: 4700
dynamics loss: 202567.21875

============================================================
time elapsed: 0:03:40
train iter: 47
num of updates: 4800
dynamics loss: 197533.37500

============================================================
time elapsed: 0:03:43
train iter: 48
num of updates: 4900
dynamics loss: 192508.65625

============================================================
time elapsed: 0:03:46
train iter: 49
num of updates: 5000
dynamics loss: 187652.15625

============================================================
time elapsed: 0:03:49
train iter: 50
num of updates: 5100
dynamics loss: 182723.34375

============================================================
time elapsed: 0:03:52
train iter: 51
num of updates: 5200
dynamics loss: 177962.39062

============================================================
time elapsed: 0:03:55
train iter: 52
num of updates: 5300
dynamics loss: 173155.65625

============================================================
time elapsed: 0:03:58
train iter: 53
num of updates: 5400
dynamics loss: 168491.87500

============================================================
time elapsed: 0:04:01
train iter: 54
num of updates: 5500
dynamics loss: 163954.29688

============================================================
time elapsed: 0:04:04
train iter: 55
num of updates: 5600
dynamics loss: 159433.68750

============================================================
time elapsed: 0:04:07
train iter: 56
num of updates: 5700
dynamics loss: 155038.50000

============================================================
time elapsed: 0:04:10
train iter: 57
num of updates: 5800
dynamics loss: 150591.35938

============================================================
time elapsed: 0:04:13
train iter: 58
num of updates: 5900
dynamics loss: 146466.65625

============================================================
time elapsed: 0:04:16
train iter: 59
num of updates: 6000
dynamics loss: 142313.50000

============================================================
time elapsed: 0:04:19
train iter: 60
num of updates: 6100
dynamics loss: 138344.10938

============================================================
time elapsed: 0:04:21
train iter: 61
num of updates: 6200
dynamics loss: 134524.78125

============================================================
time elapsed: 0:04:24
train iter: 62
num of updates: 6300
dynamics loss: 130695.40625

============================================================
time elapsed: 0:04:27
train iter: 63
num of updates: 6400
dynamics loss: 127189.33594

============================================================
time elapsed: 0:04:30
train iter: 64
num of updates: 6500
dynamics loss: 123640.19531

============================================================
time elapsed: 0:04:33
train iter: 65
num of updates: 6600
dynamics loss: 120167.28906

============================================================
time elapsed: 0:04:36
train iter: 66
num of updates: 6700
dynamics loss: 116918.03906

============================================================
time elapsed: 0:04:39
train iter: 67
num of updates: 6800
dynamics loss: 113749.29688

============================================================
time elapsed: 0:04:42
train iter: 68
num of updates: 6900
dynamics loss: 110779.33594

============================================================
time elapsed: 0:04:45
train iter: 69
num of updates: 7000
dynamics loss: 107820.12500

============================================================
time elapsed: 0:04:48
train iter: 70
num of updates: 7100
dynamics loss: 105028.05469

============================================================
time elapsed: 0:04:51
train iter: 71
num of updates: 7200
dynamics loss: 102368.85156

============================================================
time elapsed: 0:04:54
train iter: 72
num of updates: 7300
dynamics loss: 99751.32031

============================================================
time elapsed: 0:04:57
train iter: 73
num of updates: 7400
dynamics loss: 97332.22656

============================================================
time elapsed: 0:05:00
train iter: 74
num of updates: 7500
dynamics loss: 94920.14062

============================================================
time elapsed: 0:05:03
train iter: 75
num of updates: 7600
dynamics loss: 92629.90625

============================================================
time elapsed: 0:05:05
train iter: 76
num of updates: 7700
dynamics loss: 90424.43750

============================================================
time elapsed: 0:05:08
train iter: 77
num of updates: 7800
dynamics loss: 88342.03906

============================================================
time elapsed: 0:05:11
train iter: 78
num of updates: 7900
dynamics loss: 86388.37500

============================================================
time elapsed: 0:05:14
train iter: 79
num of updates: 8000
dynamics loss: 84479.23438

============================================================
time elapsed: 0:05:17
train iter: 80
num of updates: 8100
dynamics loss: 82601.11719

============================================================
time elapsed: 0:05:20
train iter: 81
num of updates: 8200
dynamics loss: 80847.57031

============================================================
time elapsed: 0:05:23
train iter: 82
num of updates: 8300
dynamics loss: 79039.09375

============================================================
time elapsed: 0:05:26
train iter: 83
num of updates: 8400
dynamics loss: 77456.58594

============================================================
time elapsed: 0:05:29
train iter: 84
num of updates: 8500
dynamics loss: 75810.67188

============================================================
time elapsed: 0:05:32
train iter: 85
num of updates: 8600
dynamics loss: 74362.42969

============================================================
time elapsed: 0:05:35
train iter: 86
num of updates: 8700
dynamics loss: 72865.31250

============================================================
time elapsed: 0:05:38
train iter: 87
num of updates: 8800
dynamics loss: 71384.42188

============================================================
time elapsed: 0:05:41
train iter: 88
num of updates: 8900
dynamics loss: 69986.80469

============================================================
time elapsed: 0:05:44
train iter: 89
num of updates: 9000
dynamics loss: 68651.82812

============================================================
time elapsed: 0:05:47
train iter: 90
num of updates: 9100
dynamics loss: 67323.14062

============================================================
time elapsed: 0:05:49
train iter: 91
num of updates: 9200
dynamics loss: 66024.85938

============================================================
time elapsed: 0:05:52
train iter: 92
num of updates: 9300
dynamics loss: 64807.90625

============================================================
time elapsed: 0:05:55
train iter: 93
num of updates: 9400
dynamics loss: 63624.24219

============================================================
time elapsed: 0:05:58
train iter: 94
num of updates: 9500
dynamics loss: 62456.80859

============================================================
time elapsed: 0:06:01
train iter: 95
num of updates: 9600
dynamics loss: 61298.08203

============================================================
time elapsed: 0:06:04
train iter: 96
num of updates: 9700
dynamics loss: 60228.99219

============================================================
time elapsed: 0:06:07
train iter: 97
num of updates: 9800
dynamics loss: 59202.01953

============================================================
time elapsed: 0:06:10
train iter: 98
num of updates: 9900
dynamics loss: 58123.32031

============================================================
time elapsed: 0:06:13
train iter: 99
num of updates: 10000
dynamics loss: 57187.52344

============================================================
time elapsed: 0:06:16
train iter: 100
num of updates: 10100
dynamics loss: 56154.32812

============================================================
time elapsed: 0:06:19
train iter: 101
num of updates: 10200
dynamics loss: 55285.52344

============================================================
time elapsed: 0:06:22
train iter: 102
num of updates: 10300
dynamics loss: 54322.49219

============================================================
time elapsed: 0:06:25
train iter: 103
num of updates: 10400
dynamics loss: 53450.33203

============================================================
time elapsed: 0:06:28
train iter: 104
num of updates: 10500
dynamics loss: 52572.80078

============================================================
time elapsed: 0:06:30
train iter: 105
num of updates: 10600
dynamics loss: 51832.70312

============================================================
time elapsed: 0:06:33
train iter: 106
num of updates: 10700
dynamics loss: 51017.85938

============================================================
time elapsed: 0:06:36
train iter: 107
num of updates: 10800
dynamics loss: 50297.08594

============================================================
time elapsed: 0:06:39
train iter: 108
num of updates: 10900
dynamics loss: 49545.73828

============================================================
time elapsed: 0:06:42
train iter: 109
num of updates: 11000
dynamics loss: 48849.64844

============================================================
time elapsed: 0:06:45
train iter: 110
num of updates: 11100
dynamics loss: 48171.06641

============================================================
time elapsed: 0:06:48
train iter: 111
num of updates: 11200
dynamics loss: 47485.51562

============================================================
time elapsed: 0:06:51
train iter: 112
num of updates: 11300
dynamics loss: 46868.63672

============================================================
time elapsed: 0:06:54
train iter: 113
num of updates: 11400
dynamics loss: 46201.90625

============================================================
time elapsed: 0:06:57
train iter: 114
num of updates: 11500
dynamics loss: 45649.95703

============================================================
time elapsed: 0:07:00
train iter: 115
num of updates: 11600
dynamics loss: 45059.16406

============================================================
time elapsed: 0:07:03
train iter: 116
num of updates: 11700
dynamics loss: 44539.22656

============================================================
time elapsed: 0:07:06
train iter: 117
num of updates: 11800
dynamics loss: 43980.00000

============================================================
time elapsed: 0:07:09
train iter: 118
num of updates: 11900
dynamics loss: 43456.30078

============================================================
time elapsed: 0:07:12
train iter: 119
num of updates: 12000
dynamics loss: 42953.32031

============================================================
time elapsed: 0:07:14
train iter: 120
num of updates: 12100
dynamics loss: 42415.58203

============================================================
time elapsed: 0:07:17
train iter: 121
num of updates: 12200
dynamics loss: 41968.35547

============================================================
time elapsed: 0:07:20
train iter: 122
num of updates: 12300
dynamics loss: 41478.16406

============================================================
time elapsed: 0:07:23
train iter: 123
num of updates: 12400
dynamics loss: 41031.38281

============================================================
time elapsed: 0:07:26
train iter: 124
num of updates: 12500
dynamics loss: 40599.48047

============================================================
time elapsed: 0:07:29
train iter: 125
num of updates: 12600
dynamics loss: 40158.08203

============================================================
time elapsed: 0:07:32
train iter: 126
num of updates: 12700
dynamics loss: 39764.58203

============================================================
time elapsed: 0:07:35
train iter: 127
num of updates: 12800
dynamics loss: 39330.79297

============================================================
time elapsed: 0:07:38
train iter: 128
num of updates: 12900
dynamics loss: 38965.26562

============================================================
time elapsed: 0:07:41
train iter: 129
num of updates: 13000
dynamics loss: 38582.39453

============================================================
time elapsed: 0:07:44
train iter: 130
num of updates: 13100
dynamics loss: 38194.28125

============================================================
time elapsed: 0:07:47
train iter: 131
num of updates: 13200
dynamics loss: 37832.65625

============================================================
time elapsed: 0:07:50
train iter: 132
num of updates: 13300
dynamics loss: 37462.44922

============================================================
time elapsed: 0:07:53
train iter: 133
num of updates: 13400
dynamics loss: 37175.41016

============================================================
time elapsed: 0:07:56
train iter: 134
num of updates: 13500
dynamics loss: 36807.52734

============================================================
time elapsed: 0:07:58
train iter: 135
num of updates: 13600
dynamics loss: 36522.64062

============================================================
time elapsed: 0:08:01
train iter: 136
num of updates: 13700
dynamics loss: 36188.62500

============================================================
time elapsed: 0:08:04
train iter: 137
num of updates: 13800
dynamics loss: 35897.57812

============================================================
time elapsed: 0:08:07
train iter: 138
num of updates: 13900
dynamics loss: 35598.47266

============================================================
time elapsed: 0:08:10
train iter: 139
num of updates: 14000
dynamics loss: 35293.45703

============================================================
time elapsed: 0:08:13
train iter: 140
num of updates: 14100
dynamics loss: 35015.68359

============================================================
time elapsed: 0:08:16
train iter: 141
num of updates: 14200
dynamics loss: 34736.56641

============================================================
time elapsed: 0:08:19
train iter: 142
num of updates: 14300
dynamics loss: 34476.95312

============================================================
time elapsed: 0:08:22
train iter: 143
num of updates: 14400
dynamics loss: 34256.24609

============================================================
time elapsed: 0:08:25
train iter: 144
num of updates: 14500
dynamics loss: 33954.35156

============================================================
time elapsed: 0:08:28
train iter: 145
num of updates: 14600
dynamics loss: 33709.69141

============================================================
time elapsed: 0:08:31
train iter: 146
num of updates: 14700
dynamics loss: 33484.66406

============================================================
time elapsed: 0:08:34
train iter: 147
num of updates: 14800
dynamics loss: 33237.59375

============================================================
time elapsed: 0:08:37
train iter: 148
num of updates: 14900
dynamics loss: 33076.78906

============================================================
time elapsed: 0:08:40
train iter: 149
num of updates: 15000
dynamics loss: 32815.01562

============================================================
time elapsed: 0:08:42
train iter: 150
num of updates: 15100
dynamics loss: 32614.15430

============================================================
time elapsed: 0:08:45
train iter: 151
num of updates: 15200
dynamics loss: 32385.53125

============================================================
time elapsed: 0:08:48
train iter: 152
num of updates: 15300
dynamics loss: 32180.21484

============================================================
time elapsed: 0:08:51
train iter: 153
num of updates: 15400
dynamics loss: 31979.71289

============================================================
time elapsed: 0:08:54
train iter: 154
num of updates: 15500
dynamics loss: 31808.22070

============================================================
time elapsed: 0:08:57
train iter: 155
num of updates: 15600
dynamics loss: 31618.23047

============================================================
time elapsed: 0:09:00
train iter: 156
num of updates: 15700
dynamics loss: 31391.02930

============================================================
time elapsed: 0:09:03
train iter: 157
num of updates: 15800
dynamics loss: 31191.46484

============================================================
time elapsed: 0:09:06
train iter: 158
num of updates: 15900
dynamics loss: 31058.90234

============================================================
time elapsed: 0:09:09
train iter: 159
num of updates: 16000
dynamics loss: 30918.37695

============================================================
time elapsed: 0:09:12
train iter: 160
num of updates: 16100
dynamics loss: 30726.52539

============================================================
time elapsed: 0:09:15
train iter: 161
num of updates: 16200
dynamics loss: 30579.67969

============================================================
time elapsed: 0:09:18
train iter: 162
num of updates: 16300
dynamics loss: 30408.05469

============================================================
time elapsed: 0:09:21
train iter: 163
num of updates: 16400
dynamics loss: 30276.06641

============================================================
time elapsed: 0:09:24
train iter: 164
num of updates: 16500
dynamics loss: 30111.67383

============================================================
time elapsed: 0:09:26
train iter: 165
num of updates: 16600
dynamics loss: 29925.82227

============================================================
time elapsed: 0:09:29
train iter: 166
num of updates: 16700
dynamics loss: 29781.97266

============================================================
time elapsed: 0:09:32
train iter: 167
num of updates: 16800
dynamics loss: 29664.33008

============================================================
time elapsed: 0:09:35
train iter: 168
num of updates: 16900
dynamics loss: 29514.89062

============================================================
time elapsed: 0:09:38
train iter: 169
num of updates: 17000
dynamics loss: 29385.94727

============================================================
time elapsed: 0:09:41
train iter: 170
num of updates: 17100
dynamics loss: 29240.84375

============================================================
time elapsed: 0:09:44
train iter: 171
num of updates: 17200
dynamics loss: 29113.04492

============================================================
time elapsed: 0:09:47
train iter: 172
num of updates: 17300
dynamics loss: 29011.03906

============================================================
time elapsed: 0:09:50
train iter: 173
num of updates: 17400
dynamics loss: 28873.77148

============================================================
time elapsed: 0:09:53
train iter: 174
num of updates: 17500
dynamics loss: 28769.51953

============================================================
time elapsed: 0:09:56
train iter: 175
num of updates: 17600
dynamics loss: 28622.52539

============================================================
time elapsed: 0:09:59
train iter: 176
num of updates: 17700
dynamics loss: 28538.83398

============================================================
time elapsed: 0:10:02
train iter: 177
num of updates: 17800
dynamics loss: 28417.37109

============================================================
time elapsed: 0:10:05
train iter: 178
num of updates: 17900
dynamics loss: 28271.77148

============================================================
time elapsed: 0:10:08
train iter: 179
num of updates: 18000
dynamics loss: 28188.71484

============================================================
time elapsed: 0:10:10
train iter: 180
num of updates: 18100
dynamics loss: 28079.80859

============================================================
time elapsed: 0:10:13
train iter: 181
num of updates: 18200
dynamics loss: 27953.37500

============================================================
time elapsed: 0:10:16
train iter: 182
num of updates: 18300
dynamics loss: 27854.01367

============================================================
time elapsed: 0:10:19
train iter: 183
num of updates: 18400
dynamics loss: 27766.76562

============================================================
time elapsed: 0:10:22
train iter: 184
num of updates: 18500
dynamics loss: 27679.82617

============================================================
time elapsed: 0:10:25
train iter: 185
num of updates: 18600
dynamics loss: 27556.11719

============================================================
time elapsed: 0:10:28
train iter: 186
num of updates: 18700
dynamics loss: 27480.66211

============================================================
time elapsed: 0:10:31
train iter: 187
num of updates: 18800
dynamics loss: 27375.38086

============================================================
time elapsed: 0:10:34
train iter: 188
num of updates: 18900
dynamics loss: 27288.46875

============================================================
time elapsed: 0:10:37
train iter: 189
num of updates: 19000
dynamics loss: 27172.75391

============================================================
time elapsed: 0:10:40
train iter: 190
num of updates: 19100
dynamics loss: 27145.56445

============================================================
time elapsed: 0:10:43
train iter: 191
num of updates: 19200
dynamics loss: 27068.94727

============================================================
time elapsed: 0:10:46
train iter: 192
num of updates: 19300
dynamics loss: 26938.32812

============================================================
time elapsed: 0:10:49
train iter: 193
num of updates: 19400
dynamics loss: 26821.31445

============================================================
time elapsed: 0:10:52
train iter: 194
num of updates: 19500
dynamics loss: 26784.50195

============================================================
time elapsed: 0:10:54
train iter: 195
num of updates: 19600
dynamics loss: 26703.78125

============================================================
time elapsed: 0:10:57
train iter: 196
num of updates: 19700
dynamics loss: 26603.61719

============================================================
time elapsed: 0:11:00
train iter: 197
num of updates: 19800
dynamics loss: 26497.17383

============================================================
time elapsed: 0:11:03
train iter: 198
num of updates: 19900
dynamics loss: 26415.29297

============================================================
time elapsed: 0:11:06
train iter: 199
num of updates: 20000
dynamics loss: 26368.60352

============================================================
time elapsed: 0:11:09
train iter: 200
num of updates: 20100
dynamics loss: 26274.94141

============================================================
time elapsed: 0:11:12
train iter: 201
num of updates: 20200
dynamics loss: 26192.90234

============================================================
time elapsed: 0:11:15
train iter: 202
num of updates: 20300
dynamics loss: 26139.51953

============================================================
time elapsed: 0:11:18
train iter: 203
num of updates: 20400
dynamics loss: 26056.11719

============================================================
time elapsed: 0:11:21
train iter: 204
num of updates: 20500
dynamics loss: 26010.10938

============================================================
time elapsed: 0:11:24
train iter: 205
num of updates: 20600
dynamics loss: 25919.27344

============================================================
time elapsed: 0:11:27
train iter: 206
num of updates: 20700
dynamics loss: 25895.53711

============================================================
time elapsed: 0:11:30
train iter: 207
num of updates: 20800
dynamics loss: 25794.42188

============================================================
time elapsed: 0:11:33
train iter: 208
num of updates: 20900
dynamics loss: 25739.41016

============================================================
time elapsed: 0:11:35
train iter: 209
num of updates: 21000
dynamics loss: 25688.00000

============================================================
time elapsed: 0:11:38
train iter: 210
num of updates: 21100
dynamics loss: 25617.58203

============================================================
time elapsed: 0:11:41
train iter: 211
num of updates: 21200
dynamics loss: 25566.75977

============================================================
time elapsed: 0:11:44
train iter: 212
num of updates: 21300
dynamics loss: 25472.79688

============================================================
time elapsed: 0:11:47
train iter: 213
num of updates: 21400
dynamics loss: 25431.31641

============================================================
time elapsed: 0:11:50
train iter: 214
num of updates: 21500
dynamics loss: 25369.47656

============================================================
time elapsed: 0:11:53
train iter: 215
num of updates: 21600
dynamics loss: 25315.05859

============================================================
time elapsed: 0:11:56
train iter: 216
num of updates: 21700
dynamics loss: 25260.99414

============================================================
time elapsed: 0:11:59
train iter: 217
num of updates: 21800
dynamics loss: 25189.02148

============================================================
time elapsed: 0:12:02
train iter: 218
num of updates: 21900
dynamics loss: 25122.24023

============================================================
time elapsed: 0:12:05
train iter: 219
num of updates: 22000
dynamics loss: 25089.79102

============================================================
time elapsed: 0:12:08
train iter: 220
num of updates: 22100
dynamics loss: 24999.10547

============================================================
time elapsed: 0:12:11
train iter: 221
num of updates: 22200
dynamics loss: 25002.03320

============================================================
time elapsed: 0:12:14
train iter: 222
num of updates: 22300
dynamics loss: 24909.43359

============================================================
time elapsed: 0:12:17
train iter: 223
num of updates: 22400
dynamics loss: 24857.49805

============================================================
time elapsed: 0:12:19
train iter: 224
num of updates: 22500
dynamics loss: 24808.34570

============================================================
time elapsed: 0:12:22
train iter: 225
num of updates: 22600
dynamics loss: 24776.75000

============================================================
time elapsed: 0:12:25
train iter: 226
num of updates: 22700
dynamics loss: 24701.68164

============================================================
time elapsed: 0:12:28
train iter: 227
num of updates: 22800
dynamics loss: 24636.81445

============================================================
time elapsed: 0:12:31
train iter: 228
num of updates: 22900
dynamics loss: 24617.15430

============================================================
time elapsed: 0:12:34
train iter: 229
num of updates: 23000
dynamics loss: 24550.19922

============================================================
time elapsed: 0:12:37
train iter: 230
num of updates: 23100
dynamics loss: 24508.20898

============================================================
time elapsed: 0:12:40
train iter: 231
num of updates: 23200
dynamics loss: 24454.66602

============================================================
time elapsed: 0:12:43
train iter: 232
num of updates: 23300
dynamics loss: 24417.15625

============================================================
time elapsed: 0:12:46
train iter: 233
num of updates: 23400
dynamics loss: 24363.07812

============================================================
time elapsed: 0:12:49
train iter: 234
num of updates: 23500
dynamics loss: 24304.85352

============================================================
time elapsed: 0:12:52
train iter: 235
num of updates: 23600
dynamics loss: 24259.66992

============================================================
time elapsed: 0:12:55
train iter: 236
num of updates: 23700
dynamics loss: 24242.56641

============================================================
time elapsed: 0:12:58
train iter: 237
num of updates: 23800
dynamics loss: 24194.17383

============================================================
time elapsed: 0:13:01
train iter: 238
num of updates: 23900
dynamics loss: 24104.42969

============================================================
time elapsed: 0:13:03
train iter: 239
num of updates: 24000
dynamics loss: 24083.91797

============================================================
time elapsed: 0:13:06
train iter: 240
num of updates: 24100
dynamics loss: 24068.14453

============================================================
time elapsed: 0:13:09
train iter: 241
num of updates: 24200
dynamics loss: 24020.71289

============================================================
time elapsed: 0:13:12
train iter: 242
num of updates: 24300
dynamics loss: 23973.09961

============================================================
time elapsed: 0:13:15
train iter: 243
num of updates: 24400
dynamics loss: 23901.71875

============================================================
time elapsed: 0:13:18
train iter: 244
num of updates: 24500
dynamics loss: 23874.85547

============================================================
time elapsed: 0:13:21
train iter: 245
num of updates: 24600
dynamics loss: 23825.95312

============================================================
time elapsed: 0:13:24
train iter: 246
num of updates: 24700
dynamics loss: 23803.61719

============================================================
time elapsed: 0:13:27
train iter: 247
num of updates: 24800
dynamics loss: 23785.12891

============================================================
time elapsed: 0:13:30
train iter: 248
num of updates: 24900
dynamics loss: 23709.68945

============================================================
time elapsed: 0:13:33
train iter: 249
num of updates: 25000
dynamics loss: 23695.56836

============================================================
time elapsed: 0:13:36
train iter: 250
num of updates: 25100
dynamics loss: 23659.11719

============================================================
time elapsed: 0:13:39
train iter: 251
num of updates: 25200
dynamics loss: 23615.79297

============================================================
time elapsed: 0:13:42
train iter: 252
num of updates: 25300
dynamics loss: 23554.22070

============================================================
time elapsed: 0:13:45
train iter: 253
num of updates: 25400
dynamics loss: 23546.65234

============================================================
time elapsed: 0:13:47
train iter: 254
num of updates: 25500
dynamics loss: 23486.09375

============================================================
time elapsed: 0:13:50
train iter: 255
num of updates: 25600
dynamics loss: 23451.17188

============================================================
time elapsed: 0:13:53
train iter: 256
num of updates: 25700
dynamics loss: 23399.31641

============================================================
time elapsed: 0:13:56
train iter: 257
num of updates: 25800
dynamics loss: 23375.81445

============================================================
time elapsed: 0:13:59
train iter: 258
num of updates: 25900
dynamics loss: 23343.35938

============================================================
time elapsed: 0:14:02
train iter: 259
num of updates: 26000
dynamics loss: 23316.31641

============================================================
time elapsed: 0:14:05
train iter: 260
num of updates: 26100
dynamics loss: 23259.99219

============================================================
time elapsed: 0:14:08
train iter: 261
num of updates: 26200
dynamics loss: 23256.08008

============================================================
time elapsed: 0:14:11
train iter: 262
num of updates: 26300
dynamics loss: 23205.98047

============================================================
time elapsed: 0:14:14
train iter: 263
num of updates: 26400
dynamics loss: 23179.07227

============================================================
time elapsed: 0:14:17
train iter: 264
num of updates: 26500
dynamics loss: 23162.22070

============================================================
time elapsed: 0:14:20
train iter: 265
num of updates: 26600
dynamics loss: 23145.14453

============================================================
time elapsed: 0:14:23
train iter: 266
num of updates: 26700
dynamics loss: 23039.02930

============================================================
time elapsed: 0:14:26
train iter: 267
num of updates: 26800
dynamics loss: 23049.27344

============================================================
time elapsed: 0:14:29
train iter: 268
num of updates: 26900
dynamics loss: 23034.75781

============================================================
time elapsed: 0:14:31
train iter: 269
num of updates: 27000
dynamics loss: 22956.87891

============================================================
time elapsed: 0:14:34
train iter: 270
num of updates: 27100
dynamics loss: 22945.32812

============================================================
time elapsed: 0:14:37
train iter: 271
num of updates: 27200
dynamics loss: 22908.03711

============================================================
time elapsed: 0:14:40
train iter: 272
num of updates: 27300
dynamics loss: 22878.73828

============================================================
time elapsed: 0:14:43
train iter: 273
num of updates: 27400
dynamics loss: 22848.42578

============================================================
time elapsed: 0:14:46
train iter: 274
num of updates: 27500
dynamics loss: 22796.54102

============================================================
time elapsed: 0:14:49
train iter: 275
num of updates: 27600
dynamics loss: 22747.74023

============================================================
time elapsed: 0:14:52
train iter: 276
num of updates: 27700
dynamics loss: 22774.99219

============================================================
time elapsed: 0:14:55
train iter: 277
num of updates: 27800
dynamics loss: 22696.52148

============================================================
time elapsed: 0:14:58
train iter: 278
num of updates: 27900
dynamics loss: 22698.34766

============================================================
time elapsed: 0:15:01
train iter: 279
num of updates: 28000
dynamics loss: 22646.63281

============================================================
time elapsed: 0:15:04
train iter: 280
num of updates: 28100
dynamics loss: 22625.27734

============================================================
time elapsed: 0:15:07
train iter: 281
num of updates: 28200
dynamics loss: 22561.25586

============================================================
time elapsed: 0:15:10
train iter: 282
num of updates: 28300
dynamics loss: 22557.11328

============================================================
time elapsed: 0:15:13
train iter: 283
num of updates: 28400
dynamics loss: 22555.12305

============================================================
time elapsed: 0:15:15
train iter: 284
num of updates: 28500
dynamics loss: 22522.14453

============================================================
time elapsed: 0:15:18
train iter: 285
num of updates: 28600
dynamics loss: 22501.03711

============================================================
time elapsed: 0:15:21
train iter: 286
num of updates: 28700
dynamics loss: 22456.47656

============================================================
time elapsed: 0:15:24
train iter: 287
num of updates: 28800
dynamics loss: 22393.20312

============================================================
time elapsed: 0:15:27
train iter: 288
num of updates: 28900
dynamics loss: 22381.46875

============================================================
time elapsed: 0:15:30
train iter: 289
num of updates: 29000
dynamics loss: 22388.80859

============================================================
time elapsed: 0:15:33
train iter: 290
num of updates: 29100
dynamics loss: 22330.23047

============================================================
time elapsed: 0:15:36
train iter: 291
num of updates: 29200
dynamics loss: 22328.72461

============================================================
time elapsed: 0:15:39
train iter: 292
num of updates: 29300
dynamics loss: 22302.14062

============================================================
time elapsed: 0:15:42
train iter: 293
num of updates: 29400
dynamics loss: 22234.87305

============================================================
time elapsed: 0:15:45
train iter: 294
num of updates: 29500
dynamics loss: 22278.68555

============================================================
time elapsed: 0:15:48
train iter: 295
num of updates: 29600
dynamics loss: 22189.27930

============================================================
time elapsed: 0:15:51
train iter: 296
num of updates: 29700
dynamics loss: 22190.64844

============================================================
time elapsed: 0:15:54
train iter: 297
num of updates: 29800
dynamics loss: 22143.65625

============================================================
time elapsed: 0:15:57
train iter: 298
num of updates: 29900
dynamics loss: 22127.92578

============================================================
time elapsed: 0:15:59
train iter: 299
num of updates: 30000
dynamics loss: 22126.31250

============================================================
time elapsed: 0:16:02
train iter: 300
num of updates: 30100
dynamics loss: 22105.04492

============================================================
time elapsed: 0:16:05
train iter: 301
num of updates: 30200
dynamics loss: 22072.47852

============================================================
time elapsed: 0:16:08
train iter: 302
num of updates: 30300
dynamics loss: 22011.95898

============================================================
time elapsed: 0:16:11
train iter: 303
num of updates: 30400
dynamics loss: 21965.75391

============================================================
time elapsed: 0:16:14
train iter: 304
num of updates: 30500
dynamics loss: 21993.22070

============================================================
time elapsed: 0:16:17
train iter: 305
num of updates: 30600
dynamics loss: 21949.81250

============================================================
time elapsed: 0:16:20
train iter: 306
num of updates: 30700
dynamics loss: 21934.46289

============================================================
time elapsed: 0:16:23
train iter: 307
num of updates: 30800
dynamics loss: 21906.00977

============================================================
time elapsed: 0:16:26
train iter: 308
num of updates: 30900
dynamics loss: 21873.34180

============================================================
time elapsed: 0:16:29
train iter: 309
num of updates: 31000
dynamics loss: 21832.92969

============================================================
time elapsed: 0:16:32
train iter: 310
num of updates: 31100
dynamics loss: 21835.78125

============================================================
time elapsed: 0:16:35
train iter: 311
num of updates: 31200
dynamics loss: 21810.69531

============================================================
time elapsed: 0:16:38
train iter: 312
num of updates: 31300
dynamics loss: 21763.87695

============================================================
time elapsed: 0:16:40
train iter: 313
num of updates: 31400
dynamics loss: 21755.06836

============================================================
time elapsed: 0:16:43
train iter: 314
num of updates: 31500
dynamics loss: 21710.43555

============================================================
time elapsed: 0:16:46
train iter: 315
num of updates: 31600
dynamics loss: 21706.84375

============================================================
time elapsed: 0:16:49
train iter: 316
num of updates: 31700
dynamics loss: 21678.93359

============================================================
time elapsed: 0:16:52
train iter: 317
num of updates: 31800
dynamics loss: 21650.34961

============================================================
time elapsed: 0:16:55
train iter: 318
num of updates: 31900
dynamics loss: 21658.20508

============================================================
time elapsed: 0:16:58
train iter: 319
num of updates: 32000
dynamics loss: 21585.17578

============================================================
time elapsed: 0:17:01
train iter: 320
num of updates: 32100
dynamics loss: 21624.88086

============================================================
time elapsed: 0:17:04
train iter: 321
num of updates: 32200
dynamics loss: 21568.30078

============================================================
time elapsed: 0:17:07
train iter: 322
num of updates: 32300
dynamics loss: 21553.13672

============================================================
time elapsed: 0:17:10
train iter: 323
num of updates: 32400
dynamics loss: 21519.06445

============================================================
time elapsed: 0:17:13
train iter: 324
num of updates: 32500
dynamics loss: 21514.67383

============================================================
time elapsed: 0:17:16
train iter: 325
num of updates: 32600
dynamics loss: 21489.84180

============================================================
time elapsed: 0:17:19
train iter: 326
num of updates: 32700
dynamics loss: 21436.20898

============================================================
time elapsed: 0:17:22
train iter: 327
num of updates: 32800
dynamics loss: 21427.23242

============================================================
time elapsed: 0:17:24
train iter: 328
num of updates: 32900
dynamics loss: 21412.60938

============================================================
time elapsed: 0:17:27
train iter: 329
num of updates: 33000
dynamics loss: 21370.38867

============================================================
time elapsed: 0:17:30
train iter: 330
num of updates: 33100
dynamics loss: 21357.44727

============================================================
time elapsed: 0:17:33
train iter: 331
num of updates: 33200
dynamics loss: 21352.85742

============================================================
time elapsed: 0:17:36
train iter: 332
num of updates: 33300
dynamics loss: 21311.65820

============================================================
time elapsed: 0:17:39
train iter: 333
num of updates: 33400
dynamics loss: 21314.17773

============================================================
time elapsed: 0:17:42
train iter: 334
num of updates: 33500
dynamics loss: 21284.98633

============================================================
time elapsed: 0:17:45
train iter: 335
num of updates: 33600
dynamics loss: 21249.65820

============================================================
time elapsed: 0:17:48
train iter: 336
num of updates: 33700
dynamics loss: 21226.71680

============================================================
time elapsed: 0:17:51
train iter: 337
num of updates: 33800
dynamics loss: 21223.45312

============================================================
time elapsed: 0:17:54
train iter: 338
num of updates: 33900
dynamics loss: 21202.51367

============================================================
time elapsed: 0:17:57
train iter: 339
num of updates: 34000
dynamics loss: 21203.81836

============================================================
time elapsed: 0:18:00
train iter: 340
num of updates: 34100
dynamics loss: 21135.90039

============================================================
time elapsed: 0:18:03
train iter: 341
num of updates: 34200
dynamics loss: 21132.67383

============================================================
time elapsed: 0:18:06
train iter: 342
num of updates: 34300
dynamics loss: 21138.65234

============================================================
time elapsed: 0:18:08
train iter: 343
num of updates: 34400
dynamics loss: 21087.81445

============================================================
time elapsed: 0:18:11
train iter: 344
num of updates: 34500
dynamics loss: 21082.61523

============================================================
time elapsed: 0:18:14
train iter: 345
num of updates: 34600
dynamics loss: 21043.59570

============================================================
time elapsed: 0:18:17
train iter: 346
num of updates: 34700
dynamics loss: 21023.80078

============================================================
time elapsed: 0:18:20
train iter: 347
num of updates: 34800
dynamics loss: 21027.04883

============================================================
time elapsed: 0:18:23
train iter: 348
num of updates: 34900
dynamics loss: 20991.32422

============================================================
time elapsed: 0:18:26
train iter: 349
num of updates: 35000
dynamics loss: 20983.32227

============================================================
time elapsed: 0:18:29
train iter: 350
num of updates: 35100
dynamics loss: 20932.83984

============================================================
time elapsed: 0:18:32
train iter: 351
num of updates: 35200
dynamics loss: 20929.24414

============================================================
time elapsed: 0:18:35
train iter: 352
num of updates: 35300
dynamics loss: 20920.65625

============================================================
time elapsed: 0:18:38
train iter: 353
num of updates: 35400
dynamics loss: 20905.52734

============================================================
time elapsed: 0:18:41
train iter: 354
num of updates: 35500
dynamics loss: 20862.33789

============================================================
time elapsed: 0:18:44
train iter: 355
num of updates: 35600
dynamics loss: 20874.27344

============================================================
time elapsed: 0:18:47
train iter: 356
num of updates: 35700
dynamics loss: 20830.85352

============================================================
time elapsed: 0:18:50
train iter: 357
num of updates: 35800
dynamics loss: 20837.50977

============================================================
time elapsed: 0:18:52
train iter: 358
num of updates: 35900
dynamics loss: 20752.03906

============================================================
time elapsed: 0:18:55
train iter: 359
num of updates: 36000
dynamics loss: 20777.86523

============================================================
time elapsed: 0:18:58
train iter: 360
num of updates: 36100
dynamics loss: 20760.60156

============================================================
time elapsed: 0:19:01
train iter: 361
num of updates: 36200
dynamics loss: 20713.19531

============================================================
time elapsed: 0:19:04
train iter: 362
num of updates: 36300
dynamics loss: 20695.95508

============================================================
time elapsed: 0:19:07
train iter: 363
num of updates: 36400
dynamics loss: 20703.93359

============================================================
time elapsed: 0:19:10
train iter: 364
num of updates: 36500
dynamics loss: 20665.60742

============================================================
time elapsed: 0:19:13
train iter: 365
num of updates: 36600
dynamics loss: 20654.80469

============================================================
time elapsed: 0:19:16
train iter: 366
num of updates: 36700
dynamics loss: 20650.96094

============================================================
time elapsed: 0:19:19
train iter: 367
num of updates: 36800
dynamics loss: 20627.29492

============================================================
time elapsed: 0:19:22
train iter: 368
num of updates: 36900
dynamics loss: 20570.44727

============================================================
time elapsed: 0:19:25
train iter: 369
num of updates: 37000
dynamics loss: 20577.93359

============================================================
time elapsed: 0:19:28
train iter: 370
num of updates: 37100
dynamics loss: 20530.61328

============================================================
time elapsed: 0:19:31
train iter: 371
num of updates: 37200
dynamics loss: 20537.25781

============================================================
time elapsed: 0:19:34
train iter: 372
num of updates: 37300
dynamics loss: 20529.91406

============================================================
time elapsed: 0:19:36
train iter: 373
num of updates: 37400
dynamics loss: 20505.14844

============================================================
time elapsed: 0:19:39
train iter: 374
num of updates: 37500
dynamics loss: 20491.42578

============================================================
time elapsed: 0:19:42
train iter: 375
num of updates: 37600
dynamics loss: 20460.69922

============================================================
time elapsed: 0:19:45
train iter: 376
num of updates: 37700
dynamics loss: 20461.07031

============================================================
time elapsed: 0:19:48
train iter: 377
num of updates: 37800
dynamics loss: 20465.53125

============================================================
time elapsed: 0:19:51
train iter: 378
num of updates: 37900
dynamics loss: 20413.47070

============================================================
time elapsed: 0:19:54
train iter: 379
num of updates: 38000
dynamics loss: 20408.31836

============================================================
time elapsed: 0:19:57
train iter: 380
num of updates: 38100
dynamics loss: 20361.66016

============================================================
time elapsed: 0:20:00
train iter: 381
num of updates: 38200
dynamics loss: 20358.09961

============================================================
time elapsed: 0:20:03
train iter: 382
num of updates: 38300
dynamics loss: 20379.27148

============================================================
time elapsed: 0:20:06
train iter: 383
num of updates: 38400
dynamics loss: 20305.32422

============================================================
time elapsed: 0:20:09
train iter: 384
num of updates: 38500
dynamics loss: 20319.66016

============================================================
time elapsed: 0:20:12
train iter: 385
num of updates: 38600
dynamics loss: 20281.43945

============================================================
time elapsed: 0:20:15
train iter: 386
num of updates: 38700
dynamics loss: 20260.92188

============================================================
time elapsed: 0:20:18
train iter: 387
num of updates: 38800
dynamics loss: 20244.15430

============================================================
time elapsed: 0:20:20
train iter: 388
num of updates: 38900
dynamics loss: 20231.42969

============================================================
time elapsed: 0:20:23
train iter: 389
num of updates: 39000
dynamics loss: 20216.45117

============================================================
time elapsed: 0:20:26
train iter: 390
num of updates: 39100
dynamics loss: 20192.79688

============================================================
time elapsed: 0:20:29
train iter: 391
num of updates: 39200
dynamics loss: 20184.64453

============================================================
time elapsed: 0:20:32
train iter: 392
num of updates: 39300
dynamics loss: 20160.21680

============================================================
time elapsed: 0:20:35
train iter: 393
num of updates: 39400
dynamics loss: 20141.29492

============================================================
time elapsed: 0:20:38
train iter: 394
num of updates: 39500
dynamics loss: 20143.34375

============================================================
time elapsed: 0:20:41
train iter: 395
num of updates: 39600
dynamics loss: 20123.06250

============================================================
time elapsed: 0:20:44
train iter: 396
num of updates: 39700
dynamics loss: 20083.43750

============================================================
time elapsed: 0:20:47
train iter: 397
num of updates: 39800
dynamics loss: 20076.27734

============================================================
time elapsed: 0:20:50
train iter: 398
num of updates: 39900
dynamics loss: 20034.91211

============================================================
time elapsed: 0:20:53
train iter: 399
num of updates: 40000
dynamics loss: 20040.58984

============================================================
time elapsed: 0:20:56
train iter: 400
num of updates: 40100
dynamics loss: 20017.47266

============================================================
time elapsed: 0:20:59
train iter: 401
num of updates: 40200
dynamics loss: 20007.74609

============================================================
time elapsed: 0:21:02
train iter: 402
num of updates: 40300
dynamics loss: 20002.33203

============================================================
time elapsed: 0:21:04
train iter: 403
num of updates: 40400
dynamics loss: 20003.82422

============================================================
time elapsed: 0:21:07
train iter: 404
num of updates: 40500
dynamics loss: 19963.82617

============================================================
time elapsed: 0:21:10
train iter: 405
num of updates: 40600
dynamics loss: 19955.19336

============================================================
time elapsed: 0:21:13
train iter: 406
num of updates: 40700
dynamics loss: 19925.06445

============================================================
time elapsed: 0:21:16
train iter: 407
num of updates: 40800
dynamics loss: 19918.66406

============================================================
time elapsed: 0:21:19
train iter: 408
num of updates: 40900
dynamics loss: 19905.13281

============================================================
time elapsed: 0:21:22
train iter: 409
num of updates: 41000
dynamics loss: 19883.25000

============================================================
time elapsed: 0:21:25
train iter: 410
num of updates: 41100
dynamics loss: 19869.99023

============================================================
time elapsed: 0:21:28
train iter: 411
num of updates: 41200
dynamics loss: 19864.14258

============================================================
time elapsed: 0:21:31
train iter: 412
num of updates: 41300
dynamics loss: 19800.03711

============================================================
time elapsed: 0:21:34
train iter: 413
num of updates: 41400
dynamics loss: 19809.83398

============================================================
time elapsed: 0:21:37
train iter: 414
num of updates: 41500
dynamics loss: 19790.78906

============================================================
time elapsed: 0:21:40
train iter: 415
num of updates: 41600
dynamics loss: 19762.63281

============================================================
time elapsed: 0:21:43
train iter: 416
num of updates: 41700
dynamics loss: 19729.67383

============================================================
time elapsed: 0:21:46
train iter: 417
num of updates: 41800
dynamics loss: 19740.84961

============================================================
time elapsed: 0:21:48
train iter: 418
num of updates: 41900
dynamics loss: 19711.50977

============================================================
time elapsed: 0:21:51
train iter: 419
num of updates: 42000
dynamics loss: 19721.54688

============================================================
time elapsed: 0:21:54
train iter: 420
num of updates: 42100
dynamics loss: 19687.34180

============================================================
time elapsed: 0:21:57
train iter: 421
num of updates: 42200
dynamics loss: 19692.82031

============================================================
time elapsed: 0:22:00
train iter: 422
num of updates: 42300
dynamics loss: 19626.79297

============================================================
time elapsed: 0:22:03
train iter: 423
num of updates: 42400
dynamics loss: 19645.75391

============================================================
time elapsed: 0:22:06
train iter: 424
num of updates: 42500
dynamics loss: 19611.64453

============================================================
time elapsed: 0:22:09
train iter: 425
num of updates: 42600
dynamics loss: 19631.16016

============================================================
time elapsed: 0:22:12
train iter: 426
num of updates: 42700
dynamics loss: 19591.60352

============================================================
time elapsed: 0:22:15
train iter: 427
num of updates: 42800
dynamics loss: 19581.19922

============================================================
time elapsed: 0:22:18
train iter: 428
num of updates: 42900
dynamics loss: 19575.38086

============================================================
time elapsed: 0:22:21
train iter: 429
num of updates: 43000
dynamics loss: 19566.42383

============================================================
time elapsed: 0:22:24
train iter: 430
num of updates: 43100
dynamics loss: 19551.06836

============================================================
time elapsed: 0:22:27
train iter: 431
num of updates: 43200
dynamics loss: 19507.53906

============================================================
time elapsed: 0:22:30
train iter: 432
num of updates: 43300
dynamics loss: 19493.71289

============================================================
time elapsed: 0:22:32
train iter: 433
num of updates: 43400
dynamics loss: 19476.36719

============================================================
time elapsed: 0:22:35
train iter: 434
num of updates: 43500
dynamics loss: 19492.48633

============================================================
time elapsed: 0:22:38
train iter: 435
num of updates: 43600
dynamics loss: 19437.90820

============================================================
time elapsed: 0:22:41
train iter: 436
num of updates: 43700
dynamics loss: 19443.96094

============================================================
time elapsed: 0:22:44
train iter: 437
num of updates: 43800
dynamics loss: 19417.30859

============================================================
time elapsed: 0:22:47
train iter: 438
num of updates: 43900
dynamics loss: 19432.84375

============================================================
time elapsed: 0:22:50
train iter: 439
num of updates: 44000
dynamics loss: 19377.58398

============================================================
time elapsed: 0:22:53
train iter: 440
num of updates: 44100
dynamics loss: 19392.38281

============================================================
time elapsed: 0:22:56
train iter: 441
num of updates: 44200
dynamics loss: 19343.40430

============================================================
time elapsed: 0:22:59
train iter: 442
num of updates: 44300
dynamics loss: 19350.96875

============================================================
time elapsed: 0:23:02
train iter: 443
num of updates: 44400
dynamics loss: 19311.37695

============================================================
time elapsed: 0:23:05
train iter: 444
num of updates: 44500
dynamics loss: 19293.88086

============================================================
time elapsed: 0:23:08
train iter: 445
num of updates: 44600
dynamics loss: 19280.29492

============================================================
time elapsed: 0:23:11
train iter: 446
num of updates: 44700
dynamics loss: 19295.55664

============================================================
time elapsed: 0:23:13
train iter: 447
num of updates: 44800
dynamics loss: 19258.81445

============================================================
time elapsed: 0:23:16
train iter: 448
num of updates: 44900
dynamics loss: 19260.54883

============================================================
time elapsed: 0:23:19
train iter: 449
num of updates: 45000
dynamics loss: 19243.53711

============================================================
time elapsed: 0:23:22
train iter: 450
num of updates: 45100
dynamics loss: 19204.33398

============================================================
time elapsed: 0:23:25
train iter: 451
num of updates: 45200
dynamics loss: 19216.50000

============================================================
time elapsed: 0:23:28
train iter: 452
num of updates: 45300
dynamics loss: 19216.37109

============================================================
time elapsed: 0:23:31
train iter: 453
num of updates: 45400
dynamics loss: 19193.18164

============================================================
time elapsed: 0:23:34
train iter: 454
num of updates: 45500
dynamics loss: 19168.62695

============================================================
time elapsed: 0:23:37
train iter: 455
num of updates: 45600
dynamics loss: 19142.13477

============================================================
time elapsed: 0:23:40
train iter: 456
num of updates: 45700
dynamics loss: 19139.39648

============================================================
time elapsed: 0:23:43
train iter: 457
num of updates: 45800
dynamics loss: 19119.57031

============================================================
time elapsed: 0:23:46
train iter: 458
num of updates: 45900
dynamics loss: 19096.41602

============================================================
time elapsed: 0:23:49
train iter: 459
num of updates: 46000
dynamics loss: 19066.45898

============================================================
time elapsed: 0:23:52
train iter: 460
num of updates: 46100
dynamics loss: 19050.80859

============================================================
time elapsed: 0:23:55
train iter: 461
num of updates: 46200
dynamics loss: 19065.68359

============================================================
time elapsed: 0:23:57
train iter: 462
num of updates: 46300
dynamics loss: 19045.15625

============================================================
time elapsed: 0:24:00
train iter: 463
num of updates: 46400
dynamics loss: 19045.54102

============================================================
time elapsed: 0:24:03
train iter: 464
num of updates: 46500
dynamics loss: 18992.48633

============================================================
time elapsed: 0:24:06
train iter: 465
num of updates: 46600
dynamics loss: 18984.33203

============================================================
time elapsed: 0:24:09
train iter: 466
num of updates: 46700
dynamics loss: 19001.91211

============================================================
time elapsed: 0:24:12
train iter: 467
num of updates: 46800
dynamics loss: 18944.32812

============================================================
time elapsed: 0:24:15
train iter: 468
num of updates: 46900
dynamics loss: 18933.62500

============================================================
time elapsed: 0:24:18
train iter: 469
num of updates: 47000
dynamics loss: 18939.70312

============================================================
time elapsed: 0:24:21
train iter: 470
num of updates: 47100
dynamics loss: 18938.95703

============================================================
time elapsed: 0:24:24
train iter: 471
num of updates: 47200
dynamics loss: 18919.20898

============================================================
time elapsed: 0:24:27
train iter: 472
num of updates: 47300
dynamics loss: 18891.15234

============================================================
time elapsed: 0:24:30
train iter: 473
num of updates: 47400
dynamics loss: 18900.46094

============================================================
time elapsed: 0:24:33
train iter: 474
num of updates: 47500
dynamics loss: 18868.46094

============================================================
time elapsed: 0:24:36
train iter: 475
num of updates: 47600
dynamics loss: 18825.69141

============================================================
time elapsed: 0:24:39
train iter: 476
num of updates: 47700
dynamics loss: 18836.74414

============================================================
time elapsed: 0:24:41
train iter: 477
num of updates: 47800
dynamics loss: 18845.08008

============================================================
time elapsed: 0:24:44
train iter: 478
num of updates: 47900
dynamics loss: 18793.84961

============================================================
time elapsed: 0:24:47
train iter: 479
num of updates: 48000
dynamics loss: 18772.54492

============================================================
time elapsed: 0:24:50
train iter: 480
num of updates: 48100
dynamics loss: 18756.19336

============================================================
time elapsed: 0:24:53
train iter: 481
num of updates: 48200
dynamics loss: 18760.50586

============================================================
time elapsed: 0:24:56
train iter: 482
num of updates: 48300
dynamics loss: 18755.46875

============================================================
time elapsed: 0:24:59
train iter: 483
num of updates: 48400
dynamics loss: 18736.26172

============================================================
time elapsed: 0:25:02
train iter: 484
num of updates: 48500
dynamics loss: 18711.72461

============================================================
time elapsed: 0:25:05
train iter: 485
num of updates: 48600
dynamics loss: 18704.79883

============================================================
time elapsed: 0:25:08
train iter: 486
num of updates: 48700
dynamics loss: 18688.90234

============================================================
time elapsed: 0:25:11
train iter: 487
num of updates: 48800
dynamics loss: 18683.12695

============================================================
time elapsed: 0:25:14
train iter: 488
num of updates: 48900
dynamics loss: 18642.33594

============================================================
time elapsed: 0:25:17
train iter: 489
num of updates: 49000
dynamics loss: 18643.98438

============================================================
time elapsed: 0:25:20
train iter: 490
num of updates: 49100
dynamics loss: 18631.15234

============================================================
time elapsed: 0:25:23
train iter: 491
num of updates: 49200
dynamics loss: 18621.89844

============================================================
time elapsed: 0:25:25
train iter: 492
num of updates: 49300
dynamics loss: 18603.58398

============================================================
time elapsed: 0:25:28
train iter: 493
num of updates: 49400
dynamics loss: 18591.59375

============================================================
time elapsed: 0:25:31
train iter: 494
num of updates: 49500
dynamics loss: 18552.79102

============================================================
time elapsed: 0:25:34
train iter: 495
num of updates: 49600
dynamics loss: 18577.30859

============================================================
time elapsed: 0:25:37
train iter: 496
num of updates: 49700
dynamics loss: 18542.84180

============================================================
time elapsed: 0:25:40
train iter: 497
num of updates: 49800
dynamics loss: 18539.28906

============================================================
time elapsed: 0:25:43
train iter: 498
num of updates: 49900
dynamics loss: 18513.82812

============================================================
time elapsed: 0:25:46
train iter: 499
num of updates: 50000
dynamics loss: 18503.75391

============================================================
time elapsed: 0:25:49
train iter: 500
num of updates: 50100
dynamics loss: 18468.26758

============================================================
time elapsed: 0:25:52
train iter: 501
num of updates: 50200
dynamics loss: 18484.68555

============================================================
time elapsed: 0:25:55
train iter: 502
num of updates: 50300
dynamics loss: 18443.66602

============================================================
time elapsed: 0:25:58
train iter: 503
num of updates: 50400
dynamics loss: 18431.66406

============================================================
time elapsed: 0:26:01
train iter: 504
num of updates: 50500
dynamics loss: 18418.91992

============================================================
time elapsed: 0:26:04
train iter: 505
num of updates: 50600
dynamics loss: 18433.73242

============================================================
time elapsed: 0:26:07
train iter: 506
num of updates: 50700
dynamics loss: 18398.28125

============================================================
time elapsed: 0:26:09
train iter: 507
num of updates: 50800
dynamics loss: 18387.16211

============================================================
time elapsed: 0:26:12
train iter: 508
num of updates: 50900
dynamics loss: 18375.51758

============================================================
time elapsed: 0:26:15
train iter: 509
num of updates: 51000
dynamics loss: 18355.68164

============================================================
time elapsed: 0:26:18
train iter: 510
num of updates: 51100
dynamics loss: 18366.34570

============================================================
time elapsed: 0:26:21
train iter: 511
num of updates: 51200
dynamics loss: 18331.28516

============================================================
time elapsed: 0:26:24
train iter: 512
num of updates: 51300
dynamics loss: 18314.13672

============================================================
time elapsed: 0:26:27
train iter: 513
num of updates: 51400
dynamics loss: 18314.35547

============================================================
time elapsed: 0:26:30
train iter: 514
num of updates: 51500
dynamics loss: 18289.26172

============================================================
time elapsed: 0:26:33
train iter: 515
num of updates: 51600
dynamics loss: 18278.32812

============================================================
time elapsed: 0:26:36
train iter: 516
num of updates: 51700
dynamics loss: 18252.10547

============================================================
time elapsed: 0:26:39
train iter: 517
num of updates: 51800
dynamics loss: 18262.11719

============================================================
time elapsed: 0:26:42
train iter: 518
num of updates: 51900
dynamics loss: 18234.12500

============================================================
time elapsed: 0:26:45
train iter: 519
num of updates: 52000
dynamics loss: 18206.10547

============================================================
time elapsed: 0:26:48
train iter: 520
num of updates: 52100
dynamics loss: 18211.21680

============================================================
time elapsed: 0:26:51
train iter: 521
num of updates: 52200
dynamics loss: 18190.84570

============================================================
time elapsed: 0:26:53
train iter: 522
num of updates: 52300
dynamics loss: 18170.03711

============================================================
time elapsed: 0:26:56
train iter: 523
num of updates: 52400
dynamics loss: 18156.55664

============================================================
time elapsed: 0:26:59
train iter: 524
num of updates: 52500
dynamics loss: 18125.71289

============================================================
time elapsed: 0:27:02
train iter: 525
num of updates: 52600
dynamics loss: 18155.15234

============================================================
time elapsed: 0:27:05
train iter: 526
num of updates: 52700
dynamics loss: 18134.16992

============================================================
time elapsed: 0:27:08
train iter: 527
num of updates: 52800
dynamics loss: 18088.96094

============================================================
time elapsed: 0:27:11
train iter: 528
num of updates: 52900
dynamics loss: 18088.37305

============================================================
time elapsed: 0:27:14
train iter: 529
num of updates: 53000
dynamics loss: 18095.10352

============================================================
time elapsed: 0:27:17
train iter: 530
num of updates: 53100
dynamics loss: 18083.87305

============================================================
time elapsed: 0:27:20
train iter: 531
num of updates: 53200
dynamics loss: 18055.58203

============================================================
time elapsed: 0:27:23
train iter: 532
num of updates: 53300
dynamics loss: 18015.48047

============================================================
time elapsed: 0:27:26
train iter: 533
num of updates: 53400
dynamics loss: 18033.39258

============================================================
time elapsed: 0:27:29
train iter: 534
num of updates: 53500
dynamics loss: 18005.39648

============================================================
time elapsed: 0:27:32
train iter: 535
num of updates: 53600
dynamics loss: 18001.81055

============================================================
time elapsed: 0:27:35
train iter: 536
num of updates: 53700
dynamics loss: 18005.22852

============================================================
time elapsed: 0:27:37
train iter: 537
num of updates: 53800
dynamics loss: 17971.14844

============================================================
time elapsed: 0:27:40
train iter: 538
num of updates: 53900
dynamics loss: 17971.17969

============================================================
time elapsed: 0:27:43
train iter: 539
num of updates: 54000
dynamics loss: 17946.78516

============================================================
time elapsed: 0:27:46
train iter: 540
num of updates: 54100
dynamics loss: 17915.13281

============================================================
time elapsed: 0:27:49
train iter: 541
num of updates: 54200
dynamics loss: 17921.73828

============================================================
time elapsed: 0:27:52
train iter: 542
num of updates: 54300
dynamics loss: 17885.29297

============================================================
time elapsed: 0:27:55
train iter: 543
num of updates: 54400
dynamics loss: 17865.21289

============================================================
time elapsed: 0:27:58
train iter: 544
num of updates: 54500
dynamics loss: 17863.54102

============================================================
time elapsed: 0:28:01
train iter: 545
num of updates: 54600
dynamics loss: 17856.23242

============================================================
time elapsed: 0:28:04
train iter: 546
num of updates: 54700
dynamics loss: 17821.69727

============================================================
time elapsed: 0:28:07
train iter: 547
num of updates: 54800
dynamics loss: 17834.12109

============================================================
time elapsed: 0:28:10
train iter: 548
num of updates: 54900
dynamics loss: 17848.05078

============================================================
time elapsed: 0:28:13
train iter: 549
num of updates: 55000
dynamics loss: 17785.69141

============================================================
time elapsed: 0:28:16
train iter: 550
num of updates: 55100
dynamics loss: 17781.90430

============================================================
time elapsed: 0:28:19
train iter: 551
num of updates: 55200
dynamics loss: 17811.80078

============================================================
time elapsed: 0:28:21
train iter: 552
num of updates: 55300
dynamics loss: 17766.23633

============================================================
time elapsed: 0:28:24
train iter: 553
num of updates: 55400
dynamics loss: 17744.44922

============================================================
time elapsed: 0:28:27
train iter: 554
num of updates: 55500
dynamics loss: 17728.66797

============================================================
time elapsed: 0:28:30
train iter: 555
num of updates: 55600
dynamics loss: 17721.81641

============================================================
time elapsed: 0:28:33
train iter: 556
num of updates: 55700
dynamics loss: 17699.51367

============================================================
time elapsed: 0:28:36
train iter: 557
num of updates: 55800
dynamics loss: 17695.74414

============================================================
time elapsed: 0:28:39
train iter: 558
num of updates: 55900
dynamics loss: 17660.46484

============================================================
time elapsed: 0:28:42
train iter: 559
num of updates: 56000
dynamics loss: 17660.50391

============================================================
time elapsed: 0:28:45
train iter: 560
num of updates: 56100
dynamics loss: 17672.27930

============================================================
time elapsed: 0:28:48
train iter: 561
num of updates: 56200
dynamics loss: 17627.00391

============================================================
time elapsed: 0:28:51
train iter: 562
num of updates: 56300
dynamics loss: 17615.20898

============================================================
time elapsed: 0:28:54
train iter: 563
num of updates: 56400
dynamics loss: 17615.49609

============================================================
time elapsed: 0:28:57
train iter: 564
num of updates: 56500
dynamics loss: 17581.75000

============================================================
time elapsed: 0:29:00
train iter: 565
num of updates: 56600
dynamics loss: 17576.95703

============================================================
time elapsed: 0:29:03
train iter: 566
num of updates: 56700
dynamics loss: 17583.00391

============================================================
time elapsed: 0:29:05
train iter: 567
num of updates: 56800
dynamics loss: 17559.11523

============================================================
time elapsed: 0:29:08
train iter: 568
num of updates: 56900
dynamics loss: 17550.34961

============================================================
time elapsed: 0:29:11
train iter: 569
num of updates: 57000
dynamics loss: 17525.13281

============================================================
time elapsed: 0:29:14
train iter: 570
num of updates: 57100
dynamics loss: 17522.92188

============================================================
time elapsed: 0:29:17
train iter: 571
num of updates: 57200
dynamics loss: 17523.37109

============================================================
time elapsed: 0:29:20
train iter: 572
num of updates: 57300
dynamics loss: 17500.53320

============================================================
time elapsed: 0:29:23
train iter: 573
num of updates: 57400
dynamics loss: 17495.28516

============================================================
time elapsed: 0:29:26
train iter: 574
num of updates: 57500
dynamics loss: 17488.00391

============================================================
time elapsed: 0:29:29
train iter: 575
num of updates: 57600
dynamics loss: 17466.60156

============================================================
time elapsed: 0:29:32
train iter: 576
num of updates: 57700
dynamics loss: 17460.02734

============================================================
time elapsed: 0:29:35
train iter: 577
num of updates: 57800
dynamics loss: 17412.68164

============================================================
time elapsed: 0:29:38
train iter: 578
num of updates: 57900
dynamics loss: 17406.15625

============================================================
time elapsed: 0:29:41
train iter: 579
num of updates: 58000
dynamics loss: 17393.06055

============================================================
time elapsed: 0:29:44
train iter: 580
num of updates: 58100
dynamics loss: 17379.21289

============================================================
time elapsed: 0:29:47
train iter: 581
num of updates: 58200
dynamics loss: 17373.79297

============================================================
time elapsed: 0:29:49
train iter: 582
num of updates: 58300
dynamics loss: 17359.72461

============================================================
time elapsed: 0:29:52
train iter: 583
num of updates: 58400
dynamics loss: 17341.32812

============================================================
time elapsed: 0:29:55
train iter: 584
num of updates: 58500
dynamics loss: 17324.93359

============================================================
time elapsed: 0:29:58
train iter: 585
num of updates: 58600
dynamics loss: 17344.66016

============================================================
time elapsed: 0:30:01
train iter: 586
num of updates: 58700
dynamics loss: 17283.78516

============================================================
time elapsed: 0:30:04
train iter: 587
num of updates: 58800
dynamics loss: 17287.82617

============================================================
time elapsed: 0:30:07
train iter: 588
num of updates: 58900
dynamics loss: 17271.02344

============================================================
time elapsed: 0:30:10
train iter: 589
num of updates: 59000
dynamics loss: 17261.96875

============================================================
time elapsed: 0:30:13
train iter: 590
num of updates: 59100
dynamics loss: 17243.18750

============================================================
time elapsed: 0:30:16
train iter: 591
num of updates: 59200
dynamics loss: 17238.56055

============================================================
time elapsed: 0:30:19
train iter: 592
num of updates: 59300
dynamics loss: 17225.20508

============================================================
time elapsed: 0:30:22
train iter: 593
num of updates: 59400
dynamics loss: 17191.63867

============================================================
time elapsed: 0:30:25
train iter: 594
num of updates: 59500
dynamics loss: 17198.42773

============================================================
time elapsed: 0:30:28
train iter: 595
num of updates: 59600
dynamics loss: 17195.72070

============================================================
time elapsed: 0:30:31
train iter: 596
num of updates: 59700
dynamics loss: 17156.33984

============================================================
time elapsed: 0:30:33
train iter: 597
num of updates: 59800
dynamics loss: 17171.83789

============================================================
time elapsed: 0:30:36
train iter: 598
num of updates: 59900
dynamics loss: 17146.16602

============================================================
time elapsed: 0:30:39
train iter: 599
num of updates: 60000
dynamics loss: 17113.67188

============================================================
time elapsed: 0:30:42
train iter: 600
num of updates: 60100
dynamics loss: 17104.24219

============================================================
time elapsed: 0:30:45
train iter: 601
num of updates: 60200
dynamics loss: 17099.04688

============================================================
time elapsed: 0:30:48
train iter: 602
num of updates: 60300
dynamics loss: 17079.37305

============================================================
time elapsed: 0:30:51
train iter: 603
num of updates: 60400
dynamics loss: 17096.52734

============================================================
time elapsed: 0:30:54
train iter: 604
num of updates: 60500
dynamics loss: 17060.31445

============================================================
time elapsed: 0:30:57
train iter: 605
num of updates: 60600
dynamics loss: 17048.31250

============================================================
time elapsed: 0:31:00
train iter: 606
num of updates: 60700
dynamics loss: 17034.92969

============================================================
time elapsed: 0:31:03
train iter: 607
num of updates: 60800
dynamics loss: 17021.89844

============================================================
time elapsed: 0:31:06
train iter: 608
num of updates: 60900
dynamics loss: 17024.00391

============================================================
time elapsed: 0:31:09
train iter: 609
num of updates: 61000
dynamics loss: 17003.90430

============================================================
time elapsed: 0:31:12
train iter: 610
num of updates: 61100
dynamics loss: 16985.58203

============================================================
time elapsed: 0:31:15
train iter: 611
num of updates: 61200
dynamics loss: 16966.50977

============================================================
time elapsed: 0:31:17
train iter: 612
num of updates: 61300
dynamics loss: 16954.98438

============================================================
time elapsed: 0:31:20
train iter: 613
num of updates: 61400
dynamics loss: 16941.10156

============================================================
time elapsed: 0:31:23
train iter: 614
num of updates: 61500
dynamics loss: 16940.95703

============================================================
time elapsed: 0:31:26
train iter: 615
num of updates: 61600
dynamics loss: 16922.54102

============================================================
time elapsed: 0:31:29
train iter: 616
num of updates: 61700
dynamics loss: 16910.85547

============================================================
time elapsed: 0:31:32
train iter: 617
num of updates: 61800
dynamics loss: 16906.61328

============================================================
time elapsed: 0:31:35
train iter: 618
num of updates: 61900
dynamics loss: 16864.79492

============================================================
time elapsed: 0:31:38
train iter: 619
num of updates: 62000
dynamics loss: 16857.81055

============================================================
time elapsed: 0:31:41
train iter: 620
num of updates: 62100
dynamics loss: 16852.30859

============================================================
time elapsed: 0:31:44
train iter: 621
num of updates: 62200
dynamics loss: 16822.46094

============================================================
time elapsed: 0:31:47
train iter: 622
num of updates: 62300
dynamics loss: 16798.06641

============================================================
time elapsed: 0:31:50
train iter: 623
num of updates: 62400
dynamics loss: 16820.89648

============================================================
time elapsed: 0:31:53
train iter: 624
num of updates: 62500
dynamics loss: 16802.58398

============================================================
time elapsed: 0:31:56
train iter: 625
num of updates: 62600
dynamics loss: 16781.60352

============================================================
time elapsed: 0:31:59
train iter: 626
num of updates: 62700
dynamics loss: 16769.85742

============================================================
time elapsed: 0:32:01
train iter: 627
num of updates: 62800
dynamics loss: 16757.00391

============================================================
time elapsed: 0:32:04
train iter: 628
num of updates: 62900
dynamics loss: 16752.99219

============================================================
time elapsed: 0:32:07
train iter: 629
num of updates: 63000
dynamics loss: 16731.29297

============================================================
time elapsed: 0:32:10
train iter: 630
num of updates: 63100
dynamics loss: 16725.93945

============================================================
time elapsed: 0:32:13
train iter: 631
num of updates: 63200
dynamics loss: 16702.04102

============================================================
time elapsed: 0:32:16
train iter: 632
num of updates: 63300
dynamics loss: 16704.17969

============================================================
time elapsed: 0:32:19
train iter: 633
num of updates: 63400
dynamics loss: 16675.48047

============================================================
time elapsed: 0:32:22
train iter: 634
num of updates: 63500
dynamics loss: 16648.74414

============================================================
time elapsed: 0:32:25
train iter: 635
num of updates: 63600
dynamics loss: 16642.23242

============================================================
time elapsed: 0:32:28
train iter: 636
num of updates: 63700
dynamics loss: 16612.76953

============================================================
time elapsed: 0:32:31
train iter: 637
num of updates: 63800
dynamics loss: 16618.66602

============================================================
time elapsed: 0:32:34
train iter: 638
num of updates: 63900
dynamics loss: 16604.87500

============================================================
time elapsed: 0:32:37
train iter: 639
num of updates: 64000
dynamics loss: 16596.26758

============================================================
time elapsed: 0:32:40
train iter: 640
num of updates: 64100
dynamics loss: 16582.12305

============================================================
time elapsed: 0:32:43
train iter: 641
num of updates: 64200
dynamics loss: 16561.20312

============================================================
time elapsed: 0:32:45
train iter: 642
num of updates: 64300
dynamics loss: 16572.75586

============================================================
time elapsed: 0:32:48
train iter: 643
num of updates: 64400
dynamics loss: 16539.46289

============================================================
time elapsed: 0:32:51
train iter: 644
num of updates: 64500
dynamics loss: 16545.37695

============================================================
time elapsed: 0:32:54
train iter: 645
num of updates: 64600
dynamics loss: 16536.33984

============================================================
time elapsed: 0:32:57
train iter: 646
num of updates: 64700
dynamics loss: 16514.70117

============================================================
time elapsed: 0:33:00
train iter: 647
num of updates: 64800
dynamics loss: 16515.53125

============================================================
time elapsed: 0:33:03
train iter: 648
num of updates: 64900
dynamics loss: 16485.73242

============================================================
time elapsed: 0:33:06
train iter: 649
num of updates: 65000
dynamics loss: 16480.59961

============================================================
time elapsed: 0:33:09
train iter: 650
num of updates: 65100
dynamics loss: 16427.55664

============================================================
time elapsed: 0:33:12
train iter: 651
num of updates: 65200
dynamics loss: 16464.02539

============================================================
time elapsed: 0:33:15
train iter: 652
num of updates: 65300
dynamics loss: 16427.65039

============================================================
time elapsed: 0:33:18
train iter: 653
num of updates: 65400
dynamics loss: 16431.34961

============================================================
time elapsed: 0:33:21
train iter: 654
num of updates: 65500
dynamics loss: 16412.60547

============================================================
time elapsed: 0:33:24
train iter: 655
num of updates: 65600
dynamics loss: 16366.65039

============================================================
time elapsed: 0:33:26
train iter: 656
num of updates: 65700
dynamics loss: 16379.60352

============================================================
time elapsed: 0:33:29
train iter: 657
num of updates: 65800
dynamics loss: 16373.20215

============================================================
time elapsed: 0:33:32
train iter: 658
num of updates: 65900
dynamics loss: 16350.06055

============================================================
time elapsed: 0:33:35
train iter: 659
num of updates: 66000
dynamics loss: 16327.79004

============================================================
time elapsed: 0:33:38
train iter: 660
num of updates: 66100
dynamics loss: 16334.90820

============================================================
time elapsed: 0:33:41
train iter: 661
num of updates: 66200
dynamics loss: 16316.65332

============================================================
time elapsed: 0:33:44
train iter: 662
num of updates: 66300
dynamics loss: 16312.15430

============================================================
time elapsed: 0:33:47
train iter: 663
num of updates: 66400
dynamics loss: 16283.03320

============================================================
time elapsed: 0:33:50
train iter: 664
num of updates: 66500
dynamics loss: 16259.91406

============================================================
time elapsed: 0:33:53
train iter: 665
num of updates: 66600
dynamics loss: 16254.24316

============================================================
time elapsed: 0:33:56
train iter: 666
num of updates: 66700
dynamics loss: 16239.40918

============================================================
time elapsed: 0:33:59
train iter: 667
num of updates: 66800
dynamics loss: 16240.59473

============================================================
time elapsed: 0:34:02
train iter: 668
num of updates: 66900
dynamics loss: 16224.67871

============================================================
time elapsed: 0:34:05
train iter: 669
num of updates: 67000
dynamics loss: 16210.21289

============================================================
time elapsed: 0:34:08
train iter: 670
num of updates: 67100
dynamics loss: 16203.80078

============================================================
time elapsed: 0:34:11
train iter: 671
num of updates: 67200
dynamics loss: 16168.65039

============================================================
time elapsed: 0:34:13
train iter: 672
num of updates: 67300
dynamics loss: 16181.75879

============================================================
time elapsed: 0:34:16
train iter: 673
num of updates: 67400
dynamics loss: 16151.63477

============================================================
time elapsed: 0:34:19
train iter: 674
num of updates: 67500
dynamics loss: 16130.68945

============================================================
time elapsed: 0:34:22
train iter: 675
num of updates: 67600
dynamics loss: 16105.53320

============================================================
time elapsed: 0:34:25
train iter: 676
num of updates: 67700
dynamics loss: 16113.88477

============================================================
time elapsed: 0:34:28
train iter: 677
num of updates: 67800
dynamics loss: 16111.65234

============================================================
time elapsed: 0:34:31
train iter: 678
num of updates: 67900
dynamics loss: 16065.56250

============================================================
time elapsed: 0:34:34
train iter: 679
num of updates: 68000
dynamics loss: 16077.81055

============================================================
time elapsed: 0:34:37
train iter: 680
num of updates: 68100
dynamics loss: 16061.44434

============================================================
time elapsed: 0:34:40
train iter: 681
num of updates: 68200
dynamics loss: 16037.63965

============================================================
time elapsed: 0:34:43
train iter: 682
num of updates: 68300
dynamics loss: 16037.49121

============================================================
time elapsed: 0:34:46
train iter: 683
num of updates: 68400
dynamics loss: 16015.97168

============================================================
time elapsed: 0:34:49
train iter: 684
num of updates: 68500
dynamics loss: 16020.82715

============================================================
time elapsed: 0:34:52
train iter: 685
num of updates: 68600
dynamics loss: 15986.30469

============================================================
time elapsed: 0:34:54
train iter: 686
num of updates: 68700
dynamics loss: 15986.13672

============================================================
time elapsed: 0:34:57
train iter: 687
num of updates: 68800
dynamics loss: 15970.61523

============================================================
time elapsed: 0:35:00
train iter: 688
num of updates: 68900
dynamics loss: 15934.95898

============================================================
time elapsed: 0:35:03
train iter: 689
num of updates: 69000
dynamics loss: 15940.91309

============================================================
time elapsed: 0:35:06
train iter: 690
num of updates: 69100
dynamics loss: 15904.57324

============================================================
time elapsed: 0:35:09
train iter: 691
num of updates: 69200
dynamics loss: 15910.08105

============================================================
time elapsed: 0:35:12
train iter: 692
num of updates: 69300
dynamics loss: 15916.02930

============================================================
time elapsed: 0:35:15
train iter: 693
num of updates: 69400
dynamics loss: 15891.93652

============================================================
time elapsed: 0:35:18
train iter: 694
num of updates: 69500
dynamics loss: 15874.61523

============================================================
time elapsed: 0:35:21
train iter: 695
num of updates: 69600
dynamics loss: 15849.26562

============================================================
time elapsed: 0:35:24
train iter: 696
num of updates: 69700
dynamics loss: 15848.17871

============================================================
time elapsed: 0:35:27
train iter: 697
num of updates: 69800
dynamics loss: 15850.43848

============================================================
time elapsed: 0:35:30
train iter: 698
num of updates: 69900
dynamics loss: 15829.56836

============================================================
time elapsed: 0:35:33
train iter: 699
num of updates: 70000
dynamics loss: 15815.77051

============================================================
time elapsed: 0:35:36
train iter: 700
num of updates: 70100
dynamics loss: 15783.48438

============================================================
time elapsed: 0:35:38
train iter: 701
num of updates: 70200
dynamics loss: 15764.14844

============================================================
time elapsed: 0:35:41
train iter: 702
num of updates: 70300
dynamics loss: 15769.04980

============================================================
time elapsed: 0:35:44
train iter: 703
num of updates: 70400
dynamics loss: 15747.32129

============================================================
time elapsed: 0:35:47
train iter: 704
num of updates: 70500
dynamics loss: 15737.49609

============================================================
time elapsed: 0:35:50
train iter: 705
num of updates: 70600
dynamics loss: 15728.98438

============================================================
time elapsed: 0:35:53
train iter: 706
num of updates: 70700
dynamics loss: 15701.70605

============================================================
time elapsed: 0:35:56
train iter: 707
num of updates: 70800
dynamics loss: 15711.04297

============================================================
time elapsed: 0:35:59
train iter: 708
num of updates: 70900
dynamics loss: 15700.27441

============================================================
time elapsed: 0:36:02
train iter: 709
num of updates: 71000
dynamics loss: 15679.68262

============================================================
time elapsed: 0:36:05
train iter: 710
num of updates: 71100
dynamics loss: 15671.28320

============================================================
time elapsed: 0:36:08
train iter: 711
num of updates: 71200
dynamics loss: 15668.50293

============================================================
time elapsed: 0:36:11
train iter: 712
num of updates: 71300
dynamics loss: 15657.63086

============================================================
time elapsed: 0:36:14
train iter: 713
num of updates: 71400
dynamics loss: 15606.29492

============================================================
time elapsed: 0:36:17
train iter: 714
num of updates: 71500
dynamics loss: 15625.85352

============================================================
time elapsed: 0:36:20
train iter: 715
num of updates: 71600
dynamics loss: 15609.19629

============================================================
time elapsed: 0:36:22
train iter: 716
num of updates: 71700
dynamics loss: 15623.40234

============================================================
time elapsed: 0:36:25
train iter: 717
num of updates: 71800
dynamics loss: 15576.96680

============================================================
time elapsed: 0:36:28
train iter: 718
num of updates: 71900
dynamics loss: 15549.69434

============================================================
time elapsed: 0:36:31
train iter: 719
num of updates: 72000
dynamics loss: 15520.93066

============================================================
time elapsed: 0:36:34
train iter: 720
num of updates: 72100
dynamics loss: 15539.37891

============================================================
time elapsed: 0:36:37
train iter: 721
num of updates: 72200
dynamics loss: 15526.01172

============================================================
time elapsed: 0:36:40
train iter: 722
num of updates: 72300
dynamics loss: 15521.04492

============================================================
time elapsed: 0:36:43
train iter: 723
num of updates: 72400
dynamics loss: 15494.35547

============================================================
time elapsed: 0:36:46
train iter: 724
num of updates: 72500
dynamics loss: 15494.97852

============================================================
time elapsed: 0:36:49
train iter: 725
num of updates: 72600
dynamics loss: 15451.01465

============================================================
time elapsed: 0:36:52
train iter: 726
num of updates: 72700
dynamics loss: 15470.49609

============================================================
time elapsed: 0:36:55
train iter: 727
num of updates: 72800
dynamics loss: 15445.77539

============================================================
time elapsed: 0:36:58
train iter: 728
num of updates: 72900
dynamics loss: 15448.91211

============================================================
time elapsed: 0:37:01
train iter: 729
num of updates: 73000
dynamics loss: 15399.04980

============================================================
time elapsed: 0:37:04
train iter: 730
num of updates: 73100
dynamics loss: 15416.33887

============================================================
time elapsed: 0:37:06
train iter: 731
num of updates: 73200
dynamics loss: 15395.89453

============================================================
time elapsed: 0:37:09
train iter: 732
num of updates: 73300
dynamics loss: 15380.27344

============================================================
time elapsed: 0:37:12
train iter: 733
num of updates: 73400
dynamics loss: 15377.41113

============================================================
time elapsed: 0:37:15
train iter: 734
num of updates: 73500
dynamics loss: 15353.97656

============================================================
time elapsed: 0:37:18
train iter: 735
num of updates: 73600
dynamics loss: 15360.99902

============================================================
time elapsed: 0:37:21
train iter: 736
num of updates: 73700
dynamics loss: 15346.05371

============================================================
time elapsed: 0:37:24
train iter: 737
num of updates: 73800
dynamics loss: 15308.83887

============================================================
time elapsed: 0:37:27
train iter: 738
num of updates: 73900
dynamics loss: 15302.60547

============================================================
time elapsed: 0:37:30
train iter: 739
num of updates: 74000
dynamics loss: 15282.77051

============================================================
time elapsed: 0:37:33
train iter: 740
num of updates: 74100
dynamics loss: 15272.05469

============================================================
time elapsed: 0:37:36
train iter: 741
num of updates: 74200
dynamics loss: 15247.84473

============================================================
time elapsed: 0:37:39
train iter: 742
num of updates: 74300
dynamics loss: 15253.86816

============================================================
time elapsed: 0:37:42
train iter: 743
num of updates: 74400
dynamics loss: 15223.72754

============================================================
time elapsed: 0:37:45
train iter: 744
num of updates: 74500
dynamics loss: 15243.54199

============================================================
time elapsed: 0:37:48
train iter: 745
num of updates: 74600
dynamics loss: 15227.70508

============================================================
time elapsed: 0:37:50
train iter: 746
num of updates: 74700
dynamics loss: 15206.36133

============================================================
time elapsed: 0:37:53
train iter: 747
num of updates: 74800
dynamics loss: 15175.77832

============================================================
time elapsed: 0:37:56
train iter: 748
num of updates: 74900
dynamics loss: 15181.56934

============================================================
time elapsed: 0:37:59
train iter: 749
num of updates: 75000
dynamics loss: 15139.38184

============================================================
time elapsed: 0:38:02
train iter: 750
num of updates: 75100
dynamics loss: 15158.03320

============================================================
time elapsed: 0:38:05
train iter: 751
num of updates: 75200
dynamics loss: 15141.65625

============================================================
time elapsed: 0:38:08
train iter: 752
num of updates: 75300
dynamics loss: 15086.86914

============================================================
time elapsed: 0:38:11
train iter: 753
num of updates: 75400
dynamics loss: 15121.66309

============================================================
time elapsed: 0:38:14
train iter: 754
num of updates: 75500
dynamics loss: 15099.72754

============================================================
time elapsed: 0:38:17
train iter: 755
num of updates: 75600
dynamics loss: 15098.72363

============================================================
time elapsed: 0:38:20
train iter: 756
num of updates: 75700
dynamics loss: 15083.31445

============================================================
time elapsed: 0:38:23
train iter: 757
num of updates: 75800
dynamics loss: 15041.75879

============================================================
time elapsed: 0:38:26
train iter: 758
num of updates: 75900
dynamics loss: 15039.53223

============================================================
time elapsed: 0:38:29
train iter: 759
num of updates: 76000
dynamics loss: 15016.40234

============================================================
time elapsed: 0:38:32
train iter: 760
num of updates: 76100
dynamics loss: 15010.07910

============================================================
time elapsed: 0:38:34
train iter: 761
num of updates: 76200
dynamics loss: 15016.18652

============================================================
time elapsed: 0:38:37
train iter: 762
num of updates: 76300
dynamics loss: 14998.95508

============================================================
time elapsed: 0:38:40
train iter: 763
num of updates: 76400
dynamics loss: 14989.26367

============================================================
time elapsed: 0:38:43
train iter: 764
num of updates: 76500
dynamics loss: 14972.73438

============================================================
time elapsed: 0:38:46
train iter: 765
num of updates: 76600
dynamics loss: 14958.66699

============================================================
time elapsed: 0:38:49
train iter: 766
num of updates: 76700
dynamics loss: 14932.51465

============================================================
time elapsed: 0:38:52
train iter: 767
num of updates: 76800
dynamics loss: 14930.72559

============================================================
time elapsed: 0:38:55
train iter: 768
num of updates: 76900
dynamics loss: 14938.70410

============================================================
time elapsed: 0:38:58
train iter: 769
num of updates: 77000
dynamics loss: 14913.95898

============================================================
time elapsed: 0:39:01
train iter: 770
num of updates: 77100
dynamics loss: 14895.61230

============================================================
time elapsed: 0:39:04
train iter: 771
num of updates: 77200
dynamics loss: 14865.34473

============================================================
time elapsed: 0:39:07
train iter: 772
num of updates: 77300
dynamics loss: 14871.25977

============================================================
time elapsed: 0:39:10
train iter: 773
num of updates: 77400
dynamics loss: 14878.99707

============================================================
time elapsed: 0:39:13
train iter: 774
num of updates: 77500
dynamics loss: 14829.60938

============================================================
time elapsed: 0:39:16
train iter: 775
num of updates: 77600
dynamics loss: 14821.32910

============================================================
time elapsed: 0:39:18
train iter: 776
num of updates: 77700
dynamics loss: 14839.16406

============================================================
time elapsed: 0:39:21
train iter: 777
num of updates: 77800
dynamics loss: 14799.16309

============================================================
time elapsed: 0:39:24
train iter: 778
num of updates: 77900
dynamics loss: 14804.01660

============================================================
time elapsed: 0:39:27
train iter: 779
num of updates: 78000
dynamics loss: 14778.81250

============================================================
time elapsed: 0:39:30
train iter: 780
num of updates: 78100
dynamics loss: 14762.55469

============================================================
time elapsed: 0:39:33
train iter: 781
num of updates: 78200
dynamics loss: 14760.09473

============================================================
time elapsed: 0:39:36
train iter: 782
num of updates: 78300
dynamics loss: 14737.56055

============================================================
time elapsed: 0:39:39
train iter: 783
num of updates: 78400
dynamics loss: 14724.50000

============================================================
time elapsed: 0:39:42
train iter: 784
num of updates: 78500
dynamics loss: 14730.20312

============================================================
time elapsed: 0:39:45
train iter: 785
num of updates: 78600
dynamics loss: 14710.17676

============================================================
time elapsed: 0:39:48
train iter: 786
num of updates: 78700
dynamics loss: 14685.96680

============================================================
time elapsed: 0:39:51
train iter: 787
num of updates: 78800
dynamics loss: 14685.12695

============================================================
time elapsed: 0:39:54
train iter: 788
num of updates: 78900
dynamics loss: 14657.47656

============================================================
time elapsed: 0:39:57
train iter: 789
num of updates: 79000
dynamics loss: 14671.27832

============================================================
time elapsed: 0:39:59
train iter: 790
num of updates: 79100
dynamics loss: 14644.86035

============================================================
time elapsed: 0:40:02
train iter: 791
num of updates: 79200
dynamics loss: 14631.86621

============================================================
time elapsed: 0:40:05
train iter: 792
num of updates: 79300
dynamics loss: 14609.96484

============================================================
time elapsed: 0:40:08
train iter: 793
num of updates: 79400
dynamics loss: 14607.22070

============================================================
time elapsed: 0:40:11
train iter: 794
num of updates: 79500
dynamics loss: 14594.17676

============================================================
time elapsed: 0:40:14
train iter: 795
num of updates: 79600
dynamics loss: 14591.98438

============================================================
time elapsed: 0:40:17
train iter: 796
num of updates: 79700
dynamics loss: 14576.48828

============================================================
time elapsed: 0:40:20
train iter: 797
num of updates: 79800
dynamics loss: 14557.32422

============================================================
time elapsed: 0:40:23
train iter: 798
num of updates: 79900
dynamics loss: 14528.62988

============================================================
time elapsed: 0:40:26
train iter: 799
num of updates: 80000
dynamics loss: 14530.28809

============================================================
time elapsed: 0:40:29
train iter: 800
num of updates: 80100
dynamics loss: 14519.61426

============================================================
time elapsed: 0:40:32
train iter: 801
num of updates: 80200
dynamics loss: 14482.40430

============================================================
time elapsed: 0:40:35
train iter: 802
num of updates: 80300
dynamics loss: 14500.03809

============================================================
time elapsed: 0:40:38
train iter: 803
num of updates: 80400
dynamics loss: 14491.97461

============================================================
time elapsed: 0:40:41
train iter: 804
num of updates: 80500
dynamics loss: 14459.75781

============================================================
time elapsed: 0:40:43
train iter: 805
num of updates: 80600
dynamics loss: 14437.50586

============================================================
time elapsed: 0:40:46
train iter: 806
num of updates: 80700
dynamics loss: 14430.11035

============================================================
time elapsed: 0:40:49
train iter: 807
num of updates: 80800
dynamics loss: 14432.69434

============================================================
time elapsed: 0:40:52
train iter: 808
num of updates: 80900
dynamics loss: 14416.47461

============================================================
time elapsed: 0:40:55
train iter: 809
num of updates: 81000
dynamics loss: 14422.17578

============================================================
time elapsed: 0:40:58
train iter: 810
num of updates: 81100
dynamics loss: 14404.57031

============================================================
time elapsed: 0:41:01
train iter: 811
num of updates: 81200
dynamics loss: 14396.99512

============================================================
time elapsed: 0:41:04
train iter: 812
num of updates: 81300
dynamics loss: 14384.87695

============================================================
time elapsed: 0:41:07
train iter: 813
num of updates: 81400
dynamics loss: 14358.54297

============================================================
time elapsed: 0:41:10
train iter: 814
num of updates: 81500
dynamics loss: 14344.05859

============================================================
time elapsed: 0:41:13
train iter: 815
num of updates: 81600
dynamics loss: 14330.17578

============================================================
time elapsed: 0:41:16
train iter: 816
num of updates: 81700
dynamics loss: 14308.46484

============================================================
time elapsed: 0:41:19
train iter: 817
num of updates: 81800
dynamics loss: 14297.54980

============================================================
time elapsed: 0:41:22
train iter: 818
num of updates: 81900
dynamics loss: 14309.81641

============================================================
time elapsed: 0:41:25
train iter: 819
num of updates: 82000
dynamics loss: 14284.75195

============================================================
time elapsed: 0:41:27
train iter: 820
num of updates: 82100
dynamics loss: 14289.96191

============================================================
time elapsed: 0:41:30
train iter: 821
num of updates: 82200
dynamics loss: 14269.76855

============================================================
time elapsed: 0:41:33
train iter: 822
num of updates: 82300
dynamics loss: 14243.70215

============================================================
time elapsed: 0:41:36
train iter: 823
num of updates: 82400
dynamics loss: 14225.60254

============================================================
time elapsed: 0:41:39
train iter: 824
num of updates: 82500
dynamics loss: 14241.87695

============================================================
time elapsed: 0:41:42
train iter: 825
num of updates: 82600
dynamics loss: 14231.74707

============================================================
time elapsed: 0:41:45
train iter: 826
num of updates: 82700
dynamics loss: 14207.19922

============================================================
time elapsed: 0:41:48
train iter: 827
num of updates: 82800
dynamics loss: 14196.86621

============================================================
time elapsed: 0:41:51
train iter: 828
num of updates: 82900
dynamics loss: 14183.40430

============================================================
time elapsed: 0:41:54
train iter: 829
num of updates: 83000
dynamics loss: 14181.58008

============================================================
time elapsed: 0:41:57
train iter: 830
num of updates: 83100
dynamics loss: 14157.30078

============================================================
time elapsed: 0:42:00
train iter: 831
num of updates: 83200
dynamics loss: 14145.51074

============================================================
time elapsed: 0:42:03
train iter: 832
num of updates: 83300
dynamics loss: 14125.78320

============================================================
time elapsed: 0:42:06
train iter: 833
num of updates: 83400
dynamics loss: 14138.33594

============================================================
time elapsed: 0:42:09
train iter: 834
num of updates: 83500
dynamics loss: 14102.55469

============================================================
time elapsed: 0:42:11
train iter: 835
num of updates: 83600
dynamics loss: 14092.28223

============================================================
time elapsed: 0:42:14
train iter: 836
num of updates: 83700
dynamics loss: 14092.09277

============================================================
time elapsed: 0:42:17
train iter: 837
num of updates: 83800
dynamics loss: 14069.04492

============================================================
time elapsed: 0:42:20
train iter: 838
num of updates: 83900
dynamics loss: 14073.93262

============================================================
time elapsed: 0:42:23
train iter: 839
num of updates: 84000
dynamics loss: 14049.73438

============================================================
time elapsed: 0:42:26
train iter: 840
num of updates: 84100
dynamics loss: 14054.38477

============================================================
time elapsed: 0:42:29
train iter: 841
num of updates: 84200
dynamics loss: 14022.70801

============================================================
time elapsed: 0:42:32
train iter: 842
num of updates: 84300
dynamics loss: 14025.33887

============================================================
time elapsed: 0:42:35
train iter: 843
num of updates: 84400
dynamics loss: 13986.60254

============================================================
time elapsed: 0:42:38
train iter: 844
num of updates: 84500
dynamics loss: 13996.74805

============================================================
time elapsed: 0:42:41
train iter: 845
num of updates: 84600
dynamics loss: 13992.49414

============================================================
time elapsed: 0:42:44
train iter: 846
num of updates: 84700
dynamics loss: 13989.69434

============================================================
time elapsed: 0:42:47
train iter: 847
num of updates: 84800
dynamics loss: 13958.03027

============================================================
time elapsed: 0:42:50
train iter: 848
num of updates: 84900
dynamics loss: 13943.11133

============================================================
time elapsed: 0:42:53
train iter: 849
num of updates: 85000
dynamics loss: 13938.43848

============================================================
time elapsed: 0:42:55
train iter: 850
num of updates: 85100
dynamics loss: 13941.16309

============================================================
time elapsed: 0:42:58
train iter: 851
num of updates: 85200
dynamics loss: 13909.27930

============================================================
time elapsed: 0:43:01
train iter: 852
num of updates: 85300
dynamics loss: 13915.50098

============================================================
time elapsed: 0:43:04
train iter: 853
num of updates: 85400
dynamics loss: 13872.87598

============================================================
time elapsed: 0:43:07
train iter: 854
num of updates: 85500
dynamics loss: 13887.35352

============================================================
time elapsed: 0:43:10
train iter: 855
num of updates: 85600
dynamics loss: 13885.09570

============================================================
time elapsed: 0:43:13
train iter: 856
num of updates: 85700
dynamics loss: 13864.48242

============================================================
time elapsed: 0:43:16
train iter: 857
num of updates: 85800
dynamics loss: 13839.90039

============================================================
time elapsed: 0:43:19
train iter: 858
num of updates: 85900
dynamics loss: 13818.62598

============================================================
time elapsed: 0:43:22
train iter: 859
num of updates: 86000
dynamics loss: 13812.78223

============================================================
time elapsed: 0:43:25
train iter: 860
num of updates: 86100
dynamics loss: 13825.83105

============================================================
time elapsed: 0:43:28
train iter: 861
num of updates: 86200
dynamics loss: 13811.30762

============================================================
time elapsed: 0:43:31
train iter: 862
num of updates: 86300
dynamics loss: 13782.92090

============================================================
time elapsed: 0:43:34
train iter: 863
num of updates: 86400
dynamics loss: 13760.19043

============================================================
time elapsed: 0:43:37
train iter: 864
num of updates: 86500
dynamics loss: 13749.86719

============================================================
time elapsed: 0:43:39
train iter: 865
num of updates: 86600
dynamics loss: 13735.69043

============================================================
time elapsed: 0:43:42
train iter: 866
num of updates: 86700
dynamics loss: 13723.64551

============================================================
time elapsed: 0:43:45
train iter: 867
num of updates: 86800
dynamics loss: 13739.86230

============================================================
time elapsed: 0:43:48
train iter: 868
num of updates: 86900
dynamics loss: 13722.66797

============================================================
time elapsed: 0:43:51
train iter: 869
num of updates: 87000
dynamics loss: 13755.92090

============================================================
time elapsed: 0:43:54
train iter: 870
num of updates: 87100
dynamics loss: 13687.31152

============================================================
time elapsed: 0:43:57
train iter: 871
num of updates: 87200
dynamics loss: 13690.06836

============================================================
time elapsed: 0:44:00
train iter: 872
num of updates: 87300
dynamics loss: 13674.61035

============================================================
time elapsed: 0:44:03
train iter: 873
num of updates: 87400
dynamics loss: 13686.98047

============================================================
time elapsed: 0:44:06
train iter: 874
num of updates: 87500
dynamics loss: 13661.03613

============================================================
time elapsed: 0:44:09
train iter: 875
num of updates: 87600
dynamics loss: 13651.78711

============================================================
time elapsed: 0:44:12
train iter: 876
num of updates: 87700
dynamics loss: 13649.40332

============================================================
time elapsed: 0:44:15
train iter: 877
num of updates: 87800
dynamics loss: 13612.68848

============================================================
time elapsed: 0:44:18
train iter: 878
num of updates: 87900
dynamics loss: 13633.73242

============================================================
time elapsed: 0:44:21
train iter: 879
num of updates: 88000
dynamics loss: 13602.37988

============================================================
time elapsed: 0:44:23
train iter: 880
num of updates: 88100
dynamics loss: 13599.18066

============================================================
time elapsed: 0:44:26
train iter: 881
num of updates: 88200
dynamics loss: 13581.50293

============================================================
time elapsed: 0:44:29
train iter: 882
num of updates: 88300
dynamics loss: 13586.06641

============================================================
time elapsed: 0:44:32
train iter: 883
num of updates: 88400
dynamics loss: 13575.04297

============================================================
time elapsed: 0:44:35
train iter: 884
num of updates: 88500
dynamics loss: 13542.30469

============================================================
time elapsed: 0:44:38
train iter: 885
num of updates: 88600
dynamics loss: 13529.05078

============================================================
time elapsed: 0:44:41
train iter: 886
num of updates: 88700
dynamics loss: 13528.51660

============================================================
time elapsed: 0:44:44
train iter: 887
num of updates: 88800
dynamics loss: 13510.65820

============================================================
time elapsed: 0:44:47
train iter: 888
num of updates: 88900
dynamics loss: 13504.23438

============================================================
time elapsed: 0:44:50
train iter: 889
num of updates: 89000
dynamics loss: 13500.38184

============================================================
time elapsed: 0:44:53
train iter: 890
num of updates: 89100
dynamics loss: 13463.08691

============================================================
time elapsed: 0:44:56
train iter: 891
num of updates: 89200
dynamics loss: 13486.55469

============================================================
time elapsed: 0:44:59
train iter: 892
num of updates: 89300
dynamics loss: 13457.47852

============================================================
time elapsed: 0:45:02
train iter: 893
num of updates: 89400
dynamics loss: 13460.16406

============================================================
time elapsed: 0:45:05
train iter: 894
num of updates: 89500
dynamics loss: 13440.88477

============================================================
time elapsed: 0:45:07
train iter: 895
num of updates: 89600
dynamics loss: 13435.76074

============================================================
time elapsed: 0:45:10
train iter: 896
num of updates: 89700
dynamics loss: 13410.49707

============================================================
time elapsed: 0:45:13
train iter: 897
num of updates: 89800
dynamics loss: 13406.82422

============================================================
time elapsed: 0:45:16
train iter: 898
num of updates: 89900
dynamics loss: 13393.67871

============================================================
time elapsed: 0:45:19
train iter: 899
num of updates: 90000
dynamics loss: 13386.26270

============================================================
time elapsed: 0:45:22
train iter: 900
num of updates: 90100
dynamics loss: 13394.54492

============================================================
time elapsed: 0:45:25
train iter: 901
num of updates: 90200
dynamics loss: 13367.91797

============================================================
time elapsed: 0:45:28
train iter: 902
num of updates: 90300
dynamics loss: 13366.85449

============================================================
time elapsed: 0:45:31
train iter: 903
num of updates: 90400
dynamics loss: 13320.18066

============================================================
time elapsed: 0:45:34
train iter: 904
num of updates: 90500
dynamics loss: 13330.27148

============================================================
time elapsed: 0:45:37
train iter: 905
num of updates: 90600
dynamics loss: 13344.53906

============================================================
time elapsed: 0:45:40
train iter: 906
num of updates: 90700
dynamics loss: 13301.85059

============================================================
time elapsed: 0:45:43
train iter: 907
num of updates: 90800
dynamics loss: 13295.94824

============================================================
time elapsed: 0:45:46
train iter: 908
num of updates: 90900
dynamics loss: 13315.19434

============================================================
time elapsed: 0:45:49
train iter: 909
num of updates: 91000
dynamics loss: 13293.20703

============================================================
time elapsed: 0:45:51
train iter: 910
num of updates: 91100
dynamics loss: 13270.15625

============================================================
time elapsed: 0:45:54
train iter: 911
num of updates: 91200
dynamics loss: 13257.71777

============================================================
time elapsed: 0:45:57
train iter: 912
num of updates: 91300
dynamics loss: 13262.87891

============================================================
time elapsed: 0:46:00
train iter: 913
num of updates: 91400
dynamics loss: 13254.23438

============================================================
time elapsed: 0:46:03
train iter: 914
num of updates: 91500
dynamics loss: 13238.29102

============================================================
time elapsed: 0:46:06
train iter: 915
num of updates: 91600
dynamics loss: 13227.57910

============================================================
time elapsed: 0:46:09
train iter: 916
num of updates: 91700
dynamics loss: 13203.04492

============================================================
time elapsed: 0:46:12
train iter: 917
num of updates: 91800
dynamics loss: 13186.45508

============================================================
time elapsed: 0:46:15
train iter: 918
num of updates: 91900
dynamics loss: 13189.68555

============================================================
time elapsed: 0:46:18
train iter: 919
num of updates: 92000
dynamics loss: 13181.54395

============================================================
time elapsed: 0:46:21
train iter: 920
num of updates: 92100
dynamics loss: 13184.22852

============================================================
time elapsed: 0:46:24
train iter: 921
num of updates: 92200
dynamics loss: 13132.69043

============================================================
time elapsed: 0:46:27
train iter: 922
num of updates: 92300
dynamics loss: 13146.40039

============================================================
time elapsed: 0:46:30
train iter: 923
num of updates: 92400
dynamics loss: 13156.62988

============================================================
time elapsed: 0:46:33
train iter: 924
num of updates: 92500
dynamics loss: 13126.62695

============================================================
time elapsed: 0:46:35
train iter: 925
num of updates: 92600
dynamics loss: 13106.71289

============================================================
time elapsed: 0:46:38
train iter: 926
num of updates: 92700
dynamics loss: 13100.10254

============================================================
time elapsed: 0:46:41
train iter: 927
num of updates: 92800
dynamics loss: 13104.76270

============================================================
time elapsed: 0:46:44
train iter: 928
num of updates: 92900
dynamics loss: 13083.25586

============================================================
time elapsed: 0:46:47
train iter: 929
num of updates: 93000
dynamics loss: 13079.14062

============================================================
time elapsed: 0:46:50
train iter: 930
num of updates: 93100
dynamics loss: 13066.31445

============================================================
time elapsed: 0:46:53
train iter: 931
num of updates: 93200
dynamics loss: 13055.32129

============================================================
time elapsed: 0:46:56
train iter: 932
num of updates: 93300
dynamics loss: 13067.45410

============================================================
time elapsed: 0:46:59
train iter: 933
num of updates: 93400
dynamics loss: 13046.85938

============================================================
time elapsed: 0:47:02
train iter: 934
num of updates: 93500
dynamics loss: 13036.56836

============================================================
time elapsed: 0:47:05
train iter: 935
num of updates: 93600
dynamics loss: 13012.64355

============================================================
time elapsed: 0:47:08
train iter: 936
num of updates: 93700
dynamics loss: 13023.79297

============================================================
time elapsed: 0:47:11
train iter: 937
num of updates: 93800
dynamics loss: 12991.60059

============================================================
time elapsed: 0:47:14
train iter: 938
num of updates: 93900
dynamics loss: 12993.68359

============================================================
time elapsed: 0:47:17
train iter: 939
num of updates: 94000
dynamics loss: 12978.54980

============================================================
time elapsed: 0:47:19
train iter: 940
num of updates: 94100
dynamics loss: 12969.35449

============================================================
time elapsed: 0:47:22
train iter: 941
num of updates: 94200
dynamics loss: 12959.35840

============================================================
time elapsed: 0:47:25
train iter: 942
num of updates: 94300
dynamics loss: 12954.67871

============================================================
time elapsed: 0:47:28
train iter: 943
num of updates: 94400
dynamics loss: 12939.45703

============================================================
time elapsed: 0:47:31
train iter: 944
num of updates: 94500
dynamics loss: 12933.30469

============================================================
time elapsed: 0:47:34
train iter: 945
num of updates: 94600
dynamics loss: 12917.78613

============================================================
time elapsed: 0:47:37
train iter: 946
num of updates: 94700
dynamics loss: 12908.31250

============================================================
time elapsed: 0:47:40
train iter: 947
num of updates: 94800
dynamics loss: 12902.92969

============================================================
time elapsed: 0:47:43
train iter: 948
num of updates: 94900
dynamics loss: 12900.36621

============================================================
time elapsed: 0:47:46
train iter: 949
num of updates: 95000
dynamics loss: 12911.31055

============================================================
time elapsed: 0:47:49
train iter: 950
num of updates: 95100
dynamics loss: 12872.63086

============================================================
time elapsed: 0:47:52
train iter: 951
num of updates: 95200
dynamics loss: 12880.63184

============================================================
time elapsed: 0:47:55
train iter: 952
num of updates: 95300
dynamics loss: 12857.02637

============================================================
time elapsed: 0:47:58
train iter: 953
num of updates: 95400
dynamics loss: 12837.85547

============================================================
time elapsed: 0:48:01
train iter: 954
num of updates: 95500
dynamics loss: 12835.24707

============================================================
time elapsed: 0:48:03
train iter: 955
num of updates: 95600
dynamics loss: 12825.95508

============================================================
time elapsed: 0:48:06
train iter: 956
num of updates: 95700
dynamics loss: 12830.02246

============================================================
time elapsed: 0:48:09
train iter: 957
num of updates: 95800
dynamics loss: 12821.00488

============================================================
time elapsed: 0:48:12
train iter: 958
num of updates: 95900
dynamics loss: 12786.63867

============================================================
time elapsed: 0:48:15
train iter: 959
num of updates: 96000
dynamics loss: 12801.77441

============================================================
time elapsed: 0:48:18
train iter: 960
num of updates: 96100
dynamics loss: 12782.26562

============================================================
time elapsed: 0:48:21
train iter: 961
num of updates: 96200
dynamics loss: 12777.51465

============================================================
time elapsed: 0:48:24
train iter: 962
num of updates: 96300
dynamics loss: 12760.39258

============================================================
time elapsed: 0:48:27
train iter: 963
num of updates: 96400
dynamics loss: 12755.02246

============================================================
time elapsed: 0:48:30
train iter: 964
num of updates: 96500
dynamics loss: 12703.91895

============================================================
time elapsed: 0:48:33
train iter: 965
num of updates: 96600
dynamics loss: 12714.15332

============================================================
time elapsed: 0:48:36
train iter: 966
num of updates: 96700
dynamics loss: 12737.88086

============================================================
time elapsed: 0:48:39
train iter: 967
num of updates: 96800
dynamics loss: 12727.26855

============================================================
time elapsed: 0:48:42
train iter: 968
num of updates: 96900
dynamics loss: 12730.99707

============================================================
time elapsed: 0:48:45
train iter: 969
num of updates: 97000
dynamics loss: 12680.44043

============================================================
time elapsed: 0:48:47
train iter: 970
num of updates: 97100
dynamics loss: 12691.23828

============================================================
time elapsed: 0:48:50
train iter: 971
num of updates: 97200
dynamics loss: 12675.11426

============================================================
time elapsed: 0:48:53
train iter: 972
num of updates: 97300
dynamics loss: 12663.39453

============================================================
time elapsed: 0:48:56
train iter: 973
num of updates: 97400
dynamics loss: 12656.96680

============================================================
time elapsed: 0:48:59
train iter: 974
num of updates: 97500
dynamics loss: 12648.91992

============================================================
time elapsed: 0:49:02
train iter: 975
num of updates: 97600
dynamics loss: 12651.36426

============================================================
time elapsed: 0:49:05
train iter: 976
num of updates: 97700
dynamics loss: 12638.35059

============================================================
time elapsed: 0:49:08
train iter: 977
num of updates: 97800
dynamics loss: 12625.63086

============================================================
time elapsed: 0:49:11
train iter: 978
num of updates: 97900
dynamics loss: 12599.22070

============================================================
time elapsed: 0:49:14
train iter: 979
num of updates: 98000
dynamics loss: 12597.25488

============================================================
time elapsed: 0:49:17
train iter: 980
num of updates: 98100
dynamics loss: 12570.86230

============================================================
time elapsed: 0:49:20
train iter: 981
num of updates: 98200
dynamics loss: 12584.11426

============================================================
time elapsed: 0:49:23
train iter: 982
num of updates: 98300
dynamics loss: 12578.13770

============================================================
time elapsed: 0:49:26
train iter: 983
num of updates: 98400
dynamics loss: 12568.57031

============================================================
time elapsed: 0:49:29
train iter: 984
num of updates: 98500
dynamics loss: 12572.70898

============================================================
time elapsed: 0:49:31
train iter: 985
num of updates: 98600
dynamics loss: 12566.82129

============================================================
time elapsed: 0:49:34
train iter: 986
num of updates: 98700
dynamics loss: 12547.45703

============================================================
time elapsed: 0:49:37
train iter: 987
num of updates: 98800
dynamics loss: 12520.09277

============================================================
time elapsed: 0:49:40
train iter: 988
num of updates: 98900
dynamics loss: 12518.41016

============================================================
time elapsed: 0:49:43
train iter: 989
num of updates: 99000
dynamics loss: 12513.04004

============================================================
time elapsed: 0:49:46
train iter: 990
num of updates: 99100
dynamics loss: 12532.12695

============================================================
time elapsed: 0:49:49
train iter: 991
num of updates: 99200
dynamics loss: 12493.73633

============================================================
time elapsed: 0:49:52
train iter: 992
num of updates: 99300
dynamics loss: 12483.50488

============================================================
time elapsed: 0:49:55
train iter: 993
num of updates: 99400
dynamics loss: 12480.77539

============================================================
time elapsed: 0:49:58
train iter: 994
num of updates: 99500
dynamics loss: 12479.52637

============================================================
time elapsed: 0:50:01
train iter: 995
num of updates: 99600
dynamics loss: 12455.19824

============================================================
time elapsed: 0:50:04
train iter: 996
num of updates: 99700
dynamics loss: 12449.99414

============================================================
time elapsed: 0:50:07
train iter: 997
num of updates: 99800
dynamics loss: 12440.31641

============================================================
time elapsed: 0:50:10
train iter: 998
num of updates: 99900
dynamics loss: 12447.08203

============================================================
time elapsed: 0:50:13
train iter: 999
num of updates: 100000
dynamics loss: 12431.74219

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/dynamics_model_100000.pt
============================================================
finished training dynamics!
============================================================
started training dynamics at: 25-09-28-00-57-49
finished training dynamics at: 25-09-28-01-48-06
total dynamics training time: 0:50:17
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/dynamics_model.pt
============================================================
2025-09-28 01:48:16.157679: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:48:18.527382: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:48:19.846895: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 324 bytes spill stores, 324 bytes spill loads

num_vae_param: 547754
2025-09-28 01:48:25.960338: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:48:25.960517: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:48:25.960572: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:48:25.960799: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:48:25.960843: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:48:27.746241: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 320 bytes spill stores, 220 bytes spill loads

2025-09-28 01:48:28.328542: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 388 bytes spill stores, 384 bytes spill loads

2025-09-28 01:48:29.922807: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 820 bytes spill stores, 564 bytes spill loads

2025-09-28 01:48:32.211829: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 1736 bytes spill stores, 1312 bytes spill loads

2025-09-28 01:48:38.053777: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15', 4 bytes spill stores, 4 bytes spill loads

2025-09-28 01:48:39.764802: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 540 bytes spill stores, 540 bytes spill loads

2025-09-28 01:48:40.653773: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 196 bytes spill stores, 200 bytes spill loads

2025-09-28 01:48:42.193186: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 8 bytes spill stores, 8 bytes spill loads

2025-09-28 01:48:44.394053: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 108 bytes spill stores, 108 bytes spill loads

2025-09-28 01:48:45.359031: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 292 bytes spill stores, 292 bytes spill loads

2025-09-28 01:48:46.097347: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 200 bytes spill stores, 200 bytes spill loads

============================================================
time elapsed: 0:51:09
train iter: 0
num of updates: 100
vae loss: 2.43364
kl loss: 0.11061
a decoder loss: 2.32303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/vae_model_100.pt
2025-09-28 01:48:59.316233: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:49:01.671336: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:49:02.970035: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 324 bytes spill stores, 324 bytes spill loads

============================================================
time elapsed: 0:51:26
train iter: 1
num of updates: 200
vae loss: 2.43950
kl loss: 0.11086
a decoder loss: 2.32864
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:27
train iter: 2
num of updates: 300
vae loss: 2.43048
kl loss: 0.10938
a decoder loss: 2.32109
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:28
train iter: 3
num of updates: 400
vae loss: 2.42391
kl loss: 0.10837
a decoder loss: 2.31555
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:29
train iter: 4
num of updates: 500
vae loss: 2.41934
kl loss: 0.10699
a decoder loss: 2.31234
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:30
train iter: 5
num of updates: 600
vae loss: 2.41827
kl loss: 0.10571
a decoder loss: 2.31256
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:31
train iter: 6
num of updates: 700
vae loss: 2.41522
kl loss: 0.10336
a decoder loss: 2.31185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:32
train iter: 7
num of updates: 800
vae loss: 2.40556
kl loss: 0.10135
a decoder loss: 2.30421
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:33
train iter: 8
num of updates: 900
vae loss: 2.39631
kl loss: 0.09941
a decoder loss: 2.29690
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:34
train iter: 9
num of updates: 1000
vae loss: 2.37824
kl loss: 0.09662
a decoder loss: 2.28162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:35
train iter: 10
num of updates: 1100
vae loss: 2.37441
kl loss: 0.09414
a decoder loss: 2.28027
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:36
train iter: 11
num of updates: 1200
vae loss: 2.36210
kl loss: 0.09156
a decoder loss: 2.27054
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:37
train iter: 12
num of updates: 1300
vae loss: 2.35337
kl loss: 0.08908
a decoder loss: 2.26429
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:38
train iter: 13
num of updates: 1400
vae loss: 2.34425
kl loss: 0.08663
a decoder loss: 2.25763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:40
train iter: 14
num of updates: 1500
vae loss: 2.32351
kl loss: 0.08380
a decoder loss: 2.23971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:41
train iter: 15
num of updates: 1600
vae loss: 2.31495
kl loss: 0.08116
a decoder loss: 2.23379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:42
train iter: 16
num of updates: 1700
vae loss: 2.28616
kl loss: 0.07887
a decoder loss: 2.20729
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:43
train iter: 17
num of updates: 1800
vae loss: 2.28029
kl loss: 0.07678
a decoder loss: 2.20351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:44
train iter: 18
num of updates: 1900
vae loss: 2.26251
kl loss: 0.07416
a decoder loss: 2.18835
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:45
train iter: 19
num of updates: 2000
vae loss: 2.24824
kl loss: 0.07215
a decoder loss: 2.17609
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:46
train iter: 20
num of updates: 2100
vae loss: 2.23368
kl loss: 0.06992
a decoder loss: 2.16376
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:47
train iter: 21
num of updates: 2200
vae loss: 2.20974
kl loss: 0.06814
a decoder loss: 2.14160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:48
train iter: 22
num of updates: 2300
vae loss: 2.19302
kl loss: 0.06643
a decoder loss: 2.12659
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:49
train iter: 23
num of updates: 2400
vae loss: 2.17235
kl loss: 0.06472
a decoder loss: 2.10763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:50
train iter: 24
num of updates: 2500
vae loss: 2.15939
kl loss: 0.06299
a decoder loss: 2.09640
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:51
train iter: 25
num of updates: 2600
vae loss: 2.13437
kl loss: 0.06122
a decoder loss: 2.07315
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:52
train iter: 26
num of updates: 2700
vae loss: 2.11489
kl loss: 0.05967
a decoder loss: 2.05521
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:53
train iter: 27
num of updates: 2800
vae loss: 2.08892
kl loss: 0.05846
a decoder loss: 2.03046
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:54
train iter: 28
num of updates: 2900
vae loss: 2.07380
kl loss: 0.05728
a decoder loss: 2.01652
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:55
train iter: 29
num of updates: 3000
vae loss: 2.04550
kl loss: 0.05597
a decoder loss: 1.98953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:56
train iter: 30
num of updates: 3100
vae loss: 2.03393
kl loss: 0.05477
a decoder loss: 1.97916
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:57
train iter: 31
num of updates: 3200
vae loss: 2.00614
kl loss: 0.05371
a decoder loss: 1.95244
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:58
train iter: 32
num of updates: 3300
vae loss: 1.99113
kl loss: 0.05282
a decoder loss: 1.93832
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:59
train iter: 33
num of updates: 3400
vae loss: 1.97111
kl loss: 0.05192
a decoder loss: 1.91919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:00
train iter: 34
num of updates: 3500
vae loss: 1.94283
kl loss: 0.05108
a decoder loss: 1.89175
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:01
train iter: 35
num of updates: 3600
vae loss: 1.92131
kl loss: 0.05019
a decoder loss: 1.87111
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:02
train iter: 36
num of updates: 3700
vae loss: 1.89829
kl loss: 0.04950
a decoder loss: 1.84879
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:03
train iter: 37
num of updates: 3800
vae loss: 1.86638
kl loss: 0.04906
a decoder loss: 1.81732
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:04
train iter: 38
num of updates: 3900
vae loss: 1.85367
kl loss: 0.04829
a decoder loss: 1.80537
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:05
train iter: 39
num of updates: 4000
vae loss: 1.82773
kl loss: 0.04775
a decoder loss: 1.77998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:06
train iter: 40
num of updates: 4100
vae loss: 1.79944
kl loss: 0.04711
a decoder loss: 1.75233
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:07
train iter: 41
num of updates: 4200
vae loss: 1.78638
kl loss: 0.04659
a decoder loss: 1.73980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:08
train iter: 42
num of updates: 4300
vae loss: 1.76866
kl loss: 0.04617
a decoder loss: 1.72249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:09
train iter: 43
num of updates: 4400
vae loss: 1.73928
kl loss: 0.04571
a decoder loss: 1.69357
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:10
train iter: 44
num of updates: 4500
vae loss: 1.72615
kl loss: 0.04542
a decoder loss: 1.68073
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:11
train iter: 45
num of updates: 4600
vae loss: 1.69636
kl loss: 0.04515
a decoder loss: 1.65121
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:12
train iter: 46
num of updates: 4700
vae loss: 1.67599
kl loss: 0.04486
a decoder loss: 1.63112
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:13
train iter: 47
num of updates: 4800
vae loss: 1.65377
kl loss: 0.04468
a decoder loss: 1.60909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:14
train iter: 48
num of updates: 4900
vae loss: 1.63063
kl loss: 0.04435
a decoder loss: 1.58628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:15
train iter: 49
num of updates: 5000
vae loss: 1.59968
kl loss: 0.04414
a decoder loss: 1.55554
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:16
train iter: 50
num of updates: 5100
vae loss: 1.58735
kl loss: 0.04413
a decoder loss: 1.54321
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:17
train iter: 51
num of updates: 5200
vae loss: 1.56014
kl loss: 0.04391
a decoder loss: 1.51623
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:18
train iter: 52
num of updates: 5300
vae loss: 1.53554
kl loss: 0.04390
a decoder loss: 1.49164
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:19
train iter: 53
num of updates: 5400
vae loss: 1.50785
kl loss: 0.04385
a decoder loss: 1.46400
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:20
train iter: 54
num of updates: 5500
vae loss: 1.49061
kl loss: 0.04382
a decoder loss: 1.44679
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:21
train iter: 55
num of updates: 5600
vae loss: 1.46948
kl loss: 0.04376
a decoder loss: 1.42571
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:22
train iter: 56
num of updates: 5700
vae loss: 1.44980
kl loss: 0.04376
a decoder loss: 1.40604
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:23
train iter: 57
num of updates: 5800
vae loss: 1.42093
kl loss: 0.04356
a decoder loss: 1.37737
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:24
train iter: 58
num of updates: 5900
vae loss: 1.39685
kl loss: 0.04362
a decoder loss: 1.35324
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:25
train iter: 59
num of updates: 6000
vae loss: 1.37942
kl loss: 0.04358
a decoder loss: 1.33584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:26
train iter: 60
num of updates: 6100
vae loss: 1.35470
kl loss: 0.04366
a decoder loss: 1.31104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:27
train iter: 61
num of updates: 6200
vae loss: 1.33794
kl loss: 0.04354
a decoder loss: 1.29439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:28
train iter: 62
num of updates: 6300
vae loss: 1.31241
kl loss: 0.04379
a decoder loss: 1.26862
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:29
train iter: 63
num of updates: 6400
vae loss: 1.28693
kl loss: 0.04369
a decoder loss: 1.24324
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:30
train iter: 64
num of updates: 6500
vae loss: 1.26525
kl loss: 0.04388
a decoder loss: 1.22136
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:31
train iter: 65
num of updates: 6600
vae loss: 1.24549
kl loss: 0.04374
a decoder loss: 1.20174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:32
train iter: 66
num of updates: 6700
vae loss: 1.22291
kl loss: 0.04360
a decoder loss: 1.17931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:33
train iter: 67
num of updates: 6800
vae loss: 1.20230
kl loss: 0.04364
a decoder loss: 1.15866
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:34
train iter: 68
num of updates: 6900
vae loss: 1.17742
kl loss: 0.04367
a decoder loss: 1.13374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:35
train iter: 69
num of updates: 7000
vae loss: 1.15813
kl loss: 0.04368
a decoder loss: 1.11446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:36
train iter: 70
num of updates: 7100
vae loss: 1.14003
kl loss: 0.04351
a decoder loss: 1.09651
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:38
train iter: 71
num of updates: 7200
vae loss: 1.11919
kl loss: 0.04351
a decoder loss: 1.07568
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:39
train iter: 72
num of updates: 7300
vae loss: 1.09485
kl loss: 0.04340
a decoder loss: 1.05144
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:40
train iter: 73
num of updates: 7400
vae loss: 1.07778
kl loss: 0.04335
a decoder loss: 1.03443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:41
train iter: 74
num of updates: 7500
vae loss: 1.05611
kl loss: 0.04321
a decoder loss: 1.01290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:42
train iter: 75
num of updates: 7600
vae loss: 1.04461
kl loss: 0.04317
a decoder loss: 1.00144
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:43
train iter: 76
num of updates: 7700
vae loss: 1.02013
kl loss: 0.04290
a decoder loss: 0.97722
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:44
train iter: 77
num of updates: 7800
vae loss: 0.99918
kl loss: 0.04275
a decoder loss: 0.95643
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:45
train iter: 78
num of updates: 7900
vae loss: 0.97442
kl loss: 0.04239
a decoder loss: 0.93202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:46
train iter: 79
num of updates: 8000
vae loss: 0.96530
kl loss: 0.04220
a decoder loss: 0.92310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:47
train iter: 80
num of updates: 8100
vae loss: 0.94580
kl loss: 0.04209
a decoder loss: 0.90372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:48
train iter: 81
num of updates: 8200
vae loss: 0.93144
kl loss: 0.04182
a decoder loss: 0.88962
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:49
train iter: 82
num of updates: 8300
vae loss: 0.90929
kl loss: 0.04157
a decoder loss: 0.86772
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:50
train iter: 83
num of updates: 8400
vae loss: 0.89579
kl loss: 0.04133
a decoder loss: 0.85446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:51
train iter: 84
num of updates: 8500
vae loss: 0.87702
kl loss: 0.04084
a decoder loss: 0.83617
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:52
train iter: 85
num of updates: 8600
vae loss: 0.86047
kl loss: 0.04065
a decoder loss: 0.81983
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:53
train iter: 86
num of updates: 8700
vae loss: 0.84562
kl loss: 0.04039
a decoder loss: 0.80523
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:54
train iter: 87
num of updates: 8800
vae loss: 0.82983
kl loss: 0.04004
a decoder loss: 0.78979
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:55
train iter: 88
num of updates: 8900
vae loss: 0.81549
kl loss: 0.03987
a decoder loss: 0.77563
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:56
train iter: 89
num of updates: 9000
vae loss: 0.79730
kl loss: 0.03945
a decoder loss: 0.75785
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:57
train iter: 90
num of updates: 9100
vae loss: 0.78383
kl loss: 0.03918
a decoder loss: 0.74465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:58
train iter: 91
num of updates: 9200
vae loss: 0.76910
kl loss: 0.03866
a decoder loss: 0.73044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:59
train iter: 92
num of updates: 9300
vae loss: 0.75204
kl loss: 0.03826
a decoder loss: 0.71378
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:00
train iter: 93
num of updates: 9400
vae loss: 0.73933
kl loss: 0.03791
a decoder loss: 0.70142
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:01
train iter: 94
num of updates: 9500
vae loss: 0.72302
kl loss: 0.03754
a decoder loss: 0.68548
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:02
train iter: 95
num of updates: 9600
vae loss: 0.71616
kl loss: 0.03697
a decoder loss: 0.67919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:03
train iter: 96
num of updates: 9700
vae loss: 0.69954
kl loss: 0.03658
a decoder loss: 0.66296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:04
train iter: 97
num of updates: 9800
vae loss: 0.68735
kl loss: 0.03613
a decoder loss: 0.65122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:05
train iter: 98
num of updates: 9900
vae loss: 0.67853
kl loss: 0.03594
a decoder loss: 0.64259
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:06
train iter: 99
num of updates: 10000
vae loss: 0.66506
kl loss: 0.03545
a decoder loss: 0.62961
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:07
train iter: 100
num of updates: 10100
vae loss: 0.65246
kl loss: 0.03506
a decoder loss: 0.61741
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:08
train iter: 101
num of updates: 10200
vae loss: 0.64289
kl loss: 0.03473
a decoder loss: 0.60816
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:09
train iter: 102
num of updates: 10300
vae loss: 0.62971
kl loss: 0.03414
a decoder loss: 0.59556
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:10
train iter: 103
num of updates: 10400
vae loss: 0.62318
kl loss: 0.03377
a decoder loss: 0.58941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:11
train iter: 104
num of updates: 10500
vae loss: 0.60937
kl loss: 0.03321
a decoder loss: 0.57615
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:12
train iter: 105
num of updates: 10600
vae loss: 0.60188
kl loss: 0.03277
a decoder loss: 0.56911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:13
train iter: 106
num of updates: 10700
vae loss: 0.59340
kl loss: 0.03243
a decoder loss: 0.56098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:14
train iter: 107
num of updates: 10800
vae loss: 0.58392
kl loss: 0.03204
a decoder loss: 0.55188
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:15
train iter: 108
num of updates: 10900
vae loss: 0.57211
kl loss: 0.03156
a decoder loss: 0.54055
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:16
train iter: 109
num of updates: 11000
vae loss: 0.56796
kl loss: 0.03105
a decoder loss: 0.53691
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:17
train iter: 110
num of updates: 11100
vae loss: 0.56032
kl loss: 0.03066
a decoder loss: 0.52966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:18
train iter: 111
num of updates: 11200
vae loss: 0.54910
kl loss: 0.03022
a decoder loss: 0.51888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:19
train iter: 112
num of updates: 11300
vae loss: 0.54376
kl loss: 0.02984
a decoder loss: 0.51392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:20
train iter: 113
num of updates: 11400
vae loss: 0.53720
kl loss: 0.02933
a decoder loss: 0.50787
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:21
train iter: 114
num of updates: 11500
vae loss: 0.52825
kl loss: 0.02886
a decoder loss: 0.49939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:22
train iter: 115
num of updates: 11600
vae loss: 0.52353
kl loss: 0.02838
a decoder loss: 0.49516
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:23
train iter: 116
num of updates: 11700
vae loss: 0.51753
kl loss: 0.02784
a decoder loss: 0.48969
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:24
train iter: 117
num of updates: 11800
vae loss: 0.50760
kl loss: 0.02734
a decoder loss: 0.48026
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:25
train iter: 118
num of updates: 11900
vae loss: 0.50357
kl loss: 0.02688
a decoder loss: 0.47670
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:26
train iter: 119
num of updates: 12000
vae loss: 0.50210
kl loss: 0.02644
a decoder loss: 0.47566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:27
train iter: 120
num of updates: 12100
vae loss: 0.49305
kl loss: 0.02592
a decoder loss: 0.46713
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:28
train iter: 121
num of updates: 12200
vae loss: 0.48662
kl loss: 0.02540
a decoder loss: 0.46122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:29
train iter: 122
num of updates: 12300
vae loss: 0.48420
kl loss: 0.02490
a decoder loss: 0.45930
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:30
train iter: 123
num of updates: 12400
vae loss: 0.47651
kl loss: 0.02438
a decoder loss: 0.45213
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:31
train iter: 124
num of updates: 12500
vae loss: 0.47146
kl loss: 0.02383
a decoder loss: 0.44763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:32
train iter: 125
num of updates: 12600
vae loss: 0.46547
kl loss: 0.02339
a decoder loss: 0.44207
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:33
train iter: 126
num of updates: 12700
vae loss: 0.46146
kl loss: 0.02290
a decoder loss: 0.43856
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:34
train iter: 127
num of updates: 12800
vae loss: 0.45641
kl loss: 0.02220
a decoder loss: 0.43421
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:35
train iter: 128
num of updates: 12900
vae loss: 0.45137
kl loss: 0.02174
a decoder loss: 0.42964
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:36
train iter: 129
num of updates: 13000
vae loss: 0.44930
kl loss: 0.02138
a decoder loss: 0.42792
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:38
train iter: 130
num of updates: 13100
vae loss: 0.44542
kl loss: 0.02080
a decoder loss: 0.42462
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:39
train iter: 131
num of updates: 13200
vae loss: 0.43994
kl loss: 0.02037
a decoder loss: 0.41956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:40
train iter: 132
num of updates: 13300
vae loss: 0.43571
kl loss: 0.01987
a decoder loss: 0.41584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:41
train iter: 133
num of updates: 13400
vae loss: 0.43358
kl loss: 0.01939
a decoder loss: 0.41419
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:42
train iter: 134
num of updates: 13500
vae loss: 0.42676
kl loss: 0.01883
a decoder loss: 0.40794
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:43
train iter: 135
num of updates: 13600
vae loss: 0.42342
kl loss: 0.01836
a decoder loss: 0.40506
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:44
train iter: 136
num of updates: 13700
vae loss: 0.41941
kl loss: 0.01786
a decoder loss: 0.40155
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:45
train iter: 137
num of updates: 13800
vae loss: 0.41618
kl loss: 0.01737
a decoder loss: 0.39881
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:46
train iter: 138
num of updates: 13900
vae loss: 0.41292
kl loss: 0.01695
a decoder loss: 0.39598
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:47
train iter: 139
num of updates: 14000
vae loss: 0.41002
kl loss: 0.01644
a decoder loss: 0.39357
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:48
train iter: 140
num of updates: 14100
vae loss: 0.40705
kl loss: 0.01591
a decoder loss: 0.39114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:49
train iter: 141
num of updates: 14200
vae loss: 0.40171
kl loss: 0.01546
a decoder loss: 0.38625
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:50
train iter: 142
num of updates: 14300
vae loss: 0.39852
kl loss: 0.01504
a decoder loss: 0.38349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:51
train iter: 143
num of updates: 14400
vae loss: 0.39789
kl loss: 0.01465
a decoder loss: 0.38323
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:52
train iter: 144
num of updates: 14500
vae loss: 0.39391
kl loss: 0.01421
a decoder loss: 0.37969
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:53
train iter: 145
num of updates: 14600
vae loss: 0.39008
kl loss: 0.01372
a decoder loss: 0.37637
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:54
train iter: 146
num of updates: 14700
vae loss: 0.38778
kl loss: 0.01332
a decoder loss: 0.37446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:55
train iter: 147
num of updates: 14800
vae loss: 0.38501
kl loss: 0.01289
a decoder loss: 0.37212
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:56
train iter: 148
num of updates: 14900
vae loss: 0.38399
kl loss: 0.01258
a decoder loss: 0.37140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:57
train iter: 149
num of updates: 15000
vae loss: 0.38024
kl loss: 0.01213
a decoder loss: 0.36811
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:58
train iter: 150
num of updates: 15100
vae loss: 0.37705
kl loss: 0.01167
a decoder loss: 0.36538
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:59
train iter: 151
num of updates: 15200
vae loss: 0.37415
kl loss: 0.01126
a decoder loss: 0.36289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:00
train iter: 152
num of updates: 15300
vae loss: 0.37265
kl loss: 0.01092
a decoder loss: 0.36173
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:01
train iter: 153
num of updates: 15400
vae loss: 0.37017
kl loss: 0.01056
a decoder loss: 0.35961
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:02
train iter: 154
num of updates: 15500
vae loss: 0.36716
kl loss: 0.01020
a decoder loss: 0.35697
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:03
train iter: 155
num of updates: 15600
vae loss: 0.36523
kl loss: 0.00988
a decoder loss: 0.35535
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:04
train iter: 156
num of updates: 15700
vae loss: 0.36139
kl loss: 0.00949
a decoder loss: 0.35191
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:05
train iter: 157
num of updates: 15800
vae loss: 0.35864
kl loss: 0.00917
a decoder loss: 0.34947
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:06
train iter: 158
num of updates: 15900
vae loss: 0.35666
kl loss: 0.00888
a decoder loss: 0.34778
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:07
train iter: 159
num of updates: 16000
vae loss: 0.35649
kl loss: 0.00858
a decoder loss: 0.34791
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:08
train iter: 160
num of updates: 16100
vae loss: 0.35250
kl loss: 0.00828
a decoder loss: 0.34422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:09
train iter: 161
num of updates: 16200
vae loss: 0.35011
kl loss: 0.00796
a decoder loss: 0.34214
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:10
train iter: 162
num of updates: 16300
vae loss: 0.34765
kl loss: 0.00770
a decoder loss: 0.33996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:11
train iter: 163
num of updates: 16400
vae loss: 0.34683
kl loss: 0.00742
a decoder loss: 0.33941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:12
train iter: 164
num of updates: 16500
vae loss: 0.34568
kl loss: 0.00720
a decoder loss: 0.33848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:13
train iter: 165
num of updates: 16600
vae loss: 0.34307
kl loss: 0.00697
a decoder loss: 0.33611
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:14
train iter: 166
num of updates: 16700
vae loss: 0.34034
kl loss: 0.00675
a decoder loss: 0.33359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:15
train iter: 167
num of updates: 16800
vae loss: 0.34013
kl loss: 0.00651
a decoder loss: 0.33361
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:16
train iter: 168
num of updates: 16900
vae loss: 0.33704
kl loss: 0.00630
a decoder loss: 0.33073
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:17
train iter: 169
num of updates: 17000
vae loss: 0.33549
kl loss: 0.00611
a decoder loss: 0.32939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:18
train iter: 170
num of updates: 17100
vae loss: 0.33302
kl loss: 0.00591
a decoder loss: 0.32711
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:19
train iter: 171
num of updates: 17200
vae loss: 0.33225
kl loss: 0.00575
a decoder loss: 0.32650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:20
train iter: 172
num of updates: 17300
vae loss: 0.32985
kl loss: 0.00554
a decoder loss: 0.32431
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:21
train iter: 173
num of updates: 17400
vae loss: 0.32947
kl loss: 0.00537
a decoder loss: 0.32409
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:22
train iter: 174
num of updates: 17500
vae loss: 0.32872
kl loss: 0.00524
a decoder loss: 0.32348
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:23
train iter: 175
num of updates: 17600
vae loss: 0.32591
kl loss: 0.00510
a decoder loss: 0.32081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:24
train iter: 176
num of updates: 17700
vae loss: 0.32528
kl loss: 0.00493
a decoder loss: 0.32035
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:25
train iter: 177
num of updates: 17800
vae loss: 0.32302
kl loss: 0.00481
a decoder loss: 0.31821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:26
train iter: 178
num of updates: 17900
vae loss: 0.32149
kl loss: 0.00470
a decoder loss: 0.31679
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:27
train iter: 179
num of updates: 18000
vae loss: 0.32009
kl loss: 0.00459
a decoder loss: 0.31550
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:28
train iter: 180
num of updates: 18100
vae loss: 0.31938
kl loss: 0.00446
a decoder loss: 0.31492
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:29
train iter: 181
num of updates: 18200
vae loss: 0.31770
kl loss: 0.00436
a decoder loss: 0.31334
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:31
train iter: 182
num of updates: 18300
vae loss: 0.31512
kl loss: 0.00422
a decoder loss: 0.31090
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:32
train iter: 183
num of updates: 18400
vae loss: 0.31574
kl loss: 0.00418
a decoder loss: 0.31157
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:33
train iter: 184
num of updates: 18500
vae loss: 0.31478
kl loss: 0.00407
a decoder loss: 0.31072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:34
train iter: 185
num of updates: 18600
vae loss: 0.31232
kl loss: 0.00399
a decoder loss: 0.30833
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:35
train iter: 186
num of updates: 18700
vae loss: 0.31216
kl loss: 0.00391
a decoder loss: 0.30825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:36
train iter: 187
num of updates: 18800
vae loss: 0.30993
kl loss: 0.00382
a decoder loss: 0.30611
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:37
train iter: 188
num of updates: 18900
vae loss: 0.30745
kl loss: 0.00374
a decoder loss: 0.30371
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:38
train iter: 189
num of updates: 19000
vae loss: 0.30878
kl loss: 0.00367
a decoder loss: 0.30511
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:39
train iter: 190
num of updates: 19100
vae loss: 0.30756
kl loss: 0.00360
a decoder loss: 0.30396
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:40
train iter: 191
num of updates: 19200
vae loss: 0.30585
kl loss: 0.00353
a decoder loss: 0.30232
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:41
train iter: 192
num of updates: 19300
vae loss: 0.30537
kl loss: 0.00347
a decoder loss: 0.30190
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:42
train iter: 193
num of updates: 19400
vae loss: 0.30251
kl loss: 0.00340
a decoder loss: 0.29911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:43
train iter: 194
num of updates: 19500
vae loss: 0.30329
kl loss: 0.00336
a decoder loss: 0.29993
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:44
train iter: 195
num of updates: 19600
vae loss: 0.30214
kl loss: 0.00330
a decoder loss: 0.29884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:45
train iter: 196
num of updates: 19700
vae loss: 0.29990
kl loss: 0.00322
a decoder loss: 0.29668
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:46
train iter: 197
num of updates: 19800
vae loss: 0.29988
kl loss: 0.00318
a decoder loss: 0.29670
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:47
train iter: 198
num of updates: 19900
vae loss: 0.29903
kl loss: 0.00311
a decoder loss: 0.29592
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:48
train iter: 199
num of updates: 20000
vae loss: 0.29698
kl loss: 0.00306
a decoder loss: 0.29392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:49
train iter: 200
num of updates: 20100
vae loss: 0.29741
kl loss: 0.00301
a decoder loss: 0.29440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:50
train iter: 201
num of updates: 20200
vae loss: 0.29536
kl loss: 0.00296
a decoder loss: 0.29240
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:51
train iter: 202
num of updates: 20300
vae loss: 0.29513
kl loss: 0.00292
a decoder loss: 0.29220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:52
train iter: 203
num of updates: 20400
vae loss: 0.29406
kl loss: 0.00287
a decoder loss: 0.29120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:53
train iter: 204
num of updates: 20500
vae loss: 0.29362
kl loss: 0.00283
a decoder loss: 0.29079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:54
train iter: 205
num of updates: 20600
vae loss: 0.29227
kl loss: 0.00278
a decoder loss: 0.28949
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:55
train iter: 206
num of updates: 20700
vae loss: 0.29334
kl loss: 0.00275
a decoder loss: 0.29059
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:56
train iter: 207
num of updates: 20800
vae loss: 0.29052
kl loss: 0.00269
a decoder loss: 0.28783
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:57
train iter: 208
num of updates: 20900
vae loss: 0.28904
kl loss: 0.00265
a decoder loss: 0.28639
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:58
train iter: 209
num of updates: 21000
vae loss: 0.29012
kl loss: 0.00261
a decoder loss: 0.28751
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:59
train iter: 210
num of updates: 21100
vae loss: 0.28920
kl loss: 0.00257
a decoder loss: 0.28663
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:00
train iter: 211
num of updates: 21200
vae loss: 0.28779
kl loss: 0.00254
a decoder loss: 0.28525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:01
train iter: 212
num of updates: 21300
vae loss: 0.28779
kl loss: 0.00249
a decoder loss: 0.28530
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:02
train iter: 213
num of updates: 21400
vae loss: 0.28725
kl loss: 0.00245
a decoder loss: 0.28479
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:03
train iter: 214
num of updates: 21500
vae loss: 0.28552
kl loss: 0.00241
a decoder loss: 0.28311
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:04
train iter: 215
num of updates: 21600
vae loss: 0.28561
kl loss: 0.00238
a decoder loss: 0.28323
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:05
train iter: 216
num of updates: 21700
vae loss: 0.28553
kl loss: 0.00234
a decoder loss: 0.28318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:06
train iter: 217
num of updates: 21800
vae loss: 0.28520
kl loss: 0.00230
a decoder loss: 0.28290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:07
train iter: 218
num of updates: 21900
vae loss: 0.28266
kl loss: 0.00227
a decoder loss: 0.28039
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:08
train iter: 219
num of updates: 22000
vae loss: 0.28195
kl loss: 0.00224
a decoder loss: 0.27971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:09
train iter: 220
num of updates: 22100
vae loss: 0.28251
kl loss: 0.00221
a decoder loss: 0.28030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:10
train iter: 221
num of updates: 22200
vae loss: 0.28106
kl loss: 0.00218
a decoder loss: 0.27888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:11
train iter: 222
num of updates: 22300
vae loss: 0.27916
kl loss: 0.00214
a decoder loss: 0.27702
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:12
train iter: 223
num of updates: 22400
vae loss: 0.28052
kl loss: 0.00211
a decoder loss: 0.27841
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:13
train iter: 224
num of updates: 22500
vae loss: 0.28093
kl loss: 0.00208
a decoder loss: 0.27884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:14
train iter: 225
num of updates: 22600
vae loss: 0.27995
kl loss: 0.00206
a decoder loss: 0.27789
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:15
train iter: 226
num of updates: 22700
vae loss: 0.27879
kl loss: 0.00203
a decoder loss: 0.27677
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:16
train iter: 227
num of updates: 22800
vae loss: 0.27788
kl loss: 0.00199
a decoder loss: 0.27589
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:17
train iter: 228
num of updates: 22900
vae loss: 0.27676
kl loss: 0.00197
a decoder loss: 0.27479
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:18
train iter: 229
num of updates: 23000
vae loss: 0.27614
kl loss: 0.00193
a decoder loss: 0.27420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:19
train iter: 230
num of updates: 23100
vae loss: 0.27597
kl loss: 0.00192
a decoder loss: 0.27405
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:20
train iter: 231
num of updates: 23200
vae loss: 0.27609
kl loss: 0.00190
a decoder loss: 0.27420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:21
train iter: 232
num of updates: 23300
vae loss: 0.27523
kl loss: 0.00187
a decoder loss: 0.27336
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:22
train iter: 233
num of updates: 23400
vae loss: 0.27443
kl loss: 0.00183
a decoder loss: 0.27260
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:23
train iter: 234
num of updates: 23500
vae loss: 0.27548
kl loss: 0.00181
a decoder loss: 0.27367
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:24
train iter: 235
num of updates: 23600
vae loss: 0.27377
kl loss: 0.00179
a decoder loss: 0.27198
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:25
train iter: 236
num of updates: 23700
vae loss: 0.27343
kl loss: 0.00176
a decoder loss: 0.27167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:26
train iter: 237
num of updates: 23800
vae loss: 0.27302
kl loss: 0.00174
a decoder loss: 0.27128
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:28
train iter: 238
num of updates: 23900
vae loss: 0.27173
kl loss: 0.00171
a decoder loss: 0.27002
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:29
train iter: 239
num of updates: 24000
vae loss: 0.27113
kl loss: 0.00168
a decoder loss: 0.26945
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:30
train iter: 240
num of updates: 24100
vae loss: 0.27192
kl loss: 0.00167
a decoder loss: 0.27025
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:31
train iter: 241
num of updates: 24200
vae loss: 0.27128
kl loss: 0.00165
a decoder loss: 0.26963
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:32
train iter: 242
num of updates: 24300
vae loss: 0.27082
kl loss: 0.00163
a decoder loss: 0.26919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:33
train iter: 243
num of updates: 24400
vae loss: 0.27069
kl loss: 0.00161
a decoder loss: 0.26909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:34
train iter: 244
num of updates: 24500
vae loss: 0.26893
kl loss: 0.00158
a decoder loss: 0.26735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:35
train iter: 245
num of updates: 24600
vae loss: 0.26924
kl loss: 0.00157
a decoder loss: 0.26767
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:36
train iter: 246
num of updates: 24700
vae loss: 0.26861
kl loss: 0.00154
a decoder loss: 0.26707
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:37
train iter: 247
num of updates: 24800
vae loss: 0.26899
kl loss: 0.00153
a decoder loss: 0.26746
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:38
train iter: 248
num of updates: 24900
vae loss: 0.26911
kl loss: 0.00150
a decoder loss: 0.26761
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:39
train iter: 249
num of updates: 25000
vae loss: 0.26746
kl loss: 0.00149
a decoder loss: 0.26597
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:40
train iter: 250
num of updates: 25100
vae loss: 0.26650
kl loss: 0.00146
a decoder loss: 0.26504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:41
train iter: 251
num of updates: 25200
vae loss: 0.26605
kl loss: 0.00145
a decoder loss: 0.26460
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:42
train iter: 252
num of updates: 25300
vae loss: 0.26762
kl loss: 0.00144
a decoder loss: 0.26619
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:43
train iter: 253
num of updates: 25400
vae loss: 0.26656
kl loss: 0.00141
a decoder loss: 0.26515
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:44
train iter: 254
num of updates: 25500
vae loss: 0.26576
kl loss: 0.00141
a decoder loss: 0.26435
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:45
train iter: 255
num of updates: 25600
vae loss: 0.26659
kl loss: 0.00138
a decoder loss: 0.26522
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:46
train iter: 256
num of updates: 25700
vae loss: 0.26447
kl loss: 0.00137
a decoder loss: 0.26310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:47
train iter: 257
num of updates: 25800
vae loss: 0.26455
kl loss: 0.00135
a decoder loss: 0.26320
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:48
train iter: 258
num of updates: 25900
vae loss: 0.26504
kl loss: 0.00132
a decoder loss: 0.26372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:49
train iter: 259
num of updates: 26000
vae loss: 0.26401
kl loss: 0.00131
a decoder loss: 0.26270
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:50
train iter: 260
num of updates: 26100
vae loss: 0.26309
kl loss: 0.00130
a decoder loss: 0.26179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:51
train iter: 261
num of updates: 26200
vae loss: 0.26309
kl loss: 0.00128
a decoder loss: 0.26181
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:52
train iter: 262
num of updates: 26300
vae loss: 0.26363
kl loss: 0.00127
a decoder loss: 0.26236
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:53
train iter: 263
num of updates: 26400
vae loss: 0.26266
kl loss: 0.00126
a decoder loss: 0.26140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:54
train iter: 264
num of updates: 26500
vae loss: 0.26283
kl loss: 0.00123
a decoder loss: 0.26160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:55
train iter: 265
num of updates: 26600
vae loss: 0.26339
kl loss: 0.00122
a decoder loss: 0.26216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:56
train iter: 266
num of updates: 26700
vae loss: 0.26198
kl loss: 0.00121
a decoder loss: 0.26077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:57
train iter: 267
num of updates: 26800
vae loss: 0.26178
kl loss: 0.00120
a decoder loss: 0.26058
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:58
train iter: 268
num of updates: 26900
vae loss: 0.26217
kl loss: 0.00118
a decoder loss: 0.26099
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:59
train iter: 269
num of updates: 27000
vae loss: 0.26207
kl loss: 0.00117
a decoder loss: 0.26090
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:00
train iter: 270
num of updates: 27100
vae loss: 0.26074
kl loss: 0.00116
a decoder loss: 0.25958
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:01
train iter: 271
num of updates: 27200
vae loss: 0.25998
kl loss: 0.00114
a decoder loss: 0.25884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:02
train iter: 272
num of updates: 27300
vae loss: 0.25991
kl loss: 0.00113
a decoder loss: 0.25878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:03
train iter: 273
num of updates: 27400
vae loss: 0.26023
kl loss: 0.00112
a decoder loss: 0.25911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:04
train iter: 274
num of updates: 27500
vae loss: 0.25945
kl loss: 0.00111
a decoder loss: 0.25834
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:05
train iter: 275
num of updates: 27600
vae loss: 0.26029
kl loss: 0.00109
a decoder loss: 0.25920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:06
train iter: 276
num of updates: 27700
vae loss: 0.26007
kl loss: 0.00108
a decoder loss: 0.25899
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:07
train iter: 277
num of updates: 27800
vae loss: 0.25928
kl loss: 0.00106
a decoder loss: 0.25822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:08
train iter: 278
num of updates: 27900
vae loss: 0.25886
kl loss: 0.00105
a decoder loss: 0.25781
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:09
train iter: 279
num of updates: 28000
vae loss: 0.25864
kl loss: 0.00106
a decoder loss: 0.25758
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:10
train iter: 280
num of updates: 28100
vae loss: 0.25805
kl loss: 0.00103
a decoder loss: 0.25701
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:11
train iter: 281
num of updates: 28200
vae loss: 0.25793
kl loss: 0.00102
a decoder loss: 0.25691
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:12
train iter: 282
num of updates: 28300
vae loss: 0.25835
kl loss: 0.00102
a decoder loss: 0.25733
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:13
train iter: 283
num of updates: 28400
vae loss: 0.25706
kl loss: 0.00100
a decoder loss: 0.25606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:14
train iter: 284
num of updates: 28500
vae loss: 0.25692
kl loss: 0.00099
a decoder loss: 0.25593
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:15
train iter: 285
num of updates: 28600
vae loss: 0.25721
kl loss: 0.00098
a decoder loss: 0.25622
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:16
train iter: 286
num of updates: 28700
vae loss: 0.25764
kl loss: 0.00097
a decoder loss: 0.25667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:17
train iter: 287
num of updates: 28800
vae loss: 0.25550
kl loss: 0.00096
a decoder loss: 0.25454
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:18
train iter: 288
num of updates: 28900
vae loss: 0.25588
kl loss: 0.00095
a decoder loss: 0.25493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:19
train iter: 289
num of updates: 29000
vae loss: 0.25684
kl loss: 0.00094
a decoder loss: 0.25589
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:21
train iter: 290
num of updates: 29100
vae loss: 0.25649
kl loss: 0.00093
a decoder loss: 0.25556
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:22
train iter: 291
num of updates: 29200
vae loss: 0.25575
kl loss: 0.00093
a decoder loss: 0.25482
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:23
train iter: 292
num of updates: 29300
vae loss: 0.25584
kl loss: 0.00091
a decoder loss: 0.25492
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:24
train iter: 293
num of updates: 29400
vae loss: 0.25483
kl loss: 0.00091
a decoder loss: 0.25392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:25
train iter: 294
num of updates: 29500
vae loss: 0.25584
kl loss: 0.00090
a decoder loss: 0.25495
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:26
train iter: 295
num of updates: 29600
vae loss: 0.25499
kl loss: 0.00089
a decoder loss: 0.25410
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:27
train iter: 296
num of updates: 29700
vae loss: 0.25518
kl loss: 0.00087
a decoder loss: 0.25431
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:28
train iter: 297
num of updates: 29800
vae loss: 0.25439
kl loss: 0.00087
a decoder loss: 0.25352
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:29
train iter: 298
num of updates: 29900
vae loss: 0.25374
kl loss: 0.00085
a decoder loss: 0.25288
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:30
train iter: 299
num of updates: 30000
vae loss: 0.25317
kl loss: 0.00085
a decoder loss: 0.25232
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:31
train iter: 300
num of updates: 30100
vae loss: 0.25463
kl loss: 0.00084
a decoder loss: 0.25379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:32
train iter: 301
num of updates: 30200
vae loss: 0.25468
kl loss: 0.00084
a decoder loss: 0.25384
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:33
train iter: 302
num of updates: 30300
vae loss: 0.25384
kl loss: 0.00083
a decoder loss: 0.25301
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:34
train iter: 303
num of updates: 30400
vae loss: 0.25339
kl loss: 0.00082
a decoder loss: 0.25257
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:35
train iter: 304
num of updates: 30500
vae loss: 0.25372
kl loss: 0.00081
a decoder loss: 0.25291
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:36
train iter: 305
num of updates: 30600
vae loss: 0.25363
kl loss: 0.00080
a decoder loss: 0.25283
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:37
train iter: 306
num of updates: 30700
vae loss: 0.25260
kl loss: 0.00080
a decoder loss: 0.25180
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:38
train iter: 307
num of updates: 30800
vae loss: 0.25212
kl loss: 0.00079
a decoder loss: 0.25133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:39
train iter: 308
num of updates: 30900
vae loss: 0.25250
kl loss: 0.00078
a decoder loss: 0.25172
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:40
train iter: 309
num of updates: 31000
vae loss: 0.25250
kl loss: 0.00077
a decoder loss: 0.25173
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:41
train iter: 310
num of updates: 31100
vae loss: 0.25287
kl loss: 0.00076
a decoder loss: 0.25210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:42
train iter: 311
num of updates: 31200
vae loss: 0.25200
kl loss: 0.00076
a decoder loss: 0.25124
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:43
train iter: 312
num of updates: 31300
vae loss: 0.25237
kl loss: 0.00076
a decoder loss: 0.25161
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:44
train iter: 313
num of updates: 31400
vae loss: 0.25179
kl loss: 0.00075
a decoder loss: 0.25105
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:45
train iter: 314
num of updates: 31500
vae loss: 0.25214
kl loss: 0.00074
a decoder loss: 0.25140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:46
train iter: 315
num of updates: 31600
vae loss: 0.25152
kl loss: 0.00074
a decoder loss: 0.25078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:47
train iter: 316
num of updates: 31700
vae loss: 0.25148
kl loss: 0.00073
a decoder loss: 0.25075
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:48
train iter: 317
num of updates: 31800
vae loss: 0.25178
kl loss: 0.00072
a decoder loss: 0.25106
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:49
train iter: 318
num of updates: 31900
vae loss: 0.25133
kl loss: 0.00072
a decoder loss: 0.25061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:50
train iter: 319
num of updates: 32000
vae loss: 0.25160
kl loss: 0.00071
a decoder loss: 0.25089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:51
train iter: 320
num of updates: 32100
vae loss: 0.25124
kl loss: 0.00070
a decoder loss: 0.25054
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:52
train iter: 321
num of updates: 32200
vae loss: 0.25109
kl loss: 0.00070
a decoder loss: 0.25039
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:53
train iter: 322
num of updates: 32300
vae loss: 0.25072
kl loss: 0.00069
a decoder loss: 0.25003
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:54
train iter: 323
num of updates: 32400
vae loss: 0.25102
kl loss: 0.00069
a decoder loss: 0.25033
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:55
train iter: 324
num of updates: 32500
vae loss: 0.25050
kl loss: 0.00068
a decoder loss: 0.24982
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:56
train iter: 325
num of updates: 32600
vae loss: 0.25036
kl loss: 0.00067
a decoder loss: 0.24968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:57
train iter: 326
num of updates: 32700
vae loss: 0.25054
kl loss: 0.00067
a decoder loss: 0.24987
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:58
train iter: 327
num of updates: 32800
vae loss: 0.25014
kl loss: 0.00066
a decoder loss: 0.24948
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:59
train iter: 328
num of updates: 32900
vae loss: 0.25027
kl loss: 0.00066
a decoder loss: 0.24961
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:00
train iter: 329
num of updates: 33000
vae loss: 0.24997
kl loss: 0.00065
a decoder loss: 0.24932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:01
train iter: 330
num of updates: 33100
vae loss: 0.24911
kl loss: 0.00065
a decoder loss: 0.24846
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:02
train iter: 331
num of updates: 33200
vae loss: 0.25031
kl loss: 0.00064
a decoder loss: 0.24966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:03
train iter: 332
num of updates: 33300
vae loss: 0.24922
kl loss: 0.00064
a decoder loss: 0.24858
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:04
train iter: 333
num of updates: 33400
vae loss: 0.24891
kl loss: 0.00063
a decoder loss: 0.24828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:05
train iter: 334
num of updates: 33500
vae loss: 0.24887
kl loss: 0.00062
a decoder loss: 0.24825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:06
train iter: 335
num of updates: 33600
vae loss: 0.24789
kl loss: 0.00062
a decoder loss: 0.24727
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:07
train iter: 336
num of updates: 33700
vae loss: 0.24807
kl loss: 0.00062
a decoder loss: 0.24746
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:08
train iter: 337
num of updates: 33800
vae loss: 0.24789
kl loss: 0.00061
a decoder loss: 0.24728
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:09
train iter: 338
num of updates: 33900
vae loss: 0.24883
kl loss: 0.00060
a decoder loss: 0.24822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:10
train iter: 339
num of updates: 34000
vae loss: 0.24942
kl loss: 0.00060
a decoder loss: 0.24882
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:11
train iter: 340
num of updates: 34100
vae loss: 0.24816
kl loss: 0.00060
a decoder loss: 0.24756
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:12
train iter: 341
num of updates: 34200
vae loss: 0.24875
kl loss: 0.00059
a decoder loss: 0.24816
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:13
train iter: 342
num of updates: 34300
vae loss: 0.24852
kl loss: 0.00059
a decoder loss: 0.24793
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:14
train iter: 343
num of updates: 34400
vae loss: 0.24822
kl loss: 0.00058
a decoder loss: 0.24763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:15
train iter: 344
num of updates: 34500
vae loss: 0.24771
kl loss: 0.00058
a decoder loss: 0.24713
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:16
train iter: 345
num of updates: 34600
vae loss: 0.24896
kl loss: 0.00057
a decoder loss: 0.24838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:18
train iter: 346
num of updates: 34700
vae loss: 0.24731
kl loss: 0.00057
a decoder loss: 0.24674
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:19
train iter: 347
num of updates: 34800
vae loss: 0.24751
kl loss: 0.00057
a decoder loss: 0.24694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:20
train iter: 348
num of updates: 34900
vae loss: 0.24830
kl loss: 0.00056
a decoder loss: 0.24773
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:21
train iter: 349
num of updates: 35000
vae loss: 0.24754
kl loss: 0.00055
a decoder loss: 0.24698
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:22
train iter: 350
num of updates: 35100
vae loss: 0.24779
kl loss: 0.00056
a decoder loss: 0.24723
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:23
train iter: 351
num of updates: 35200
vae loss: 0.24709
kl loss: 0.00055
a decoder loss: 0.24654
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:24
train iter: 352
num of updates: 35300
vae loss: 0.24737
kl loss: 0.00054
a decoder loss: 0.24683
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:25
train iter: 353
num of updates: 35400
vae loss: 0.24709
kl loss: 0.00054
a decoder loss: 0.24655
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:26
train iter: 354
num of updates: 35500
vae loss: 0.24712
kl loss: 0.00054
a decoder loss: 0.24658
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:27
train iter: 355
num of updates: 35600
vae loss: 0.24599
kl loss: 0.00053
a decoder loss: 0.24546
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:28
train iter: 356
num of updates: 35700
vae loss: 0.24686
kl loss: 0.00053
a decoder loss: 0.24633
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:29
train iter: 357
num of updates: 35800
vae loss: 0.24616
kl loss: 0.00053
a decoder loss: 0.24563
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:30
train iter: 358
num of updates: 35900
vae loss: 0.24696
kl loss: 0.00052
a decoder loss: 0.24644
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:31
train iter: 359
num of updates: 36000
vae loss: 0.24681
kl loss: 0.00052
a decoder loss: 0.24629
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:32
train iter: 360
num of updates: 36100
vae loss: 0.24498
kl loss: 0.00051
a decoder loss: 0.24447
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:33
train iter: 361
num of updates: 36200
vae loss: 0.24651
kl loss: 0.00051
a decoder loss: 0.24600
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:34
train iter: 362
num of updates: 36300
vae loss: 0.24640
kl loss: 0.00051
a decoder loss: 0.24589
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:35
train iter: 363
num of updates: 36400
vae loss: 0.24584
kl loss: 0.00051
a decoder loss: 0.24534
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:36
train iter: 364
num of updates: 36500
vae loss: 0.24664
kl loss: 0.00050
a decoder loss: 0.24614
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:37
train iter: 365
num of updates: 36600
vae loss: 0.24586
kl loss: 0.00050
a decoder loss: 0.24537
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:38
train iter: 366
num of updates: 36700
vae loss: 0.24585
kl loss: 0.00049
a decoder loss: 0.24537
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:39
train iter: 367
num of updates: 36800
vae loss: 0.24657
kl loss: 0.00049
a decoder loss: 0.24608
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:40
train iter: 368
num of updates: 36900
vae loss: 0.24608
kl loss: 0.00049
a decoder loss: 0.24560
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:41
train iter: 369
num of updates: 37000
vae loss: 0.24615
kl loss: 0.00048
a decoder loss: 0.24567
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:42
train iter: 370
num of updates: 37100
vae loss: 0.24542
kl loss: 0.00048
a decoder loss: 0.24494
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:43
train iter: 371
num of updates: 37200
vae loss: 0.24601
kl loss: 0.00048
a decoder loss: 0.24553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:44
train iter: 372
num of updates: 37300
vae loss: 0.24588
kl loss: 0.00048
a decoder loss: 0.24541
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:45
train iter: 373
num of updates: 37400
vae loss: 0.24577
kl loss: 0.00047
a decoder loss: 0.24530
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:46
train iter: 374
num of updates: 37500
vae loss: 0.24447
kl loss: 0.00047
a decoder loss: 0.24400
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:47
train iter: 375
num of updates: 37600
vae loss: 0.24526
kl loss: 0.00046
a decoder loss: 0.24480
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:48
train iter: 376
num of updates: 37700
vae loss: 0.24486
kl loss: 0.00046
a decoder loss: 0.24440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:49
train iter: 377
num of updates: 37800
vae loss: 0.24493
kl loss: 0.00046
a decoder loss: 0.24447
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:50
train iter: 378
num of updates: 37900
vae loss: 0.24469
kl loss: 0.00045
a decoder loss: 0.24424
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:51
train iter: 379
num of updates: 38000
vae loss: 0.24403
kl loss: 0.00045
a decoder loss: 0.24358
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:52
train iter: 380
num of updates: 38100
vae loss: 0.24613
kl loss: 0.00045
a decoder loss: 0.24567
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:53
train iter: 381
num of updates: 38200
vae loss: 0.24475
kl loss: 0.00045
a decoder loss: 0.24430
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:54
train iter: 382
num of updates: 38300
vae loss: 0.24459
kl loss: 0.00044
a decoder loss: 0.24414
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:55
train iter: 383
num of updates: 38400
vae loss: 0.24394
kl loss: 0.00044
a decoder loss: 0.24350
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:56
train iter: 384
num of updates: 38500
vae loss: 0.24540
kl loss: 0.00044
a decoder loss: 0.24496
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:57
train iter: 385
num of updates: 38600
vae loss: 0.24458
kl loss: 0.00043
a decoder loss: 0.24415
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:58
train iter: 386
num of updates: 38700
vae loss: 0.24350
kl loss: 0.00043
a decoder loss: 0.24306
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:59
train iter: 387
num of updates: 38800
vae loss: 0.24394
kl loss: 0.00043
a decoder loss: 0.24351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:00
train iter: 388
num of updates: 38900
vae loss: 0.24483
kl loss: 0.00043
a decoder loss: 0.24440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:01
train iter: 389
num of updates: 39000
vae loss: 0.24474
kl loss: 0.00043
a decoder loss: 0.24431
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:02
train iter: 390
num of updates: 39100
vae loss: 0.24407
kl loss: 0.00042
a decoder loss: 0.24365
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:03
train iter: 391
num of updates: 39200
vae loss: 0.24362
kl loss: 0.00042
a decoder loss: 0.24320
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:04
train iter: 392
num of updates: 39300
vae loss: 0.24315
kl loss: 0.00042
a decoder loss: 0.24273
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:05
train iter: 393
num of updates: 39400
vae loss: 0.24389
kl loss: 0.00041
a decoder loss: 0.24348
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:06
train iter: 394
num of updates: 39500
vae loss: 0.24310
kl loss: 0.00041
a decoder loss: 0.24268
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:08
train iter: 395
num of updates: 39600
vae loss: 0.24389
kl loss: 0.00041
a decoder loss: 0.24348
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:09
train iter: 396
num of updates: 39700
vae loss: 0.24304
kl loss: 0.00041
a decoder loss: 0.24264
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:10
train iter: 397
num of updates: 39800
vae loss: 0.24386
kl loss: 0.00041
a decoder loss: 0.24345
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:11
train iter: 398
num of updates: 39900
vae loss: 0.24277
kl loss: 0.00040
a decoder loss: 0.24237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:12
train iter: 399
num of updates: 40000
vae loss: 0.24299
kl loss: 0.00040
a decoder loss: 0.24260
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:13
train iter: 400
num of updates: 40100
vae loss: 0.24315
kl loss: 0.00040
a decoder loss: 0.24275
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:14
train iter: 401
num of updates: 40200
vae loss: 0.24305
kl loss: 0.00039
a decoder loss: 0.24266
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:15
train iter: 402
num of updates: 40300
vae loss: 0.24320
kl loss: 0.00039
a decoder loss: 0.24281
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:16
train iter: 403
num of updates: 40400
vae loss: 0.24247
kl loss: 0.00039
a decoder loss: 0.24208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:17
train iter: 404
num of updates: 40500
vae loss: 0.24239
kl loss: 0.00039
a decoder loss: 0.24200
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:18
train iter: 405
num of updates: 40600
vae loss: 0.24302
kl loss: 0.00039
a decoder loss: 0.24263
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:19
train iter: 406
num of updates: 40700
vae loss: 0.24335
kl loss: 0.00039
a decoder loss: 0.24297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:20
train iter: 407
num of updates: 40800
vae loss: 0.24307
kl loss: 0.00038
a decoder loss: 0.24268
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:21
train iter: 408
num of updates: 40900
vae loss: 0.24258
kl loss: 0.00038
a decoder loss: 0.24220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:22
train iter: 409
num of updates: 41000
vae loss: 0.24275
kl loss: 0.00038
a decoder loss: 0.24237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:23
train iter: 410
num of updates: 41100
vae loss: 0.24300
kl loss: 0.00038
a decoder loss: 0.24262
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:24
train iter: 411
num of updates: 41200
vae loss: 0.24340
kl loss: 0.00037
a decoder loss: 0.24302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:25
train iter: 412
num of updates: 41300
vae loss: 0.24286
kl loss: 0.00037
a decoder loss: 0.24249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:26
train iter: 413
num of updates: 41400
vae loss: 0.24123
kl loss: 0.00037
a decoder loss: 0.24086
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:27
train iter: 414
num of updates: 41500
vae loss: 0.24301
kl loss: 0.00037
a decoder loss: 0.24264
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:28
train iter: 415
num of updates: 41600
vae loss: 0.24289
kl loss: 0.00037
a decoder loss: 0.24252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:29
train iter: 416
num of updates: 41700
vae loss: 0.24199
kl loss: 0.00036
a decoder loss: 0.24163
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:30
train iter: 417
num of updates: 41800
vae loss: 0.24190
kl loss: 0.00036
a decoder loss: 0.24153
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:31
train iter: 418
num of updates: 41900
vae loss: 0.24269
kl loss: 0.00036
a decoder loss: 0.24234
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:32
train iter: 419
num of updates: 42000
vae loss: 0.24216
kl loss: 0.00036
a decoder loss: 0.24180
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:33
train iter: 420
num of updates: 42100
vae loss: 0.24177
kl loss: 0.00035
a decoder loss: 0.24142
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:34
train iter: 421
num of updates: 42200
vae loss: 0.24318
kl loss: 0.00036
a decoder loss: 0.24283
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:35
train iter: 422
num of updates: 42300
vae loss: 0.24255
kl loss: 0.00035
a decoder loss: 0.24220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:36
train iter: 423
num of updates: 42400
vae loss: 0.24110
kl loss: 0.00035
a decoder loss: 0.24075
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:37
train iter: 424
num of updates: 42500
vae loss: 0.24201
kl loss: 0.00035
a decoder loss: 0.24166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:38
train iter: 425
num of updates: 42600
vae loss: 0.24178
kl loss: 0.00035
a decoder loss: 0.24143
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:39
train iter: 426
num of updates: 42700
vae loss: 0.24132
kl loss: 0.00034
a decoder loss: 0.24098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:40
train iter: 427
num of updates: 42800
vae loss: 0.24177
kl loss: 0.00034
a decoder loss: 0.24143
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:41
train iter: 428
num of updates: 42900
vae loss: 0.24209
kl loss: 0.00034
a decoder loss: 0.24175
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:42
train iter: 429
num of updates: 43000
vae loss: 0.24204
kl loss: 0.00034
a decoder loss: 0.24170
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:43
train iter: 430
num of updates: 43100
vae loss: 0.24119
kl loss: 0.00034
a decoder loss: 0.24085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:44
train iter: 431
num of updates: 43200
vae loss: 0.24098
kl loss: 0.00033
a decoder loss: 0.24065
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:45
train iter: 432
num of updates: 43300
vae loss: 0.24136
kl loss: 0.00033
a decoder loss: 0.24103
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:46
train iter: 433
num of updates: 43400
vae loss: 0.24112
kl loss: 0.00033
a decoder loss: 0.24079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:47
train iter: 434
num of updates: 43500
vae loss: 0.24160
kl loss: 0.00033
a decoder loss: 0.24127
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:48
train iter: 435
num of updates: 43600
vae loss: 0.24051
kl loss: 0.00033
a decoder loss: 0.24019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:49
train iter: 436
num of updates: 43700
vae loss: 0.24174
kl loss: 0.00033
a decoder loss: 0.24141
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:50
train iter: 437
num of updates: 43800
vae loss: 0.24145
kl loss: 0.00033
a decoder loss: 0.24113
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:51
train iter: 438
num of updates: 43900
vae loss: 0.24197
kl loss: 0.00033
a decoder loss: 0.24164
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:52
train iter: 439
num of updates: 44000
vae loss: 0.24109
kl loss: 0.00032
a decoder loss: 0.24076
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:53
train iter: 440
num of updates: 44100
vae loss: 0.24161
kl loss: 0.00032
a decoder loss: 0.24129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:54
train iter: 441
num of updates: 44200
vae loss: 0.24150
kl loss: 0.00032
a decoder loss: 0.24118
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:55
train iter: 442
num of updates: 44300
vae loss: 0.24000
kl loss: 0.00032
a decoder loss: 0.23969
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:56
train iter: 443
num of updates: 44400
vae loss: 0.24163
kl loss: 0.00032
a decoder loss: 0.24131
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:57
train iter: 444
num of updates: 44500
vae loss: 0.24078
kl loss: 0.00031
a decoder loss: 0.24047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:58
train iter: 445
num of updates: 44600
vae loss: 0.24140
kl loss: 0.00031
a decoder loss: 0.24108
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:59
train iter: 446
num of updates: 44700
vae loss: 0.24109
kl loss: 0.00031
a decoder loss: 0.24078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:00
train iter: 447
num of updates: 44800
vae loss: 0.24172
kl loss: 0.00031
a decoder loss: 0.24141
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:01
train iter: 448
num of updates: 44900
vae loss: 0.24052
kl loss: 0.00031
a decoder loss: 0.24021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:02
train iter: 449
num of updates: 45000
vae loss: 0.24184
kl loss: 0.00031
a decoder loss: 0.24154
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:03
train iter: 450
num of updates: 45100
vae loss: 0.24142
kl loss: 0.00030
a decoder loss: 0.24112
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:04
train iter: 451
num of updates: 45200
vae loss: 0.24082
kl loss: 0.00030
a decoder loss: 0.24052
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:05
train iter: 452
num of updates: 45300
vae loss: 0.24061
kl loss: 0.00030
a decoder loss: 0.24031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:06
train iter: 453
num of updates: 45400
vae loss: 0.24039
kl loss: 0.00030
a decoder loss: 0.24009
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:07
train iter: 454
num of updates: 45500
vae loss: 0.24062
kl loss: 0.00030
a decoder loss: 0.24032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:08
train iter: 455
num of updates: 45600
vae loss: 0.24026
kl loss: 0.00030
a decoder loss: 0.23996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:10
train iter: 456
num of updates: 45700
vae loss: 0.24066
kl loss: 0.00030
a decoder loss: 0.24036
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:11
train iter: 457
num of updates: 45800
vae loss: 0.23957
kl loss: 0.00029
a decoder loss: 0.23928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:12
train iter: 458
num of updates: 45900
vae loss: 0.24087
kl loss: 0.00029
a decoder loss: 0.24057
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:13
train iter: 459
num of updates: 46000
vae loss: 0.24033
kl loss: 0.00029
a decoder loss: 0.24004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:14
train iter: 460
num of updates: 46100
vae loss: 0.24049
kl loss: 0.00029
a decoder loss: 0.24020
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:15
train iter: 461
num of updates: 46200
vae loss: 0.23992
kl loss: 0.00029
a decoder loss: 0.23963
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:16
train iter: 462
num of updates: 46300
vae loss: 0.24079
kl loss: 0.00029
a decoder loss: 0.24050
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:17
train iter: 463
num of updates: 46400
vae loss: 0.23947
kl loss: 0.00029
a decoder loss: 0.23919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:18
train iter: 464
num of updates: 46500
vae loss: 0.24067
kl loss: 0.00029
a decoder loss: 0.24038
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:19
train iter: 465
num of updates: 46600
vae loss: 0.24015
kl loss: 0.00028
a decoder loss: 0.23986
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:20
train iter: 466
num of updates: 46700
vae loss: 0.23999
kl loss: 0.00028
a decoder loss: 0.23971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:21
train iter: 467
num of updates: 46800
vae loss: 0.23941
kl loss: 0.00028
a decoder loss: 0.23913
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:22
train iter: 468
num of updates: 46900
vae loss: 0.23898
kl loss: 0.00028
a decoder loss: 0.23870
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:23
train iter: 469
num of updates: 47000
vae loss: 0.23904
kl loss: 0.00028
a decoder loss: 0.23876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:24
train iter: 470
num of updates: 47100
vae loss: 0.24009
kl loss: 0.00028
a decoder loss: 0.23981
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:25
train iter: 471
num of updates: 47200
vae loss: 0.24048
kl loss: 0.00028
a decoder loss: 0.24020
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:26
train iter: 472
num of updates: 47300
vae loss: 0.23967
kl loss: 0.00028
a decoder loss: 0.23939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:27
train iter: 473
num of updates: 47400
vae loss: 0.24007
kl loss: 0.00027
a decoder loss: 0.23980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:28
train iter: 474
num of updates: 47500
vae loss: 0.24023
kl loss: 0.00027
a decoder loss: 0.23996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:29
train iter: 475
num of updates: 47600
vae loss: 0.23954
kl loss: 0.00027
a decoder loss: 0.23927
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:30
train iter: 476
num of updates: 47700
vae loss: 0.23898
kl loss: 0.00027
a decoder loss: 0.23871
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:31
train iter: 477
num of updates: 47800
vae loss: 0.23913
kl loss: 0.00027
a decoder loss: 0.23886
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:32
train iter: 478
num of updates: 47900
vae loss: 0.23960
kl loss: 0.00027
a decoder loss: 0.23933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:33
train iter: 479
num of updates: 48000
vae loss: 0.23997
kl loss: 0.00027
a decoder loss: 0.23970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:34
train iter: 480
num of updates: 48100
vae loss: 0.23917
kl loss: 0.00027
a decoder loss: 0.23890
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:35
train iter: 481
num of updates: 48200
vae loss: 0.23851
kl loss: 0.00027
a decoder loss: 0.23824
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:36
train iter: 482
num of updates: 48300
vae loss: 0.23980
kl loss: 0.00026
a decoder loss: 0.23953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:37
train iter: 483
num of updates: 48400
vae loss: 0.23972
kl loss: 0.00026
a decoder loss: 0.23946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:38
train iter: 484
num of updates: 48500
vae loss: 0.24045
kl loss: 0.00026
a decoder loss: 0.24019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:39
train iter: 485
num of updates: 48600
vae loss: 0.23791
kl loss: 0.00026
a decoder loss: 0.23765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:40
train iter: 486
num of updates: 48700
vae loss: 0.23944
kl loss: 0.00026
a decoder loss: 0.23918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:41
train iter: 487
num of updates: 48800
vae loss: 0.23935
kl loss: 0.00026
a decoder loss: 0.23909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:42
train iter: 488
num of updates: 48900
vae loss: 0.23928
kl loss: 0.00026
a decoder loss: 0.23902
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:43
train iter: 489
num of updates: 49000
vae loss: 0.23933
kl loss: 0.00026
a decoder loss: 0.23907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:44
train iter: 490
num of updates: 49100
vae loss: 0.23884
kl loss: 0.00026
a decoder loss: 0.23858
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:45
train iter: 491
num of updates: 49200
vae loss: 0.23930
kl loss: 0.00026
a decoder loss: 0.23904
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:46
train iter: 492
num of updates: 49300
vae loss: 0.23847
kl loss: 0.00025
a decoder loss: 0.23821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:47
train iter: 493
num of updates: 49400
vae loss: 0.23815
kl loss: 0.00025
a decoder loss: 0.23790
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:48
train iter: 494
num of updates: 49500
vae loss: 0.23900
kl loss: 0.00025
a decoder loss: 0.23875
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:49
train iter: 495
num of updates: 49600
vae loss: 0.23908
kl loss: 0.00025
a decoder loss: 0.23884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:50
train iter: 496
num of updates: 49700
vae loss: 0.23855
kl loss: 0.00025
a decoder loss: 0.23830
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:51
train iter: 497
num of updates: 49800
vae loss: 0.23914
kl loss: 0.00025
a decoder loss: 0.23889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:52
train iter: 498
num of updates: 49900
vae loss: 0.23923
kl loss: 0.00025
a decoder loss: 0.23898
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:53
train iter: 499
num of updates: 50000
vae loss: 0.23878
kl loss: 0.00024
a decoder loss: 0.23854
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:54
train iter: 500
num of updates: 50100
vae loss: 0.23986
kl loss: 0.00025
a decoder loss: 0.23961
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:55
train iter: 501
num of updates: 50200
vae loss: 0.23846
kl loss: 0.00024
a decoder loss: 0.23822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:56
train iter: 502
num of updates: 50300
vae loss: 0.23840
kl loss: 0.00024
a decoder loss: 0.23815
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:57
train iter: 503
num of updates: 50400
vae loss: 0.23866
kl loss: 0.00024
a decoder loss: 0.23842
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:58
train iter: 504
num of updates: 50500
vae loss: 0.23800
kl loss: 0.00024
a decoder loss: 0.23776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:59
train iter: 505
num of updates: 50600
vae loss: 0.23869
kl loss: 0.00024
a decoder loss: 0.23845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:00
train iter: 506
num of updates: 50700
vae loss: 0.23680
kl loss: 0.00024
a decoder loss: 0.23656
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:01
train iter: 507
num of updates: 50800
vae loss: 0.23867
kl loss: 0.00024
a decoder loss: 0.23843
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:02
train iter: 508
num of updates: 50900
vae loss: 0.23898
kl loss: 0.00024
a decoder loss: 0.23875
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:03
train iter: 509
num of updates: 51000
vae loss: 0.23904
kl loss: 0.00024
a decoder loss: 0.23880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:04
train iter: 510
num of updates: 51100
vae loss: 0.23833
kl loss: 0.00024
a decoder loss: 0.23810
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:05
train iter: 511
num of updates: 51200
vae loss: 0.23803
kl loss: 0.00024
a decoder loss: 0.23779
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:06
train iter: 512
num of updates: 51300
vae loss: 0.23810
kl loss: 0.00023
a decoder loss: 0.23786
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:08
train iter: 513
num of updates: 51400
vae loss: 0.23753
kl loss: 0.00023
a decoder loss: 0.23730
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:09
train iter: 514
num of updates: 51500
vae loss: 0.23906
kl loss: 0.00023
a decoder loss: 0.23883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:10
train iter: 515
num of updates: 51600
vae loss: 0.23910
kl loss: 0.00023
a decoder loss: 0.23886
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:11
train iter: 516
num of updates: 51700
vae loss: 0.23867
kl loss: 0.00023
a decoder loss: 0.23844
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:12
train iter: 517
num of updates: 51800
vae loss: 0.23773
kl loss: 0.00023
a decoder loss: 0.23750
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:13
train iter: 518
num of updates: 51900
vae loss: 0.23809
kl loss: 0.00023
a decoder loss: 0.23786
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:14
train iter: 519
num of updates: 52000
vae loss: 0.23790
kl loss: 0.00023
a decoder loss: 0.23768
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:15
train iter: 520
num of updates: 52100
vae loss: 0.23788
kl loss: 0.00023
a decoder loss: 0.23765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:16
train iter: 521
num of updates: 52200
vae loss: 0.23814
kl loss: 0.00023
a decoder loss: 0.23791
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:17
train iter: 522
num of updates: 52300
vae loss: 0.23777
kl loss: 0.00023
a decoder loss: 0.23754
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:18
train iter: 523
num of updates: 52400
vae loss: 0.23823
kl loss: 0.00023
a decoder loss: 0.23800
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:19
train iter: 524
num of updates: 52500
vae loss: 0.23797
kl loss: 0.00022
a decoder loss: 0.23775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:20
train iter: 525
num of updates: 52600
vae loss: 0.23725
kl loss: 0.00023
a decoder loss: 0.23703
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:21
train iter: 526
num of updates: 52700
vae loss: 0.23787
kl loss: 0.00022
a decoder loss: 0.23765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:22
train iter: 527
num of updates: 52800
vae loss: 0.23848
kl loss: 0.00022
a decoder loss: 0.23826
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:23
train iter: 528
num of updates: 52900
vae loss: 0.23775
kl loss: 0.00022
a decoder loss: 0.23753
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:24
train iter: 529
num of updates: 53000
vae loss: 0.23761
kl loss: 0.00022
a decoder loss: 0.23739
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:25
train iter: 530
num of updates: 53100
vae loss: 0.23695
kl loss: 0.00022
a decoder loss: 0.23673
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:26
train iter: 531
num of updates: 53200
vae loss: 0.23690
kl loss: 0.00022
a decoder loss: 0.23668
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:27
train iter: 532
num of updates: 53300
vae loss: 0.23745
kl loss: 0.00022
a decoder loss: 0.23723
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:28
train iter: 533
num of updates: 53400
vae loss: 0.23744
kl loss: 0.00022
a decoder loss: 0.23723
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:29
train iter: 534
num of updates: 53500
vae loss: 0.23798
kl loss: 0.00022
a decoder loss: 0.23776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:30
train iter: 535
num of updates: 53600
vae loss: 0.23792
kl loss: 0.00022
a decoder loss: 0.23770
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:31
train iter: 536
num of updates: 53700
vae loss: 0.23720
kl loss: 0.00022
a decoder loss: 0.23699
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:32
train iter: 537
num of updates: 53800
vae loss: 0.23796
kl loss: 0.00021
a decoder loss: 0.23775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:33
train iter: 538
num of updates: 53900
vae loss: 0.23773
kl loss: 0.00021
a decoder loss: 0.23752
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:34
train iter: 539
num of updates: 54000
vae loss: 0.23780
kl loss: 0.00021
a decoder loss: 0.23759
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:35
train iter: 540
num of updates: 54100
vae loss: 0.23795
kl loss: 0.00021
a decoder loss: 0.23773
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:36
train iter: 541
num of updates: 54200
vae loss: 0.23880
kl loss: 0.00021
a decoder loss: 0.23859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:37
train iter: 542
num of updates: 54300
vae loss: 0.23697
kl loss: 0.00021
a decoder loss: 0.23676
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:38
train iter: 543
num of updates: 54400
vae loss: 0.23718
kl loss: 0.00021
a decoder loss: 0.23697
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:39
train iter: 544
num of updates: 54500
vae loss: 0.23765
kl loss: 0.00021
a decoder loss: 0.23744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:40
train iter: 545
num of updates: 54600
vae loss: 0.23736
kl loss: 0.00021
a decoder loss: 0.23715
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:41
train iter: 546
num of updates: 54700
vae loss: 0.23811
kl loss: 0.00021
a decoder loss: 0.23790
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:42
train iter: 547
num of updates: 54800
vae loss: 0.23781
kl loss: 0.00021
a decoder loss: 0.23760
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:43
train iter: 548
num of updates: 54900
vae loss: 0.23655
kl loss: 0.00021
a decoder loss: 0.23634
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:44
train iter: 549
num of updates: 55000
vae loss: 0.23842
kl loss: 0.00021
a decoder loss: 0.23821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:45
train iter: 550
num of updates: 55100
vae loss: 0.23793
kl loss: 0.00021
a decoder loss: 0.23772
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:46
train iter: 551
num of updates: 55200
vae loss: 0.23726
kl loss: 0.00021
a decoder loss: 0.23705
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:47
train iter: 552
num of updates: 55300
vae loss: 0.23687
kl loss: 0.00020
a decoder loss: 0.23667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:48
train iter: 553
num of updates: 55400
vae loss: 0.23795
kl loss: 0.00021
a decoder loss: 0.23775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:49
train iter: 554
num of updates: 55500
vae loss: 0.23669
kl loss: 0.00020
a decoder loss: 0.23649
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:50
train iter: 555
num of updates: 55600
vae loss: 0.23848
kl loss: 0.00020
a decoder loss: 0.23828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:51
train iter: 556
num of updates: 55700
vae loss: 0.23661
kl loss: 0.00020
a decoder loss: 0.23641
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:52
train iter: 557
num of updates: 55800
vae loss: 0.23734
kl loss: 0.00020
a decoder loss: 0.23714
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:53
train iter: 558
num of updates: 55900
vae loss: 0.23646
kl loss: 0.00020
a decoder loss: 0.23626
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:54
train iter: 559
num of updates: 56000
vae loss: 0.23719
kl loss: 0.00020
a decoder loss: 0.23699
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:55
train iter: 560
num of updates: 56100
vae loss: 0.23625
kl loss: 0.00020
a decoder loss: 0.23605
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:56
train iter: 561
num of updates: 56200
vae loss: 0.23746
kl loss: 0.00020
a decoder loss: 0.23726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:57
train iter: 562
num of updates: 56300
vae loss: 0.23692
kl loss: 0.00020
a decoder loss: 0.23672
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:58
train iter: 563
num of updates: 56400
vae loss: 0.23663
kl loss: 0.00020
a decoder loss: 0.23644
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:59
train iter: 564
num of updates: 56500
vae loss: 0.23730
kl loss: 0.00020
a decoder loss: 0.23710
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:00
train iter: 565
num of updates: 56600
vae loss: 0.23670
kl loss: 0.00020
a decoder loss: 0.23651
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:01
train iter: 566
num of updates: 56700
vae loss: 0.23613
kl loss: 0.00020
a decoder loss: 0.23593
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:03
train iter: 567
num of updates: 56800
vae loss: 0.23625
kl loss: 0.00019
a decoder loss: 0.23606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:04
train iter: 568
num of updates: 56900
vae loss: 0.23776
kl loss: 0.00019
a decoder loss: 0.23756
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:05
train iter: 569
num of updates: 57000
vae loss: 0.23768
kl loss: 0.00019
a decoder loss: 0.23749
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:06
train iter: 570
num of updates: 57100
vae loss: 0.23713
kl loss: 0.00019
a decoder loss: 0.23693
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:07
train iter: 571
num of updates: 57200
vae loss: 0.23699
kl loss: 0.00019
a decoder loss: 0.23680
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:08
train iter: 572
num of updates: 57300
vae loss: 0.23661
kl loss: 0.00019
a decoder loss: 0.23642
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:09
train iter: 573
num of updates: 57400
vae loss: 0.23653
kl loss: 0.00019
a decoder loss: 0.23634
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:10
train iter: 574
num of updates: 57500
vae loss: 0.23715
kl loss: 0.00019
a decoder loss: 0.23696
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:11
train iter: 575
num of updates: 57600
vae loss: 0.23704
kl loss: 0.00019
a decoder loss: 0.23685
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:12
train iter: 576
num of updates: 57700
vae loss: 0.23744
kl loss: 0.00019
a decoder loss: 0.23725
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:13
train iter: 577
num of updates: 57800
vae loss: 0.23605
kl loss: 0.00019
a decoder loss: 0.23586
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:14
train iter: 578
num of updates: 57900
vae loss: 0.23684
kl loss: 0.00019
a decoder loss: 0.23665
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:15
train iter: 579
num of updates: 58000
vae loss: 0.23668
kl loss: 0.00019
a decoder loss: 0.23649
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:16
train iter: 580
num of updates: 58100
vae loss: 0.23697
kl loss: 0.00019
a decoder loss: 0.23678
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:17
train iter: 581
num of updates: 58200
vae loss: 0.23691
kl loss: 0.00019
a decoder loss: 0.23672
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:18
train iter: 582
num of updates: 58300
vae loss: 0.23643
kl loss: 0.00019
a decoder loss: 0.23624
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:19
train iter: 583
num of updates: 58400
vae loss: 0.23677
kl loss: 0.00019
a decoder loss: 0.23659
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:20
train iter: 584
num of updates: 58500
vae loss: 0.23704
kl loss: 0.00018
a decoder loss: 0.23686
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:21
train iter: 585
num of updates: 58600
vae loss: 0.23620
kl loss: 0.00018
a decoder loss: 0.23602
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:22
train iter: 586
num of updates: 58700
vae loss: 0.23603
kl loss: 0.00018
a decoder loss: 0.23585
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:23
train iter: 587
num of updates: 58800
vae loss: 0.23683
kl loss: 0.00018
a decoder loss: 0.23665
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:24
train iter: 588
num of updates: 58900
vae loss: 0.23598
kl loss: 0.00018
a decoder loss: 0.23580
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:25
train iter: 589
num of updates: 59000
vae loss: 0.23668
kl loss: 0.00018
a decoder loss: 0.23650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:26
train iter: 590
num of updates: 59100
vae loss: 0.23584
kl loss: 0.00018
a decoder loss: 0.23566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:27
train iter: 591
num of updates: 59200
vae loss: 0.23608
kl loss: 0.00018
a decoder loss: 0.23589
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:28
train iter: 592
num of updates: 59300
vae loss: 0.23712
kl loss: 0.00018
a decoder loss: 0.23694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:29
train iter: 593
num of updates: 59400
vae loss: 0.23596
kl loss: 0.00018
a decoder loss: 0.23578
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:30
train iter: 594
num of updates: 59500
vae loss: 0.23592
kl loss: 0.00018
a decoder loss: 0.23574
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:31
train iter: 595
num of updates: 59600
vae loss: 0.23627
kl loss: 0.00018
a decoder loss: 0.23609
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:32
train iter: 596
num of updates: 59700
vae loss: 0.23683
kl loss: 0.00018
a decoder loss: 0.23665
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:33
train iter: 597
num of updates: 59800
vae loss: 0.23724
kl loss: 0.00018
a decoder loss: 0.23706
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:34
train iter: 598
num of updates: 59900
vae loss: 0.23620
kl loss: 0.00018
a decoder loss: 0.23603
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:35
train iter: 599
num of updates: 60000
vae loss: 0.23684
kl loss: 0.00018
a decoder loss: 0.23666
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:36
train iter: 600
num of updates: 60100
vae loss: 0.23585
kl loss: 0.00018
a decoder loss: 0.23567
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:37
train iter: 601
num of updates: 60200
vae loss: 0.23608
kl loss: 0.00018
a decoder loss: 0.23590
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:38
train iter: 602
num of updates: 60300
vae loss: 0.23645
kl loss: 0.00018
a decoder loss: 0.23627
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:39
train iter: 603
num of updates: 60400
vae loss: 0.23532
kl loss: 0.00017
a decoder loss: 0.23515
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:40
train iter: 604
num of updates: 60500
vae loss: 0.23642
kl loss: 0.00017
a decoder loss: 0.23625
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:41
train iter: 605
num of updates: 60600
vae loss: 0.23515
kl loss: 0.00017
a decoder loss: 0.23498
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:42
train iter: 606
num of updates: 60700
vae loss: 0.23677
kl loss: 0.00017
a decoder loss: 0.23660
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:43
train iter: 607
num of updates: 60800
vae loss: 0.23630
kl loss: 0.00017
a decoder loss: 0.23613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:44
train iter: 608
num of updates: 60900
vae loss: 0.23577
kl loss: 0.00017
a decoder loss: 0.23559
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:45
train iter: 609
num of updates: 61000
vae loss: 0.23594
kl loss: 0.00017
a decoder loss: 0.23577
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:46
train iter: 610
num of updates: 61100
vae loss: 0.23613
kl loss: 0.00017
a decoder loss: 0.23596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:47
train iter: 611
num of updates: 61200
vae loss: 0.23737
kl loss: 0.00017
a decoder loss: 0.23720
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:48
train iter: 612
num of updates: 61300
vae loss: 0.23645
kl loss: 0.00017
a decoder loss: 0.23628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:49
train iter: 613
num of updates: 61400
vae loss: 0.23645
kl loss: 0.00017
a decoder loss: 0.23628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:50
train iter: 614
num of updates: 61500
vae loss: 0.23616
kl loss: 0.00017
a decoder loss: 0.23599
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:51
train iter: 615
num of updates: 61600
vae loss: 0.23634
kl loss: 0.00017
a decoder loss: 0.23618
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:52
train iter: 616
num of updates: 61700
vae loss: 0.23553
kl loss: 0.00017
a decoder loss: 0.23536
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:53
train iter: 617
num of updates: 61800
vae loss: 0.23536
kl loss: 0.00017
a decoder loss: 0.23519
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:54
train iter: 618
num of updates: 61900
vae loss: 0.23659
kl loss: 0.00017
a decoder loss: 0.23642
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:56
train iter: 619
num of updates: 62000
vae loss: 0.23569
kl loss: 0.00017
a decoder loss: 0.23553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:57
train iter: 620
num of updates: 62100
vae loss: 0.23553
kl loss: 0.00017
a decoder loss: 0.23536
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:58
train iter: 621
num of updates: 62200
vae loss: 0.23638
kl loss: 0.00017
a decoder loss: 0.23621
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:59
train iter: 622
num of updates: 62300
vae loss: 0.23529
kl loss: 0.00017
a decoder loss: 0.23513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:00
train iter: 623
num of updates: 62400
vae loss: 0.23630
kl loss: 0.00016
a decoder loss: 0.23613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:01
train iter: 624
num of updates: 62500
vae loss: 0.23562
kl loss: 0.00016
a decoder loss: 0.23545
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:02
train iter: 625
num of updates: 62600
vae loss: 0.23656
kl loss: 0.00016
a decoder loss: 0.23640
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:03
train iter: 626
num of updates: 62700
vae loss: 0.23648
kl loss: 0.00016
a decoder loss: 0.23632
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:04
train iter: 627
num of updates: 62800
vae loss: 0.23640
kl loss: 0.00016
a decoder loss: 0.23623
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:05
train iter: 628
num of updates: 62900
vae loss: 0.23503
kl loss: 0.00016
a decoder loss: 0.23487
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:06
train iter: 629
num of updates: 63000
vae loss: 0.23512
kl loss: 0.00016
a decoder loss: 0.23496
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:07
train iter: 630
num of updates: 63100
vae loss: 0.23559
kl loss: 0.00016
a decoder loss: 0.23542
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:08
train iter: 631
num of updates: 63200
vae loss: 0.23480
kl loss: 0.00016
a decoder loss: 0.23464
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:09
train iter: 632
num of updates: 63300
vae loss: 0.23573
kl loss: 0.00016
a decoder loss: 0.23556
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:10
train iter: 633
num of updates: 63400
vae loss: 0.23588
kl loss: 0.00016
a decoder loss: 0.23572
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:11
train iter: 634
num of updates: 63500
vae loss: 0.23524
kl loss: 0.00016
a decoder loss: 0.23508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:12
train iter: 635
num of updates: 63600
vae loss: 0.23574
kl loss: 0.00016
a decoder loss: 0.23558
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:13
train iter: 636
num of updates: 63700
vae loss: 0.23569
kl loss: 0.00016
a decoder loss: 0.23553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:14
train iter: 637
num of updates: 63800
vae loss: 0.23591
kl loss: 0.00016
a decoder loss: 0.23575
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:15
train iter: 638
num of updates: 63900
vae loss: 0.23603
kl loss: 0.00016
a decoder loss: 0.23587
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:16
train iter: 639
num of updates: 64000
vae loss: 0.23604
kl loss: 0.00016
a decoder loss: 0.23588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:17
train iter: 640
num of updates: 64100
vae loss: 0.23639
kl loss: 0.00016
a decoder loss: 0.23623
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:18
train iter: 641
num of updates: 64200
vae loss: 0.23498
kl loss: 0.00016
a decoder loss: 0.23483
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:19
train iter: 642
num of updates: 64300
vae loss: 0.23529
kl loss: 0.00016
a decoder loss: 0.23513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:20
train iter: 643
num of updates: 64400
vae loss: 0.23506
kl loss: 0.00016
a decoder loss: 0.23490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:21
train iter: 644
num of updates: 64500
vae loss: 0.23497
kl loss: 0.00016
a decoder loss: 0.23481
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:22
train iter: 645
num of updates: 64600
vae loss: 0.23598
kl loss: 0.00016
a decoder loss: 0.23583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:23
train iter: 646
num of updates: 64700
vae loss: 0.23609
kl loss: 0.00016
a decoder loss: 0.23594
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:24
train iter: 647
num of updates: 64800
vae loss: 0.23594
kl loss: 0.00015
a decoder loss: 0.23579
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:25
train iter: 648
num of updates: 64900
vae loss: 0.23494
kl loss: 0.00016
a decoder loss: 0.23478
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:26
train iter: 649
num of updates: 65000
vae loss: 0.23447
kl loss: 0.00015
a decoder loss: 0.23432
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:27
train iter: 650
num of updates: 65100
vae loss: 0.23531
kl loss: 0.00015
a decoder loss: 0.23515
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:28
train iter: 651
num of updates: 65200
vae loss: 0.23593
kl loss: 0.00015
a decoder loss: 0.23578
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:29
train iter: 652
num of updates: 65300
vae loss: 0.23471
kl loss: 0.00015
a decoder loss: 0.23456
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:30
train iter: 653
num of updates: 65400
vae loss: 0.23487
kl loss: 0.00015
a decoder loss: 0.23472
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:31
train iter: 654
num of updates: 65500
vae loss: 0.23527
kl loss: 0.00015
a decoder loss: 0.23511
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:32
train iter: 655
num of updates: 65600
vae loss: 0.23500
kl loss: 0.00015
a decoder loss: 0.23485
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:33
train iter: 656
num of updates: 65700
vae loss: 0.23566
kl loss: 0.00015
a decoder loss: 0.23551
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:34
train iter: 657
num of updates: 65800
vae loss: 0.23578
kl loss: 0.00015
a decoder loss: 0.23563
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:35
train iter: 658
num of updates: 65900
vae loss: 0.23560
kl loss: 0.00015
a decoder loss: 0.23545
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:36
train iter: 659
num of updates: 66000
vae loss: 0.23491
kl loss: 0.00015
a decoder loss: 0.23476
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:37
train iter: 660
num of updates: 66100
vae loss: 0.23499
kl loss: 0.00015
a decoder loss: 0.23484
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:38
train iter: 661
num of updates: 66200
vae loss: 0.23556
kl loss: 0.00015
a decoder loss: 0.23540
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:39
train iter: 662
num of updates: 66300
vae loss: 0.23473
kl loss: 0.00015
a decoder loss: 0.23458
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:40
train iter: 663
num of updates: 66400
vae loss: 0.23489
kl loss: 0.00015
a decoder loss: 0.23474
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:41
train iter: 664
num of updates: 66500
vae loss: 0.23569
kl loss: 0.00015
a decoder loss: 0.23554
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:42
train iter: 665
num of updates: 66600
vae loss: 0.23538
kl loss: 0.00015
a decoder loss: 0.23523
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:43
train iter: 666
num of updates: 66700
vae loss: 0.23551
kl loss: 0.00015
a decoder loss: 0.23536
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:44
train iter: 667
num of updates: 66800
vae loss: 0.23504
kl loss: 0.00015
a decoder loss: 0.23490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:45
train iter: 668
num of updates: 66900
vae loss: 0.23531
kl loss: 0.00015
a decoder loss: 0.23516
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:46
train iter: 669
num of updates: 67000
vae loss: 0.23490
kl loss: 0.00015
a decoder loss: 0.23475
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:47
train iter: 670
num of updates: 67100
vae loss: 0.23544
kl loss: 0.00015
a decoder loss: 0.23529
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:48
train iter: 671
num of updates: 67200
vae loss: 0.23478
kl loss: 0.00015
a decoder loss: 0.23463
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:49
train iter: 672
num of updates: 67300
vae loss: 0.23520
kl loss: 0.00015
a decoder loss: 0.23505
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:50
train iter: 673
num of updates: 67400
vae loss: 0.23539
kl loss: 0.00015
a decoder loss: 0.23525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:51
train iter: 674
num of updates: 67500
vae loss: 0.23499
kl loss: 0.00015
a decoder loss: 0.23484
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:52
train iter: 675
num of updates: 67600
vae loss: 0.23501
kl loss: 0.00015
a decoder loss: 0.23486
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:53
train iter: 676
num of updates: 67700
vae loss: 0.23502
kl loss: 0.00014
a decoder loss: 0.23488
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:54
train iter: 677
num of updates: 67800
vae loss: 0.23465
kl loss: 0.00014
a decoder loss: 0.23450
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:55
train iter: 678
num of updates: 67900
vae loss: 0.23539
kl loss: 0.00014
a decoder loss: 0.23525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:56
train iter: 679
num of updates: 68000
vae loss: 0.23581
kl loss: 0.00014
a decoder loss: 0.23566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:57
train iter: 680
num of updates: 68100
vae loss: 0.23490
kl loss: 0.00014
a decoder loss: 0.23476
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:58
train iter: 681
num of updates: 68200
vae loss: 0.23502
kl loss: 0.00014
a decoder loss: 0.23487
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:59
train iter: 682
num of updates: 68300
vae loss: 0.23545
kl loss: 0.00014
a decoder loss: 0.23531
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:00
train iter: 683
num of updates: 68400
vae loss: 0.23500
kl loss: 0.00014
a decoder loss: 0.23486
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:01
train iter: 684
num of updates: 68500
vae loss: 0.23435
kl loss: 0.00014
a decoder loss: 0.23420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:02
train iter: 685
num of updates: 68600
vae loss: 0.23505
kl loss: 0.00014
a decoder loss: 0.23491
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:03
train iter: 686
num of updates: 68700
vae loss: 0.23508
kl loss: 0.00014
a decoder loss: 0.23493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:04
train iter: 687
num of updates: 68800
vae loss: 0.23505
kl loss: 0.00014
a decoder loss: 0.23491
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:05
train iter: 688
num of updates: 68900
vae loss: 0.23482
kl loss: 0.00014
a decoder loss: 0.23468
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:07
train iter: 689
num of updates: 69000
vae loss: 0.23489
kl loss: 0.00014
a decoder loss: 0.23475
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:08
train iter: 690
num of updates: 69100
vae loss: 0.23420
kl loss: 0.00014
a decoder loss: 0.23406
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:09
train iter: 691
num of updates: 69200
vae loss: 0.23481
kl loss: 0.00014
a decoder loss: 0.23467
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:10
train iter: 692
num of updates: 69300
vae loss: 0.23512
kl loss: 0.00014
a decoder loss: 0.23498
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:11
train iter: 693
num of updates: 69400
vae loss: 0.23475
kl loss: 0.00014
a decoder loss: 0.23461
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:12
train iter: 694
num of updates: 69500
vae loss: 0.23457
kl loss: 0.00014
a decoder loss: 0.23443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:13
train iter: 695
num of updates: 69600
vae loss: 0.23426
kl loss: 0.00014
a decoder loss: 0.23412
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:14
train iter: 696
num of updates: 69700
vae loss: 0.23635
kl loss: 0.00014
a decoder loss: 0.23621
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:15
train iter: 697
num of updates: 69800
vae loss: 0.23459
kl loss: 0.00014
a decoder loss: 0.23445
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:16
train iter: 698
num of updates: 69900
vae loss: 0.23481
kl loss: 0.00014
a decoder loss: 0.23467
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:17
train iter: 699
num of updates: 70000
vae loss: 0.23481
kl loss: 0.00014
a decoder loss: 0.23467
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:18
train iter: 700
num of updates: 70100
vae loss: 0.23368
kl loss: 0.00014
a decoder loss: 0.23355
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:19
train iter: 701
num of updates: 70200
vae loss: 0.23462
kl loss: 0.00014
a decoder loss: 0.23448
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:20
train iter: 702
num of updates: 70300
vae loss: 0.23524
kl loss: 0.00014
a decoder loss: 0.23510
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:21
train iter: 703
num of updates: 70400
vae loss: 0.23511
kl loss: 0.00014
a decoder loss: 0.23497
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:22
train iter: 704
num of updates: 70500
vae loss: 0.23539
kl loss: 0.00014
a decoder loss: 0.23525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:23
train iter: 705
num of updates: 70600
vae loss: 0.23457
kl loss: 0.00014
a decoder loss: 0.23444
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:24
train iter: 706
num of updates: 70700
vae loss: 0.23452
kl loss: 0.00013
a decoder loss: 0.23439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:25
train iter: 707
num of updates: 70800
vae loss: 0.23473
kl loss: 0.00013
a decoder loss: 0.23459
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:26
train iter: 708
num of updates: 70900
vae loss: 0.23377
kl loss: 0.00014
a decoder loss: 0.23363
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:27
train iter: 709
num of updates: 71000
vae loss: 0.23387
kl loss: 0.00013
a decoder loss: 0.23374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:28
train iter: 710
num of updates: 71100
vae loss: 0.23440
kl loss: 0.00013
a decoder loss: 0.23426
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:29
train iter: 711
num of updates: 71200
vae loss: 0.23389
kl loss: 0.00013
a decoder loss: 0.23376
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:30
train iter: 712
num of updates: 71300
vae loss: 0.23541
kl loss: 0.00013
a decoder loss: 0.23528
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:31
train iter: 713
num of updates: 71400
vae loss: 0.23389
kl loss: 0.00013
a decoder loss: 0.23376
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:32
train iter: 714
num of updates: 71500
vae loss: 0.23400
kl loss: 0.00013
a decoder loss: 0.23387
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:33
train iter: 715
num of updates: 71600
vae loss: 0.23438
kl loss: 0.00013
a decoder loss: 0.23425
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:34
train iter: 716
num of updates: 71700
vae loss: 0.23449
kl loss: 0.00013
a decoder loss: 0.23436
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:35
train iter: 717
num of updates: 71800
vae loss: 0.23391
kl loss: 0.00013
a decoder loss: 0.23378
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:36
train iter: 718
num of updates: 71900
vae loss: 0.23546
kl loss: 0.00013
a decoder loss: 0.23533
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:37
train iter: 719
num of updates: 72000
vae loss: 0.23464
kl loss: 0.00013
a decoder loss: 0.23451
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:38
train iter: 720
num of updates: 72100
vae loss: 0.23447
kl loss: 0.00013
a decoder loss: 0.23434
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:39
train iter: 721
num of updates: 72200
vae loss: 0.23452
kl loss: 0.00013
a decoder loss: 0.23439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:40
train iter: 722
num of updates: 72300
vae loss: 0.23460
kl loss: 0.00013
a decoder loss: 0.23447
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:41
train iter: 723
num of updates: 72400
vae loss: 0.23396
kl loss: 0.00013
a decoder loss: 0.23383
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:42
train iter: 724
num of updates: 72500
vae loss: 0.23496
kl loss: 0.00013
a decoder loss: 0.23483
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:43
train iter: 725
num of updates: 72600
vae loss: 0.23463
kl loss: 0.00013
a decoder loss: 0.23450
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:44
train iter: 726
num of updates: 72700
vae loss: 0.23380
kl loss: 0.00013
a decoder loss: 0.23367
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:45
train iter: 727
num of updates: 72800
vae loss: 0.23452
kl loss: 0.00013
a decoder loss: 0.23440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:46
train iter: 728
num of updates: 72900
vae loss: 0.23469
kl loss: 0.00013
a decoder loss: 0.23456
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:47
train iter: 729
num of updates: 73000
vae loss: 0.23513
kl loss: 0.00013
a decoder loss: 0.23500
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:48
train iter: 730
num of updates: 73100
vae loss: 0.23491
kl loss: 0.00013
a decoder loss: 0.23479
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:49
train iter: 731
num of updates: 73200
vae loss: 0.23435
kl loss: 0.00013
a decoder loss: 0.23422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:50
train iter: 732
num of updates: 73300
vae loss: 0.23539
kl loss: 0.00013
a decoder loss: 0.23527
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:51
train iter: 733
num of updates: 73400
vae loss: 0.23452
kl loss: 0.00013
a decoder loss: 0.23439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:52
train iter: 734
num of updates: 73500
vae loss: 0.23432
kl loss: 0.00013
a decoder loss: 0.23419
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:53
train iter: 735
num of updates: 73600
vae loss: 0.23468
kl loss: 0.00013
a decoder loss: 0.23455
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:54
train iter: 736
num of updates: 73700
vae loss: 0.23387
kl loss: 0.00013
a decoder loss: 0.23374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:55
train iter: 737
num of updates: 73800
vae loss: 0.23420
kl loss: 0.00013
a decoder loss: 0.23408
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:56
train iter: 738
num of updates: 73900
vae loss: 0.23407
kl loss: 0.00013
a decoder loss: 0.23394
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:57
train iter: 739
num of updates: 74000
vae loss: 0.23400
kl loss: 0.00013
a decoder loss: 0.23387
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:58
train iter: 740
num of updates: 74100
vae loss: 0.23440
kl loss: 0.00013
a decoder loss: 0.23427
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:59
train iter: 741
num of updates: 74200
vae loss: 0.23362
kl loss: 0.00012
a decoder loss: 0.23349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:00
train iter: 742
num of updates: 74300
vae loss: 0.23471
kl loss: 0.00012
a decoder loss: 0.23458
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:01
train iter: 743
num of updates: 74400
vae loss: 0.23469
kl loss: 0.00013
a decoder loss: 0.23456
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:02
train iter: 744
num of updates: 74500
vae loss: 0.23437
kl loss: 0.00012
a decoder loss: 0.23425
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:03
train iter: 745
num of updates: 74600
vae loss: 0.23393
kl loss: 0.00012
a decoder loss: 0.23381
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:04
train iter: 746
num of updates: 74700
vae loss: 0.23481
kl loss: 0.00012
a decoder loss: 0.23469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:05
train iter: 747
num of updates: 74800
vae loss: 0.23370
kl loss: 0.00012
a decoder loss: 0.23357
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:06
train iter: 748
num of updates: 74900
vae loss: 0.23357
kl loss: 0.00012
a decoder loss: 0.23345
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:07
train iter: 749
num of updates: 75000
vae loss: 0.23342
kl loss: 0.00012
a decoder loss: 0.23330
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:08
train iter: 750
num of updates: 75100
vae loss: 0.23470
kl loss: 0.00012
a decoder loss: 0.23458
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:09
train iter: 751
num of updates: 75200
vae loss: 0.23461
kl loss: 0.00012
a decoder loss: 0.23449
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:10
train iter: 752
num of updates: 75300
vae loss: 0.23323
kl loss: 0.00012
a decoder loss: 0.23311
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:11
train iter: 753
num of updates: 75400
vae loss: 0.23356
kl loss: 0.00012
a decoder loss: 0.23344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:12
train iter: 754
num of updates: 75500
vae loss: 0.23314
kl loss: 0.00012
a decoder loss: 0.23302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:13
train iter: 755
num of updates: 75600
vae loss: 0.23424
kl loss: 0.00012
a decoder loss: 0.23412
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:14
train iter: 756
num of updates: 75700
vae loss: 0.23457
kl loss: 0.00012
a decoder loss: 0.23445
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:15
train iter: 757
num of updates: 75800
vae loss: 0.23528
kl loss: 0.00012
a decoder loss: 0.23516
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:16
train iter: 758
num of updates: 75900
vae loss: 0.23374
kl loss: 0.00012
a decoder loss: 0.23361
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:18
train iter: 759
num of updates: 76000
vae loss: 0.23350
kl loss: 0.00012
a decoder loss: 0.23338
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:19
train iter: 760
num of updates: 76100
vae loss: 0.23477
kl loss: 0.00012
a decoder loss: 0.23465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:20
train iter: 761
num of updates: 76200
vae loss: 0.23430
kl loss: 0.00012
a decoder loss: 0.23418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:21
train iter: 762
num of updates: 76300
vae loss: 0.23394
kl loss: 0.00012
a decoder loss: 0.23382
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:22
train iter: 763
num of updates: 76400
vae loss: 0.23264
kl loss: 0.00012
a decoder loss: 0.23252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:23
train iter: 764
num of updates: 76500
vae loss: 0.23445
kl loss: 0.00012
a decoder loss: 0.23433
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:24
train iter: 765
num of updates: 76600
vae loss: 0.23378
kl loss: 0.00012
a decoder loss: 0.23367
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:25
train iter: 766
num of updates: 76700
vae loss: 0.23331
kl loss: 0.00012
a decoder loss: 0.23319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:26
train iter: 767
num of updates: 76800
vae loss: 0.23447
kl loss: 0.00012
a decoder loss: 0.23435
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:27
train iter: 768
num of updates: 76900
vae loss: 0.23394
kl loss: 0.00012
a decoder loss: 0.23382
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:28
train iter: 769
num of updates: 77000
vae loss: 0.23399
kl loss: 0.00012
a decoder loss: 0.23387
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:29
train iter: 770
num of updates: 77100
vae loss: 0.23329
kl loss: 0.00012
a decoder loss: 0.23318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:30
train iter: 771
num of updates: 77200
vae loss: 0.23385
kl loss: 0.00012
a decoder loss: 0.23373
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:31
train iter: 772
num of updates: 77300
vae loss: 0.23446
kl loss: 0.00012
a decoder loss: 0.23434
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:32
train iter: 773
num of updates: 77400
vae loss: 0.23363
kl loss: 0.00012
a decoder loss: 0.23351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:33
train iter: 774
num of updates: 77500
vae loss: 0.23311
kl loss: 0.00012
a decoder loss: 0.23299
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:34
train iter: 775
num of updates: 77600
vae loss: 0.23412
kl loss: 0.00012
a decoder loss: 0.23401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:35
train iter: 776
num of updates: 77700
vae loss: 0.23324
kl loss: 0.00012
a decoder loss: 0.23312
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:36
train iter: 777
num of updates: 77800
vae loss: 0.23385
kl loss: 0.00012
a decoder loss: 0.23373
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:37
train iter: 778
num of updates: 77900
vae loss: 0.23352
kl loss: 0.00012
a decoder loss: 0.23340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:38
train iter: 779
num of updates: 78000
vae loss: 0.23325
kl loss: 0.00011
a decoder loss: 0.23313
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:39
train iter: 780
num of updates: 78100
vae loss: 0.23378
kl loss: 0.00012
a decoder loss: 0.23366
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:40
train iter: 781
num of updates: 78200
vae loss: 0.23415
kl loss: 0.00012
a decoder loss: 0.23404
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:41
train iter: 782
num of updates: 78300
vae loss: 0.23423
kl loss: 0.00011
a decoder loss: 0.23412
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:42
train iter: 783
num of updates: 78400
vae loss: 0.23372
kl loss: 0.00012
a decoder loss: 0.23360
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:43
train iter: 784
num of updates: 78500
vae loss: 0.23362
kl loss: 0.00011
a decoder loss: 0.23351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:44
train iter: 785
num of updates: 78600
vae loss: 0.23335
kl loss: 0.00012
a decoder loss: 0.23324
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:45
train iter: 786
num of updates: 78700
vae loss: 0.23349
kl loss: 0.00011
a decoder loss: 0.23338
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:46
train iter: 787
num of updates: 78800
vae loss: 0.23382
kl loss: 0.00011
a decoder loss: 0.23370
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:47
train iter: 788
num of updates: 78900
vae loss: 0.23424
kl loss: 0.00011
a decoder loss: 0.23412
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:48
train iter: 789
num of updates: 79000
vae loss: 0.23370
kl loss: 0.00011
a decoder loss: 0.23359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:49
train iter: 790
num of updates: 79100
vae loss: 0.23383
kl loss: 0.00011
a decoder loss: 0.23372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:50
train iter: 791
num of updates: 79200
vae loss: 0.23329
kl loss: 0.00011
a decoder loss: 0.23318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:51
train iter: 792
num of updates: 79300
vae loss: 0.23414
kl loss: 0.00011
a decoder loss: 0.23403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:52
train iter: 793
num of updates: 79400
vae loss: 0.23380
kl loss: 0.00011
a decoder loss: 0.23369
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:53
train iter: 794
num of updates: 79500
vae loss: 0.23425
kl loss: 0.00011
a decoder loss: 0.23414
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:54
train iter: 795
num of updates: 79600
vae loss: 0.23378
kl loss: 0.00011
a decoder loss: 0.23367
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:55
train iter: 796
num of updates: 79700
vae loss: 0.23278
kl loss: 0.00011
a decoder loss: 0.23266
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:56
train iter: 797
num of updates: 79800
vae loss: 0.23386
kl loss: 0.00011
a decoder loss: 0.23374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:57
train iter: 798
num of updates: 79900
vae loss: 0.23319
kl loss: 0.00011
a decoder loss: 0.23308
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:58
train iter: 799
num of updates: 80000
vae loss: 0.23312
kl loss: 0.00011
a decoder loss: 0.23301
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:59
train iter: 800
num of updates: 80100
vae loss: 0.23421
kl loss: 0.00011
a decoder loss: 0.23410
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:00
train iter: 801
num of updates: 80200
vae loss: 0.23329
kl loss: 0.00011
a decoder loss: 0.23318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:01
train iter: 802
num of updates: 80300
vae loss: 0.23381
kl loss: 0.00011
a decoder loss: 0.23370
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:02
train iter: 803
num of updates: 80400
vae loss: 0.23355
kl loss: 0.00011
a decoder loss: 0.23344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:03
train iter: 804
num of updates: 80500
vae loss: 0.23395
kl loss: 0.00011
a decoder loss: 0.23384
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:04
train iter: 805
num of updates: 80600
vae loss: 0.23351
kl loss: 0.00011
a decoder loss: 0.23340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:05
train iter: 806
num of updates: 80700
vae loss: 0.23376
kl loss: 0.00011
a decoder loss: 0.23365
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:06
train iter: 807
num of updates: 80800
vae loss: 0.23328
kl loss: 0.00011
a decoder loss: 0.23317
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:07
train iter: 808
num of updates: 80900
vae loss: 0.23310
kl loss: 0.00011
a decoder loss: 0.23299
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:08
train iter: 809
num of updates: 81000
vae loss: 0.23314
kl loss: 0.00011
a decoder loss: 0.23303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:09
train iter: 810
num of updates: 81100
vae loss: 0.23363
kl loss: 0.00011
a decoder loss: 0.23352
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:10
train iter: 811
num of updates: 81200
vae loss: 0.23372
kl loss: 0.00011
a decoder loss: 0.23361
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:11
train iter: 812
num of updates: 81300
vae loss: 0.23359
kl loss: 0.00011
a decoder loss: 0.23349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:12
train iter: 813
num of updates: 81400
vae loss: 0.23364
kl loss: 0.00011
a decoder loss: 0.23353
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:13
train iter: 814
num of updates: 81500
vae loss: 0.23381
kl loss: 0.00011
a decoder loss: 0.23370
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:14
train iter: 815
num of updates: 81600
vae loss: 0.23362
kl loss: 0.00011
a decoder loss: 0.23351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:15
train iter: 816
num of updates: 81700
vae loss: 0.23395
kl loss: 0.00011
a decoder loss: 0.23384
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:16
train iter: 817
num of updates: 81800
vae loss: 0.23362
kl loss: 0.00011
a decoder loss: 0.23351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:17
train iter: 818
num of updates: 81900
vae loss: 0.23326
kl loss: 0.00011
a decoder loss: 0.23315
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:18
train iter: 819
num of updates: 82000
vae loss: 0.23335
kl loss: 0.00011
a decoder loss: 0.23325
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:19
train iter: 820
num of updates: 82100
vae loss: 0.23412
kl loss: 0.00011
a decoder loss: 0.23401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:20
train iter: 821
num of updates: 82200
vae loss: 0.23257
kl loss: 0.00011
a decoder loss: 0.23246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:21
train iter: 822
num of updates: 82300
vae loss: 0.23353
kl loss: 0.00011
a decoder loss: 0.23343
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:22
train iter: 823
num of updates: 82400
vae loss: 0.23353
kl loss: 0.00011
a decoder loss: 0.23342
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:23
train iter: 824
num of updates: 82500
vae loss: 0.23337
kl loss: 0.00011
a decoder loss: 0.23326
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:24
train iter: 825
num of updates: 82600
vae loss: 0.23308
kl loss: 0.00011
a decoder loss: 0.23298
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:25
train iter: 826
num of updates: 82700
vae loss: 0.23304
kl loss: 0.00011
a decoder loss: 0.23293
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:26
train iter: 827
num of updates: 82800
vae loss: 0.23275
kl loss: 0.00011
a decoder loss: 0.23265
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:28
train iter: 828
num of updates: 82900
vae loss: 0.23332
kl loss: 0.00011
a decoder loss: 0.23321
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:29
train iter: 829
num of updates: 83000
vae loss: 0.23307
kl loss: 0.00010
a decoder loss: 0.23296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:30
train iter: 830
num of updates: 83100
vae loss: 0.23341
kl loss: 0.00011
a decoder loss: 0.23331
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:31
train iter: 831
num of updates: 83200
vae loss: 0.23318
kl loss: 0.00010
a decoder loss: 0.23308
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:32
train iter: 832
num of updates: 83300
vae loss: 0.23352
kl loss: 0.00010
a decoder loss: 0.23342
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:33
train iter: 833
num of updates: 83400
vae loss: 0.23333
kl loss: 0.00010
a decoder loss: 0.23322
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:34
train iter: 834
num of updates: 83500
vae loss: 0.23271
kl loss: 0.00010
a decoder loss: 0.23261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:35
train iter: 835
num of updates: 83600
vae loss: 0.23382
kl loss: 0.00010
a decoder loss: 0.23372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:36
train iter: 836
num of updates: 83700
vae loss: 0.23284
kl loss: 0.00010
a decoder loss: 0.23273
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:37
train iter: 837
num of updates: 83800
vae loss: 0.23349
kl loss: 0.00010
a decoder loss: 0.23339
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:38
train iter: 838
num of updates: 83900
vae loss: 0.23237
kl loss: 0.00010
a decoder loss: 0.23227
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:39
train iter: 839
num of updates: 84000
vae loss: 0.23348
kl loss: 0.00010
a decoder loss: 0.23337
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:40
train iter: 840
num of updates: 84100
vae loss: 0.23323
kl loss: 0.00010
a decoder loss: 0.23312
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:41
train iter: 841
num of updates: 84200
vae loss: 0.23300
kl loss: 0.00010
a decoder loss: 0.23290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:42
train iter: 842
num of updates: 84300
vae loss: 0.23277
kl loss: 0.00010
a decoder loss: 0.23266
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:43
train iter: 843
num of updates: 84400
vae loss: 0.23221
kl loss: 0.00010
a decoder loss: 0.23211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:44
train iter: 844
num of updates: 84500
vae loss: 0.23391
kl loss: 0.00010
a decoder loss: 0.23380
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:45
train iter: 845
num of updates: 84600
vae loss: 0.23334
kl loss: 0.00010
a decoder loss: 0.23323
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:46
train iter: 846
num of updates: 84700
vae loss: 0.23338
kl loss: 0.00010
a decoder loss: 0.23327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:47
train iter: 847
num of updates: 84800
vae loss: 0.23235
kl loss: 0.00010
a decoder loss: 0.23225
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:48
train iter: 848
num of updates: 84900
vae loss: 0.23374
kl loss: 0.00010
a decoder loss: 0.23363
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:49
train iter: 849
num of updates: 85000
vae loss: 0.23324
kl loss: 0.00010
a decoder loss: 0.23314
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:50
train iter: 850
num of updates: 85100
vae loss: 0.23251
kl loss: 0.00010
a decoder loss: 0.23241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:51
train iter: 851
num of updates: 85200
vae loss: 0.23321
kl loss: 0.00010
a decoder loss: 0.23311
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:52
train iter: 852
num of updates: 85300
vae loss: 0.23304
kl loss: 0.00010
a decoder loss: 0.23294
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:53
train iter: 853
num of updates: 85400
vae loss: 0.23342
kl loss: 0.00010
a decoder loss: 0.23332
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:54
train iter: 854
num of updates: 85500
vae loss: 0.23311
kl loss: 0.00010
a decoder loss: 0.23301
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:55
train iter: 855
num of updates: 85600
vae loss: 0.23297
kl loss: 0.00010
a decoder loss: 0.23287
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:56
train iter: 856
num of updates: 85700
vae loss: 0.23337
kl loss: 0.00010
a decoder loss: 0.23327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:57
train iter: 857
num of updates: 85800
vae loss: 0.23284
kl loss: 0.00010
a decoder loss: 0.23274
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:58
train iter: 858
num of updates: 85900
vae loss: 0.23348
kl loss: 0.00010
a decoder loss: 0.23338
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:59
train iter: 859
num of updates: 86000
vae loss: 0.23336
kl loss: 0.00010
a decoder loss: 0.23326
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:00
train iter: 860
num of updates: 86100
vae loss: 0.23267
kl loss: 0.00010
a decoder loss: 0.23257
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:01
train iter: 861
num of updates: 86200
vae loss: 0.23233
kl loss: 0.00010
a decoder loss: 0.23223
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:02
train iter: 862
num of updates: 86300
vae loss: 0.23268
kl loss: 0.00010
a decoder loss: 0.23258
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:03
train iter: 863
num of updates: 86400
vae loss: 0.23371
kl loss: 0.00010
a decoder loss: 0.23361
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:04
train iter: 864
num of updates: 86500
vae loss: 0.23215
kl loss: 0.00010
a decoder loss: 0.23205
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:05
train iter: 865
num of updates: 86600
vae loss: 0.23361
kl loss: 0.00010
a decoder loss: 0.23351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:06
train iter: 866
num of updates: 86700
vae loss: 0.23262
kl loss: 0.00010
a decoder loss: 0.23252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:07
train iter: 867
num of updates: 86800
vae loss: 0.23264
kl loss: 0.00010
a decoder loss: 0.23254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:08
train iter: 868
num of updates: 86900
vae loss: 0.23307
kl loss: 0.00010
a decoder loss: 0.23297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:09
train iter: 869
num of updates: 87000
vae loss: 0.23238
kl loss: 0.00010
a decoder loss: 0.23228
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:10
train iter: 870
num of updates: 87100
vae loss: 0.23283
kl loss: 0.00010
a decoder loss: 0.23273
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:11
train iter: 871
num of updates: 87200
vae loss: 0.23277
kl loss: 0.00010
a decoder loss: 0.23267
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:12
train iter: 872
num of updates: 87300
vae loss: 0.23162
kl loss: 0.00010
a decoder loss: 0.23152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:13
train iter: 873
num of updates: 87400
vae loss: 0.23269
kl loss: 0.00010
a decoder loss: 0.23259
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:14
train iter: 874
num of updates: 87500
vae loss: 0.23261
kl loss: 0.00010
a decoder loss: 0.23251
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:15
train iter: 875
num of updates: 87600
vae loss: 0.23241
kl loss: 0.00010
a decoder loss: 0.23232
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:16
train iter: 876
num of updates: 87700
vae loss: 0.23249
kl loss: 0.00010
a decoder loss: 0.23239
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:17
train iter: 877
num of updates: 87800
vae loss: 0.23359
kl loss: 0.00010
a decoder loss: 0.23350
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:18
train iter: 878
num of updates: 87900
vae loss: 0.23314
kl loss: 0.00010
a decoder loss: 0.23304
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:19
train iter: 879
num of updates: 88000
vae loss: 0.23252
kl loss: 0.00010
a decoder loss: 0.23242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:20
train iter: 880
num of updates: 88100
vae loss: 0.23260
kl loss: 0.00010
a decoder loss: 0.23251
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:21
train iter: 881
num of updates: 88200
vae loss: 0.23329
kl loss: 0.00010
a decoder loss: 0.23320
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:22
train iter: 882
num of updates: 88300
vae loss: 0.23259
kl loss: 0.00010
a decoder loss: 0.23250
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:23
train iter: 883
num of updates: 88400
vae loss: 0.23390
kl loss: 0.00010
a decoder loss: 0.23380
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:24
train iter: 884
num of updates: 88500
vae loss: 0.23253
kl loss: 0.00010
a decoder loss: 0.23243
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:25
train iter: 885
num of updates: 88600
vae loss: 0.23312
kl loss: 0.00010
a decoder loss: 0.23303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:26
train iter: 886
num of updates: 88700
vae loss: 0.23297
kl loss: 0.00010
a decoder loss: 0.23287
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:27
train iter: 887
num of updates: 88800
vae loss: 0.23290
kl loss: 0.00010
a decoder loss: 0.23280
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:28
train iter: 888
num of updates: 88900
vae loss: 0.23260
kl loss: 0.00009
a decoder loss: 0.23251
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:29
train iter: 889
num of updates: 89000
vae loss: 0.23190
kl loss: 0.00009
a decoder loss: 0.23181
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:30
train iter: 890
num of updates: 89100
vae loss: 0.23177
kl loss: 0.00010
a decoder loss: 0.23167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:31
train iter: 891
num of updates: 89200
vae loss: 0.23276
kl loss: 0.00009
a decoder loss: 0.23266
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:32
train iter: 892
num of updates: 89300
vae loss: 0.23193
kl loss: 0.00009
a decoder loss: 0.23184
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:33
train iter: 893
num of updates: 89400
vae loss: 0.23235
kl loss: 0.00009
a decoder loss: 0.23225
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:34
train iter: 894
num of updates: 89500
vae loss: 0.23237
kl loss: 0.00009
a decoder loss: 0.23228
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:35
train iter: 895
num of updates: 89600
vae loss: 0.23317
kl loss: 0.00009
a decoder loss: 0.23307
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:36
train iter: 896
num of updates: 89700
vae loss: 0.23186
kl loss: 0.00009
a decoder loss: 0.23177
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:37
train iter: 897
num of updates: 89800
vae loss: 0.23315
kl loss: 0.00009
a decoder loss: 0.23306
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:39
train iter: 898
num of updates: 89900
vae loss: 0.23317
kl loss: 0.00009
a decoder loss: 0.23308
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:40
train iter: 899
num of updates: 90000
vae loss: 0.23335
kl loss: 0.00009
a decoder loss: 0.23326
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:41
train iter: 900
num of updates: 90100
vae loss: 0.23216
kl loss: 0.00009
a decoder loss: 0.23207
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:42
train iter: 901
num of updates: 90200
vae loss: 0.23289
kl loss: 0.00009
a decoder loss: 0.23280
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:43
train iter: 902
num of updates: 90300
vae loss: 0.23260
kl loss: 0.00009
a decoder loss: 0.23250
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:44
train iter: 903
num of updates: 90400
vae loss: 0.23240
kl loss: 0.00009
a decoder loss: 0.23230
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:45
train iter: 904
num of updates: 90500
vae loss: 0.23276
kl loss: 0.00009
a decoder loss: 0.23267
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:46
train iter: 905
num of updates: 90600
vae loss: 0.23113
kl loss: 0.00009
a decoder loss: 0.23104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:47
train iter: 906
num of updates: 90700
vae loss: 0.23359
kl loss: 0.00009
a decoder loss: 0.23350
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:48
train iter: 907
num of updates: 90800
vae loss: 0.23237
kl loss: 0.00009
a decoder loss: 0.23228
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:49
train iter: 908
num of updates: 90900
vae loss: 0.23224
kl loss: 0.00009
a decoder loss: 0.23215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:50
train iter: 909
num of updates: 91000
vae loss: 0.23174
kl loss: 0.00009
a decoder loss: 0.23165
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:51
train iter: 910
num of updates: 91100
vae loss: 0.23292
kl loss: 0.00009
a decoder loss: 0.23283
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:52
train iter: 911
num of updates: 91200
vae loss: 0.23216
kl loss: 0.00009
a decoder loss: 0.23207
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:53
train iter: 912
num of updates: 91300
vae loss: 0.23331
kl loss: 0.00009
a decoder loss: 0.23322
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:54
train iter: 913
num of updates: 91400
vae loss: 0.23246
kl loss: 0.00009
a decoder loss: 0.23236
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:55
train iter: 914
num of updates: 91500
vae loss: 0.23276
kl loss: 0.00009
a decoder loss: 0.23267
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:56
train iter: 915
num of updates: 91600
vae loss: 0.23222
kl loss: 0.00009
a decoder loss: 0.23213
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:57
train iter: 916
num of updates: 91700
vae loss: 0.23224
kl loss: 0.00009
a decoder loss: 0.23215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:58
train iter: 917
num of updates: 91800
vae loss: 0.23281
kl loss: 0.00009
a decoder loss: 0.23272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:59
train iter: 918
num of updates: 91900
vae loss: 0.23329
kl loss: 0.00009
a decoder loss: 0.23320
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:00
train iter: 919
num of updates: 92000
vae loss: 0.23258
kl loss: 0.00009
a decoder loss: 0.23249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:01
train iter: 920
num of updates: 92100
vae loss: 0.23271
kl loss: 0.00009
a decoder loss: 0.23262
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:02
train iter: 921
num of updates: 92200
vae loss: 0.23282
kl loss: 0.00009
a decoder loss: 0.23272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:03
train iter: 922
num of updates: 92300
vae loss: 0.23296
kl loss: 0.00009
a decoder loss: 0.23287
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:04
train iter: 923
num of updates: 92400
vae loss: 0.23255
kl loss: 0.00009
a decoder loss: 0.23246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:05
train iter: 924
num of updates: 92500
vae loss: 0.23240
kl loss: 0.00009
a decoder loss: 0.23231
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:06
train iter: 925
num of updates: 92600
vae loss: 0.23250
kl loss: 0.00009
a decoder loss: 0.23241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:07
train iter: 926
num of updates: 92700
vae loss: 0.23238
kl loss: 0.00009
a decoder loss: 0.23229
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:08
train iter: 927
num of updates: 92800
vae loss: 0.23245
kl loss: 0.00009
a decoder loss: 0.23237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:09
train iter: 928
num of updates: 92900
vae loss: 0.23251
kl loss: 0.00009
a decoder loss: 0.23242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:10
train iter: 929
num of updates: 93000
vae loss: 0.23220
kl loss: 0.00009
a decoder loss: 0.23211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:11
train iter: 930
num of updates: 93100
vae loss: 0.23300
kl loss: 0.00009
a decoder loss: 0.23291
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:12
train iter: 931
num of updates: 93200
vae loss: 0.23214
kl loss: 0.00009
a decoder loss: 0.23205
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:13
train iter: 932
num of updates: 93300
vae loss: 0.23238
kl loss: 0.00009
a decoder loss: 0.23229
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:14
train iter: 933
num of updates: 93400
vae loss: 0.23316
kl loss: 0.00009
a decoder loss: 0.23307
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:15
train iter: 934
num of updates: 93500
vae loss: 0.23205
kl loss: 0.00009
a decoder loss: 0.23196
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:16
train iter: 935
num of updates: 93600
vae loss: 0.23247
kl loss: 0.00009
a decoder loss: 0.23238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:17
train iter: 936
num of updates: 93700
vae loss: 0.23287
kl loss: 0.00009
a decoder loss: 0.23278
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:18
train iter: 937
num of updates: 93800
vae loss: 0.23176
kl loss: 0.00009
a decoder loss: 0.23167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:19
train iter: 938
num of updates: 93900
vae loss: 0.23330
kl loss: 0.00009
a decoder loss: 0.23321
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:20
train iter: 939
num of updates: 94000
vae loss: 0.23210
kl loss: 0.00009
a decoder loss: 0.23202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:21
train iter: 940
num of updates: 94100
vae loss: 0.23200
kl loss: 0.00009
a decoder loss: 0.23191
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:22
train iter: 941
num of updates: 94200
vae loss: 0.23174
kl loss: 0.00009
a decoder loss: 0.23166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:23
train iter: 942
num of updates: 94300
vae loss: 0.23229
kl loss: 0.00009
a decoder loss: 0.23221
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:24
train iter: 943
num of updates: 94400
vae loss: 0.23260
kl loss: 0.00009
a decoder loss: 0.23252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:25
train iter: 944
num of updates: 94500
vae loss: 0.23319
kl loss: 0.00009
a decoder loss: 0.23310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:26
train iter: 945
num of updates: 94600
vae loss: 0.23176
kl loss: 0.00009
a decoder loss: 0.23167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:27
train iter: 946
num of updates: 94700
vae loss: 0.23261
kl loss: 0.00009
a decoder loss: 0.23252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:28
train iter: 947
num of updates: 94800
vae loss: 0.23219
kl loss: 0.00009
a decoder loss: 0.23211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:29
train iter: 948
num of updates: 94900
vae loss: 0.23244
kl loss: 0.00009
a decoder loss: 0.23235
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:30
train iter: 949
num of updates: 95000
vae loss: 0.23229
kl loss: 0.00009
a decoder loss: 0.23220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:31
train iter: 950
num of updates: 95100
vae loss: 0.23174
kl loss: 0.00009
a decoder loss: 0.23166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:32
train iter: 951
num of updates: 95200
vae loss: 0.23306
kl loss: 0.00009
a decoder loss: 0.23297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:33
train iter: 952
num of updates: 95300
vae loss: 0.23228
kl loss: 0.00009
a decoder loss: 0.23219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:34
train iter: 953
num of updates: 95400
vae loss: 0.23249
kl loss: 0.00009
a decoder loss: 0.23241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:35
train iter: 954
num of updates: 95500
vae loss: 0.23264
kl loss: 0.00009
a decoder loss: 0.23256
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:36
train iter: 955
num of updates: 95600
vae loss: 0.23169
kl loss: 0.00009
a decoder loss: 0.23161
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:37
train iter: 956
num of updates: 95700
vae loss: 0.23278
kl loss: 0.00009
a decoder loss: 0.23270
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:38
train iter: 957
num of updates: 95800
vae loss: 0.23209
kl loss: 0.00009
a decoder loss: 0.23201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:39
train iter: 958
num of updates: 95900
vae loss: 0.23114
kl loss: 0.00008
a decoder loss: 0.23106
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:40
train iter: 959
num of updates: 96000
vae loss: 0.23238
kl loss: 0.00009
a decoder loss: 0.23230
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:41
train iter: 960
num of updates: 96100
vae loss: 0.23237
kl loss: 0.00009
a decoder loss: 0.23229
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:42
train iter: 961
num of updates: 96200
vae loss: 0.23216
kl loss: 0.00008
a decoder loss: 0.23208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:43
train iter: 962
num of updates: 96300
vae loss: 0.23258
kl loss: 0.00008
a decoder loss: 0.23250
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:44
train iter: 963
num of updates: 96400
vae loss: 0.23256
kl loss: 0.00008
a decoder loss: 0.23248
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:45
train iter: 964
num of updates: 96500
vae loss: 0.23203
kl loss: 0.00008
a decoder loss: 0.23194
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:46
train iter: 965
num of updates: 96600
vae loss: 0.23259
kl loss: 0.00008
a decoder loss: 0.23250
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:47
train iter: 966
num of updates: 96700
vae loss: 0.23235
kl loss: 0.00008
a decoder loss: 0.23227
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:49
train iter: 967
num of updates: 96800
vae loss: 0.23248
kl loss: 0.00008
a decoder loss: 0.23239
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:50
train iter: 968
num of updates: 96900
vae loss: 0.23267
kl loss: 0.00008
a decoder loss: 0.23259
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:51
train iter: 969
num of updates: 97000
vae loss: 0.23232
kl loss: 0.00008
a decoder loss: 0.23223
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:52
train iter: 970
num of updates: 97100
vae loss: 0.23176
kl loss: 0.00008
a decoder loss: 0.23168
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:53
train iter: 971
num of updates: 97200
vae loss: 0.23283
kl loss: 0.00008
a decoder loss: 0.23275
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:54
train iter: 972
num of updates: 97300
vae loss: 0.23206
kl loss: 0.00008
a decoder loss: 0.23198
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:55
train iter: 973
num of updates: 97400
vae loss: 0.23246
kl loss: 0.00008
a decoder loss: 0.23237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:56
train iter: 974
num of updates: 97500
vae loss: 0.23269
kl loss: 0.00008
a decoder loss: 0.23261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:57
train iter: 975
num of updates: 97600
vae loss: 0.23273
kl loss: 0.00008
a decoder loss: 0.23265
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:58
train iter: 976
num of updates: 97700
vae loss: 0.23202
kl loss: 0.00008
a decoder loss: 0.23194
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:59
train iter: 977
num of updates: 97800
vae loss: 0.23220
kl loss: 0.00008
a decoder loss: 0.23212
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:00
train iter: 978
num of updates: 97900
vae loss: 0.23197
kl loss: 0.00008
a decoder loss: 0.23189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:01
train iter: 979
num of updates: 98000
vae loss: 0.23246
kl loss: 0.00008
a decoder loss: 0.23238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:02
train iter: 980
num of updates: 98100
vae loss: 0.23178
kl loss: 0.00008
a decoder loss: 0.23170
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:03
train iter: 981
num of updates: 98200
vae loss: 0.23259
kl loss: 0.00008
a decoder loss: 0.23251
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:04
train iter: 982
num of updates: 98300
vae loss: 0.23242
kl loss: 0.00008
a decoder loss: 0.23234
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:05
train iter: 983
num of updates: 98400
vae loss: 0.23285
kl loss: 0.00008
a decoder loss: 0.23277
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:06
train iter: 984
num of updates: 98500
vae loss: 0.23227
kl loss: 0.00008
a decoder loss: 0.23219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:07
train iter: 985
num of updates: 98600
vae loss: 0.23208
kl loss: 0.00008
a decoder loss: 0.23199
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:08
train iter: 986
num of updates: 98700
vae loss: 0.23276
kl loss: 0.00008
a decoder loss: 0.23268
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:09
train iter: 987
num of updates: 98800
vae loss: 0.23253
kl loss: 0.00008
a decoder loss: 0.23245
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:10
train iter: 988
num of updates: 98900
vae loss: 0.23170
kl loss: 0.00008
a decoder loss: 0.23162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:11
train iter: 989
num of updates: 99000
vae loss: 0.23199
kl loss: 0.00008
a decoder loss: 0.23191
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:12
train iter: 990
num of updates: 99100
vae loss: 0.23220
kl loss: 0.00008
a decoder loss: 0.23212
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:13
train iter: 991
num of updates: 99200
vae loss: 0.23221
kl loss: 0.00008
a decoder loss: 0.23213
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:14
train iter: 992
num of updates: 99300
vae loss: 0.23277
kl loss: 0.00008
a decoder loss: 0.23268
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:15
train iter: 993
num of updates: 99400
vae loss: 0.23121
kl loss: 0.00008
a decoder loss: 0.23113
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:16
train iter: 994
num of updates: 99500
vae loss: 0.23197
kl loss: 0.00008
a decoder loss: 0.23189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:17
train iter: 995
num of updates: 99600
vae loss: 0.23177
kl loss: 0.00008
a decoder loss: 0.23169
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:18
train iter: 996
num of updates: 99700
vae loss: 0.23147
kl loss: 0.00008
a decoder loss: 0.23139
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:19
train iter: 997
num of updates: 99800
vae loss: 0.23210
kl loss: 0.00008
a decoder loss: 0.23202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:20
train iter: 998
num of updates: 99900
vae loss: 0.23180
kl loss: 0.00008
a decoder loss: 0.23172
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:21
train iter: 999
num of updates: 100000
vae loss: 0.23243
kl loss: 0.00008
a decoder loss: 0.23235
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/vae_model_100000.pt
============================================================
finished training vae!
============================================================
started training vae at: 25-09-28-00-57-49
finished training vae at: 25-09-28-02-06-20
total vae training time: 1:08:31
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/vae_model.pt
============================================================
2025-09-28 02:06:22.946526: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:06:24.739800: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 20 bytes spill stores, 20 bytes spill loads

2025-09-28 02:06:24.761956: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 40 bytes spill stores, 40 bytes spill loads

2025-09-28 02:06:25.523239: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 02:06:26.732999: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:06:29.143920: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:06:29.144004: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:06:29.621753: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:06:32.134957: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:06:34.971064: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 504 bytes spill stores, 460 bytes spill loads

2025-09-28 02:06:35.164662: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 404 bytes spill stores, 404 bytes spill loads

2025-09-28 02:06:36.210376: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 236 bytes spill stores, 236 bytes spill loads

2025-09-28 02:06:37.047162: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 908 bytes spill stores, 668 bytes spill loads

2025-09-28 02:06:37.988945: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 1868 bytes spill stores, 1352 bytes spill loads

2025-09-28 02:06:38.912642: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:06:40.584067: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 24 bytes spill stores, 24 bytes spill loads

Error executing job with overrides: ['state_dep_prior=True', 'learn_dynamics_std=False', 'autonomous=False', 'gamma=0.98']
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/jax_dt/train_dt.py", line 1286, in train
    _vae_params = load_params(load_current_model_path)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 75, in load_params
    with File(path, 'rb') as fin:
         ^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 59, in __init__
    self.f = open(fileName, mode)
             ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-57-49/vae_model_1000000.pt'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrelocate-expert-v1-985440[0m at: [34mhttps://wandb.ai/james-gatsby/jax_dt/runs/j012czr7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250928_005837-j012czr7/logs[0m
Exception ignored in: <function OffScreenViewer.__del__ at 0x7518911b0b80>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/platform/baseplatform.py", line 487, in __call__
    return self(*args, **named)
           ^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x751866d53050>,
		<OpenGL._opaque.EGLContext_pointer object at 0x751866d534d0>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x7518b3bd11c0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x751866d53050>,
		<OpenGL._opaque.EGLContext_pointer object at 0x751866d534d0>,
	),
	result = 0
)
Exception ignored in: <function OffScreenViewer.__del__ at 0x7518911b0b80>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x751866d53050>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7518b3b75350>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7518b3b75350>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7518b3b750d0>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x7518b3bd11c0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x751866d53050>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7518b3b75350>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7518b3b75350>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7518b3b750d0>,
	),
	result = 0
)
