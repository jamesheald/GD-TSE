Launching a python run
Sun Sep 28 12:50:51 AM UTC 2025
Active conda env: /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/python3
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/pip
2025-09-28 00:51:29.162345: I external/xla/xla/pjrt/pjrt_api.cc:115] GetPjrtApi was found for cuda at /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/jax_plugins/xla_cuda12/xla_cuda_plugin.so
2025-09-28 00:51:29.163481: I external/xla/xla/pjrt/pjrt_api.cc:93] PJRT_Api is set for device type cuda
2025-09-28 00:51:29.488444: I external/xla/xla/pjrt/pjrt_api.cc:161] The PJRT plugin has PJRT API version 0.70. The framework PJRT API version is 0.70.
2025-09-28 00:51:29.778470: I external/xla/xla/service/service.cc:153] XLA service 0x58f3b86474b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-09-28 00:51:29.778508: I external/xla/xla/service/service.cc:161]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2025-09-28 00:51:29.893838: I external/xla/xla/pjrt/pjrt_c_api_client.cc:130] PjRtCApiClient created.
[CudaDevice(id=0)]
/nfs/nhome/live/jheald/jax_dt/train_dt.py:50: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path=cfg_path, config_name="config.yaml")
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
============================================================
start time: 25-09-28-00-51-36
============================================================
dataset path: data//relocate-expert-v1-fullnextstate.pkl
log csv save path: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/log.csv
[2025-09-28 00:51:38,789][OpenGL.acceleratesupport][INFO] - No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'
wandb: Currently logged in as: james-heald (james-gatsby) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /nfs/nhome/live/jheald/jax_dt/outputs/2025-09-28/00-51-31/wandb/run-20250928_005229-1b3wv9by
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run relocate-expert-v1-985440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/james-gatsby/jax_dt
wandb: üöÄ View run at https://wandb.ai/james-gatsby/jax_dt/runs/1b3wv9by
2025-09-28 00:52:41.507758: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 12 bytes spill stores, 12 bytes spill loads

2025-09-28 00:52:43.712864: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 1016 bytes spill stores, 1016 bytes spill loads

2025-09-28 00:52:46.090208: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 16008 bytes spill stores, 16296 bytes spill loads

2025-09-28 00:52:47.030755: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 5912 bytes spill stores, 5776 bytes spill loads

2025-09-28 00:52:50.174500: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 14984 bytes spill stores, 14840 bytes spill loads

============================================================
time elapsed: 0:01:21
train iter: 0
num of updates: 100
dynamics loss: 3.11587

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/dynamics_model_100.pt
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = _fork_exec(
============================================================
time elapsed: 0:01:36
train iter: 1
num of updates: 200
dynamics loss: 3.11469

============================================================
time elapsed: 0:01:39
train iter: 2
num of updates: 300
dynamics loss: 3.11237

============================================================
time elapsed: 0:01:42
train iter: 3
num of updates: 400
dynamics loss: 3.10842

============================================================
time elapsed: 0:01:45
train iter: 4
num of updates: 500
dynamics loss: 3.10467

============================================================
time elapsed: 0:01:48
train iter: 5
num of updates: 600
dynamics loss: 3.09905

============================================================
time elapsed: 0:01:50
train iter: 6
num of updates: 700
dynamics loss: 3.09299

============================================================
time elapsed: 0:01:53
train iter: 7
num of updates: 800
dynamics loss: 3.08564

============================================================
time elapsed: 0:01:56
train iter: 8
num of updates: 900
dynamics loss: 3.07799

============================================================
time elapsed: 0:01:59
train iter: 9
num of updates: 1000
dynamics loss: 3.06857

============================================================
time elapsed: 0:02:02
train iter: 10
num of updates: 1100
dynamics loss: 3.05875

============================================================
time elapsed: 0:02:05
train iter: 11
num of updates: 1200
dynamics loss: 3.04819

============================================================
time elapsed: 0:02:08
train iter: 12
num of updates: 1300
dynamics loss: 3.03723

============================================================
time elapsed: 0:02:10
train iter: 13
num of updates: 1400
dynamics loss: 3.02584

============================================================
time elapsed: 0:02:13
train iter: 14
num of updates: 1500
dynamics loss: 3.01367

============================================================
time elapsed: 0:02:16
train iter: 15
num of updates: 1600
dynamics loss: 3.00118

============================================================
time elapsed: 0:02:19
train iter: 16
num of updates: 1700
dynamics loss: 2.98816

============================================================
time elapsed: 0:02:22
train iter: 17
num of updates: 1800
dynamics loss: 2.97580

============================================================
time elapsed: 0:02:25
train iter: 18
num of updates: 1900
dynamics loss: 2.96180

============================================================
time elapsed: 0:02:28
train iter: 19
num of updates: 2000
dynamics loss: 2.94805

============================================================
time elapsed: 0:02:31
train iter: 20
num of updates: 2100
dynamics loss: 2.93391

============================================================
time elapsed: 0:02:33
train iter: 21
num of updates: 2200
dynamics loss: 2.91994

============================================================
time elapsed: 0:02:36
train iter: 22
num of updates: 2300
dynamics loss: 2.90551

============================================================
time elapsed: 0:02:39
train iter: 23
num of updates: 2400
dynamics loss: 2.89152

============================================================
time elapsed: 0:02:42
train iter: 24
num of updates: 2500
dynamics loss: 2.87737

============================================================
time elapsed: 0:02:45
train iter: 25
num of updates: 2600
dynamics loss: 2.86253

============================================================
time elapsed: 0:02:48
train iter: 26
num of updates: 2700
dynamics loss: 2.84806

============================================================
time elapsed: 0:02:51
train iter: 27
num of updates: 2800
dynamics loss: 2.83389

============================================================
time elapsed: 0:02:53
train iter: 28
num of updates: 2900
dynamics loss: 2.81981

============================================================
time elapsed: 0:02:56
train iter: 29
num of updates: 3000
dynamics loss: 2.80561

============================================================
time elapsed: 0:02:59
train iter: 30
num of updates: 3100
dynamics loss: 2.79119

============================================================
time elapsed: 0:03:02
train iter: 31
num of updates: 3200
dynamics loss: 2.77749

============================================================
time elapsed: 0:03:05
train iter: 32
num of updates: 3300
dynamics loss: 2.76315

============================================================
time elapsed: 0:03:08
train iter: 33
num of updates: 3400
dynamics loss: 2.74942

============================================================
time elapsed: 0:03:11
train iter: 34
num of updates: 3500
dynamics loss: 2.73541

============================================================
time elapsed: 0:03:14
train iter: 35
num of updates: 3600
dynamics loss: 2.72203

============================================================
time elapsed: 0:03:16
train iter: 36
num of updates: 3700
dynamics loss: 2.70835

============================================================
time elapsed: 0:03:19
train iter: 37
num of updates: 3800
dynamics loss: 2.69512

============================================================
time elapsed: 0:03:22
train iter: 38
num of updates: 3900
dynamics loss: 2.68182

============================================================
time elapsed: 0:03:25
train iter: 39
num of updates: 4000
dynamics loss: 2.66838

============================================================
time elapsed: 0:03:28
train iter: 40
num of updates: 4100
dynamics loss: 2.65522

============================================================
time elapsed: 0:03:31
train iter: 41
num of updates: 4200
dynamics loss: 2.64230

============================================================
time elapsed: 0:03:34
train iter: 42
num of updates: 4300
dynamics loss: 2.62926

============================================================
time elapsed: 0:03:36
train iter: 43
num of updates: 4400
dynamics loss: 2.61630

============================================================
time elapsed: 0:03:39
train iter: 44
num of updates: 4500
dynamics loss: 2.60379

============================================================
time elapsed: 0:03:42
train iter: 45
num of updates: 4600
dynamics loss: 2.59115

============================================================
time elapsed: 0:03:45
train iter: 46
num of updates: 4700
dynamics loss: 2.57837

============================================================
time elapsed: 0:03:48
train iter: 47
num of updates: 4800
dynamics loss: 2.56619

============================================================
time elapsed: 0:03:51
train iter: 48
num of updates: 4900
dynamics loss: 2.55338

============================================================
time elapsed: 0:03:54
train iter: 49
num of updates: 5000
dynamics loss: 2.54115

============================================================
time elapsed: 0:03:57
train iter: 50
num of updates: 5100
dynamics loss: 2.52862

============================================================
time elapsed: 0:03:59
train iter: 51
num of updates: 5200
dynamics loss: 2.51628

============================================================
time elapsed: 0:04:02
train iter: 52
num of updates: 5300
dynamics loss: 2.50369

============================================================
time elapsed: 0:04:05
train iter: 53
num of updates: 5400
dynamics loss: 2.49138

============================================================
time elapsed: 0:04:08
train iter: 54
num of updates: 5500
dynamics loss: 2.47917

============================================================
time elapsed: 0:04:11
train iter: 55
num of updates: 5600
dynamics loss: 2.46673

============================================================
time elapsed: 0:04:14
train iter: 56
num of updates: 5700
dynamics loss: 2.45452

============================================================
time elapsed: 0:04:17
train iter: 57
num of updates: 5800
dynamics loss: 2.44211

============================================================
time elapsed: 0:04:19
train iter: 58
num of updates: 5900
dynamics loss: 2.42942

============================================================
time elapsed: 0:04:22
train iter: 59
num of updates: 6000
dynamics loss: 2.41687

============================================================
time elapsed: 0:04:25
train iter: 60
num of updates: 6100
dynamics loss: 2.40427

============================================================
time elapsed: 0:04:28
train iter: 61
num of updates: 6200
dynamics loss: 2.39194

============================================================
time elapsed: 0:04:31
train iter: 62
num of updates: 6300
dynamics loss: 2.37934

============================================================
time elapsed: 0:04:34
train iter: 63
num of updates: 6400
dynamics loss: 2.36656

============================================================
time elapsed: 0:04:37
train iter: 64
num of updates: 6500
dynamics loss: 2.35382

============================================================
time elapsed: 0:04:40
train iter: 65
num of updates: 6600
dynamics loss: 2.34091

============================================================
time elapsed: 0:04:42
train iter: 66
num of updates: 6700
dynamics loss: 2.32825

============================================================
time elapsed: 0:04:45
train iter: 67
num of updates: 6800
dynamics loss: 2.31510

============================================================
time elapsed: 0:04:48
train iter: 68
num of updates: 6900
dynamics loss: 2.30223

============================================================
time elapsed: 0:04:51
train iter: 69
num of updates: 7000
dynamics loss: 2.28899

============================================================
time elapsed: 0:04:54
train iter: 70
num of updates: 7100
dynamics loss: 2.27596

============================================================
time elapsed: 0:04:57
train iter: 71
num of updates: 7200
dynamics loss: 2.26272

============================================================
time elapsed: 0:05:00
train iter: 72
num of updates: 7300
dynamics loss: 2.24949

============================================================
time elapsed: 0:05:02
train iter: 73
num of updates: 7400
dynamics loss: 2.23617

============================================================
time elapsed: 0:05:05
train iter: 74
num of updates: 7500
dynamics loss: 2.22249

============================================================
time elapsed: 0:05:08
train iter: 75
num of updates: 7600
dynamics loss: 2.20917

============================================================
time elapsed: 0:05:11
train iter: 76
num of updates: 7700
dynamics loss: 2.19571

============================================================
time elapsed: 0:05:14
train iter: 77
num of updates: 7800
dynamics loss: 2.18194

============================================================
time elapsed: 0:05:17
train iter: 78
num of updates: 7900
dynamics loss: 2.16838

============================================================
time elapsed: 0:05:20
train iter: 79
num of updates: 8000
dynamics loss: 2.15477

============================================================
time elapsed: 0:05:23
train iter: 80
num of updates: 8100
dynamics loss: 2.14099

============================================================
time elapsed: 0:05:25
train iter: 81
num of updates: 8200
dynamics loss: 2.12739

============================================================
time elapsed: 0:05:28
train iter: 82
num of updates: 8300
dynamics loss: 2.11324

============================================================
time elapsed: 0:05:31
train iter: 83
num of updates: 8400
dynamics loss: 2.09955

============================================================
time elapsed: 0:05:34
train iter: 84
num of updates: 8500
dynamics loss: 2.08570

============================================================
time elapsed: 0:05:37
train iter: 85
num of updates: 8600
dynamics loss: 2.07200

============================================================
time elapsed: 0:05:40
train iter: 86
num of updates: 8700
dynamics loss: 2.05802

============================================================
time elapsed: 0:05:43
train iter: 87
num of updates: 8800
dynamics loss: 2.04381

============================================================
time elapsed: 0:05:45
train iter: 88
num of updates: 8900
dynamics loss: 2.02984

============================================================
time elapsed: 0:05:48
train iter: 89
num of updates: 9000
dynamics loss: 2.01580

============================================================
time elapsed: 0:05:51
train iter: 90
num of updates: 9100
dynamics loss: 2.00165

============================================================
time elapsed: 0:05:54
train iter: 91
num of updates: 9200
dynamics loss: 1.98742

============================================================
time elapsed: 0:05:57
train iter: 92
num of updates: 9300
dynamics loss: 1.97379

============================================================
time elapsed: 0:06:00
train iter: 93
num of updates: 9400
dynamics loss: 1.95957

============================================================
time elapsed: 0:06:03
train iter: 94
num of updates: 9500
dynamics loss: 1.94537

============================================================
time elapsed: 0:06:06
train iter: 95
num of updates: 9600
dynamics loss: 1.93120

============================================================
time elapsed: 0:06:08
train iter: 96
num of updates: 9700
dynamics loss: 1.91719

============================================================
time elapsed: 0:06:11
train iter: 97
num of updates: 9800
dynamics loss: 1.90338

============================================================
time elapsed: 0:06:14
train iter: 98
num of updates: 9900
dynamics loss: 1.88923

============================================================
time elapsed: 0:06:17
train iter: 99
num of updates: 10000
dynamics loss: 1.87538

============================================================
time elapsed: 0:06:20
train iter: 100
num of updates: 10100
dynamics loss: 1.86158

============================================================
time elapsed: 0:06:23
train iter: 101
num of updates: 10200
dynamics loss: 1.84784

============================================================
time elapsed: 0:06:26
train iter: 102
num of updates: 10300
dynamics loss: 1.83410

============================================================
time elapsed: 0:06:28
train iter: 103
num of updates: 10400
dynamics loss: 1.82047

============================================================
time elapsed: 0:06:31
train iter: 104
num of updates: 10500
dynamics loss: 1.80696

============================================================
time elapsed: 0:06:34
train iter: 105
num of updates: 10600
dynamics loss: 1.79401

============================================================
time elapsed: 0:06:37
train iter: 106
num of updates: 10700
dynamics loss: 1.78124

============================================================
time elapsed: 0:06:40
train iter: 107
num of updates: 10800
dynamics loss: 1.76861

============================================================
time elapsed: 0:06:43
train iter: 108
num of updates: 10900
dynamics loss: 1.75561

============================================================
time elapsed: 0:06:46
train iter: 109
num of updates: 11000
dynamics loss: 1.74309

============================================================
time elapsed: 0:06:49
train iter: 110
num of updates: 11100
dynamics loss: 1.73092

============================================================
time elapsed: 0:06:51
train iter: 111
num of updates: 11200
dynamics loss: 1.71851

============================================================
time elapsed: 0:06:54
train iter: 112
num of updates: 11300
dynamics loss: 1.70675

============================================================
time elapsed: 0:06:57
train iter: 113
num of updates: 11400
dynamics loss: 1.69444

============================================================
time elapsed: 0:07:00
train iter: 114
num of updates: 11500
dynamics loss: 1.68333

============================================================
time elapsed: 0:07:03
train iter: 115
num of updates: 11600
dynamics loss: 1.67153

============================================================
time elapsed: 0:07:06
train iter: 116
num of updates: 11700
dynamics loss: 1.66041

============================================================
time elapsed: 0:07:09
train iter: 117
num of updates: 11800
dynamics loss: 1.64903

============================================================
time elapsed: 0:07:11
train iter: 118
num of updates: 11900
dynamics loss: 1.63808

============================================================
time elapsed: 0:07:14
train iter: 119
num of updates: 12000
dynamics loss: 1.62732

============================================================
time elapsed: 0:07:17
train iter: 120
num of updates: 12100
dynamics loss: 1.61617

============================================================
time elapsed: 0:07:20
train iter: 121
num of updates: 12200
dynamics loss: 1.60565

============================================================
time elapsed: 0:07:23
train iter: 122
num of updates: 12300
dynamics loss: 1.59490

============================================================
time elapsed: 0:07:26
train iter: 123
num of updates: 12400
dynamics loss: 1.58458

============================================================
time elapsed: 0:07:29
train iter: 124
num of updates: 12500
dynamics loss: 1.57437

============================================================
time elapsed: 0:07:32
train iter: 125
num of updates: 12600
dynamics loss: 1.56425

============================================================
time elapsed: 0:07:34
train iter: 126
num of updates: 12700
dynamics loss: 1.55455

============================================================
time elapsed: 0:07:37
train iter: 127
num of updates: 12800
dynamics loss: 1.54494

============================================================
time elapsed: 0:07:40
train iter: 128
num of updates: 12900
dynamics loss: 1.53523

============================================================
time elapsed: 0:07:43
train iter: 129
num of updates: 13000
dynamics loss: 1.52547

============================================================
time elapsed: 0:07:46
train iter: 130
num of updates: 13100
dynamics loss: 1.51619

============================================================
time elapsed: 0:07:49
train iter: 131
num of updates: 13200
dynamics loss: 1.50681

============================================================
time elapsed: 0:07:52
train iter: 132
num of updates: 13300
dynamics loss: 1.49749

============================================================
time elapsed: 0:07:54
train iter: 133
num of updates: 13400
dynamics loss: 1.48883

============================================================
time elapsed: 0:07:57
train iter: 134
num of updates: 13500
dynamics loss: 1.47963

============================================================
time elapsed: 0:08:00
train iter: 135
num of updates: 13600
dynamics loss: 1.47137

============================================================
time elapsed: 0:08:03
train iter: 136
num of updates: 13700
dynamics loss: 1.46264

============================================================
time elapsed: 0:08:06
train iter: 137
num of updates: 13800
dynamics loss: 1.45424

============================================================
time elapsed: 0:08:09
train iter: 138
num of updates: 13900
dynamics loss: 1.44588

============================================================
time elapsed: 0:08:12
train iter: 139
num of updates: 14000
dynamics loss: 1.43771

============================================================
time elapsed: 0:08:15
train iter: 140
num of updates: 14100
dynamics loss: 1.42960

============================================================
time elapsed: 0:08:17
train iter: 141
num of updates: 14200
dynamics loss: 1.42140

============================================================
time elapsed: 0:08:20
train iter: 142
num of updates: 14300
dynamics loss: 1.41367

============================================================
time elapsed: 0:08:23
train iter: 143
num of updates: 14400
dynamics loss: 1.40623

============================================================
time elapsed: 0:08:26
train iter: 144
num of updates: 14500
dynamics loss: 1.39825

============================================================
time elapsed: 0:08:29
train iter: 145
num of updates: 14600
dynamics loss: 1.39084

============================================================
time elapsed: 0:08:32
train iter: 146
num of updates: 14700
dynamics loss: 1.38335

============================================================
time elapsed: 0:08:35
train iter: 147
num of updates: 14800
dynamics loss: 1.37625

============================================================
time elapsed: 0:08:37
train iter: 148
num of updates: 14900
dynamics loss: 1.36975

============================================================
time elapsed: 0:08:40
train iter: 149
num of updates: 15000
dynamics loss: 1.36227

============================================================
time elapsed: 0:08:43
train iter: 150
num of updates: 15100
dynamics loss: 1.35587

============================================================
time elapsed: 0:08:46
train iter: 151
num of updates: 15200
dynamics loss: 1.34843

============================================================
time elapsed: 0:08:49
train iter: 152
num of updates: 15300
dynamics loss: 1.34175

============================================================
time elapsed: 0:08:52
train iter: 153
num of updates: 15400
dynamics loss: 1.33519

============================================================
time elapsed: 0:08:55
train iter: 154
num of updates: 15500
dynamics loss: 1.32899

============================================================
time elapsed: 0:08:58
train iter: 155
num of updates: 15600
dynamics loss: 1.32246

============================================================
time elapsed: 0:09:00
train iter: 156
num of updates: 15700
dynamics loss: 1.31568

============================================================
time elapsed: 0:09:03
train iter: 157
num of updates: 15800
dynamics loss: 1.30922

============================================================
time elapsed: 0:09:06
train iter: 158
num of updates: 15900
dynamics loss: 1.30365

============================================================
time elapsed: 0:09:09
train iter: 159
num of updates: 16000
dynamics loss: 1.29782

============================================================
time elapsed: 0:09:12
train iter: 160
num of updates: 16100
dynamics loss: 1.29162

============================================================
time elapsed: 0:09:15
train iter: 161
num of updates: 16200
dynamics loss: 1.28660

============================================================
time elapsed: 0:09:18
train iter: 162
num of updates: 16300
dynamics loss: 1.28055

============================================================
time elapsed: 0:09:20
train iter: 163
num of updates: 16400
dynamics loss: 1.27489

============================================================
time elapsed: 0:09:23
train iter: 164
num of updates: 16500
dynamics loss: 1.26946

============================================================
time elapsed: 0:09:26
train iter: 165
num of updates: 16600
dynamics loss: 1.26342

============================================================
time elapsed: 0:09:29
train iter: 166
num of updates: 16700
dynamics loss: 1.25832

============================================================
time elapsed: 0:09:32
train iter: 167
num of updates: 16800
dynamics loss: 1.25325

============================================================
time elapsed: 0:09:35
train iter: 168
num of updates: 16900
dynamics loss: 1.24773

============================================================
time elapsed: 0:09:38
train iter: 169
num of updates: 17000
dynamics loss: 1.24280

============================================================
time elapsed: 0:09:40
train iter: 170
num of updates: 17100
dynamics loss: 1.23756

============================================================
time elapsed: 0:09:43
train iter: 171
num of updates: 17200
dynamics loss: 1.23270

============================================================
time elapsed: 0:09:46
train iter: 172
num of updates: 17300
dynamics loss: 1.22850

============================================================
time elapsed: 0:09:49
train iter: 173
num of updates: 17400
dynamics loss: 1.22309

============================================================
time elapsed: 0:09:52
train iter: 174
num of updates: 17500
dynamics loss: 1.21885

============================================================
time elapsed: 0:09:55
train iter: 175
num of updates: 17600
dynamics loss: 1.21372

============================================================
time elapsed: 0:09:58
train iter: 176
num of updates: 17700
dynamics loss: 1.20931

============================================================
time elapsed: 0:10:01
train iter: 177
num of updates: 17800
dynamics loss: 1.20461

============================================================
time elapsed: 0:10:03
train iter: 178
num of updates: 17900
dynamics loss: 1.19987

============================================================
time elapsed: 0:10:06
train iter: 179
num of updates: 18000
dynamics loss: 1.19588

============================================================
time elapsed: 0:10:09
train iter: 180
num of updates: 18100
dynamics loss: 1.19161

============================================================
time elapsed: 0:10:12
train iter: 181
num of updates: 18200
dynamics loss: 1.18709

============================================================
time elapsed: 0:10:15
train iter: 182
num of updates: 18300
dynamics loss: 1.18283

============================================================
time elapsed: 0:10:18
train iter: 183
num of updates: 18400
dynamics loss: 1.17880

============================================================
time elapsed: 0:10:21
train iter: 184
num of updates: 18500
dynamics loss: 1.17494

============================================================
time elapsed: 0:10:23
train iter: 185
num of updates: 18600
dynamics loss: 1.17052

============================================================
time elapsed: 0:10:26
train iter: 186
num of updates: 18700
dynamics loss: 1.16711

============================================================
time elapsed: 0:10:29
train iter: 187
num of updates: 18800
dynamics loss: 1.16309

============================================================
time elapsed: 0:10:32
train iter: 188
num of updates: 18900
dynamics loss: 1.15931

============================================================
time elapsed: 0:10:35
train iter: 189
num of updates: 19000
dynamics loss: 1.15503

============================================================
time elapsed: 0:10:38
train iter: 190
num of updates: 19100
dynamics loss: 1.15197

============================================================
time elapsed: 0:10:41
train iter: 191
num of updates: 19200
dynamics loss: 1.14869

============================================================
time elapsed: 0:10:44
train iter: 192
num of updates: 19300
dynamics loss: 1.14413

============================================================
time elapsed: 0:10:46
train iter: 193
num of updates: 19400
dynamics loss: 1.14027

============================================================
time elapsed: 0:10:49
train iter: 194
num of updates: 19500
dynamics loss: 1.13745

============================================================
time elapsed: 0:10:52
train iter: 195
num of updates: 19600
dynamics loss: 1.13397

============================================================
time elapsed: 0:10:55
train iter: 196
num of updates: 19700
dynamics loss: 1.13022

============================================================
time elapsed: 0:10:58
train iter: 197
num of updates: 19800
dynamics loss: 1.12673

============================================================
time elapsed: 0:11:01
train iter: 198
num of updates: 19900
dynamics loss: 1.12310

============================================================
time elapsed: 0:11:04
train iter: 199
num of updates: 20000
dynamics loss: 1.12038

============================================================
time elapsed: 0:11:06
train iter: 200
num of updates: 20100
dynamics loss: 1.11703

============================================================
time elapsed: 0:11:09
train iter: 201
num of updates: 20200
dynamics loss: 1.11346

============================================================
time elapsed: 0:11:12
train iter: 202
num of updates: 20300
dynamics loss: 1.11051

============================================================
time elapsed: 0:11:15
train iter: 203
num of updates: 20400
dynamics loss: 1.10744

============================================================
time elapsed: 0:11:18
train iter: 204
num of updates: 20500
dynamics loss: 1.10468

============================================================
time elapsed: 0:11:21
train iter: 205
num of updates: 20600
dynamics loss: 1.10146

============================================================
time elapsed: 0:11:24
train iter: 206
num of updates: 20700
dynamics loss: 1.09903

============================================================
time elapsed: 0:11:27
train iter: 207
num of updates: 20800
dynamics loss: 1.09560

============================================================
time elapsed: 0:11:29
train iter: 208
num of updates: 20900
dynamics loss: 1.09286

============================================================
time elapsed: 0:11:32
train iter: 209
num of updates: 21000
dynamics loss: 1.09013

============================================================
time elapsed: 0:11:35
train iter: 210
num of updates: 21100
dynamics loss: 1.08742

============================================================
time elapsed: 0:11:38
train iter: 211
num of updates: 21200
dynamics loss: 1.08492

============================================================
time elapsed: 0:11:41
train iter: 212
num of updates: 21300
dynamics loss: 1.08128

============================================================
time elapsed: 0:11:44
train iter: 213
num of updates: 21400
dynamics loss: 1.07909

============================================================
time elapsed: 0:11:47
train iter: 214
num of updates: 21500
dynamics loss: 1.07619

============================================================
time elapsed: 0:11:50
train iter: 215
num of updates: 21600
dynamics loss: 1.07423

============================================================
time elapsed: 0:11:52
train iter: 216
num of updates: 21700
dynamics loss: 1.07135

============================================================
time elapsed: 0:11:55
train iter: 217
num of updates: 21800
dynamics loss: 1.06856

============================================================
time elapsed: 0:11:58
train iter: 218
num of updates: 21900
dynamics loss: 1.06572

============================================================
time elapsed: 0:12:01
train iter: 219
num of updates: 22000
dynamics loss: 1.06371

============================================================
time elapsed: 0:12:04
train iter: 220
num of updates: 22100
dynamics loss: 1.06081

============================================================
time elapsed: 0:12:07
train iter: 221
num of updates: 22200
dynamics loss: 1.05912

============================================================
time elapsed: 0:12:10
train iter: 222
num of updates: 22300
dynamics loss: 1.05618

============================================================
time elapsed: 0:12:12
train iter: 223
num of updates: 22400
dynamics loss: 1.05384

============================================================
time elapsed: 0:12:15
train iter: 224
num of updates: 22500
dynamics loss: 1.05153

============================================================
time elapsed: 0:12:18
train iter: 225
num of updates: 22600
dynamics loss: 1.04978

============================================================
time elapsed: 0:12:21
train iter: 226
num of updates: 22700
dynamics loss: 1.04688

============================================================
time elapsed: 0:12:24
train iter: 227
num of updates: 22800
dynamics loss: 1.04448

============================================================
time elapsed: 0:12:27
train iter: 228
num of updates: 22900
dynamics loss: 1.04233

============================================================
time elapsed: 0:12:30
train iter: 229
num of updates: 23000
dynamics loss: 1.04001

============================================================
time elapsed: 0:12:33
train iter: 230
num of updates: 23100
dynamics loss: 1.03782

============================================================
time elapsed: 0:12:35
train iter: 231
num of updates: 23200
dynamics loss: 1.03567

============================================================
time elapsed: 0:12:38
train iter: 232
num of updates: 23300
dynamics loss: 1.03388

============================================================
time elapsed: 0:12:41
train iter: 233
num of updates: 23400
dynamics loss: 1.03149

============================================================
time elapsed: 0:12:44
train iter: 234
num of updates: 23500
dynamics loss: 1.02900

============================================================
time elapsed: 0:12:47
train iter: 235
num of updates: 23600
dynamics loss: 1.02739

============================================================
time elapsed: 0:12:50
train iter: 236
num of updates: 23700
dynamics loss: 1.02578

============================================================
time elapsed: 0:12:53
train iter: 237
num of updates: 23800
dynamics loss: 1.02387

============================================================
time elapsed: 0:12:55
train iter: 238
num of updates: 23900
dynamics loss: 1.02098

============================================================
time elapsed: 0:12:58
train iter: 239
num of updates: 24000
dynamics loss: 1.01929

============================================================
time elapsed: 0:13:01
train iter: 240
num of updates: 24100
dynamics loss: 1.01811

============================================================
time elapsed: 0:13:04
train iter: 241
num of updates: 24200
dynamics loss: 1.01603

============================================================
time elapsed: 0:13:07
train iter: 242
num of updates: 24300
dynamics loss: 1.01395

============================================================
time elapsed: 0:13:10
train iter: 243
num of updates: 24400
dynamics loss: 1.01164

============================================================
time elapsed: 0:13:13
train iter: 244
num of updates: 24500
dynamics loss: 1.01008

============================================================
time elapsed: 0:13:16
train iter: 245
num of updates: 24600
dynamics loss: 1.00810

============================================================
time elapsed: 0:13:18
train iter: 246
num of updates: 24700
dynamics loss: 1.00686

============================================================
time elapsed: 0:13:21
train iter: 247
num of updates: 24800
dynamics loss: 1.00534

============================================================
time elapsed: 0:13:24
train iter: 248
num of updates: 24900
dynamics loss: 1.00285

============================================================
time elapsed: 0:13:27
train iter: 249
num of updates: 25000
dynamics loss: 1.00167

============================================================
time elapsed: 0:13:30
train iter: 250
num of updates: 25100
dynamics loss: 0.99997

============================================================
time elapsed: 0:13:33
train iter: 251
num of updates: 25200
dynamics loss: 0.99840

============================================================
time elapsed: 0:13:36
train iter: 252
num of updates: 25300
dynamics loss: 0.99627

============================================================
time elapsed: 0:13:38
train iter: 253
num of updates: 25400
dynamics loss: 0.99502

============================================================
time elapsed: 0:13:41
train iter: 254
num of updates: 25500
dynamics loss: 0.99262

============================================================
time elapsed: 0:13:44
train iter: 255
num of updates: 25600
dynamics loss: 0.99123

============================================================
time elapsed: 0:13:47
train iter: 256
num of updates: 25700
dynamics loss: 0.98941

============================================================
time elapsed: 0:13:50
train iter: 257
num of updates: 25800
dynamics loss: 0.98806

============================================================
time elapsed: 0:13:53
train iter: 258
num of updates: 25900
dynamics loss: 0.98653

============================================================
time elapsed: 0:13:56
train iter: 259
num of updates: 26000
dynamics loss: 0.98520

============================================================
time elapsed: 0:13:59
train iter: 260
num of updates: 26100
dynamics loss: 0.98329

============================================================
time elapsed: 0:14:01
train iter: 261
num of updates: 26200
dynamics loss: 0.98221

============================================================
time elapsed: 0:14:04
train iter: 262
num of updates: 26300
dynamics loss: 0.98040

============================================================
time elapsed: 0:14:07
train iter: 263
num of updates: 26400
dynamics loss: 0.97908

============================================================
time elapsed: 0:14:10
train iter: 264
num of updates: 26500
dynamics loss: 0.97781

============================================================
time elapsed: 0:14:13
train iter: 265
num of updates: 26600
dynamics loss: 0.97695

============================================================
time elapsed: 0:14:16
train iter: 266
num of updates: 26700
dynamics loss: 0.97407

============================================================
time elapsed: 0:14:19
train iter: 267
num of updates: 26800
dynamics loss: 0.97348

============================================================
time elapsed: 0:14:21
train iter: 268
num of updates: 26900
dynamics loss: 0.97198

============================================================
time elapsed: 0:14:24
train iter: 269
num of updates: 27000
dynamics loss: 0.97066

============================================================
time elapsed: 0:14:27
train iter: 270
num of updates: 27100
dynamics loss: 0.96927

============================================================
time elapsed: 0:14:30
train iter: 271
num of updates: 27200
dynamics loss: 0.96723

============================================================
time elapsed: 0:14:33
train iter: 272
num of updates: 27300
dynamics loss: 0.96627

============================================================
time elapsed: 0:14:36
train iter: 273
num of updates: 27400
dynamics loss: 0.96481

============================================================
time elapsed: 0:14:39
train iter: 274
num of updates: 27500
dynamics loss: 0.96370

============================================================
time elapsed: 0:14:42
train iter: 275
num of updates: 27600
dynamics loss: 0.96166

============================================================
time elapsed: 0:14:44
train iter: 276
num of updates: 27700
dynamics loss: 0.96130

============================================================
time elapsed: 0:14:47
train iter: 277
num of updates: 27800
dynamics loss: 0.95912

============================================================
time elapsed: 0:14:50
train iter: 278
num of updates: 27900
dynamics loss: 0.95885

============================================================
time elapsed: 0:14:53
train iter: 279
num of updates: 28000
dynamics loss: 0.95718

============================================================
time elapsed: 0:14:56
train iter: 280
num of updates: 28100
dynamics loss: 0.95584

============================================================
time elapsed: 0:14:59
train iter: 281
num of updates: 28200
dynamics loss: 0.95412

============================================================
time elapsed: 0:15:02
train iter: 282
num of updates: 28300
dynamics loss: 0.95328

============================================================
time elapsed: 0:15:04
train iter: 283
num of updates: 28400
dynamics loss: 0.95236

============================================================
time elapsed: 0:15:07
train iter: 284
num of updates: 28500
dynamics loss: 0.95132

============================================================
time elapsed: 0:15:10
train iter: 285
num of updates: 28600
dynamics loss: 0.95018

============================================================
time elapsed: 0:15:13
train iter: 286
num of updates: 28700
dynamics loss: 0.94907

============================================================
time elapsed: 0:15:16
train iter: 287
num of updates: 28800
dynamics loss: 0.94688

============================================================
time elapsed: 0:15:19
train iter: 288
num of updates: 28900
dynamics loss: 0.94621

============================================================
time elapsed: 0:15:22
train iter: 289
num of updates: 29000
dynamics loss: 0.94568

============================================================
time elapsed: 0:15:25
train iter: 290
num of updates: 29100
dynamics loss: 0.94392

============================================================
time elapsed: 0:15:27
train iter: 291
num of updates: 29200
dynamics loss: 0.94332

============================================================
time elapsed: 0:15:30
train iter: 292
num of updates: 29300
dynamics loss: 0.94242

============================================================
time elapsed: 0:15:33
train iter: 293
num of updates: 29400
dynamics loss: 0.94061

============================================================
time elapsed: 0:15:36
train iter: 294
num of updates: 29500
dynamics loss: 0.94025

============================================================
time elapsed: 0:15:39
train iter: 295
num of updates: 29600
dynamics loss: 0.93823

============================================================
time elapsed: 0:15:42
train iter: 296
num of updates: 29700
dynamics loss: 0.93754

============================================================
time elapsed: 0:15:45
train iter: 297
num of updates: 29800
dynamics loss: 0.93650

============================================================
time elapsed: 0:15:48
train iter: 298
num of updates: 29900
dynamics loss: 0.93552

============================================================
time elapsed: 0:15:50
train iter: 299
num of updates: 30000
dynamics loss: 0.93476

============================================================
time elapsed: 0:15:53
train iter: 300
num of updates: 30100
dynamics loss: 0.93395

============================================================
time elapsed: 0:15:56
train iter: 301
num of updates: 30200
dynamics loss: 0.93250

============================================================
time elapsed: 0:15:59
train iter: 302
num of updates: 30300
dynamics loss: 0.93142

============================================================
time elapsed: 0:16:02
train iter: 303
num of updates: 30400
dynamics loss: 0.92976

============================================================
time elapsed: 0:16:05
train iter: 304
num of updates: 30500
dynamics loss: 0.92995

============================================================
time elapsed: 0:16:08
train iter: 305
num of updates: 30600
dynamics loss: 0.92846

============================================================
time elapsed: 0:16:10
train iter: 306
num of updates: 30700
dynamics loss: 0.92759

============================================================
time elapsed: 0:16:13
train iter: 307
num of updates: 30800
dynamics loss: 0.92647

============================================================
time elapsed: 0:16:16
train iter: 308
num of updates: 30900
dynamics loss: 0.92545

============================================================
time elapsed: 0:16:19
train iter: 309
num of updates: 31000
dynamics loss: 0.92424

============================================================
time elapsed: 0:16:22
train iter: 310
num of updates: 31100
dynamics loss: 0.92389

============================================================
time elapsed: 0:16:25
train iter: 311
num of updates: 31200
dynamics loss: 0.92290

============================================================
time elapsed: 0:16:28
train iter: 312
num of updates: 31300
dynamics loss: 0.92167

============================================================
time elapsed: 0:16:31
train iter: 313
num of updates: 31400
dynamics loss: 0.92113

============================================================
time elapsed: 0:16:33
train iter: 314
num of updates: 31500
dynamics loss: 0.91959

============================================================
time elapsed: 0:16:36
train iter: 315
num of updates: 31600
dynamics loss: 0.91886

============================================================
time elapsed: 0:16:39
train iter: 316
num of updates: 31700
dynamics loss: 0.91763

============================================================
time elapsed: 0:16:42
train iter: 317
num of updates: 31800
dynamics loss: 0.91705

============================================================
time elapsed: 0:16:45
train iter: 318
num of updates: 31900
dynamics loss: 0.91668

============================================================
time elapsed: 0:16:48
train iter: 319
num of updates: 32000
dynamics loss: 0.91481

============================================================
time elapsed: 0:16:51
train iter: 320
num of updates: 32100
dynamics loss: 0.91498

============================================================
time elapsed: 0:16:53
train iter: 321
num of updates: 32200
dynamics loss: 0.91358

============================================================
time elapsed: 0:16:56
train iter: 322
num of updates: 32300
dynamics loss: 0.91282

============================================================
time elapsed: 0:16:59
train iter: 323
num of updates: 32400
dynamics loss: 0.91198

============================================================
time elapsed: 0:17:02
train iter: 324
num of updates: 32500
dynamics loss: 0.91123

============================================================
time elapsed: 0:17:05
train iter: 325
num of updates: 32600
dynamics loss: 0.91042

============================================================
time elapsed: 0:17:08
train iter: 326
num of updates: 32700
dynamics loss: 0.90922

============================================================
time elapsed: 0:17:11
train iter: 327
num of updates: 32800
dynamics loss: 0.90841

============================================================
time elapsed: 0:17:14
train iter: 328
num of updates: 32900
dynamics loss: 0.90815

============================================================
time elapsed: 0:17:16
train iter: 329
num of updates: 33000
dynamics loss: 0.90678

============================================================
time elapsed: 0:17:19
train iter: 330
num of updates: 33100
dynamics loss: 0.90604

============================================================
time elapsed: 0:17:22
train iter: 331
num of updates: 33200
dynamics loss: 0.90551

============================================================
time elapsed: 0:17:25
train iter: 332
num of updates: 33300
dynamics loss: 0.90458

============================================================
time elapsed: 0:17:28
train iter: 333
num of updates: 33400
dynamics loss: 0.90425

============================================================
time elapsed: 0:17:31
train iter: 334
num of updates: 33500
dynamics loss: 0.90291

============================================================
time elapsed: 0:17:34
train iter: 335
num of updates: 33600
dynamics loss: 0.90212

============================================================
time elapsed: 0:17:36
train iter: 336
num of updates: 33700
dynamics loss: 0.90120

============================================================
time elapsed: 0:17:39
train iter: 337
num of updates: 33800
dynamics loss: 0.90065

============================================================
time elapsed: 0:17:42
train iter: 338
num of updates: 33900
dynamics loss: 0.89983

============================================================
time elapsed: 0:17:45
train iter: 339
num of updates: 34000
dynamics loss: 0.89940

============================================================
time elapsed: 0:17:48
train iter: 340
num of updates: 34100
dynamics loss: 0.89825

============================================================
time elapsed: 0:17:51
train iter: 341
num of updates: 34200
dynamics loss: 0.89757

============================================================
time elapsed: 0:17:54
train iter: 342
num of updates: 34300
dynamics loss: 0.89725

============================================================
time elapsed: 0:17:57
train iter: 343
num of updates: 34400
dynamics loss: 0.89605

============================================================
time elapsed: 0:17:59
train iter: 344
num of updates: 34500
dynamics loss: 0.89550

============================================================
time elapsed: 0:18:02
train iter: 345
num of updates: 34600
dynamics loss: 0.89472

============================================================
time elapsed: 0:18:05
train iter: 346
num of updates: 34700
dynamics loss: 0.89376

============================================================
time elapsed: 0:18:08
train iter: 347
num of updates: 34800
dynamics loss: 0.89318

============================================================
time elapsed: 0:18:11
train iter: 348
num of updates: 34900
dynamics loss: 0.89254

============================================================
time elapsed: 0:18:14
train iter: 349
num of updates: 35000
dynamics loss: 0.89174

============================================================
time elapsed: 0:18:17
train iter: 350
num of updates: 35100
dynamics loss: 0.89080

============================================================
time elapsed: 0:18:20
train iter: 351
num of updates: 35200
dynamics loss: 0.89039

============================================================
time elapsed: 0:18:22
train iter: 352
num of updates: 35300
dynamics loss: 0.88977

============================================================
time elapsed: 0:18:25
train iter: 353
num of updates: 35400
dynamics loss: 0.88917

============================================================
time elapsed: 0:18:28
train iter: 354
num of updates: 35500
dynamics loss: 0.88830

============================================================
time elapsed: 0:18:31
train iter: 355
num of updates: 35600
dynamics loss: 0.88783

============================================================
time elapsed: 0:18:34
train iter: 356
num of updates: 35700
dynamics loss: 0.88691

============================================================
time elapsed: 0:18:37
train iter: 357
num of updates: 35800
dynamics loss: 0.88667

============================================================
time elapsed: 0:18:40
train iter: 358
num of updates: 35900
dynamics loss: 0.88513

============================================================
time elapsed: 0:18:42
train iter: 359
num of updates: 36000
dynamics loss: 0.88514

============================================================
time elapsed: 0:18:45
train iter: 360
num of updates: 36100
dynamics loss: 0.88420

============================================================
time elapsed: 0:18:48
train iter: 361
num of updates: 36200
dynamics loss: 0.88309

============================================================
time elapsed: 0:18:51
train iter: 362
num of updates: 36300
dynamics loss: 0.88280

============================================================
time elapsed: 0:18:54
train iter: 363
num of updates: 36400
dynamics loss: 0.88211

============================================================
time elapsed: 0:18:57
train iter: 364
num of updates: 36500
dynamics loss: 0.88147

============================================================
time elapsed: 0:19:00
train iter: 365
num of updates: 36600
dynamics loss: 0.88102

============================================================
time elapsed: 0:19:03
train iter: 366
num of updates: 36700
dynamics loss: 0.88046

============================================================
time elapsed: 0:19:05
train iter: 367
num of updates: 36800
dynamics loss: 0.87961

============================================================
time elapsed: 0:19:08
train iter: 368
num of updates: 36900
dynamics loss: 0.87841

============================================================
time elapsed: 0:19:11
train iter: 369
num of updates: 37000
dynamics loss: 0.87830

============================================================
time elapsed: 0:19:14
train iter: 370
num of updates: 37100
dynamics loss: 0.87731

============================================================
time elapsed: 0:19:17
train iter: 371
num of updates: 37200
dynamics loss: 0.87650

============================================================
time elapsed: 0:19:20
train iter: 372
num of updates: 37300
dynamics loss: 0.87642

============================================================
time elapsed: 0:19:23
train iter: 373
num of updates: 37400
dynamics loss: 0.87586

============================================================
time elapsed: 0:19:26
train iter: 374
num of updates: 37500
dynamics loss: 0.87541

============================================================
time elapsed: 0:19:28
train iter: 375
num of updates: 37600
dynamics loss: 0.87458

============================================================
time elapsed: 0:19:31
train iter: 376
num of updates: 37700
dynamics loss: 0.87373

============================================================
time elapsed: 0:19:34
train iter: 377
num of updates: 37800
dynamics loss: 0.87388

============================================================
time elapsed: 0:19:37
train iter: 378
num of updates: 37900
dynamics loss: 0.87239

============================================================
time elapsed: 0:19:40
train iter: 379
num of updates: 38000
dynamics loss: 0.87238

============================================================
time elapsed: 0:19:43
train iter: 380
num of updates: 38100
dynamics loss: 0.87133

============================================================
time elapsed: 0:19:46
train iter: 381
num of updates: 38200
dynamics loss: 0.87063

============================================================
time elapsed: 0:19:48
train iter: 382
num of updates: 38300
dynamics loss: 0.87101

============================================================
time elapsed: 0:19:51
train iter: 383
num of updates: 38400
dynamics loss: 0.86982

============================================================
time elapsed: 0:19:54
train iter: 384
num of updates: 38500
dynamics loss: 0.86940

============================================================
time elapsed: 0:19:57
train iter: 385
num of updates: 38600
dynamics loss: 0.86830

============================================================
time elapsed: 0:20:00
train iter: 386
num of updates: 38700
dynamics loss: 0.86778

============================================================
time elapsed: 0:20:03
train iter: 387
num of updates: 38800
dynamics loss: 0.86748

============================================================
time elapsed: 0:20:06
train iter: 388
num of updates: 38900
dynamics loss: 0.86640

============================================================
time elapsed: 0:20:09
train iter: 389
num of updates: 39000
dynamics loss: 0.86610

============================================================
time elapsed: 0:20:11
train iter: 390
num of updates: 39100
dynamics loss: 0.86529

============================================================
time elapsed: 0:20:14
train iter: 391
num of updates: 39200
dynamics loss: 0.86517

============================================================
time elapsed: 0:20:17
train iter: 392
num of updates: 39300
dynamics loss: 0.86452

============================================================
time elapsed: 0:20:20
train iter: 393
num of updates: 39400
dynamics loss: 0.86380

============================================================
time elapsed: 0:20:23
train iter: 394
num of updates: 39500
dynamics loss: 0.86377

============================================================
time elapsed: 0:20:26
train iter: 395
num of updates: 39600
dynamics loss: 0.86258

============================================================
time elapsed: 0:20:29
train iter: 396
num of updates: 39700
dynamics loss: 0.86227

============================================================
time elapsed: 0:20:31
train iter: 397
num of updates: 39800
dynamics loss: 0.86165

============================================================
time elapsed: 0:20:34
train iter: 398
num of updates: 39900
dynamics loss: 0.86071

============================================================
time elapsed: 0:20:37
train iter: 399
num of updates: 40000
dynamics loss: 0.86060

============================================================
time elapsed: 0:20:40
train iter: 400
num of updates: 40100
dynamics loss: 0.85973

============================================================
time elapsed: 0:20:43
train iter: 401
num of updates: 40200
dynamics loss: 0.85981

============================================================
time elapsed: 0:20:46
train iter: 402
num of updates: 40300
dynamics loss: 0.85922

============================================================
time elapsed: 0:20:49
train iter: 403
num of updates: 40400
dynamics loss: 0.85869

============================================================
time elapsed: 0:20:52
train iter: 404
num of updates: 40500
dynamics loss: 0.85786

============================================================
time elapsed: 0:20:54
train iter: 405
num of updates: 40600
dynamics loss: 0.85732

============================================================
time elapsed: 0:20:57
train iter: 406
num of updates: 40700
dynamics loss: 0.85666

============================================================
time elapsed: 0:21:00
train iter: 407
num of updates: 40800
dynamics loss: 0.85649

============================================================
time elapsed: 0:21:03
train iter: 408
num of updates: 40900
dynamics loss: 0.85568

============================================================
time elapsed: 0:21:06
train iter: 409
num of updates: 41000
dynamics loss: 0.85502

============================================================
time elapsed: 0:21:09
train iter: 410
num of updates: 41100
dynamics loss: 0.85488

============================================================
time elapsed: 0:21:12
train iter: 411
num of updates: 41200
dynamics loss: 0.85473

============================================================
time elapsed: 0:21:14
train iter: 412
num of updates: 41300
dynamics loss: 0.85308

============================================================
time elapsed: 0:21:17
train iter: 413
num of updates: 41400
dynamics loss: 0.85268

============================================================
time elapsed: 0:21:20
train iter: 414
num of updates: 41500
dynamics loss: 0.85238

============================================================
time elapsed: 0:21:23
train iter: 415
num of updates: 41600
dynamics loss: 0.85161

============================================================
time elapsed: 0:21:26
train iter: 416
num of updates: 41700
dynamics loss: 0.85100

============================================================
time elapsed: 0:21:29
train iter: 417
num of updates: 41800
dynamics loss: 0.85086

============================================================
time elapsed: 0:21:32
train iter: 418
num of updates: 41900
dynamics loss: 0.85012

============================================================
time elapsed: 0:21:35
train iter: 419
num of updates: 42000
dynamics loss: 0.85004

============================================================
time elapsed: 0:21:37
train iter: 420
num of updates: 42100
dynamics loss: 0.84941

============================================================
time elapsed: 0:21:40
train iter: 421
num of updates: 42200
dynamics loss: 0.84921

============================================================
time elapsed: 0:21:43
train iter: 422
num of updates: 42300
dynamics loss: 0.84798

============================================================
time elapsed: 0:21:46
train iter: 423
num of updates: 42400
dynamics loss: 0.84797

============================================================
time elapsed: 0:21:49
train iter: 424
num of updates: 42500
dynamics loss: 0.84720

============================================================
time elapsed: 0:21:52
train iter: 425
num of updates: 42600
dynamics loss: 0.84727

============================================================
time elapsed: 0:21:55
train iter: 426
num of updates: 42700
dynamics loss: 0.84614

============================================================
time elapsed: 0:21:58
train iter: 427
num of updates: 42800
dynamics loss: 0.84593

============================================================
time elapsed: 0:22:00
train iter: 428
num of updates: 42900
dynamics loss: 0.84583

============================================================
time elapsed: 0:22:03
train iter: 429
num of updates: 43000
dynamics loss: 0.84520

============================================================
time elapsed: 0:22:06
train iter: 430
num of updates: 43100
dynamics loss: 0.84479

============================================================
time elapsed: 0:22:09
train iter: 431
num of updates: 43200
dynamics loss: 0.84365

============================================================
time elapsed: 0:22:12
train iter: 432
num of updates: 43300
dynamics loss: 0.84333

============================================================
time elapsed: 0:22:15
train iter: 433
num of updates: 43400
dynamics loss: 0.84283

============================================================
time elapsed: 0:22:18
train iter: 434
num of updates: 43500
dynamics loss: 0.84263

============================================================
time elapsed: 0:22:20
train iter: 435
num of updates: 43600
dynamics loss: 0.84165

============================================================
time elapsed: 0:22:23
train iter: 436
num of updates: 43700
dynamics loss: 0.84166

============================================================
time elapsed: 0:22:26
train iter: 437
num of updates: 43800
dynamics loss: 0.84085

============================================================
time elapsed: 0:22:29
train iter: 438
num of updates: 43900
dynamics loss: 0.84103

============================================================
time elapsed: 0:22:32
train iter: 439
num of updates: 44000
dynamics loss: 0.83989

============================================================
time elapsed: 0:22:35
train iter: 440
num of updates: 44100
dynamics loss: 0.83991

============================================================
time elapsed: 0:22:38
train iter: 441
num of updates: 44200
dynamics loss: 0.83873

============================================================
time elapsed: 0:22:40
train iter: 442
num of updates: 44300
dynamics loss: 0.83854

============================================================
time elapsed: 0:22:43
train iter: 443
num of updates: 44400
dynamics loss: 0.83763

============================================================
time elapsed: 0:22:46
train iter: 444
num of updates: 44500
dynamics loss: 0.83718

============================================================
time elapsed: 0:22:49
train iter: 445
num of updates: 44600
dynamics loss: 0.83660

============================================================
time elapsed: 0:22:52
train iter: 446
num of updates: 44700
dynamics loss: 0.83716

============================================================
time elapsed: 0:22:55
train iter: 447
num of updates: 44800
dynamics loss: 0.83643

============================================================
time elapsed: 0:22:58
train iter: 448
num of updates: 44900
dynamics loss: 0.83585

============================================================
time elapsed: 0:23:01
train iter: 449
num of updates: 45000
dynamics loss: 0.83511

============================================================
time elapsed: 0:23:03
train iter: 450
num of updates: 45100
dynamics loss: 0.83468

============================================================
time elapsed: 0:23:06
train iter: 451
num of updates: 45200
dynamics loss: 0.83461

============================================================
time elapsed: 0:23:09
train iter: 452
num of updates: 45300
dynamics loss: 0.83415

============================================================
time elapsed: 0:23:12
train iter: 453
num of updates: 45400
dynamics loss: 0.83353

============================================================
time elapsed: 0:23:15
train iter: 454
num of updates: 45500
dynamics loss: 0.83324

============================================================
time elapsed: 0:23:18
train iter: 455
num of updates: 45600
dynamics loss: 0.83233

============================================================
time elapsed: 0:23:21
train iter: 456
num of updates: 45700
dynamics loss: 0.83218

============================================================
time elapsed: 0:23:23
train iter: 457
num of updates: 45800
dynamics loss: 0.83120

============================================================
time elapsed: 0:23:26
train iter: 458
num of updates: 45900
dynamics loss: 0.83116

============================================================
time elapsed: 0:23:29
train iter: 459
num of updates: 46000
dynamics loss: 0.83040

============================================================
time elapsed: 0:23:32
train iter: 460
num of updates: 46100
dynamics loss: 0.83009

============================================================
time elapsed: 0:23:35
train iter: 461
num of updates: 46200
dynamics loss: 0.82987

============================================================
time elapsed: 0:23:38
train iter: 462
num of updates: 46300
dynamics loss: 0.82948

============================================================
time elapsed: 0:23:41
train iter: 463
num of updates: 46400
dynamics loss: 0.82913

============================================================
time elapsed: 0:23:44
train iter: 464
num of updates: 46500
dynamics loss: 0.82796

============================================================
time elapsed: 0:23:46
train iter: 465
num of updates: 46600
dynamics loss: 0.82779

============================================================
time elapsed: 0:23:49
train iter: 466
num of updates: 46700
dynamics loss: 0.82750

============================================================
time elapsed: 0:23:52
train iter: 467
num of updates: 46800
dynamics loss: 0.82678

============================================================
time elapsed: 0:23:55
train iter: 468
num of updates: 46900
dynamics loss: 0.82661

============================================================
time elapsed: 0:23:58
train iter: 469
num of updates: 47000
dynamics loss: 0.82635

============================================================
time elapsed: 0:24:01
train iter: 470
num of updates: 47100
dynamics loss: 0.82583

============================================================
time elapsed: 0:24:04
train iter: 471
num of updates: 47200
dynamics loss: 0.82538

============================================================
time elapsed: 0:24:06
train iter: 472
num of updates: 47300
dynamics loss: 0.82486

============================================================
time elapsed: 0:24:09
train iter: 473
num of updates: 47400
dynamics loss: 0.82460

============================================================
time elapsed: 0:24:12
train iter: 474
num of updates: 47500
dynamics loss: 0.82406

============================================================
time elapsed: 0:24:15
train iter: 475
num of updates: 47600
dynamics loss: 0.82301

============================================================
time elapsed: 0:24:18
train iter: 476
num of updates: 47700
dynamics loss: 0.82300

============================================================
time elapsed: 0:24:21
train iter: 477
num of updates: 47800
dynamics loss: 0.82345

============================================================
time elapsed: 0:24:24
train iter: 478
num of updates: 47900
dynamics loss: 0.82146

============================================================
time elapsed: 0:24:26
train iter: 479
num of updates: 48000
dynamics loss: 0.82123

============================================================
time elapsed: 0:24:29
train iter: 480
num of updates: 48100
dynamics loss: 0.82084

============================================================
time elapsed: 0:24:32
train iter: 481
num of updates: 48200
dynamics loss: 0.82089

============================================================
time elapsed: 0:24:35
train iter: 482
num of updates: 48300
dynamics loss: 0.82047

============================================================
time elapsed: 0:24:38
train iter: 483
num of updates: 48400
dynamics loss: 0.81999

============================================================
time elapsed: 0:24:41
train iter: 484
num of updates: 48500
dynamics loss: 0.81940

============================================================
time elapsed: 0:24:44
train iter: 485
num of updates: 48600
dynamics loss: 0.81919

============================================================
time elapsed: 0:24:47
train iter: 486
num of updates: 48700
dynamics loss: 0.81869

============================================================
time elapsed: 0:24:49
train iter: 487
num of updates: 48800
dynamics loss: 0.81869

============================================================
time elapsed: 0:24:52
train iter: 488
num of updates: 48900
dynamics loss: 0.81765

============================================================
time elapsed: 0:24:55
train iter: 489
num of updates: 49000
dynamics loss: 0.81728

============================================================
time elapsed: 0:24:58
train iter: 490
num of updates: 49100
dynamics loss: 0.81716

============================================================
time elapsed: 0:25:01
train iter: 491
num of updates: 49200
dynamics loss: 0.81645

============================================================
time elapsed: 0:25:04
train iter: 492
num of updates: 49300
dynamics loss: 0.81604

============================================================
time elapsed: 0:25:07
train iter: 493
num of updates: 49400
dynamics loss: 0.81551

============================================================
time elapsed: 0:25:09
train iter: 494
num of updates: 49500
dynamics loss: 0.81483

============================================================
time elapsed: 0:25:12
train iter: 495
num of updates: 49600
dynamics loss: 0.81525

============================================================
time elapsed: 0:25:15
train iter: 496
num of updates: 49700
dynamics loss: 0.81467

============================================================
time elapsed: 0:25:18
train iter: 497
num of updates: 49800
dynamics loss: 0.81414

============================================================
time elapsed: 0:25:21
train iter: 498
num of updates: 49900
dynamics loss: 0.81355

============================================================
time elapsed: 0:25:24
train iter: 499
num of updates: 50000
dynamics loss: 0.81339

============================================================
time elapsed: 0:25:27
train iter: 500
num of updates: 50100
dynamics loss: 0.81245

============================================================
time elapsed: 0:25:30
train iter: 501
num of updates: 50200
dynamics loss: 0.81254

============================================================
time elapsed: 0:25:32
train iter: 502
num of updates: 50300
dynamics loss: 0.81164

============================================================
time elapsed: 0:25:35
train iter: 503
num of updates: 50400
dynamics loss: 0.81124

============================================================
time elapsed: 0:25:38
train iter: 504
num of updates: 50500
dynamics loss: 0.81073

============================================================
time elapsed: 0:25:41
train iter: 505
num of updates: 50600
dynamics loss: 0.81090

============================================================
time elapsed: 0:25:44
train iter: 506
num of updates: 50700
dynamics loss: 0.80997

============================================================
time elapsed: 0:25:47
train iter: 507
num of updates: 50800
dynamics loss: 0.80987

============================================================
time elapsed: 0:25:50
train iter: 508
num of updates: 50900
dynamics loss: 0.80935

============================================================
time elapsed: 0:25:52
train iter: 509
num of updates: 51000
dynamics loss: 0.80914

============================================================
time elapsed: 0:25:55
train iter: 510
num of updates: 51100
dynamics loss: 0.80883

============================================================
time elapsed: 0:25:58
train iter: 511
num of updates: 51200
dynamics loss: 0.80809

============================================================
time elapsed: 0:26:01
train iter: 512
num of updates: 51300
dynamics loss: 0.80787

============================================================
time elapsed: 0:26:04
train iter: 513
num of updates: 51400
dynamics loss: 0.80732

============================================================
time elapsed: 0:26:07
train iter: 514
num of updates: 51500
dynamics loss: 0.80703

============================================================
time elapsed: 0:26:10
train iter: 515
num of updates: 51600
dynamics loss: 0.80681

============================================================
time elapsed: 0:26:13
train iter: 516
num of updates: 51700
dynamics loss: 0.80592

============================================================
time elapsed: 0:26:15
train iter: 517
num of updates: 51800
dynamics loss: 0.80577

============================================================
time elapsed: 0:26:18
train iter: 518
num of updates: 51900
dynamics loss: 0.80553

============================================================
time elapsed: 0:26:21
train iter: 519
num of updates: 52000
dynamics loss: 0.80442

============================================================
time elapsed: 0:26:24
train iter: 520
num of updates: 52100
dynamics loss: 0.80449

============================================================
time elapsed: 0:26:27
train iter: 521
num of updates: 52200
dynamics loss: 0.80469

============================================================
time elapsed: 0:26:30
train iter: 522
num of updates: 52300
dynamics loss: 0.80364

============================================================
time elapsed: 0:26:33
train iter: 523
num of updates: 52400
dynamics loss: 0.80331

============================================================
time elapsed: 0:26:36
train iter: 524
num of updates: 52500
dynamics loss: 0.80240

============================================================
time elapsed: 0:26:38
train iter: 525
num of updates: 52600
dynamics loss: 0.80264

============================================================
time elapsed: 0:26:41
train iter: 526
num of updates: 52700
dynamics loss: 0.80237

============================================================
time elapsed: 0:26:44
train iter: 527
num of updates: 52800
dynamics loss: 0.80153

============================================================
time elapsed: 0:26:47
train iter: 528
num of updates: 52900
dynamics loss: 0.80100

============================================================
time elapsed: 0:26:50
train iter: 529
num of updates: 53000
dynamics loss: 0.80112

============================================================
time elapsed: 0:26:53
train iter: 530
num of updates: 53100
dynamics loss: 0.80102

============================================================
time elapsed: 0:26:56
train iter: 531
num of updates: 53200
dynamics loss: 0.80021

============================================================
time elapsed: 0:26:58
train iter: 532
num of updates: 53300
dynamics loss: 0.79944

============================================================
time elapsed: 0:27:01
train iter: 533
num of updates: 53400
dynamics loss: 0.79974

============================================================
time elapsed: 0:27:04
train iter: 534
num of updates: 53500
dynamics loss: 0.79895

============================================================
time elapsed: 0:27:07
train iter: 535
num of updates: 53600
dynamics loss: 0.79864

============================================================
time elapsed: 0:27:10
train iter: 536
num of updates: 53700
dynamics loss: 0.79851

============================================================
time elapsed: 0:27:13
train iter: 537
num of updates: 53800
dynamics loss: 0.79794

============================================================
time elapsed: 0:27:16
train iter: 538
num of updates: 53900
dynamics loss: 0.79734

============================================================
time elapsed: 0:27:18
train iter: 539
num of updates: 54000
dynamics loss: 0.79746

============================================================
time elapsed: 0:27:21
train iter: 540
num of updates: 54100
dynamics loss: 0.79679

============================================================
time elapsed: 0:27:24
train iter: 541
num of updates: 54200
dynamics loss: 0.79653

============================================================
time elapsed: 0:27:27
train iter: 542
num of updates: 54300
dynamics loss: 0.79553

============================================================
time elapsed: 0:27:30
train iter: 543
num of updates: 54400
dynamics loss: 0.79504

============================================================
time elapsed: 0:27:33
train iter: 544
num of updates: 54500
dynamics loss: 0.79471

============================================================
time elapsed: 0:27:36
train iter: 545
num of updates: 54600
dynamics loss: 0.79470

============================================================
time elapsed: 0:27:39
train iter: 546
num of updates: 54700
dynamics loss: 0.79384

============================================================
time elapsed: 0:27:41
train iter: 547
num of updates: 54800
dynamics loss: 0.79396

============================================================
time elapsed: 0:27:44
train iter: 548
num of updates: 54900
dynamics loss: 0.79386

============================================================
time elapsed: 0:27:47
train iter: 549
num of updates: 55000
dynamics loss: 0.79273

============================================================
time elapsed: 0:27:50
train iter: 550
num of updates: 55100
dynamics loss: 0.79236

============================================================
time elapsed: 0:27:53
train iter: 551
num of updates: 55200
dynamics loss: 0.79263

============================================================
time elapsed: 0:27:56
train iter: 552
num of updates: 55300
dynamics loss: 0.79198

============================================================
time elapsed: 0:27:59
train iter: 553
num of updates: 55400
dynamics loss: 0.79142

============================================================
time elapsed: 0:28:01
train iter: 554
num of updates: 55500
dynamics loss: 0.79086

============================================================
time elapsed: 0:28:04
train iter: 555
num of updates: 55600
dynamics loss: 0.79045

============================================================
time elapsed: 0:28:07
train iter: 556
num of updates: 55700
dynamics loss: 0.79024

============================================================
time elapsed: 0:28:10
train iter: 557
num of updates: 55800
dynamics loss: 0.78985

============================================================
time elapsed: 0:28:13
train iter: 558
num of updates: 55900
dynamics loss: 0.78950

============================================================
time elapsed: 0:28:16
train iter: 559
num of updates: 56000
dynamics loss: 0.78903

============================================================
time elapsed: 0:28:19
train iter: 560
num of updates: 56100
dynamics loss: 0.78898

============================================================
time elapsed: 0:28:22
train iter: 561
num of updates: 56200
dynamics loss: 0.78826

============================================================
time elapsed: 0:28:24
train iter: 562
num of updates: 56300
dynamics loss: 0.78777

============================================================
time elapsed: 0:28:27
train iter: 563
num of updates: 56400
dynamics loss: 0.78762

============================================================
time elapsed: 0:28:30
train iter: 564
num of updates: 56500
dynamics loss: 0.78695

============================================================
time elapsed: 0:28:33
train iter: 565
num of updates: 56600
dynamics loss: 0.78642

============================================================
time elapsed: 0:28:36
train iter: 566
num of updates: 56700
dynamics loss: 0.78651

============================================================
time elapsed: 0:28:39
train iter: 567
num of updates: 56800
dynamics loss: 0.78619

============================================================
time elapsed: 0:28:42
train iter: 568
num of updates: 56900
dynamics loss: 0.78587

============================================================
time elapsed: 0:28:44
train iter: 569
num of updates: 57000
dynamics loss: 0.78501

============================================================
time elapsed: 0:28:47
train iter: 570
num of updates: 57100
dynamics loss: 0.78484

============================================================
time elapsed: 0:28:50
train iter: 571
num of updates: 57200
dynamics loss: 0.78489

============================================================
time elapsed: 0:28:53
train iter: 572
num of updates: 57300
dynamics loss: 0.78406

============================================================
time elapsed: 0:28:56
train iter: 573
num of updates: 57400
dynamics loss: 0.78423

============================================================
time elapsed: 0:28:59
train iter: 574
num of updates: 57500
dynamics loss: 0.78397

============================================================
time elapsed: 0:29:02
train iter: 575
num of updates: 57600
dynamics loss: 0.78309

============================================================
time elapsed: 0:29:05
train iter: 576
num of updates: 57700
dynamics loss: 0.78295

============================================================
time elapsed: 0:29:07
train iter: 577
num of updates: 57800
dynamics loss: 0.78188

============================================================
time elapsed: 0:29:10
train iter: 578
num of updates: 57900
dynamics loss: 0.78196

============================================================
time elapsed: 0:29:13
train iter: 579
num of updates: 58000
dynamics loss: 0.78128

============================================================
time elapsed: 0:29:16
train iter: 580
num of updates: 58100
dynamics loss: 0.78074

============================================================
time elapsed: 0:29:19
train iter: 581
num of updates: 58200
dynamics loss: 0.78049

============================================================
time elapsed: 0:29:22
train iter: 582
num of updates: 58300
dynamics loss: 0.78044

============================================================
time elapsed: 0:29:25
train iter: 583
num of updates: 58400
dynamics loss: 0.77977

============================================================
time elapsed: 0:29:28
train iter: 584
num of updates: 58500
dynamics loss: 0.77962

============================================================
time elapsed: 0:29:30
train iter: 585
num of updates: 58600
dynamics loss: 0.77943

============================================================
time elapsed: 0:29:33
train iter: 586
num of updates: 58700
dynamics loss: 0.77847

============================================================
time elapsed: 0:29:36
train iter: 587
num of updates: 58800
dynamics loss: 0.77817

============================================================
time elapsed: 0:29:39
train iter: 588
num of updates: 58900
dynamics loss: 0.77791

============================================================
time elapsed: 0:29:42
train iter: 589
num of updates: 59000
dynamics loss: 0.77769

============================================================
time elapsed: 0:29:45
train iter: 590
num of updates: 59100
dynamics loss: 0.77696

============================================================
time elapsed: 0:29:48
train iter: 591
num of updates: 59200
dynamics loss: 0.77693

============================================================
time elapsed: 0:29:50
train iter: 592
num of updates: 59300
dynamics loss: 0.77618

============================================================
time elapsed: 0:29:53
train iter: 593
num of updates: 59400
dynamics loss: 0.77587

============================================================
time elapsed: 0:29:56
train iter: 594
num of updates: 59500
dynamics loss: 0.77595

============================================================
time elapsed: 0:29:59
train iter: 595
num of updates: 59600
dynamics loss: 0.77588

============================================================
time elapsed: 0:30:02
train iter: 596
num of updates: 59700
dynamics loss: 0.77469

============================================================
time elapsed: 0:30:05
train iter: 597
num of updates: 59800
dynamics loss: 0.77481

============================================================
time elapsed: 0:30:08
train iter: 598
num of updates: 59900
dynamics loss: 0.77432

============================================================
time elapsed: 0:30:10
train iter: 599
num of updates: 60000
dynamics loss: 0.77375

============================================================
time elapsed: 0:30:13
train iter: 600
num of updates: 60100
dynamics loss: 0.77326

============================================================
time elapsed: 0:30:16
train iter: 601
num of updates: 60200
dynamics loss: 0.77334

============================================================
time elapsed: 0:30:19
train iter: 602
num of updates: 60300
dynamics loss: 0.77272

============================================================
time elapsed: 0:30:22
train iter: 603
num of updates: 60400
dynamics loss: 0.77269

============================================================
time elapsed: 0:30:25
train iter: 604
num of updates: 60500
dynamics loss: 0.77191

============================================================
time elapsed: 0:30:28
train iter: 605
num of updates: 60600
dynamics loss: 0.77128

============================================================
time elapsed: 0:30:31
train iter: 606
num of updates: 60700
dynamics loss: 0.77089

============================================================
time elapsed: 0:30:33
train iter: 607
num of updates: 60800
dynamics loss: 0.77077

============================================================
time elapsed: 0:30:36
train iter: 608
num of updates: 60900
dynamics loss: 0.77074

============================================================
time elapsed: 0:30:39
train iter: 609
num of updates: 61000
dynamics loss: 0.77025

============================================================
time elapsed: 0:30:42
train iter: 610
num of updates: 61100
dynamics loss: 0.76970

============================================================
time elapsed: 0:30:45
train iter: 611
num of updates: 61200
dynamics loss: 0.76921

============================================================
time elapsed: 0:30:48
train iter: 612
num of updates: 61300
dynamics loss: 0.76906

============================================================
time elapsed: 0:30:51
train iter: 613
num of updates: 61400
dynamics loss: 0.76856

============================================================
time elapsed: 0:30:53
train iter: 614
num of updates: 61500
dynamics loss: 0.76818

============================================================
time elapsed: 0:30:56
train iter: 615
num of updates: 61600
dynamics loss: 0.76804

============================================================
time elapsed: 0:30:59
train iter: 616
num of updates: 61700
dynamics loss: 0.76752

============================================================
time elapsed: 0:31:02
train iter: 617
num of updates: 61800
dynamics loss: 0.76708

============================================================
time elapsed: 0:31:05
train iter: 618
num of updates: 61900
dynamics loss: 0.76641

============================================================
time elapsed: 0:31:08
train iter: 619
num of updates: 62000
dynamics loss: 0.76627

============================================================
time elapsed: 0:31:11
train iter: 620
num of updates: 62100
dynamics loss: 0.76573

============================================================
time elapsed: 0:31:14
train iter: 621
num of updates: 62200
dynamics loss: 0.76551

============================================================
time elapsed: 0:31:16
train iter: 622
num of updates: 62300
dynamics loss: 0.76485

============================================================
time elapsed: 0:31:19
train iter: 623
num of updates: 62400
dynamics loss: 0.76521

============================================================
time elapsed: 0:31:22
train iter: 624
num of updates: 62500
dynamics loss: 0.76488

============================================================
time elapsed: 0:31:25
train iter: 625
num of updates: 62600
dynamics loss: 0.76421

============================================================
time elapsed: 0:31:28
train iter: 626
num of updates: 62700
dynamics loss: 0.76377

============================================================
time elapsed: 0:31:31
train iter: 627
num of updates: 62800
dynamics loss: 0.76355

============================================================
time elapsed: 0:31:34
train iter: 628
num of updates: 62900
dynamics loss: 0.76312

============================================================
time elapsed: 0:31:36
train iter: 629
num of updates: 63000
dynamics loss: 0.76283

============================================================
time elapsed: 0:31:39
train iter: 630
num of updates: 63100
dynamics loss: 0.76218

============================================================
time elapsed: 0:31:42
train iter: 631
num of updates: 63200
dynamics loss: 0.76160

============================================================
time elapsed: 0:31:45
train iter: 632
num of updates: 63300
dynamics loss: 0.76180

============================================================
time elapsed: 0:31:48
train iter: 633
num of updates: 63400
dynamics loss: 0.76151

============================================================
time elapsed: 0:31:51
train iter: 634
num of updates: 63500
dynamics loss: 0.76042

============================================================
time elapsed: 0:31:54
train iter: 635
num of updates: 63600
dynamics loss: 0.76051

============================================================
time elapsed: 0:31:57
train iter: 636
num of updates: 63700
dynamics loss: 0.75935

============================================================
time elapsed: 0:31:59
train iter: 637
num of updates: 63800
dynamics loss: 0.75964

============================================================
time elapsed: 0:32:02
train iter: 638
num of updates: 63900
dynamics loss: 0.75961

============================================================
time elapsed: 0:32:05
train iter: 639
num of updates: 64000
dynamics loss: 0.75878

============================================================
time elapsed: 0:32:08
train iter: 640
num of updates: 64100
dynamics loss: 0.75876

============================================================
time elapsed: 0:32:11
train iter: 641
num of updates: 64200
dynamics loss: 0.75794

============================================================
time elapsed: 0:32:14
train iter: 642
num of updates: 64300
dynamics loss: 0.75774

============================================================
time elapsed: 0:32:17
train iter: 643
num of updates: 64400
dynamics loss: 0.75722

============================================================
time elapsed: 0:32:19
train iter: 644
num of updates: 64500
dynamics loss: 0.75745

============================================================
time elapsed: 0:32:22
train iter: 645
num of updates: 64600
dynamics loss: 0.75677

============================================================
time elapsed: 0:32:25
train iter: 646
num of updates: 64700
dynamics loss: 0.75666

============================================================
time elapsed: 0:32:28
train iter: 647
num of updates: 64800
dynamics loss: 0.75639

============================================================
time elapsed: 0:32:31
train iter: 648
num of updates: 64900
dynamics loss: 0.75561

============================================================
time elapsed: 0:32:34
train iter: 649
num of updates: 65000
dynamics loss: 0.75526

============================================================
time elapsed: 0:32:37
train iter: 650
num of updates: 65100
dynamics loss: 0.75458

============================================================
time elapsed: 0:32:40
train iter: 651
num of updates: 65200
dynamics loss: 0.75485

============================================================
time elapsed: 0:32:42
train iter: 652
num of updates: 65300
dynamics loss: 0.75405

============================================================
time elapsed: 0:32:45
train iter: 653
num of updates: 65400
dynamics loss: 0.75382

============================================================
time elapsed: 0:32:48
train iter: 654
num of updates: 65500
dynamics loss: 0.75376

============================================================
time elapsed: 0:32:51
train iter: 655
num of updates: 65600
dynamics loss: 0.75328

============================================================
time elapsed: 0:32:54
train iter: 656
num of updates: 65700
dynamics loss: 0.75293

============================================================
time elapsed: 0:32:57
train iter: 657
num of updates: 65800
dynamics loss: 0.75305

============================================================
time elapsed: 0:33:00
train iter: 658
num of updates: 65900
dynamics loss: 0.75204

============================================================
time elapsed: 0:33:02
train iter: 659
num of updates: 66000
dynamics loss: 0.75127

============================================================
time elapsed: 0:33:05
train iter: 660
num of updates: 66100
dynamics loss: 0.75163

============================================================
time elapsed: 0:33:08
train iter: 661
num of updates: 66200
dynamics loss: 0.75082

============================================================
time elapsed: 0:33:11
train iter: 662
num of updates: 66300
dynamics loss: 0.75050

============================================================
time elapsed: 0:33:14
train iter: 663
num of updates: 66400
dynamics loss: 0.75004

============================================================
time elapsed: 0:33:17
train iter: 664
num of updates: 66500
dynamics loss: 0.74972

============================================================
time elapsed: 0:33:20
train iter: 665
num of updates: 66600
dynamics loss: 0.74920

============================================================
time elapsed: 0:33:23
train iter: 666
num of updates: 66700
dynamics loss: 0.74898

============================================================
time elapsed: 0:33:25
train iter: 667
num of updates: 66800
dynamics loss: 0.74879

============================================================
time elapsed: 0:33:28
train iter: 668
num of updates: 66900
dynamics loss: 0.74818

============================================================
time elapsed: 0:33:31
train iter: 669
num of updates: 67000
dynamics loss: 0.74807

============================================================
time elapsed: 0:33:34
train iter: 670
num of updates: 67100
dynamics loss: 0.74806

============================================================
time elapsed: 0:33:37
train iter: 671
num of updates: 67200
dynamics loss: 0.74713

============================================================
time elapsed: 0:33:40
train iter: 672
num of updates: 67300
dynamics loss: 0.74706

============================================================
time elapsed: 0:33:43
train iter: 673
num of updates: 67400
dynamics loss: 0.74649

============================================================
time elapsed: 0:33:45
train iter: 674
num of updates: 67500
dynamics loss: 0.74605

============================================================
time elapsed: 0:33:48
train iter: 675
num of updates: 67600
dynamics loss: 0.74545

============================================================
time elapsed: 0:33:51
train iter: 676
num of updates: 67700
dynamics loss: 0.74495

============================================================
time elapsed: 0:33:54
train iter: 677
num of updates: 67800
dynamics loss: 0.74537

============================================================
time elapsed: 0:33:57
train iter: 678
num of updates: 67900
dynamics loss: 0.74418

============================================================
time elapsed: 0:34:00
train iter: 679
num of updates: 68000
dynamics loss: 0.74442

============================================================
time elapsed: 0:34:03
train iter: 680
num of updates: 68100
dynamics loss: 0.74376

============================================================
time elapsed: 0:34:06
train iter: 681
num of updates: 68200
dynamics loss: 0.74323

============================================================
time elapsed: 0:34:08
train iter: 682
num of updates: 68300
dynamics loss: 0.74265

============================================================
time elapsed: 0:34:11
train iter: 683
num of updates: 68400
dynamics loss: 0.74251

============================================================
time elapsed: 0:34:14
train iter: 684
num of updates: 68500
dynamics loss: 0.74250

============================================================
time elapsed: 0:34:17
train iter: 685
num of updates: 68600
dynamics loss: 0.74188

============================================================
time elapsed: 0:34:20
train iter: 686
num of updates: 68700
dynamics loss: 0.74188

============================================================
time elapsed: 0:34:23
train iter: 687
num of updates: 68800
dynamics loss: 0.74126

============================================================
time elapsed: 0:34:26
train iter: 688
num of updates: 68900
dynamics loss: 0.74049

============================================================
time elapsed: 0:34:28
train iter: 689
num of updates: 69000
dynamics loss: 0.74029

============================================================
time elapsed: 0:34:31
train iter: 690
num of updates: 69100
dynamics loss: 0.73959

============================================================
time elapsed: 0:34:34
train iter: 691
num of updates: 69200
dynamics loss: 0.73930

============================================================
time elapsed: 0:34:37
train iter: 692
num of updates: 69300
dynamics loss: 0.73941

============================================================
time elapsed: 0:34:40
train iter: 693
num of updates: 69400
dynamics loss: 0.73910

============================================================
time elapsed: 0:34:43
train iter: 694
num of updates: 69500
dynamics loss: 0.73852

============================================================
time elapsed: 0:34:46
train iter: 695
num of updates: 69600
dynamics loss: 0.73820

============================================================
time elapsed: 0:34:48
train iter: 696
num of updates: 69700
dynamics loss: 0.73770

============================================================
time elapsed: 0:34:51
train iter: 697
num of updates: 69800
dynamics loss: 0.73778

============================================================
time elapsed: 0:34:54
train iter: 698
num of updates: 69900
dynamics loss: 0.73759

============================================================
time elapsed: 0:34:57
train iter: 699
num of updates: 70000
dynamics loss: 0.73685

============================================================
time elapsed: 0:35:00
train iter: 700
num of updates: 70100
dynamics loss: 0.73584

============================================================
time elapsed: 0:35:03
train iter: 701
num of updates: 70200
dynamics loss: 0.73559

============================================================
time elapsed: 0:35:06
train iter: 702
num of updates: 70300
dynamics loss: 0.73585

============================================================
time elapsed: 0:35:09
train iter: 703
num of updates: 70400
dynamics loss: 0.73526

============================================================
time elapsed: 0:35:11
train iter: 704
num of updates: 70500
dynamics loss: 0.73476

============================================================
time elapsed: 0:35:14
train iter: 705
num of updates: 70600
dynamics loss: 0.73466

============================================================
time elapsed: 0:35:17
train iter: 706
num of updates: 70700
dynamics loss: 0.73414

============================================================
time elapsed: 0:35:20
train iter: 707
num of updates: 70800
dynamics loss: 0.73405

============================================================
time elapsed: 0:35:23
train iter: 708
num of updates: 70900
dynamics loss: 0.73342

============================================================
time elapsed: 0:35:26
train iter: 709
num of updates: 71000
dynamics loss: 0.73305

============================================================
time elapsed: 0:35:29
train iter: 710
num of updates: 71100
dynamics loss: 0.73271

============================================================
time elapsed: 0:35:31
train iter: 711
num of updates: 71200
dynamics loss: 0.73279

============================================================
time elapsed: 0:35:34
train iter: 712
num of updates: 71300
dynamics loss: 0.73226

============================================================
time elapsed: 0:35:37
train iter: 713
num of updates: 71400
dynamics loss: 0.73124

============================================================
time elapsed: 0:35:40
train iter: 714
num of updates: 71500
dynamics loss: 0.73129

============================================================
time elapsed: 0:35:43
train iter: 715
num of updates: 71600
dynamics loss: 0.73093

============================================================
time elapsed: 0:35:46
train iter: 716
num of updates: 71700
dynamics loss: 0.73089

============================================================
time elapsed: 0:35:49
train iter: 717
num of updates: 71800
dynamics loss: 0.73006

============================================================
time elapsed: 0:35:52
train iter: 718
num of updates: 71900
dynamics loss: 0.72949

============================================================
time elapsed: 0:35:54
train iter: 719
num of updates: 72000
dynamics loss: 0.72850

============================================================
time elapsed: 0:35:57
train iter: 720
num of updates: 72100
dynamics loss: 0.72905

============================================================
time elapsed: 0:36:00
train iter: 721
num of updates: 72200
dynamics loss: 0.72863

============================================================
time elapsed: 0:36:03
train iter: 722
num of updates: 72300
dynamics loss: 0.72838

============================================================
time elapsed: 0:36:06
train iter: 723
num of updates: 72400
dynamics loss: 0.72778

============================================================
time elapsed: 0:36:09
train iter: 724
num of updates: 72500
dynamics loss: 0.72730

============================================================
time elapsed: 0:36:12
train iter: 725
num of updates: 72600
dynamics loss: 0.72668

============================================================
time elapsed: 0:36:14
train iter: 726
num of updates: 72700
dynamics loss: 0.72688

============================================================
time elapsed: 0:36:17
train iter: 727
num of updates: 72800
dynamics loss: 0.72649

============================================================
time elapsed: 0:36:20
train iter: 728
num of updates: 72900
dynamics loss: 0.72630

============================================================
time elapsed: 0:36:23
train iter: 729
num of updates: 73000
dynamics loss: 0.72503

============================================================
time elapsed: 0:36:26
train iter: 730
num of updates: 73100
dynamics loss: 0.72516

============================================================
time elapsed: 0:36:29
train iter: 731
num of updates: 73200
dynamics loss: 0.72472

============================================================
time elapsed: 0:36:32
train iter: 732
num of updates: 73300
dynamics loss: 0.72406

============================================================
time elapsed: 0:36:35
train iter: 733
num of updates: 73400
dynamics loss: 0.72430

============================================================
time elapsed: 0:36:37
train iter: 734
num of updates: 73500
dynamics loss: 0.72360

============================================================
time elapsed: 0:36:40
train iter: 735
num of updates: 73600
dynamics loss: 0.72319

============================================================
time elapsed: 0:36:43
train iter: 736
num of updates: 73700
dynamics loss: 0.72356

============================================================
time elapsed: 0:36:46
train iter: 737
num of updates: 73800
dynamics loss: 0.72271

============================================================
time elapsed: 0:36:49
train iter: 738
num of updates: 73900
dynamics loss: 0.72233

============================================================
time elapsed: 0:36:52
train iter: 739
num of updates: 74000
dynamics loss: 0.72144

============================================================
time elapsed: 0:36:55
train iter: 740
num of updates: 74100
dynamics loss: 0.72142

============================================================
time elapsed: 0:36:57
train iter: 741
num of updates: 74200
dynamics loss: 0.72085

============================================================
time elapsed: 0:37:00
train iter: 742
num of updates: 74300
dynamics loss: 0.72023

============================================================
time elapsed: 0:37:03
train iter: 743
num of updates: 74400
dynamics loss: 0.72009

============================================================
time elapsed: 0:37:06
train iter: 744
num of updates: 74500
dynamics loss: 0.72017

============================================================
time elapsed: 0:37:09
train iter: 745
num of updates: 74600
dynamics loss: 0.71970

============================================================
time elapsed: 0:37:12
train iter: 746
num of updates: 74700
dynamics loss: 0.71919

============================================================
time elapsed: 0:37:15
train iter: 747
num of updates: 74800
dynamics loss: 0.71863

============================================================
time elapsed: 0:37:18
train iter: 748
num of updates: 74900
dynamics loss: 0.71843

============================================================
time elapsed: 0:37:20
train iter: 749
num of updates: 75000
dynamics loss: 0.71747

============================================================
time elapsed: 0:37:23
train iter: 750
num of updates: 75100
dynamics loss: 0.71759

============================================================
time elapsed: 0:37:26
train iter: 751
num of updates: 75200
dynamics loss: 0.71708

============================================================
time elapsed: 0:37:29
train iter: 752
num of updates: 75300
dynamics loss: 0.71615

============================================================
time elapsed: 0:37:32
train iter: 753
num of updates: 75400
dynamics loss: 0.71685

============================================================
time elapsed: 0:37:35
train iter: 754
num of updates: 75500
dynamics loss: 0.71595

============================================================
time elapsed: 0:37:38
train iter: 755
num of updates: 75600
dynamics loss: 0.71583

============================================================
time elapsed: 0:37:40
train iter: 756
num of updates: 75700
dynamics loss: 0.71567

============================================================
time elapsed: 0:37:43
train iter: 757
num of updates: 75800
dynamics loss: 0.71455

============================================================
time elapsed: 0:37:46
train iter: 758
num of updates: 75900
dynamics loss: 0.71429

============================================================
time elapsed: 0:37:49
train iter: 759
num of updates: 76000
dynamics loss: 0.71416

============================================================
time elapsed: 0:37:52
train iter: 760
num of updates: 76100
dynamics loss: 0.71338

============================================================
time elapsed: 0:37:55
train iter: 761
num of updates: 76200
dynamics loss: 0.71329

============================================================
time elapsed: 0:37:58
train iter: 762
num of updates: 76300
dynamics loss: 0.71275

============================================================
time elapsed: 0:38:01
train iter: 763
num of updates: 76400
dynamics loss: 0.71280

============================================================
time elapsed: 0:38:03
train iter: 764
num of updates: 76500
dynamics loss: 0.71195

============================================================
time elapsed: 0:38:06
train iter: 765
num of updates: 76600
dynamics loss: 0.71180

============================================================
time elapsed: 0:38:09
train iter: 766
num of updates: 76700
dynamics loss: 0.71148

============================================================
time elapsed: 0:38:12
train iter: 767
num of updates: 76800
dynamics loss: 0.71106

============================================================
time elapsed: 0:38:15
train iter: 768
num of updates: 76900
dynamics loss: 0.71082

============================================================
time elapsed: 0:38:18
train iter: 769
num of updates: 77000
dynamics loss: 0.71037

============================================================
time elapsed: 0:38:21
train iter: 770
num of updates: 77100
dynamics loss: 0.70950

============================================================
time elapsed: 0:38:23
train iter: 771
num of updates: 77200
dynamics loss: 0.70967

============================================================
time elapsed: 0:38:26
train iter: 772
num of updates: 77300
dynamics loss: 0.70899

============================================================
time elapsed: 0:38:29
train iter: 773
num of updates: 77400
dynamics loss: 0.70927

============================================================
time elapsed: 0:38:32
train iter: 774
num of updates: 77500
dynamics loss: 0.70816

============================================================
time elapsed: 0:38:35
train iter: 775
num of updates: 77600
dynamics loss: 0.70780

============================================================
time elapsed: 0:38:38
train iter: 776
num of updates: 77700
dynamics loss: 0.70784

============================================================
time elapsed: 0:38:41
train iter: 777
num of updates: 77800
dynamics loss: 0.70710

============================================================
time elapsed: 0:38:44
train iter: 778
num of updates: 77900
dynamics loss: 0.70676

============================================================
time elapsed: 0:38:46
train iter: 779
num of updates: 78000
dynamics loss: 0.70639

============================================================
time elapsed: 0:38:49
train iter: 780
num of updates: 78100
dynamics loss: 0.70585

============================================================
time elapsed: 0:38:52
train iter: 781
num of updates: 78200
dynamics loss: 0.70544

============================================================
time elapsed: 0:38:55
train iter: 782
num of updates: 78300
dynamics loss: 0.70518

============================================================
time elapsed: 0:38:58
train iter: 783
num of updates: 78400
dynamics loss: 0.70449

============================================================
time elapsed: 0:39:01
train iter: 784
num of updates: 78500
dynamics loss: 0.70468

============================================================
time elapsed: 0:39:04
train iter: 785
num of updates: 78600
dynamics loss: 0.70435

============================================================
time elapsed: 0:39:06
train iter: 786
num of updates: 78700
dynamics loss: 0.70316

============================================================
time elapsed: 0:39:09
train iter: 787
num of updates: 78800
dynamics loss: 0.70331

============================================================
time elapsed: 0:39:12
train iter: 788
num of updates: 78900
dynamics loss: 0.70239

============================================================
time elapsed: 0:39:15
train iter: 789
num of updates: 79000
dynamics loss: 0.70245

============================================================
time elapsed: 0:39:18
train iter: 790
num of updates: 79100
dynamics loss: 0.70236

============================================================
time elapsed: 0:39:21
train iter: 791
num of updates: 79200
dynamics loss: 0.70151

============================================================
time elapsed: 0:39:24
train iter: 792
num of updates: 79300
dynamics loss: 0.70090

============================================================
time elapsed: 0:39:27
train iter: 793
num of updates: 79400
dynamics loss: 0.70119

============================================================
time elapsed: 0:39:29
train iter: 794
num of updates: 79500
dynamics loss: 0.70040

============================================================
time elapsed: 0:39:32
train iter: 795
num of updates: 79600
dynamics loss: 0.70053

============================================================
time elapsed: 0:39:35
train iter: 796
num of updates: 79700
dynamics loss: 0.70006

============================================================
time elapsed: 0:39:38
train iter: 797
num of updates: 79800
dynamics loss: 0.69953

============================================================
time elapsed: 0:39:41
train iter: 798
num of updates: 79900
dynamics loss: 0.69856

============================================================
time elapsed: 0:39:44
train iter: 799
num of updates: 80000
dynamics loss: 0.69828

============================================================
time elapsed: 0:39:47
train iter: 800
num of updates: 80100
dynamics loss: 0.69769

============================================================
time elapsed: 0:39:49
train iter: 801
num of updates: 80200
dynamics loss: 0.69715

============================================================
time elapsed: 0:39:52
train iter: 802
num of updates: 80300
dynamics loss: 0.69729

============================================================
time elapsed: 0:39:55
train iter: 803
num of updates: 80400
dynamics loss: 0.69721

============================================================
time elapsed: 0:39:58
train iter: 804
num of updates: 80500
dynamics loss: 0.69578

============================================================
time elapsed: 0:40:01
train iter: 805
num of updates: 80600
dynamics loss: 0.69544

============================================================
time elapsed: 0:40:04
train iter: 806
num of updates: 80700
dynamics loss: 0.69558

============================================================
time elapsed: 0:40:07
train iter: 807
num of updates: 80800
dynamics loss: 0.69528

============================================================
time elapsed: 0:40:09
train iter: 808
num of updates: 80900
dynamics loss: 0.69502

============================================================
time elapsed: 0:40:12
train iter: 809
num of updates: 81000
dynamics loss: 0.69459

============================================================
time elapsed: 0:40:15
train iter: 810
num of updates: 81100
dynamics loss: 0.69417

============================================================
time elapsed: 0:40:18
train iter: 811
num of updates: 81200
dynamics loss: 0.69404

============================================================
time elapsed: 0:40:21
train iter: 812
num of updates: 81300
dynamics loss: 0.69324

============================================================
time elapsed: 0:40:24
train iter: 813
num of updates: 81400
dynamics loss: 0.69283

============================================================
time elapsed: 0:40:27
train iter: 814
num of updates: 81500
dynamics loss: 0.69218

============================================================
time elapsed: 0:40:30
train iter: 815
num of updates: 81600
dynamics loss: 0.69186

============================================================
time elapsed: 0:40:32
train iter: 816
num of updates: 81700
dynamics loss: 0.69126

============================================================
time elapsed: 0:40:35
train iter: 817
num of updates: 81800
dynamics loss: 0.69122

============================================================
time elapsed: 0:40:38
train iter: 818
num of updates: 81900
dynamics loss: 0.69069

============================================================
time elapsed: 0:40:41
train iter: 819
num of updates: 82000
dynamics loss: 0.69006

============================================================
time elapsed: 0:40:44
train iter: 820
num of updates: 82100
dynamics loss: 0.69021

============================================================
time elapsed: 0:40:47
train iter: 821
num of updates: 82200
dynamics loss: 0.68961

============================================================
time elapsed: 0:40:50
train iter: 822
num of updates: 82300
dynamics loss: 0.68892

============================================================
time elapsed: 0:40:52
train iter: 823
num of updates: 82400
dynamics loss: 0.68862

============================================================
time elapsed: 0:40:55
train iter: 824
num of updates: 82500
dynamics loss: 0.68836

============================================================
time elapsed: 0:40:58
train iter: 825
num of updates: 82600
dynamics loss: 0.68828

============================================================
time elapsed: 0:41:01
train iter: 826
num of updates: 82700
dynamics loss: 0.68750

============================================================
time elapsed: 0:41:04
train iter: 827
num of updates: 82800
dynamics loss: 0.68721

============================================================
time elapsed: 0:41:07
train iter: 828
num of updates: 82900
dynamics loss: 0.68685

============================================================
time elapsed: 0:41:10
train iter: 829
num of updates: 83000
dynamics loss: 0.68642

============================================================
time elapsed: 0:41:13
train iter: 830
num of updates: 83100
dynamics loss: 0.68595

============================================================
time elapsed: 0:41:15
train iter: 831
num of updates: 83200
dynamics loss: 0.68539

============================================================
time elapsed: 0:41:18
train iter: 832
num of updates: 83300
dynamics loss: 0.68471

============================================================
time elapsed: 0:41:21
train iter: 833
num of updates: 83400
dynamics loss: 0.68469

============================================================
time elapsed: 0:41:24
train iter: 834
num of updates: 83500
dynamics loss: 0.68412

============================================================
time elapsed: 0:41:27
train iter: 835
num of updates: 83600
dynamics loss: 0.68370

============================================================
time elapsed: 0:41:30
train iter: 836
num of updates: 83700
dynamics loss: 0.68344

============================================================
time elapsed: 0:41:33
train iter: 837
num of updates: 83800
dynamics loss: 0.68298

============================================================
time elapsed: 0:41:35
train iter: 838
num of updates: 83900
dynamics loss: 0.68275

============================================================
time elapsed: 0:41:38
train iter: 839
num of updates: 84000
dynamics loss: 0.68195

============================================================
time elapsed: 0:41:41
train iter: 840
num of updates: 84100
dynamics loss: 0.68211

============================================================
time elapsed: 0:41:44
train iter: 841
num of updates: 84200
dynamics loss: 0.68111

============================================================
time elapsed: 0:41:47
train iter: 842
num of updates: 84300
dynamics loss: 0.68095

============================================================
time elapsed: 0:41:50
train iter: 843
num of updates: 84400
dynamics loss: 0.68006

============================================================
time elapsed: 0:41:53
train iter: 844
num of updates: 84500
dynamics loss: 0.68030

============================================================
time elapsed: 0:41:56
train iter: 845
num of updates: 84600
dynamics loss: 0.67977

============================================================
time elapsed: 0:41:58
train iter: 846
num of updates: 84700
dynamics loss: 0.67955

============================================================
time elapsed: 0:42:01
train iter: 847
num of updates: 84800
dynamics loss: 0.67912

============================================================
time elapsed: 0:42:04
train iter: 848
num of updates: 84900
dynamics loss: 0.67854

============================================================
time elapsed: 0:42:07
train iter: 849
num of updates: 85000
dynamics loss: 0.67804

============================================================
time elapsed: 0:42:10
train iter: 850
num of updates: 85100
dynamics loss: 0.67750

============================================================
time elapsed: 0:42:13
train iter: 851
num of updates: 85200
dynamics loss: 0.67714

============================================================
time elapsed: 0:42:16
train iter: 852
num of updates: 85300
dynamics loss: 0.67677

============================================================
time elapsed: 0:42:18
train iter: 853
num of updates: 85400
dynamics loss: 0.67557

============================================================
time elapsed: 0:42:21
train iter: 854
num of updates: 85500
dynamics loss: 0.67583

============================================================
time elapsed: 0:42:24
train iter: 855
num of updates: 85600
dynamics loss: 0.67551

============================================================
time elapsed: 0:42:27
train iter: 856
num of updates: 85700
dynamics loss: 0.67482

============================================================
time elapsed: 0:42:30
train iter: 857
num of updates: 85800
dynamics loss: 0.67436

============================================================
time elapsed: 0:42:33
train iter: 858
num of updates: 85900
dynamics loss: 0.67408

============================================================
time elapsed: 0:42:36
train iter: 859
num of updates: 86000
dynamics loss: 0.67369

============================================================
time elapsed: 0:42:39
train iter: 860
num of updates: 86100
dynamics loss: 0.67315

============================================================
time elapsed: 0:42:41
train iter: 861
num of updates: 86200
dynamics loss: 0.67307

============================================================
time elapsed: 0:42:44
train iter: 862
num of updates: 86300
dynamics loss: 0.67236

============================================================
time elapsed: 0:42:47
train iter: 863
num of updates: 86400
dynamics loss: 0.67191

============================================================
time elapsed: 0:42:50
train iter: 864
num of updates: 86500
dynamics loss: 0.67127

============================================================
time elapsed: 0:42:53
train iter: 865
num of updates: 86600
dynamics loss: 0.67070

============================================================
time elapsed: 0:42:56
train iter: 866
num of updates: 86700
dynamics loss: 0.67044

============================================================
time elapsed: 0:42:59
train iter: 867
num of updates: 86800
dynamics loss: 0.67059

============================================================
time elapsed: 0:43:01
train iter: 868
num of updates: 86900
dynamics loss: 0.66998

============================================================
time elapsed: 0:43:04
train iter: 869
num of updates: 87000
dynamics loss: 0.67041

============================================================
time elapsed: 0:43:07
train iter: 870
num of updates: 87100
dynamics loss: 0.66859

============================================================
time elapsed: 0:43:10
train iter: 871
num of updates: 87200
dynamics loss: 0.66871

============================================================
time elapsed: 0:43:13
train iter: 872
num of updates: 87300
dynamics loss: 0.66799

============================================================
time elapsed: 0:43:16
train iter: 873
num of updates: 87400
dynamics loss: 0.66795

============================================================
time elapsed: 0:43:19
train iter: 874
num of updates: 87500
dynamics loss: 0.66743

============================================================
time elapsed: 0:43:22
train iter: 875
num of updates: 87600
dynamics loss: 0.66682

============================================================
time elapsed: 0:43:24
train iter: 876
num of updates: 87700
dynamics loss: 0.66659

============================================================
time elapsed: 0:43:27
train iter: 877
num of updates: 87800
dynamics loss: 0.66570

============================================================
time elapsed: 0:43:30
train iter: 878
num of updates: 87900
dynamics loss: 0.66588

============================================================
time elapsed: 0:43:33
train iter: 879
num of updates: 88000
dynamics loss: 0.66493

============================================================
time elapsed: 0:43:36
train iter: 880
num of updates: 88100
dynamics loss: 0.66500

============================================================
time elapsed: 0:43:39
train iter: 881
num of updates: 88200
dynamics loss: 0.66425

============================================================
time elapsed: 0:43:42
train iter: 882
num of updates: 88300
dynamics loss: 0.66414

============================================================
time elapsed: 0:43:44
train iter: 883
num of updates: 88400
dynamics loss: 0.66384

============================================================
time elapsed: 0:43:47
train iter: 884
num of updates: 88500
dynamics loss: 0.66297

============================================================
time elapsed: 0:43:50
train iter: 885
num of updates: 88600
dynamics loss: 0.66238

============================================================
time elapsed: 0:43:53
train iter: 886
num of updates: 88700
dynamics loss: 0.66203

============================================================
time elapsed: 0:43:56
train iter: 887
num of updates: 88800
dynamics loss: 0.66129

============================================================
time elapsed: 0:43:59
train iter: 888
num of updates: 88900
dynamics loss: 0.66101

============================================================
time elapsed: 0:44:02
train iter: 889
num of updates: 89000
dynamics loss: 0.66096

============================================================
time elapsed: 0:44:05
train iter: 890
num of updates: 89100
dynamics loss: 0.65989

============================================================
time elapsed: 0:44:07
train iter: 891
num of updates: 89200
dynamics loss: 0.66002

============================================================
time elapsed: 0:44:10
train iter: 892
num of updates: 89300
dynamics loss: 0.65907

============================================================
time elapsed: 0:44:13
train iter: 893
num of updates: 89400
dynamics loss: 0.65890

============================================================
time elapsed: 0:44:16
train iter: 894
num of updates: 89500
dynamics loss: 0.65852

============================================================
time elapsed: 0:44:19
train iter: 895
num of updates: 89600
dynamics loss: 0.65800

============================================================
time elapsed: 0:44:22
train iter: 896
num of updates: 89700
dynamics loss: 0.65758

============================================================
time elapsed: 0:44:25
train iter: 897
num of updates: 89800
dynamics loss: 0.65703

============================================================
time elapsed: 0:44:27
train iter: 898
num of updates: 89900
dynamics loss: 0.65682

============================================================
time elapsed: 0:44:30
train iter: 899
num of updates: 90000
dynamics loss: 0.65650

============================================================
time elapsed: 0:44:33
train iter: 900
num of updates: 90100
dynamics loss: 0.65605

============================================================
time elapsed: 0:44:36
train iter: 901
num of updates: 90200
dynamics loss: 0.65544

============================================================
time elapsed: 0:44:39
train iter: 902
num of updates: 90300
dynamics loss: 0.65538

============================================================
time elapsed: 0:44:42
train iter: 903
num of updates: 90400
dynamics loss: 0.65417

============================================================
time elapsed: 0:44:45
train iter: 904
num of updates: 90500
dynamics loss: 0.65403

============================================================
time elapsed: 0:44:48
train iter: 905
num of updates: 90600
dynamics loss: 0.65370

============================================================
time elapsed: 0:44:50
train iter: 906
num of updates: 90700
dynamics loss: 0.65301

============================================================
time elapsed: 0:44:53
train iter: 907
num of updates: 90800
dynamics loss: 0.65234

============================================================
time elapsed: 0:44:56
train iter: 908
num of updates: 90900
dynamics loss: 0.65269

============================================================
time elapsed: 0:44:59
train iter: 909
num of updates: 91000
dynamics loss: 0.65212

============================================================
time elapsed: 0:45:02
train iter: 910
num of updates: 91100
dynamics loss: 0.65150

============================================================
time elapsed: 0:45:05
train iter: 911
num of updates: 91200
dynamics loss: 0.65086

============================================================
time elapsed: 0:45:08
train iter: 912
num of updates: 91300
dynamics loss: 0.65104

============================================================
time elapsed: 0:45:10
train iter: 913
num of updates: 91400
dynamics loss: 0.65014

============================================================
time elapsed: 0:45:13
train iter: 914
num of updates: 91500
dynamics loss: 0.64974

============================================================
time elapsed: 0:45:16
train iter: 915
num of updates: 91600
dynamics loss: 0.64904

============================================================
time elapsed: 0:45:19
train iter: 916
num of updates: 91700
dynamics loss: 0.64850

============================================================
time elapsed: 0:45:22
train iter: 917
num of updates: 91800
dynamics loss: 0.64770

============================================================
time elapsed: 0:45:25
train iter: 918
num of updates: 91900
dynamics loss: 0.64780

============================================================
time elapsed: 0:45:28
train iter: 919
num of updates: 92000
dynamics loss: 0.64732

============================================================
time elapsed: 0:45:31
train iter: 920
num of updates: 92100
dynamics loss: 0.64718

============================================================
time elapsed: 0:45:33
train iter: 921
num of updates: 92200
dynamics loss: 0.64594

============================================================
time elapsed: 0:45:36
train iter: 922
num of updates: 92300
dynamics loss: 0.64589

============================================================
time elapsed: 0:45:39
train iter: 923
num of updates: 92400
dynamics loss: 0.64560

============================================================
time elapsed: 0:45:42
train iter: 924
num of updates: 92500
dynamics loss: 0.64509

============================================================
time elapsed: 0:45:45
train iter: 925
num of updates: 92600
dynamics loss: 0.64440

============================================================
time elapsed: 0:45:48
train iter: 926
num of updates: 92700
dynamics loss: 0.64382

============================================================
time elapsed: 0:45:51
train iter: 927
num of updates: 92800
dynamics loss: 0.64371

============================================================
time elapsed: 0:45:54
train iter: 928
num of updates: 92900
dynamics loss: 0.64270

============================================================
time elapsed: 0:45:56
train iter: 929
num of updates: 93000
dynamics loss: 0.64241

============================================================
time elapsed: 0:45:59
train iter: 930
num of updates: 93100
dynamics loss: 0.64213

============================================================
time elapsed: 0:46:02
train iter: 931
num of updates: 93200
dynamics loss: 0.64180

============================================================
time elapsed: 0:46:05
train iter: 932
num of updates: 93300
dynamics loss: 0.64168

============================================================
time elapsed: 0:46:08
train iter: 933
num of updates: 93400
dynamics loss: 0.64110

============================================================
time elapsed: 0:46:11
train iter: 934
num of updates: 93500
dynamics loss: 0.64060

============================================================
time elapsed: 0:46:14
train iter: 935
num of updates: 93600
dynamics loss: 0.63925

============================================================
time elapsed: 0:46:16
train iter: 936
num of updates: 93700
dynamics loss: 0.63933

============================================================
time elapsed: 0:46:19
train iter: 937
num of updates: 93800
dynamics loss: 0.63851

============================================================
time elapsed: 0:46:22
train iter: 938
num of updates: 93900
dynamics loss: 0.63851

============================================================
time elapsed: 0:46:25
train iter: 939
num of updates: 94000
dynamics loss: 0.63799

============================================================
time elapsed: 0:46:28
train iter: 940
num of updates: 94100
dynamics loss: 0.63765

============================================================
time elapsed: 0:46:31
train iter: 941
num of updates: 94200
dynamics loss: 0.63672

============================================================
time elapsed: 0:46:34
train iter: 942
num of updates: 94300
dynamics loss: 0.63652

============================================================
time elapsed: 0:46:37
train iter: 943
num of updates: 94400
dynamics loss: 0.63635

============================================================
time elapsed: 0:46:39
train iter: 944
num of updates: 94500
dynamics loss: 0.63570

============================================================
time elapsed: 0:46:42
train iter: 945
num of updates: 94600
dynamics loss: 0.63500

============================================================
time elapsed: 0:46:45
train iter: 946
num of updates: 94700
dynamics loss: 0.63427

============================================================
time elapsed: 0:46:48
train iter: 947
num of updates: 94800
dynamics loss: 0.63389

============================================================
time elapsed: 0:46:51
train iter: 948
num of updates: 94900
dynamics loss: 0.63387

============================================================
time elapsed: 0:46:54
train iter: 949
num of updates: 95000
dynamics loss: 0.63393

============================================================
time elapsed: 0:46:57
train iter: 950
num of updates: 95100
dynamics loss: 0.63279

============================================================
time elapsed: 0:46:59
train iter: 951
num of updates: 95200
dynamics loss: 0.63234

============================================================
time elapsed: 0:47:02
train iter: 952
num of updates: 95300
dynamics loss: 0.63191

============================================================
time elapsed: 0:47:05
train iter: 953
num of updates: 95400
dynamics loss: 0.63132

============================================================
time elapsed: 0:47:08
train iter: 954
num of updates: 95500
dynamics loss: 0.63101

============================================================
time elapsed: 0:47:11
train iter: 955
num of updates: 95600
dynamics loss: 0.63036

============================================================
time elapsed: 0:47:14
train iter: 956
num of updates: 95700
dynamics loss: 0.62977

============================================================
time elapsed: 0:47:17
train iter: 957
num of updates: 95800
dynamics loss: 0.62973

============================================================
time elapsed: 0:47:20
train iter: 958
num of updates: 95900
dynamics loss: 0.62895

============================================================
time elapsed: 0:47:22
train iter: 959
num of updates: 96000
dynamics loss: 0.62844

============================================================
time elapsed: 0:47:25
train iter: 960
num of updates: 96100
dynamics loss: 0.62790

============================================================
time elapsed: 0:47:28
train iter: 961
num of updates: 96200
dynamics loss: 0.62755

============================================================
time elapsed: 0:47:31
train iter: 962
num of updates: 96300
dynamics loss: 0.62729

============================================================
time elapsed: 0:47:34
train iter: 963
num of updates: 96400
dynamics loss: 0.62677

============================================================
time elapsed: 0:47:37
train iter: 964
num of updates: 96500
dynamics loss: 0.62526

============================================================
time elapsed: 0:47:40
train iter: 965
num of updates: 96600
dynamics loss: 0.62509

============================================================
time elapsed: 0:47:42
train iter: 966
num of updates: 96700
dynamics loss: 0.62550

============================================================
time elapsed: 0:47:45
train iter: 967
num of updates: 96800
dynamics loss: 0.62475

============================================================
time elapsed: 0:47:48
train iter: 968
num of updates: 96900
dynamics loss: 0.62449

============================================================
time elapsed: 0:47:51
train iter: 969
num of updates: 97000
dynamics loss: 0.62304

============================================================
time elapsed: 0:47:54
train iter: 970
num of updates: 97100
dynamics loss: 0.62303

============================================================
time elapsed: 0:47:57
train iter: 971
num of updates: 97200
dynamics loss: 0.62278

============================================================
time elapsed: 0:48:00
train iter: 972
num of updates: 97300
dynamics loss: 0.62197

============================================================
time elapsed: 0:48:02
train iter: 973
num of updates: 97400
dynamics loss: 0.62160

============================================================
time elapsed: 0:48:05
train iter: 974
num of updates: 97500
dynamics loss: 0.62151

============================================================
time elapsed: 0:48:08
train iter: 975
num of updates: 97600
dynamics loss: 0.62093

============================================================
time elapsed: 0:48:11
train iter: 976
num of updates: 97700
dynamics loss: 0.62023

============================================================
time elapsed: 0:48:14
train iter: 977
num of updates: 97800
dynamics loss: 0.62006

============================================================
time elapsed: 0:48:17
train iter: 978
num of updates: 97900
dynamics loss: 0.61881

============================================================
time elapsed: 0:48:20
train iter: 979
num of updates: 98000
dynamics loss: 0.61865

============================================================
time elapsed: 0:48:23
train iter: 980
num of updates: 98100
dynamics loss: 0.61778

============================================================
time elapsed: 0:48:25
train iter: 981
num of updates: 98200
dynamics loss: 0.61770

============================================================
time elapsed: 0:48:28
train iter: 982
num of updates: 98300
dynamics loss: 0.61720

============================================================
time elapsed: 0:48:31
train iter: 983
num of updates: 98400
dynamics loss: 0.61676

============================================================
time elapsed: 0:48:34
train iter: 984
num of updates: 98500
dynamics loss: 0.61645

============================================================
time elapsed: 0:48:37
train iter: 985
num of updates: 98600
dynamics loss: 0.61627

============================================================
time elapsed: 0:48:40
train iter: 986
num of updates: 98700
dynamics loss: 0.61538

============================================================
time elapsed: 0:48:43
train iter: 987
num of updates: 98800
dynamics loss: 0.61434

============================================================
time elapsed: 0:48:45
train iter: 988
num of updates: 98900
dynamics loss: 0.61441

============================================================
time elapsed: 0:48:48
train iter: 989
num of updates: 99000
dynamics loss: 0.61401

============================================================
time elapsed: 0:48:51
train iter: 990
num of updates: 99100
dynamics loss: 0.61384

============================================================
time elapsed: 0:48:54
train iter: 991
num of updates: 99200
dynamics loss: 0.61271

============================================================
time elapsed: 0:48:57
train iter: 992
num of updates: 99300
dynamics loss: 0.61221

============================================================
time elapsed: 0:49:00
train iter: 993
num of updates: 99400
dynamics loss: 0.61194

============================================================
time elapsed: 0:49:03
train iter: 994
num of updates: 99500
dynamics loss: 0.61165

============================================================
time elapsed: 0:49:06
train iter: 995
num of updates: 99600
dynamics loss: 0.61055

============================================================
time elapsed: 0:49:08
train iter: 996
num of updates: 99700
dynamics loss: 0.61041

============================================================
time elapsed: 0:49:11
train iter: 997
num of updates: 99800
dynamics loss: 0.61002

============================================================
time elapsed: 0:49:14
train iter: 998
num of updates: 99900
dynamics loss: 0.60975

============================================================
time elapsed: 0:49:17
train iter: 999
num of updates: 100000
dynamics loss: 0.60888

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/dynamics_model_100000.pt
============================================================
finished training dynamics!
============================================================
started training dynamics at: 25-09-28-00-51-36
finished training dynamics at: 25-09-28-01-40-57
total dynamics training time: 0:49:21
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/dynamics_model.pt
============================================================
2025-09-28 01:41:09.116643: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:41:11.673590: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:41:13.817961: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 324 bytes spill stores, 324 bytes spill loads

num_vae_param: 547754
2025-09-28 01:41:19.635643: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:41:19.635860: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:41:19.635920: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:41:19.636145: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:41:19.636200: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:41:21.412857: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 320 bytes spill stores, 220 bytes spill loads

2025-09-28 01:41:23.236292: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 388 bytes spill stores, 384 bytes spill loads

2025-09-28 01:41:24.492754: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 820 bytes spill stores, 564 bytes spill loads

2025-09-28 01:41:24.958661: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 1736 bytes spill stores, 1312 bytes spill loads

2025-09-28 01:41:28.891507: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15', 4 bytes spill stores, 4 bytes spill loads

2025-09-28 01:41:33.856086: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 540 bytes spill stores, 540 bytes spill loads

2025-09-28 01:41:35.820488: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 8 bytes spill stores, 8 bytes spill loads

2025-09-28 01:41:36.895665: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 196 bytes spill stores, 200 bytes spill loads

2025-09-28 01:41:39.702374: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 108 bytes spill stores, 108 bytes spill loads

2025-09-28 01:41:40.628100: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 200 bytes spill stores, 200 bytes spill loads

2025-09-28 01:41:41.600839: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 292 bytes spill stores, 292 bytes spill loads

============================================================
time elapsed: 0:50:17
train iter: 0
num of updates: 100
vae loss: 2.19801
kl loss: 0.11153
a decoder loss: 2.08648
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/vae_model_100.pt
2025-09-28 01:41:54.035890: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:41:56.176345: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:41:57.067222: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 324 bytes spill stores, 324 bytes spill loads

============================================================
time elapsed: 0:50:33
train iter: 1
num of updates: 200
vae loss: 2.19992
kl loss: 0.11173
a decoder loss: 2.08819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:34
train iter: 2
num of updates: 300
vae loss: 2.19370
kl loss: 0.11030
a decoder loss: 2.08340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:35
train iter: 3
num of updates: 400
vae loss: 2.18861
kl loss: 0.10910
a decoder loss: 2.07951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:37
train iter: 4
num of updates: 500
vae loss: 2.18650
kl loss: 0.10777
a decoder loss: 2.07873
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:38
train iter: 5
num of updates: 600
vae loss: 2.18512
kl loss: 0.10643
a decoder loss: 2.07869
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:39
train iter: 6
num of updates: 700
vae loss: 2.17932
kl loss: 0.10403
a decoder loss: 2.07529
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:40
train iter: 7
num of updates: 800
vae loss: 2.17097
kl loss: 0.10197
a decoder loss: 2.06900
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:41
train iter: 8
num of updates: 900
vae loss: 2.16282
kl loss: 0.10006
a decoder loss: 2.06276
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:42
train iter: 9
num of updates: 1000
vae loss: 2.14816
kl loss: 0.09719
a decoder loss: 2.05097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:43
train iter: 10
num of updates: 1100
vae loss: 2.14312
kl loss: 0.09464
a decoder loss: 2.04848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:44
train iter: 11
num of updates: 1200
vae loss: 2.12345
kl loss: 0.09206
a decoder loss: 2.03138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:45
train iter: 12
num of updates: 1300
vae loss: 2.12326
kl loss: 0.08949
a decoder loss: 2.03377
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:46
train iter: 13
num of updates: 1400
vae loss: 2.11781
kl loss: 0.08694
a decoder loss: 2.03087
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:47
train iter: 14
num of updates: 1500
vae loss: 2.09527
kl loss: 0.08414
a decoder loss: 2.01113
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:48
train iter: 15
num of updates: 1600
vae loss: 2.08284
kl loss: 0.08144
a decoder loss: 2.00140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:49
train iter: 16
num of updates: 1700
vae loss: 2.05850
kl loss: 0.07908
a decoder loss: 1.97942
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:50
train iter: 17
num of updates: 1800
vae loss: 2.05007
kl loss: 0.07693
a decoder loss: 1.97314
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:51
train iter: 18
num of updates: 1900
vae loss: 2.03763
kl loss: 0.07429
a decoder loss: 1.96334
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:52
train iter: 19
num of updates: 2000
vae loss: 2.02521
kl loss: 0.07222
a decoder loss: 1.95300
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:53
train iter: 20
num of updates: 2100
vae loss: 2.01481
kl loss: 0.06992
a decoder loss: 1.94490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:54
train iter: 21
num of updates: 2200
vae loss: 1.98787
kl loss: 0.06812
a decoder loss: 1.91974
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:55
train iter: 22
num of updates: 2300
vae loss: 1.97078
kl loss: 0.06629
a decoder loss: 1.90449
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:56
train iter: 23
num of updates: 2400
vae loss: 1.95776
kl loss: 0.06448
a decoder loss: 1.89328
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:57
train iter: 24
num of updates: 2500
vae loss: 1.94260
kl loss: 0.06266
a decoder loss: 1.87994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:58
train iter: 25
num of updates: 2600
vae loss: 1.91862
kl loss: 0.06082
a decoder loss: 1.85780
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:59
train iter: 26
num of updates: 2700
vae loss: 1.89960
kl loss: 0.05917
a decoder loss: 1.84043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:00
train iter: 27
num of updates: 2800
vae loss: 1.87959
kl loss: 0.05786
a decoder loss: 1.82174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:01
train iter: 28
num of updates: 2900
vae loss: 1.86244
kl loss: 0.05651
a decoder loss: 1.80593
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:02
train iter: 29
num of updates: 3000
vae loss: 1.84528
kl loss: 0.05512
a decoder loss: 1.79017
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:03
train iter: 30
num of updates: 3100
vae loss: 1.82687
kl loss: 0.05384
a decoder loss: 1.77303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:04
train iter: 31
num of updates: 3200
vae loss: 1.80338
kl loss: 0.05264
a decoder loss: 1.75075
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:05
train iter: 32
num of updates: 3300
vae loss: 1.78824
kl loss: 0.05164
a decoder loss: 1.73659
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:06
train iter: 33
num of updates: 3400
vae loss: 1.76855
kl loss: 0.05066
a decoder loss: 1.71789
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:07
train iter: 34
num of updates: 3500
vae loss: 1.74472
kl loss: 0.04967
a decoder loss: 1.69505
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:08
train iter: 35
num of updates: 3600
vae loss: 1.72390
kl loss: 0.04867
a decoder loss: 1.67524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:09
train iter: 36
num of updates: 3700
vae loss: 1.70026
kl loss: 0.04787
a decoder loss: 1.65239
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:10
train iter: 37
num of updates: 3800
vae loss: 1.67274
kl loss: 0.04729
a decoder loss: 1.62544
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:11
train iter: 38
num of updates: 3900
vae loss: 1.66225
kl loss: 0.04644
a decoder loss: 1.61581
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:12
train iter: 39
num of updates: 4000
vae loss: 1.63895
kl loss: 0.04577
a decoder loss: 1.59318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:13
train iter: 40
num of updates: 4100
vae loss: 1.61246
kl loss: 0.04502
a decoder loss: 1.56744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:14
train iter: 41
num of updates: 4200
vae loss: 1.59950
kl loss: 0.04442
a decoder loss: 1.55508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:15
train iter: 42
num of updates: 4300
vae loss: 1.57900
kl loss: 0.04391
a decoder loss: 1.53508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:16
train iter: 43
num of updates: 4400
vae loss: 1.55526
kl loss: 0.04340
a decoder loss: 1.51185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:17
train iter: 44
num of updates: 4500
vae loss: 1.54121
kl loss: 0.04302
a decoder loss: 1.49819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:18
train iter: 45
num of updates: 4600
vae loss: 1.51916
kl loss: 0.04267
a decoder loss: 1.47650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:19
train iter: 46
num of updates: 4700
vae loss: 1.49501
kl loss: 0.04232
a decoder loss: 1.45269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:20
train iter: 47
num of updates: 4800
vae loss: 1.48020
kl loss: 0.04212
a decoder loss: 1.43808
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:21
train iter: 48
num of updates: 4900
vae loss: 1.45642
kl loss: 0.04174
a decoder loss: 1.41469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:22
train iter: 49
num of updates: 5000
vae loss: 1.43248
kl loss: 0.04150
a decoder loss: 1.39098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:23
train iter: 50
num of updates: 5100
vae loss: 1.41750
kl loss: 0.04144
a decoder loss: 1.37606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:25
train iter: 51
num of updates: 5200
vae loss: 1.39302
kl loss: 0.04113
a decoder loss: 1.35189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:26
train iter: 52
num of updates: 5300
vae loss: 1.36982
kl loss: 0.04105
a decoder loss: 1.32876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:27
train iter: 53
num of updates: 5400
vae loss: 1.34565
kl loss: 0.04099
a decoder loss: 1.30467
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:28
train iter: 54
num of updates: 5500
vae loss: 1.33262
kl loss: 0.04091
a decoder loss: 1.29171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:29
train iter: 55
num of updates: 5600
vae loss: 1.30999
kl loss: 0.04080
a decoder loss: 1.26919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:30
train iter: 56
num of updates: 5700
vae loss: 1.29537
kl loss: 0.04075
a decoder loss: 1.25461
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:31
train iter: 57
num of updates: 5800
vae loss: 1.26549
kl loss: 0.04053
a decoder loss: 1.22496
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:32
train iter: 58
num of updates: 5900
vae loss: 1.24797
kl loss: 0.04061
a decoder loss: 1.20736
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:33
train iter: 59
num of updates: 6000
vae loss: 1.23256
kl loss: 0.04055
a decoder loss: 1.19201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:34
train iter: 60
num of updates: 6100
vae loss: 1.21006
kl loss: 0.04057
a decoder loss: 1.16948
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:35
train iter: 61
num of updates: 6200
vae loss: 1.19245
kl loss: 0.04039
a decoder loss: 1.15206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:36
train iter: 62
num of updates: 6300
vae loss: 1.16996
kl loss: 0.04065
a decoder loss: 1.12931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:37
train iter: 63
num of updates: 6400
vae loss: 1.14787
kl loss: 0.04047
a decoder loss: 1.10740
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:38
train iter: 64
num of updates: 6500
vae loss: 1.13003
kl loss: 0.04064
a decoder loss: 1.08939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:39
train iter: 65
num of updates: 6600
vae loss: 1.11173
kl loss: 0.04053
a decoder loss: 1.07120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:40
train iter: 66
num of updates: 6700
vae loss: 1.09101
kl loss: 0.04035
a decoder loss: 1.05066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:41
train iter: 67
num of updates: 6800
vae loss: 1.07168
kl loss: 0.04037
a decoder loss: 1.03132
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:42
train iter: 68
num of updates: 6900
vae loss: 1.05043
kl loss: 0.04035
a decoder loss: 1.01007
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:43
train iter: 69
num of updates: 7000
vae loss: 1.03244
kl loss: 0.04029
a decoder loss: 0.99215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:44
train iter: 70
num of updates: 7100
vae loss: 1.01709
kl loss: 0.04016
a decoder loss: 0.97693
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:45
train iter: 71
num of updates: 7200
vae loss: 0.99867
kl loss: 0.04017
a decoder loss: 0.95850
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:46
train iter: 72
num of updates: 7300
vae loss: 0.97575
kl loss: 0.04001
a decoder loss: 0.93575
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:47
train iter: 73
num of updates: 7400
vae loss: 0.96248
kl loss: 0.03991
a decoder loss: 0.92258
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:48
train iter: 74
num of updates: 7500
vae loss: 0.94269
kl loss: 0.03980
a decoder loss: 0.90289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:49
train iter: 75
num of updates: 7600
vae loss: 0.93136
kl loss: 0.03974
a decoder loss: 0.89162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:50
train iter: 76
num of updates: 7700
vae loss: 0.91329
kl loss: 0.03946
a decoder loss: 0.87383
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:51
train iter: 77
num of updates: 7800
vae loss: 0.89243
kl loss: 0.03925
a decoder loss: 0.85318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:52
train iter: 78
num of updates: 7900
vae loss: 0.87160
kl loss: 0.03898
a decoder loss: 0.83261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:53
train iter: 79
num of updates: 8000
vae loss: 0.86327
kl loss: 0.03873
a decoder loss: 0.82454
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:54
train iter: 80
num of updates: 8100
vae loss: 0.84527
kl loss: 0.03859
a decoder loss: 0.80667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:55
train iter: 81
num of updates: 8200
vae loss: 0.83156
kl loss: 0.03837
a decoder loss: 0.79319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:56
train iter: 82
num of updates: 8300
vae loss: 0.81415
kl loss: 0.03814
a decoder loss: 0.77601
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:57
train iter: 83
num of updates: 8400
vae loss: 0.79989
kl loss: 0.03787
a decoder loss: 0.76201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:58
train iter: 84
num of updates: 8500
vae loss: 0.78490
kl loss: 0.03744
a decoder loss: 0.74746
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:59
train iter: 85
num of updates: 8600
vae loss: 0.77138
kl loss: 0.03723
a decoder loss: 0.73414
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:00
train iter: 86
num of updates: 8700
vae loss: 0.75880
kl loss: 0.03697
a decoder loss: 0.72183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:01
train iter: 87
num of updates: 8800
vae loss: 0.74204
kl loss: 0.03659
a decoder loss: 0.70544
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:02
train iter: 88
num of updates: 8900
vae loss: 0.73010
kl loss: 0.03642
a decoder loss: 0.69368
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:03
train iter: 89
num of updates: 9000
vae loss: 0.71549
kl loss: 0.03603
a decoder loss: 0.67946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:04
train iter: 90
num of updates: 9100
vae loss: 0.70177
kl loss: 0.03577
a decoder loss: 0.66600
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:05
train iter: 91
num of updates: 9200
vae loss: 0.68917
kl loss: 0.03529
a decoder loss: 0.65388
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:06
train iter: 92
num of updates: 9300
vae loss: 0.67641
kl loss: 0.03494
a decoder loss: 0.64147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:07
train iter: 93
num of updates: 9400
vae loss: 0.66181
kl loss: 0.03454
a decoder loss: 0.62726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:08
train iter: 94
num of updates: 9500
vae loss: 0.64875
kl loss: 0.03423
a decoder loss: 0.61452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:09
train iter: 95
num of updates: 9600
vae loss: 0.64054
kl loss: 0.03360
a decoder loss: 0.60694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:10
train iter: 96
num of updates: 9700
vae loss: 0.62829
kl loss: 0.03325
a decoder loss: 0.59504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:11
train iter: 97
num of updates: 9800
vae loss: 0.61553
kl loss: 0.03282
a decoder loss: 0.58272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:12
train iter: 98
num of updates: 9900
vae loss: 0.60983
kl loss: 0.03266
a decoder loss: 0.57717
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:13
train iter: 99
num of updates: 10000
vae loss: 0.59623
kl loss: 0.03218
a decoder loss: 0.56405
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:14
train iter: 100
num of updates: 10100
vae loss: 0.58593
kl loss: 0.03180
a decoder loss: 0.55413
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:15
train iter: 101
num of updates: 10200
vae loss: 0.57731
kl loss: 0.03149
a decoder loss: 0.54583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:16
train iter: 102
num of updates: 10300
vae loss: 0.56611
kl loss: 0.03093
a decoder loss: 0.53518
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:17
train iter: 103
num of updates: 10400
vae loss: 0.55896
kl loss: 0.03056
a decoder loss: 0.52840
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:18
train iter: 104
num of updates: 10500
vae loss: 0.54751
kl loss: 0.03002
a decoder loss: 0.51749
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:20
train iter: 105
num of updates: 10600
vae loss: 0.53932
kl loss: 0.02957
a decoder loss: 0.50975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:21
train iter: 106
num of updates: 10700
vae loss: 0.53040
kl loss: 0.02923
a decoder loss: 0.50117
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:22
train iter: 107
num of updates: 10800
vae loss: 0.52362
kl loss: 0.02884
a decoder loss: 0.49478
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:23
train iter: 108
num of updates: 10900
vae loss: 0.51454
kl loss: 0.02842
a decoder loss: 0.48613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:24
train iter: 109
num of updates: 11000
vae loss: 0.50866
kl loss: 0.02786
a decoder loss: 0.48080
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:25
train iter: 110
num of updates: 11100
vae loss: 0.50401
kl loss: 0.02751
a decoder loss: 0.47650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:26
train iter: 111
num of updates: 11200
vae loss: 0.49260
kl loss: 0.02706
a decoder loss: 0.46554
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:27
train iter: 112
num of updates: 11300
vae loss: 0.48848
kl loss: 0.02669
a decoder loss: 0.46179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:28
train iter: 113
num of updates: 11400
vae loss: 0.48200
kl loss: 0.02618
a decoder loss: 0.45582
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:29
train iter: 114
num of updates: 11500
vae loss: 0.47525
kl loss: 0.02574
a decoder loss: 0.44951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:30
train iter: 115
num of updates: 11600
vae loss: 0.46944
kl loss: 0.02525
a decoder loss: 0.44418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:31
train iter: 116
num of updates: 11700
vae loss: 0.46435
kl loss: 0.02472
a decoder loss: 0.43963
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:32
train iter: 117
num of updates: 11800
vae loss: 0.45603
kl loss: 0.02421
a decoder loss: 0.43182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:33
train iter: 118
num of updates: 11900
vae loss: 0.45368
kl loss: 0.02383
a decoder loss: 0.42984
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:34
train iter: 119
num of updates: 12000
vae loss: 0.45040
kl loss: 0.02332
a decoder loss: 0.42708
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:35
train iter: 120
num of updates: 12100
vae loss: 0.44291
kl loss: 0.02286
a decoder loss: 0.42005
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:36
train iter: 121
num of updates: 12200
vae loss: 0.43666
kl loss: 0.02231
a decoder loss: 0.41435
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:37
train iter: 122
num of updates: 12300
vae loss: 0.43424
kl loss: 0.02182
a decoder loss: 0.41241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:38
train iter: 123
num of updates: 12400
vae loss: 0.42735
kl loss: 0.02132
a decoder loss: 0.40603
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:39
train iter: 124
num of updates: 12500
vae loss: 0.42316
kl loss: 0.02079
a decoder loss: 0.40238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:40
train iter: 125
num of updates: 12600
vae loss: 0.41754
kl loss: 0.02036
a decoder loss: 0.39717
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:41
train iter: 126
num of updates: 12700
vae loss: 0.41352
kl loss: 0.01987
a decoder loss: 0.39365
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:42
train iter: 127
num of updates: 12800
vae loss: 0.40920
kl loss: 0.01924
a decoder loss: 0.38996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:43
train iter: 128
num of updates: 12900
vae loss: 0.40400
kl loss: 0.01879
a decoder loss: 0.38521
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:44
train iter: 129
num of updates: 13000
vae loss: 0.40309
kl loss: 0.01843
a decoder loss: 0.38465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:45
train iter: 130
num of updates: 13100
vae loss: 0.39858
kl loss: 0.01788
a decoder loss: 0.38070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:46
train iter: 131
num of updates: 13200
vae loss: 0.39377
kl loss: 0.01749
a decoder loss: 0.37628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:47
train iter: 132
num of updates: 13300
vae loss: 0.39085
kl loss: 0.01706
a decoder loss: 0.37379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:48
train iter: 133
num of updates: 13400
vae loss: 0.38819
kl loss: 0.01659
a decoder loss: 0.37160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:49
train iter: 134
num of updates: 13500
vae loss: 0.38227
kl loss: 0.01605
a decoder loss: 0.36621
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:50
train iter: 135
num of updates: 13600
vae loss: 0.38004
kl loss: 0.01565
a decoder loss: 0.36439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:51
train iter: 136
num of updates: 13700
vae loss: 0.37500
kl loss: 0.01514
a decoder loss: 0.35986
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:52
train iter: 137
num of updates: 13800
vae loss: 0.37310
kl loss: 0.01472
a decoder loss: 0.35838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:53
train iter: 138
num of updates: 13900
vae loss: 0.36988
kl loss: 0.01433
a decoder loss: 0.35555
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:54
train iter: 139
num of updates: 14000
vae loss: 0.36811
kl loss: 0.01391
a decoder loss: 0.35420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:55
train iter: 140
num of updates: 14100
vae loss: 0.36542
kl loss: 0.01343
a decoder loss: 0.35199
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:56
train iter: 141
num of updates: 14200
vae loss: 0.35902
kl loss: 0.01300
a decoder loss: 0.34602
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:57
train iter: 142
num of updates: 14300
vae loss: 0.35718
kl loss: 0.01265
a decoder loss: 0.34453
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:58
train iter: 143
num of updates: 14400
vae loss: 0.35577
kl loss: 0.01230
a decoder loss: 0.34347
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:59
train iter: 144
num of updates: 14500
vae loss: 0.35411
kl loss: 0.01195
a decoder loss: 0.34216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:00
train iter: 145
num of updates: 14600
vae loss: 0.34877
kl loss: 0.01151
a decoder loss: 0.33726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:01
train iter: 146
num of updates: 14700
vae loss: 0.34760
kl loss: 0.01118
a decoder loss: 0.33642
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:02
train iter: 147
num of updates: 14800
vae loss: 0.34439
kl loss: 0.01080
a decoder loss: 0.33360
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:03
train iter: 148
num of updates: 14900
vae loss: 0.34325
kl loss: 0.01054
a decoder loss: 0.33271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:04
train iter: 149
num of updates: 15000
vae loss: 0.33994
kl loss: 0.01018
a decoder loss: 0.32976
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:05
train iter: 150
num of updates: 15100
vae loss: 0.33821
kl loss: 0.00981
a decoder loss: 0.32840
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:06
train iter: 151
num of updates: 15200
vae loss: 0.33475
kl loss: 0.00946
a decoder loss: 0.32529
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:07
train iter: 152
num of updates: 15300
vae loss: 0.33307
kl loss: 0.00918
a decoder loss: 0.32389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:08
train iter: 153
num of updates: 15400
vae loss: 0.33161
kl loss: 0.00890
a decoder loss: 0.32271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:09
train iter: 154
num of updates: 15500
vae loss: 0.32895
kl loss: 0.00859
a decoder loss: 0.32035
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:10
train iter: 155
num of updates: 15600
vae loss: 0.32666
kl loss: 0.00835
a decoder loss: 0.31832
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:11
train iter: 156
num of updates: 15700
vae loss: 0.32399
kl loss: 0.00803
a decoder loss: 0.31596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:12
train iter: 157
num of updates: 15800
vae loss: 0.32158
kl loss: 0.00778
a decoder loss: 0.31380
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:13
train iter: 158
num of updates: 15900
vae loss: 0.31925
kl loss: 0.00755
a decoder loss: 0.31170
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:14
train iter: 159
num of updates: 16000
vae loss: 0.31848
kl loss: 0.00730
a decoder loss: 0.31119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:16
train iter: 160
num of updates: 16100
vae loss: 0.31530
kl loss: 0.00707
a decoder loss: 0.30823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:17
train iter: 161
num of updates: 16200
vae loss: 0.31314
kl loss: 0.00681
a decoder loss: 0.30633
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:18
train iter: 162
num of updates: 16300
vae loss: 0.31125
kl loss: 0.00660
a decoder loss: 0.30465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:19
train iter: 163
num of updates: 16400
vae loss: 0.31031
kl loss: 0.00638
a decoder loss: 0.30393
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:20
train iter: 164
num of updates: 16500
vae loss: 0.30974
kl loss: 0.00622
a decoder loss: 0.30352
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:21
train iter: 165
num of updates: 16600
vae loss: 0.30691
kl loss: 0.00602
a decoder loss: 0.30089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:22
train iter: 166
num of updates: 16700
vae loss: 0.30431
kl loss: 0.00585
a decoder loss: 0.29845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:23
train iter: 167
num of updates: 16800
vae loss: 0.30518
kl loss: 0.00568
a decoder loss: 0.29950
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:24
train iter: 168
num of updates: 16900
vae loss: 0.30151
kl loss: 0.00551
a decoder loss: 0.29600
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:25
train iter: 169
num of updates: 17000
vae loss: 0.30104
kl loss: 0.00536
a decoder loss: 0.29568
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:26
train iter: 170
num of updates: 17100
vae loss: 0.29864
kl loss: 0.00521
a decoder loss: 0.29344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:27
train iter: 171
num of updates: 17200
vae loss: 0.29798
kl loss: 0.00508
a decoder loss: 0.29289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:28
train iter: 172
num of updates: 17300
vae loss: 0.29586
kl loss: 0.00491
a decoder loss: 0.29095
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:29
train iter: 173
num of updates: 17400
vae loss: 0.29586
kl loss: 0.00479
a decoder loss: 0.29107
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:30
train iter: 174
num of updates: 17500
vae loss: 0.29491
kl loss: 0.00469
a decoder loss: 0.29022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:31
train iter: 175
num of updates: 17600
vae loss: 0.29175
kl loss: 0.00457
a decoder loss: 0.28719
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:32
train iter: 176
num of updates: 17700
vae loss: 0.29156
kl loss: 0.00443
a decoder loss: 0.28712
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:33
train iter: 177
num of updates: 17800
vae loss: 0.29017
kl loss: 0.00434
a decoder loss: 0.28583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:34
train iter: 178
num of updates: 17900
vae loss: 0.28919
kl loss: 0.00426
a decoder loss: 0.28493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:35
train iter: 179
num of updates: 18000
vae loss: 0.28695
kl loss: 0.00417
a decoder loss: 0.28279
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:36
train iter: 180
num of updates: 18100
vae loss: 0.28689
kl loss: 0.00407
a decoder loss: 0.28283
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:37
train iter: 181
num of updates: 18200
vae loss: 0.28536
kl loss: 0.00398
a decoder loss: 0.28137
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:38
train iter: 182
num of updates: 18300
vae loss: 0.28247
kl loss: 0.00386
a decoder loss: 0.27860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:39
train iter: 183
num of updates: 18400
vae loss: 0.28325
kl loss: 0.00383
a decoder loss: 0.27941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:40
train iter: 184
num of updates: 18500
vae loss: 0.28201
kl loss: 0.00374
a decoder loss: 0.27827
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:41
train iter: 185
num of updates: 18600
vae loss: 0.28087
kl loss: 0.00367
a decoder loss: 0.27720
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:42
train iter: 186
num of updates: 18700
vae loss: 0.28024
kl loss: 0.00361
a decoder loss: 0.27662
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:43
train iter: 187
num of updates: 18800
vae loss: 0.27760
kl loss: 0.00353
a decoder loss: 0.27407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:44
train iter: 188
num of updates: 18900
vae loss: 0.27587
kl loss: 0.00347
a decoder loss: 0.27240
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:45
train iter: 189
num of updates: 19000
vae loss: 0.27627
kl loss: 0.00341
a decoder loss: 0.27286
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:46
train iter: 190
num of updates: 19100
vae loss: 0.27627
kl loss: 0.00334
a decoder loss: 0.27293
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:47
train iter: 191
num of updates: 19200
vae loss: 0.27446
kl loss: 0.00328
a decoder loss: 0.27118
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:48
train iter: 192
num of updates: 19300
vae loss: 0.27403
kl loss: 0.00323
a decoder loss: 0.27079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:49
train iter: 193
num of updates: 19400
vae loss: 0.27143
kl loss: 0.00317
a decoder loss: 0.26826
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:50
train iter: 194
num of updates: 19500
vae loss: 0.27173
kl loss: 0.00313
a decoder loss: 0.26860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:51
train iter: 195
num of updates: 19600
vae loss: 0.27076
kl loss: 0.00308
a decoder loss: 0.26768
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:52
train iter: 196
num of updates: 19700
vae loss: 0.26907
kl loss: 0.00301
a decoder loss: 0.26606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:53
train iter: 197
num of updates: 19800
vae loss: 0.26969
kl loss: 0.00297
a decoder loss: 0.26673
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:54
train iter: 198
num of updates: 19900
vae loss: 0.26875
kl loss: 0.00291
a decoder loss: 0.26584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:55
train iter: 199
num of updates: 20000
vae loss: 0.26645
kl loss: 0.00286
a decoder loss: 0.26359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:56
train iter: 200
num of updates: 20100
vae loss: 0.26657
kl loss: 0.00282
a decoder loss: 0.26375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:57
train iter: 201
num of updates: 20200
vae loss: 0.26547
kl loss: 0.00277
a decoder loss: 0.26269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:58
train iter: 202
num of updates: 20300
vae loss: 0.26546
kl loss: 0.00273
a decoder loss: 0.26273
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:59
train iter: 203
num of updates: 20400
vae loss: 0.26354
kl loss: 0.00268
a decoder loss: 0.26086
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:00
train iter: 204
num of updates: 20500
vae loss: 0.26386
kl loss: 0.00265
a decoder loss: 0.26121
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:01
train iter: 205
num of updates: 20600
vae loss: 0.26253
kl loss: 0.00260
a decoder loss: 0.25992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:02
train iter: 206
num of updates: 20700
vae loss: 0.26318
kl loss: 0.00257
a decoder loss: 0.26061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:03
train iter: 207
num of updates: 20800
vae loss: 0.26017
kl loss: 0.00252
a decoder loss: 0.25765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:04
train iter: 208
num of updates: 20900
vae loss: 0.25936
kl loss: 0.00249
a decoder loss: 0.25687
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:05
train iter: 209
num of updates: 21000
vae loss: 0.25980
kl loss: 0.00245
a decoder loss: 0.25735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:06
train iter: 210
num of updates: 21100
vae loss: 0.25971
kl loss: 0.00241
a decoder loss: 0.25730
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:07
train iter: 211
num of updates: 21200
vae loss: 0.25889
kl loss: 0.00238
a decoder loss: 0.25651
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:09
train iter: 212
num of updates: 21300
vae loss: 0.25810
kl loss: 0.00233
a decoder loss: 0.25577
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:10
train iter: 213
num of updates: 21400
vae loss: 0.25799
kl loss: 0.00230
a decoder loss: 0.25569
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:11
train iter: 214
num of updates: 21500
vae loss: 0.25614
kl loss: 0.00226
a decoder loss: 0.25389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:12
train iter: 215
num of updates: 21600
vae loss: 0.25611
kl loss: 0.00223
a decoder loss: 0.25388
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:13
train iter: 216
num of updates: 21700
vae loss: 0.25627
kl loss: 0.00220
a decoder loss: 0.25407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:14
train iter: 217
num of updates: 21800
vae loss: 0.25588
kl loss: 0.00215
a decoder loss: 0.25372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:15
train iter: 218
num of updates: 21900
vae loss: 0.25374
kl loss: 0.00213
a decoder loss: 0.25162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:16
train iter: 219
num of updates: 22000
vae loss: 0.25370
kl loss: 0.00210
a decoder loss: 0.25160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:17
train iter: 220
num of updates: 22100
vae loss: 0.25390
kl loss: 0.00207
a decoder loss: 0.25183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:18
train iter: 221
num of updates: 22200
vae loss: 0.25293
kl loss: 0.00205
a decoder loss: 0.25088
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:19
train iter: 222
num of updates: 22300
vae loss: 0.25072
kl loss: 0.00201
a decoder loss: 0.24872
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:20
train iter: 223
num of updates: 22400
vae loss: 0.25212
kl loss: 0.00198
a decoder loss: 0.25014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:21
train iter: 224
num of updates: 22500
vae loss: 0.25201
kl loss: 0.00196
a decoder loss: 0.25005
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:22
train iter: 225
num of updates: 22600
vae loss: 0.25123
kl loss: 0.00193
a decoder loss: 0.24930
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:23
train iter: 226
num of updates: 22700
vae loss: 0.25051
kl loss: 0.00190
a decoder loss: 0.24861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:24
train iter: 227
num of updates: 22800
vae loss: 0.24963
kl loss: 0.00187
a decoder loss: 0.24776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:25
train iter: 228
num of updates: 22900
vae loss: 0.24888
kl loss: 0.00185
a decoder loss: 0.24703
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:26
train iter: 229
num of updates: 23000
vae loss: 0.24795
kl loss: 0.00182
a decoder loss: 0.24613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:27
train iter: 230
num of updates: 23100
vae loss: 0.24838
kl loss: 0.00181
a decoder loss: 0.24658
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:28
train iter: 231
num of updates: 23200
vae loss: 0.24793
kl loss: 0.00178
a decoder loss: 0.24615
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:29
train iter: 232
num of updates: 23300
vae loss: 0.24766
kl loss: 0.00175
a decoder loss: 0.24591
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:30
train iter: 233
num of updates: 23400
vae loss: 0.24655
kl loss: 0.00172
a decoder loss: 0.24482
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:31
train iter: 234
num of updates: 23500
vae loss: 0.24718
kl loss: 0.00170
a decoder loss: 0.24548
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:32
train iter: 235
num of updates: 23600
vae loss: 0.24539
kl loss: 0.00168
a decoder loss: 0.24371
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:33
train iter: 236
num of updates: 23700
vae loss: 0.24542
kl loss: 0.00165
a decoder loss: 0.24376
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:34
train iter: 237
num of updates: 23800
vae loss: 0.24532
kl loss: 0.00163
a decoder loss: 0.24368
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:35
train iter: 238
num of updates: 23900
vae loss: 0.24323
kl loss: 0.00160
a decoder loss: 0.24163
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:36
train iter: 239
num of updates: 24000
vae loss: 0.24368
kl loss: 0.00158
a decoder loss: 0.24210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:37
train iter: 240
num of updates: 24100
vae loss: 0.24378
kl loss: 0.00157
a decoder loss: 0.24221
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:38
train iter: 241
num of updates: 24200
vae loss: 0.24334
kl loss: 0.00155
a decoder loss: 0.24179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:39
train iter: 242
num of updates: 24300
vae loss: 0.24332
kl loss: 0.00153
a decoder loss: 0.24179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:40
train iter: 243
num of updates: 24400
vae loss: 0.24289
kl loss: 0.00151
a decoder loss: 0.24138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:41
train iter: 244
num of updates: 24500
vae loss: 0.24163
kl loss: 0.00149
a decoder loss: 0.24014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:42
train iter: 245
num of updates: 24600
vae loss: 0.24159
kl loss: 0.00147
a decoder loss: 0.24012
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:43
train iter: 246
num of updates: 24700
vae loss: 0.24159
kl loss: 0.00145
a decoder loss: 0.24014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:44
train iter: 247
num of updates: 24800
vae loss: 0.24167
kl loss: 0.00144
a decoder loss: 0.24023
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:45
train iter: 248
num of updates: 24900
vae loss: 0.24134
kl loss: 0.00141
a decoder loss: 0.23992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:46
train iter: 249
num of updates: 25000
vae loss: 0.24031
kl loss: 0.00140
a decoder loss: 0.23891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:47
train iter: 250
num of updates: 25100
vae loss: 0.23919
kl loss: 0.00137
a decoder loss: 0.23782
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:48
train iter: 251
num of updates: 25200
vae loss: 0.23875
kl loss: 0.00136
a decoder loss: 0.23739
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:49
train iter: 252
num of updates: 25300
vae loss: 0.24018
kl loss: 0.00135
a decoder loss: 0.23883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:50
train iter: 253
num of updates: 25400
vae loss: 0.23941
kl loss: 0.00133
a decoder loss: 0.23809
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:51
train iter: 254
num of updates: 25500
vae loss: 0.23848
kl loss: 0.00133
a decoder loss: 0.23715
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:52
train iter: 255
num of updates: 25600
vae loss: 0.23954
kl loss: 0.00129
a decoder loss: 0.23825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:53
train iter: 256
num of updates: 25700
vae loss: 0.23674
kl loss: 0.00129
a decoder loss: 0.23546
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:54
train iter: 257
num of updates: 25800
vae loss: 0.23783
kl loss: 0.00127
a decoder loss: 0.23656
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:55
train iter: 258
num of updates: 25900
vae loss: 0.23790
kl loss: 0.00125
a decoder loss: 0.23665
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:56
train iter: 259
num of updates: 26000
vae loss: 0.23683
kl loss: 0.00124
a decoder loss: 0.23560
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:57
train iter: 260
num of updates: 26100
vae loss: 0.23597
kl loss: 0.00123
a decoder loss: 0.23474
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:58
train iter: 261
num of updates: 26200
vae loss: 0.23589
kl loss: 0.00121
a decoder loss: 0.23468
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:59
train iter: 262
num of updates: 26300
vae loss: 0.23645
kl loss: 0.00120
a decoder loss: 0.23525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:00
train iter: 263
num of updates: 26400
vae loss: 0.23563
kl loss: 0.00119
a decoder loss: 0.23445
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:01
train iter: 264
num of updates: 26500
vae loss: 0.23589
kl loss: 0.00116
a decoder loss: 0.23473
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:02
train iter: 265
num of updates: 26600
vae loss: 0.23679
kl loss: 0.00115
a decoder loss: 0.23564
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:03
train iter: 266
num of updates: 26700
vae loss: 0.23523
kl loss: 0.00114
a decoder loss: 0.23408
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:04
train iter: 267
num of updates: 26800
vae loss: 0.23556
kl loss: 0.00113
a decoder loss: 0.23443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:05
train iter: 268
num of updates: 26900
vae loss: 0.23550
kl loss: 0.00112
a decoder loss: 0.23438
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:06
train iter: 269
num of updates: 27000
vae loss: 0.23521
kl loss: 0.00110
a decoder loss: 0.23410
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:07
train iter: 270
num of updates: 27100
vae loss: 0.23366
kl loss: 0.00109
a decoder loss: 0.23257
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:09
train iter: 271
num of updates: 27200
vae loss: 0.23405
kl loss: 0.00108
a decoder loss: 0.23297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:10
train iter: 272
num of updates: 27300
vae loss: 0.23402
kl loss: 0.00107
a decoder loss: 0.23296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:11
train iter: 273
num of updates: 27400
vae loss: 0.23354
kl loss: 0.00105
a decoder loss: 0.23249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:12
train iter: 274
num of updates: 27500
vae loss: 0.23309
kl loss: 0.00105
a decoder loss: 0.23204
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:13
train iter: 275
num of updates: 27600
vae loss: 0.23358
kl loss: 0.00103
a decoder loss: 0.23255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:14
train iter: 276
num of updates: 27700
vae loss: 0.23374
kl loss: 0.00102
a decoder loss: 0.23272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:15
train iter: 277
num of updates: 27800
vae loss: 0.23241
kl loss: 0.00100
a decoder loss: 0.23141
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:16
train iter: 278
num of updates: 27900
vae loss: 0.23221
kl loss: 0.00099
a decoder loss: 0.23122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:17
train iter: 279
num of updates: 28000
vae loss: 0.23219
kl loss: 0.00100
a decoder loss: 0.23119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:18
train iter: 280
num of updates: 28100
vae loss: 0.23192
kl loss: 0.00097
a decoder loss: 0.23094
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:19
train iter: 281
num of updates: 28200
vae loss: 0.23166
kl loss: 0.00096
a decoder loss: 0.23070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:20
train iter: 282
num of updates: 28300
vae loss: 0.23187
kl loss: 0.00097
a decoder loss: 0.23091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:21
train iter: 283
num of updates: 28400
vae loss: 0.23039
kl loss: 0.00094
a decoder loss: 0.22944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:22
train iter: 284
num of updates: 28500
vae loss: 0.23053
kl loss: 0.00094
a decoder loss: 0.22959
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:23
train iter: 285
num of updates: 28600
vae loss: 0.23080
kl loss: 0.00093
a decoder loss: 0.22987
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:24
train iter: 286
num of updates: 28700
vae loss: 0.23120
kl loss: 0.00092
a decoder loss: 0.23029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:25
train iter: 287
num of updates: 28800
vae loss: 0.22921
kl loss: 0.00091
a decoder loss: 0.22831
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:26
train iter: 288
num of updates: 28900
vae loss: 0.23013
kl loss: 0.00090
a decoder loss: 0.22923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:27
train iter: 289
num of updates: 29000
vae loss: 0.23088
kl loss: 0.00089
a decoder loss: 0.22998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:28
train iter: 290
num of updates: 29100
vae loss: 0.23003
kl loss: 0.00088
a decoder loss: 0.22915
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:29
train iter: 291
num of updates: 29200
vae loss: 0.22948
kl loss: 0.00088
a decoder loss: 0.22860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:30
train iter: 292
num of updates: 29300
vae loss: 0.22931
kl loss: 0.00086
a decoder loss: 0.22845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:31
train iter: 293
num of updates: 29400
vae loss: 0.22907
kl loss: 0.00086
a decoder loss: 0.22821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:32
train iter: 294
num of updates: 29500
vae loss: 0.22936
kl loss: 0.00085
a decoder loss: 0.22851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:33
train iter: 295
num of updates: 29600
vae loss: 0.22920
kl loss: 0.00084
a decoder loss: 0.22836
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:34
train iter: 296
num of updates: 29700
vae loss: 0.22864
kl loss: 0.00083
a decoder loss: 0.22782
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:35
train iter: 297
num of updates: 29800
vae loss: 0.22826
kl loss: 0.00082
a decoder loss: 0.22744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:36
train iter: 298
num of updates: 29900
vae loss: 0.22794
kl loss: 0.00081
a decoder loss: 0.22713
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:37
train iter: 299
num of updates: 30000
vae loss: 0.22701
kl loss: 0.00081
a decoder loss: 0.22620
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:38
train iter: 300
num of updates: 30100
vae loss: 0.22845
kl loss: 0.00080
a decoder loss: 0.22765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:39
train iter: 301
num of updates: 30200
vae loss: 0.22917
kl loss: 0.00079
a decoder loss: 0.22837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:40
train iter: 302
num of updates: 30300
vae loss: 0.22764
kl loss: 0.00078
a decoder loss: 0.22685
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:41
train iter: 303
num of updates: 30400
vae loss: 0.22779
kl loss: 0.00078
a decoder loss: 0.22701
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:42
train iter: 304
num of updates: 30500
vae loss: 0.22803
kl loss: 0.00077
a decoder loss: 0.22726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:43
train iter: 305
num of updates: 30600
vae loss: 0.22770
kl loss: 0.00076
a decoder loss: 0.22694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:44
train iter: 306
num of updates: 30700
vae loss: 0.22710
kl loss: 0.00075
a decoder loss: 0.22635
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:45
train iter: 307
num of updates: 30800
vae loss: 0.22651
kl loss: 0.00075
a decoder loss: 0.22576
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:46
train iter: 308
num of updates: 30900
vae loss: 0.22662
kl loss: 0.00074
a decoder loss: 0.22588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:47
train iter: 309
num of updates: 31000
vae loss: 0.22690
kl loss: 0.00073
a decoder loss: 0.22616
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:48
train iter: 310
num of updates: 31100
vae loss: 0.22704
kl loss: 0.00072
a decoder loss: 0.22631
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:49
train iter: 311
num of updates: 31200
vae loss: 0.22661
kl loss: 0.00072
a decoder loss: 0.22589
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:50
train iter: 312
num of updates: 31300
vae loss: 0.22671
kl loss: 0.00072
a decoder loss: 0.22599
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:51
train iter: 313
num of updates: 31400
vae loss: 0.22620
kl loss: 0.00071
a decoder loss: 0.22549
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:52
train iter: 314
num of updates: 31500
vae loss: 0.22594
kl loss: 0.00071
a decoder loss: 0.22524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:53
train iter: 315
num of updates: 31600
vae loss: 0.22622
kl loss: 0.00070
a decoder loss: 0.22552
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:54
train iter: 316
num of updates: 31700
vae loss: 0.22589
kl loss: 0.00069
a decoder loss: 0.22520
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:55
train iter: 317
num of updates: 31800
vae loss: 0.22634
kl loss: 0.00068
a decoder loss: 0.22566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:56
train iter: 318
num of updates: 31900
vae loss: 0.22490
kl loss: 0.00068
a decoder loss: 0.22422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:57
train iter: 319
num of updates: 32000
vae loss: 0.22576
kl loss: 0.00067
a decoder loss: 0.22509
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:58
train iter: 320
num of updates: 32100
vae loss: 0.22557
kl loss: 0.00067
a decoder loss: 0.22490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:59
train iter: 321
num of updates: 32200
vae loss: 0.22574
kl loss: 0.00067
a decoder loss: 0.22507
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:00
train iter: 322
num of updates: 32300
vae loss: 0.22519
kl loss: 0.00066
a decoder loss: 0.22454
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:01
train iter: 323
num of updates: 32400
vae loss: 0.22568
kl loss: 0.00065
a decoder loss: 0.22503
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:02
train iter: 324
num of updates: 32500
vae loss: 0.22466
kl loss: 0.00065
a decoder loss: 0.22401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:03
train iter: 325
num of updates: 32600
vae loss: 0.22467
kl loss: 0.00064
a decoder loss: 0.22403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:04
train iter: 326
num of updates: 32700
vae loss: 0.22526
kl loss: 0.00063
a decoder loss: 0.22462
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:05
train iter: 327
num of updates: 32800
vae loss: 0.22495
kl loss: 0.00063
a decoder loss: 0.22432
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:06
train iter: 328
num of updates: 32900
vae loss: 0.22464
kl loss: 0.00063
a decoder loss: 0.22401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:07
train iter: 329
num of updates: 33000
vae loss: 0.22460
kl loss: 0.00062
a decoder loss: 0.22398
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:09
train iter: 330
num of updates: 33100
vae loss: 0.22375
kl loss: 0.00062
a decoder loss: 0.22313
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:10
train iter: 331
num of updates: 33200
vae loss: 0.22430
kl loss: 0.00061
a decoder loss: 0.22369
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:11
train iter: 332
num of updates: 33300
vae loss: 0.22353
kl loss: 0.00060
a decoder loss: 0.22293
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:12
train iter: 333
num of updates: 33400
vae loss: 0.22346
kl loss: 0.00060
a decoder loss: 0.22286
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:13
train iter: 334
num of updates: 33500
vae loss: 0.22412
kl loss: 0.00059
a decoder loss: 0.22353
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:14
train iter: 335
num of updates: 33600
vae loss: 0.22276
kl loss: 0.00059
a decoder loss: 0.22217
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:15
train iter: 336
num of updates: 33700
vae loss: 0.22312
kl loss: 0.00058
a decoder loss: 0.22254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:16
train iter: 337
num of updates: 33800
vae loss: 0.22264
kl loss: 0.00058
a decoder loss: 0.22206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:17
train iter: 338
num of updates: 33900
vae loss: 0.22377
kl loss: 0.00057
a decoder loss: 0.22319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:18
train iter: 339
num of updates: 34000
vae loss: 0.22405
kl loss: 0.00057
a decoder loss: 0.22347
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:19
train iter: 340
num of updates: 34100
vae loss: 0.22300
kl loss: 0.00057
a decoder loss: 0.22244
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:20
train iter: 341
num of updates: 34200
vae loss: 0.22358
kl loss: 0.00056
a decoder loss: 0.22302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:21
train iter: 342
num of updates: 34300
vae loss: 0.22336
kl loss: 0.00056
a decoder loss: 0.22280
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:22
train iter: 343
num of updates: 34400
vae loss: 0.22318
kl loss: 0.00055
a decoder loss: 0.22263
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:23
train iter: 344
num of updates: 34500
vae loss: 0.22252
kl loss: 0.00055
a decoder loss: 0.22197
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:24
train iter: 345
num of updates: 34600
vae loss: 0.22338
kl loss: 0.00054
a decoder loss: 0.22284
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:25
train iter: 346
num of updates: 34700
vae loss: 0.22176
kl loss: 0.00054
a decoder loss: 0.22122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:26
train iter: 347
num of updates: 34800
vae loss: 0.22219
kl loss: 0.00054
a decoder loss: 0.22165
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:27
train iter: 348
num of updates: 34900
vae loss: 0.22269
kl loss: 0.00054
a decoder loss: 0.22215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:28
train iter: 349
num of updates: 35000
vae loss: 0.22219
kl loss: 0.00053
a decoder loss: 0.22166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:29
train iter: 350
num of updates: 35100
vae loss: 0.22272
kl loss: 0.00053
a decoder loss: 0.22219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:30
train iter: 351
num of updates: 35200
vae loss: 0.22153
kl loss: 0.00052
a decoder loss: 0.22101
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:31
train iter: 352
num of updates: 35300
vae loss: 0.22189
kl loss: 0.00052
a decoder loss: 0.22137
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:32
train iter: 353
num of updates: 35400
vae loss: 0.22200
kl loss: 0.00051
a decoder loss: 0.22149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:33
train iter: 354
num of updates: 35500
vae loss: 0.22234
kl loss: 0.00051
a decoder loss: 0.22183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:34
train iter: 355
num of updates: 35600
vae loss: 0.22072
kl loss: 0.00051
a decoder loss: 0.22021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:35
train iter: 356
num of updates: 35700
vae loss: 0.22202
kl loss: 0.00051
a decoder loss: 0.22152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:36
train iter: 357
num of updates: 35800
vae loss: 0.22052
kl loss: 0.00050
a decoder loss: 0.22002
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:37
train iter: 358
num of updates: 35900
vae loss: 0.22208
kl loss: 0.00050
a decoder loss: 0.22158
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:38
train iter: 359
num of updates: 36000
vae loss: 0.22179
kl loss: 0.00050
a decoder loss: 0.22130
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:39
train iter: 360
num of updates: 36100
vae loss: 0.21965
kl loss: 0.00049
a decoder loss: 0.21916
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:40
train iter: 361
num of updates: 36200
vae loss: 0.22120
kl loss: 0.00049
a decoder loss: 0.22072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:41
train iter: 362
num of updates: 36300
vae loss: 0.22137
kl loss: 0.00048
a decoder loss: 0.22089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:42
train iter: 363
num of updates: 36400
vae loss: 0.22029
kl loss: 0.00048
a decoder loss: 0.21981
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:43
train iter: 364
num of updates: 36500
vae loss: 0.22131
kl loss: 0.00047
a decoder loss: 0.22084
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:44
train iter: 365
num of updates: 36600
vae loss: 0.22116
kl loss: 0.00047
a decoder loss: 0.22069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:45
train iter: 366
num of updates: 36700
vae loss: 0.22092
kl loss: 0.00046
a decoder loss: 0.22045
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:46
train iter: 367
num of updates: 36800
vae loss: 0.22124
kl loss: 0.00047
a decoder loss: 0.22077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:47
train iter: 368
num of updates: 36900
vae loss: 0.22091
kl loss: 0.00047
a decoder loss: 0.22044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:48
train iter: 369
num of updates: 37000
vae loss: 0.22088
kl loss: 0.00046
a decoder loss: 0.22042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:49
train iter: 370
num of updates: 37100
vae loss: 0.22002
kl loss: 0.00046
a decoder loss: 0.21956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:50
train iter: 371
num of updates: 37200
vae loss: 0.22085
kl loss: 0.00045
a decoder loss: 0.22039
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:51
train iter: 372
num of updates: 37300
vae loss: 0.22106
kl loss: 0.00045
a decoder loss: 0.22061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:52
train iter: 373
num of updates: 37400
vae loss: 0.22107
kl loss: 0.00045
a decoder loss: 0.22062
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:53
train iter: 374
num of updates: 37500
vae loss: 0.21929
kl loss: 0.00045
a decoder loss: 0.21885
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:54
train iter: 375
num of updates: 37600
vae loss: 0.22051
kl loss: 0.00044
a decoder loss: 0.22007
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:55
train iter: 376
num of updates: 37700
vae loss: 0.22033
kl loss: 0.00044
a decoder loss: 0.21989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:56
train iter: 377
num of updates: 37800
vae loss: 0.21994
kl loss: 0.00043
a decoder loss: 0.21950
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:57
train iter: 378
num of updates: 37900
vae loss: 0.22009
kl loss: 0.00043
a decoder loss: 0.21965
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:58
train iter: 379
num of updates: 38000
vae loss: 0.21931
kl loss: 0.00043
a decoder loss: 0.21888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:59
train iter: 380
num of updates: 38100
vae loss: 0.22080
kl loss: 0.00043
a decoder loss: 0.22037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:00
train iter: 381
num of updates: 38200
vae loss: 0.22011
kl loss: 0.00043
a decoder loss: 0.21968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:01
train iter: 382
num of updates: 38300
vae loss: 0.21934
kl loss: 0.00042
a decoder loss: 0.21892
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:02
train iter: 383
num of updates: 38400
vae loss: 0.21893
kl loss: 0.00042
a decoder loss: 0.21851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:03
train iter: 384
num of updates: 38500
vae loss: 0.22027
kl loss: 0.00042
a decoder loss: 0.21985
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:04
train iter: 385
num of updates: 38600
vae loss: 0.21961
kl loss: 0.00041
a decoder loss: 0.21920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:06
train iter: 386
num of updates: 38700
vae loss: 0.21862
kl loss: 0.00041
a decoder loss: 0.21821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:07
train iter: 387
num of updates: 38800
vae loss: 0.21870
kl loss: 0.00041
a decoder loss: 0.21829
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:08
train iter: 388
num of updates: 38900
vae loss: 0.21932
kl loss: 0.00041
a decoder loss: 0.21891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:09
train iter: 389
num of updates: 39000
vae loss: 0.22007
kl loss: 0.00040
a decoder loss: 0.21967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:10
train iter: 390
num of updates: 39100
vae loss: 0.21870
kl loss: 0.00040
a decoder loss: 0.21830
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:11
train iter: 391
num of updates: 39200
vae loss: 0.21878
kl loss: 0.00040
a decoder loss: 0.21838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:12
train iter: 392
num of updates: 39300
vae loss: 0.21793
kl loss: 0.00040
a decoder loss: 0.21753
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:13
train iter: 393
num of updates: 39400
vae loss: 0.21886
kl loss: 0.00039
a decoder loss: 0.21847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:14
train iter: 394
num of updates: 39500
vae loss: 0.21815
kl loss: 0.00039
a decoder loss: 0.21776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:15
train iter: 395
num of updates: 39600
vae loss: 0.21867
kl loss: 0.00039
a decoder loss: 0.21828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:16
train iter: 396
num of updates: 39700
vae loss: 0.21835
kl loss: 0.00039
a decoder loss: 0.21796
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:17
train iter: 397
num of updates: 39800
vae loss: 0.21888
kl loss: 0.00039
a decoder loss: 0.21849
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:18
train iter: 398
num of updates: 39900
vae loss: 0.21761
kl loss: 0.00038
a decoder loss: 0.21723
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:19
train iter: 399
num of updates: 40000
vae loss: 0.21816
kl loss: 0.00038
a decoder loss: 0.21778
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:20
train iter: 400
num of updates: 40100
vae loss: 0.21852
kl loss: 0.00038
a decoder loss: 0.21814
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:21
train iter: 401
num of updates: 40200
vae loss: 0.21856
kl loss: 0.00037
a decoder loss: 0.21818
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:22
train iter: 402
num of updates: 40300
vae loss: 0.21809
kl loss: 0.00037
a decoder loss: 0.21772
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:23
train iter: 403
num of updates: 40400
vae loss: 0.21800
kl loss: 0.00037
a decoder loss: 0.21763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:24
train iter: 404
num of updates: 40500
vae loss: 0.21771
kl loss: 0.00037
a decoder loss: 0.21734
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:25
train iter: 405
num of updates: 40600
vae loss: 0.21829
kl loss: 0.00037
a decoder loss: 0.21792
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:26
train iter: 406
num of updates: 40700
vae loss: 0.21833
kl loss: 0.00037
a decoder loss: 0.21796
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:27
train iter: 407
num of updates: 40800
vae loss: 0.21857
kl loss: 0.00036
a decoder loss: 0.21820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:28
train iter: 408
num of updates: 40900
vae loss: 0.21773
kl loss: 0.00036
a decoder loss: 0.21737
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:29
train iter: 409
num of updates: 41000
vae loss: 0.21781
kl loss: 0.00036
a decoder loss: 0.21745
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:30
train iter: 410
num of updates: 41100
vae loss: 0.21763
kl loss: 0.00036
a decoder loss: 0.21728
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:31
train iter: 411
num of updates: 41200
vae loss: 0.21863
kl loss: 0.00036
a decoder loss: 0.21828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:32
train iter: 412
num of updates: 41300
vae loss: 0.21791
kl loss: 0.00035
a decoder loss: 0.21756
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:33
train iter: 413
num of updates: 41400
vae loss: 0.21622
kl loss: 0.00035
a decoder loss: 0.21587
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:34
train iter: 414
num of updates: 41500
vae loss: 0.21740
kl loss: 0.00035
a decoder loss: 0.21705
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:35
train iter: 415
num of updates: 41600
vae loss: 0.21823
kl loss: 0.00035
a decoder loss: 0.21788
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:36
train iter: 416
num of updates: 41700
vae loss: 0.21741
kl loss: 0.00034
a decoder loss: 0.21707
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:37
train iter: 417
num of updates: 41800
vae loss: 0.21707
kl loss: 0.00034
a decoder loss: 0.21673
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:38
train iter: 418
num of updates: 41900
vae loss: 0.21769
kl loss: 0.00034
a decoder loss: 0.21735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:39
train iter: 419
num of updates: 42000
vae loss: 0.21763
kl loss: 0.00034
a decoder loss: 0.21729
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:40
train iter: 420
num of updates: 42100
vae loss: 0.21750
kl loss: 0.00034
a decoder loss: 0.21716
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:41
train iter: 421
num of updates: 42200
vae loss: 0.21884
kl loss: 0.00034
a decoder loss: 0.21851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:42
train iter: 422
num of updates: 42300
vae loss: 0.21782
kl loss: 0.00033
a decoder loss: 0.21749
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:43
train iter: 423
num of updates: 42400
vae loss: 0.21635
kl loss: 0.00033
a decoder loss: 0.21602
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:44
train iter: 424
num of updates: 42500
vae loss: 0.21744
kl loss: 0.00033
a decoder loss: 0.21711
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:45
train iter: 425
num of updates: 42600
vae loss: 0.21754
kl loss: 0.00033
a decoder loss: 0.21721
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:46
train iter: 426
num of updates: 42700
vae loss: 0.21661
kl loss: 0.00033
a decoder loss: 0.21628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:47
train iter: 427
num of updates: 42800
vae loss: 0.21705
kl loss: 0.00032
a decoder loss: 0.21672
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:48
train iter: 428
num of updates: 42900
vae loss: 0.21767
kl loss: 0.00032
a decoder loss: 0.21735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:49
train iter: 429
num of updates: 43000
vae loss: 0.21713
kl loss: 0.00032
a decoder loss: 0.21681
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:50
train iter: 430
num of updates: 43100
vae loss: 0.21599
kl loss: 0.00032
a decoder loss: 0.21566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:51
train iter: 431
num of updates: 43200
vae loss: 0.21639
kl loss: 0.00032
a decoder loss: 0.21607
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:52
train iter: 432
num of updates: 43300
vae loss: 0.21658
kl loss: 0.00032
a decoder loss: 0.21626
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:53
train iter: 433
num of updates: 43400
vae loss: 0.21649
kl loss: 0.00032
a decoder loss: 0.21617
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:54
train iter: 434
num of updates: 43500
vae loss: 0.21694
kl loss: 0.00031
a decoder loss: 0.21663
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:56
train iter: 435
num of updates: 43600
vae loss: 0.21621
kl loss: 0.00031
a decoder loss: 0.21590
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:57
train iter: 436
num of updates: 43700
vae loss: 0.21675
kl loss: 0.00031
a decoder loss: 0.21644
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:58
train iter: 437
num of updates: 43800
vae loss: 0.21705
kl loss: 0.00031
a decoder loss: 0.21674
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:59
train iter: 438
num of updates: 43900
vae loss: 0.21728
kl loss: 0.00031
a decoder loss: 0.21697
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:00
train iter: 439
num of updates: 44000
vae loss: 0.21644
kl loss: 0.00031
a decoder loss: 0.21613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:01
train iter: 440
num of updates: 44100
vae loss: 0.21681
kl loss: 0.00031
a decoder loss: 0.21650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:02
train iter: 441
num of updates: 44200
vae loss: 0.21688
kl loss: 0.00030
a decoder loss: 0.21658
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:03
train iter: 442
num of updates: 44300
vae loss: 0.21579
kl loss: 0.00030
a decoder loss: 0.21549
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:04
train iter: 443
num of updates: 44400
vae loss: 0.21710
kl loss: 0.00030
a decoder loss: 0.21679
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:05
train iter: 444
num of updates: 44500
vae loss: 0.21601
kl loss: 0.00030
a decoder loss: 0.21571
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:06
train iter: 445
num of updates: 44600
vae loss: 0.21680
kl loss: 0.00030
a decoder loss: 0.21650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:07
train iter: 446
num of updates: 44700
vae loss: 0.21607
kl loss: 0.00030
a decoder loss: 0.21577
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:08
train iter: 447
num of updates: 44800
vae loss: 0.21717
kl loss: 0.00029
a decoder loss: 0.21688
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:09
train iter: 448
num of updates: 44900
vae loss: 0.21643
kl loss: 0.00029
a decoder loss: 0.21613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:10
train iter: 449
num of updates: 45000
vae loss: 0.21715
kl loss: 0.00029
a decoder loss: 0.21686
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:11
train iter: 450
num of updates: 45100
vae loss: 0.21619
kl loss: 0.00029
a decoder loss: 0.21590
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:12
train iter: 451
num of updates: 45200
vae loss: 0.21613
kl loss: 0.00029
a decoder loss: 0.21584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:13
train iter: 452
num of updates: 45300
vae loss: 0.21575
kl loss: 0.00029
a decoder loss: 0.21546
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:14
train iter: 453
num of updates: 45400
vae loss: 0.21581
kl loss: 0.00028
a decoder loss: 0.21553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:15
train iter: 454
num of updates: 45500
vae loss: 0.21578
kl loss: 0.00028
a decoder loss: 0.21550
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:16
train iter: 455
num of updates: 45600
vae loss: 0.21581
kl loss: 0.00028
a decoder loss: 0.21553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:17
train iter: 456
num of updates: 45700
vae loss: 0.21616
kl loss: 0.00028
a decoder loss: 0.21588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:18
train iter: 457
num of updates: 45800
vae loss: 0.21529
kl loss: 0.00028
a decoder loss: 0.21501
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:19
train iter: 458
num of updates: 45900
vae loss: 0.21650
kl loss: 0.00028
a decoder loss: 0.21622
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:20
train iter: 459
num of updates: 46000
vae loss: 0.21536
kl loss: 0.00028
a decoder loss: 0.21508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:21
train iter: 460
num of updates: 46100
vae loss: 0.21559
kl loss: 0.00028
a decoder loss: 0.21532
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:22
train iter: 461
num of updates: 46200
vae loss: 0.21538
kl loss: 0.00027
a decoder loss: 0.21510
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:23
train iter: 462
num of updates: 46300
vae loss: 0.21673
kl loss: 0.00027
a decoder loss: 0.21645
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:24
train iter: 463
num of updates: 46400
vae loss: 0.21479
kl loss: 0.00027
a decoder loss: 0.21452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:25
train iter: 464
num of updates: 46500
vae loss: 0.21623
kl loss: 0.00027
a decoder loss: 0.21596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:26
train iter: 465
num of updates: 46600
vae loss: 0.21540
kl loss: 0.00027
a decoder loss: 0.21513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:27
train iter: 466
num of updates: 46700
vae loss: 0.21554
kl loss: 0.00027
a decoder loss: 0.21527
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:28
train iter: 467
num of updates: 46800
vae loss: 0.21496
kl loss: 0.00027
a decoder loss: 0.21469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:29
train iter: 468
num of updates: 46900
vae loss: 0.21470
kl loss: 0.00027
a decoder loss: 0.21443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:30
train iter: 469
num of updates: 47000
vae loss: 0.21470
kl loss: 0.00027
a decoder loss: 0.21444
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:31
train iter: 470
num of updates: 47100
vae loss: 0.21551
kl loss: 0.00027
a decoder loss: 0.21524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:32
train iter: 471
num of updates: 47200
vae loss: 0.21590
kl loss: 0.00026
a decoder loss: 0.21563
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:33
train iter: 472
num of updates: 47300
vae loss: 0.21490
kl loss: 0.00026
a decoder loss: 0.21464
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:34
train iter: 473
num of updates: 47400
vae loss: 0.21581
kl loss: 0.00026
a decoder loss: 0.21555
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:35
train iter: 474
num of updates: 47500
vae loss: 0.21587
kl loss: 0.00026
a decoder loss: 0.21561
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:36
train iter: 475
num of updates: 47600
vae loss: 0.21540
kl loss: 0.00026
a decoder loss: 0.21514
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:37
train iter: 476
num of updates: 47700
vae loss: 0.21421
kl loss: 0.00026
a decoder loss: 0.21396
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:38
train iter: 477
num of updates: 47800
vae loss: 0.21466
kl loss: 0.00026
a decoder loss: 0.21440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:39
train iter: 478
num of updates: 47900
vae loss: 0.21544
kl loss: 0.00026
a decoder loss: 0.21518
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:40
train iter: 479
num of updates: 48000
vae loss: 0.21534
kl loss: 0.00026
a decoder loss: 0.21509
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:41
train iter: 480
num of updates: 48100
vae loss: 0.21485
kl loss: 0.00025
a decoder loss: 0.21460
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:42
train iter: 481
num of updates: 48200
vae loss: 0.21422
kl loss: 0.00025
a decoder loss: 0.21397
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:43
train iter: 482
num of updates: 48300
vae loss: 0.21538
kl loss: 0.00025
a decoder loss: 0.21513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:44
train iter: 483
num of updates: 48400
vae loss: 0.21507
kl loss: 0.00025
a decoder loss: 0.21482
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:45
train iter: 484
num of updates: 48500
vae loss: 0.21563
kl loss: 0.00025
a decoder loss: 0.21538
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:46
train iter: 485
num of updates: 48600
vae loss: 0.21352
kl loss: 0.00025
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:47
train iter: 486
num of updates: 48700
vae loss: 0.21529
kl loss: 0.00025
a decoder loss: 0.21504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:48
train iter: 487
num of updates: 48800
vae loss: 0.21497
kl loss: 0.00025
a decoder loss: 0.21472
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:49
train iter: 488
num of updates: 48900
vae loss: 0.21463
kl loss: 0.00024
a decoder loss: 0.21439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:50
train iter: 489
num of updates: 49000
vae loss: 0.21523
kl loss: 0.00024
a decoder loss: 0.21499
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:51
train iter: 490
num of updates: 49100
vae loss: 0.21437
kl loss: 0.00024
a decoder loss: 0.21413
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:52
train iter: 491
num of updates: 49200
vae loss: 0.21473
kl loss: 0.00024
a decoder loss: 0.21449
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:53
train iter: 492
num of updates: 49300
vae loss: 0.21399
kl loss: 0.00024
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:54
train iter: 493
num of updates: 49400
vae loss: 0.21427
kl loss: 0.00024
a decoder loss: 0.21403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:55
train iter: 494
num of updates: 49500
vae loss: 0.21450
kl loss: 0.00024
a decoder loss: 0.21426
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:56
train iter: 495
num of updates: 49600
vae loss: 0.21495
kl loss: 0.00024
a decoder loss: 0.21471
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:58
train iter: 496
num of updates: 49700
vae loss: 0.21445
kl loss: 0.00024
a decoder loss: 0.21422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:59
train iter: 497
num of updates: 49800
vae loss: 0.21442
kl loss: 0.00024
a decoder loss: 0.21418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:00
train iter: 498
num of updates: 49900
vae loss: 0.21521
kl loss: 0.00023
a decoder loss: 0.21497
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:01
train iter: 499
num of updates: 50000
vae loss: 0.21475
kl loss: 0.00023
a decoder loss: 0.21452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:02
train iter: 500
num of updates: 50100
vae loss: 0.21527
kl loss: 0.00023
a decoder loss: 0.21504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:03
train iter: 501
num of updates: 50200
vae loss: 0.21417
kl loss: 0.00023
a decoder loss: 0.21394
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:04
train iter: 502
num of updates: 50300
vae loss: 0.21399
kl loss: 0.00023
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:05
train iter: 503
num of updates: 50400
vae loss: 0.21382
kl loss: 0.00023
a decoder loss: 0.21359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:06
train iter: 504
num of updates: 50500
vae loss: 0.21359
kl loss: 0.00023
a decoder loss: 0.21336
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:07
train iter: 505
num of updates: 50600
vae loss: 0.21448
kl loss: 0.00023
a decoder loss: 0.21426
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:08
train iter: 506
num of updates: 50700
vae loss: 0.21294
kl loss: 0.00023
a decoder loss: 0.21271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:09
train iter: 507
num of updates: 50800
vae loss: 0.21398
kl loss: 0.00023
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:10
train iter: 508
num of updates: 50900
vae loss: 0.21469
kl loss: 0.00022
a decoder loss: 0.21446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:11
train iter: 509
num of updates: 51000
vae loss: 0.21426
kl loss: 0.00022
a decoder loss: 0.21403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:12
train iter: 510
num of updates: 51100
vae loss: 0.21442
kl loss: 0.00022
a decoder loss: 0.21420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:13
train iter: 511
num of updates: 51200
vae loss: 0.21354
kl loss: 0.00022
a decoder loss: 0.21332
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:14
train iter: 512
num of updates: 51300
vae loss: 0.21374
kl loss: 0.00022
a decoder loss: 0.21351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:15
train iter: 513
num of updates: 51400
vae loss: 0.21336
kl loss: 0.00022
a decoder loss: 0.21314
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:16
train iter: 514
num of updates: 51500
vae loss: 0.21428
kl loss: 0.00022
a decoder loss: 0.21406
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:17
train iter: 515
num of updates: 51600
vae loss: 0.21463
kl loss: 0.00022
a decoder loss: 0.21441
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:18
train iter: 516
num of updates: 51700
vae loss: 0.21417
kl loss: 0.00022
a decoder loss: 0.21395
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:19
train iter: 517
num of updates: 51800
vae loss: 0.21323
kl loss: 0.00022
a decoder loss: 0.21302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:20
train iter: 518
num of updates: 51900
vae loss: 0.21413
kl loss: 0.00022
a decoder loss: 0.21392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:21
train iter: 519
num of updates: 52000
vae loss: 0.21363
kl loss: 0.00022
a decoder loss: 0.21341
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:22
train iter: 520
num of updates: 52100
vae loss: 0.21370
kl loss: 0.00022
a decoder loss: 0.21349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:23
train iter: 521
num of updates: 52200
vae loss: 0.21396
kl loss: 0.00022
a decoder loss: 0.21374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:24
train iter: 522
num of updates: 52300
vae loss: 0.21359
kl loss: 0.00021
a decoder loss: 0.21338
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:25
train iter: 523
num of updates: 52400
vae loss: 0.21413
kl loss: 0.00022
a decoder loss: 0.21391
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:26
train iter: 524
num of updates: 52500
vae loss: 0.21365
kl loss: 0.00021
a decoder loss: 0.21344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:27
train iter: 525
num of updates: 52600
vae loss: 0.21332
kl loss: 0.00021
a decoder loss: 0.21310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:28
train iter: 526
num of updates: 52700
vae loss: 0.21364
kl loss: 0.00021
a decoder loss: 0.21343
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:29
train iter: 527
num of updates: 52800
vae loss: 0.21447
kl loss: 0.00021
a decoder loss: 0.21427
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:30
train iter: 528
num of updates: 52900
vae loss: 0.21363
kl loss: 0.00021
a decoder loss: 0.21342
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:31
train iter: 529
num of updates: 53000
vae loss: 0.21328
kl loss: 0.00021
a decoder loss: 0.21307
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:32
train iter: 530
num of updates: 53100
vae loss: 0.21317
kl loss: 0.00021
a decoder loss: 0.21296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:33
train iter: 531
num of updates: 53200
vae loss: 0.21251
kl loss: 0.00021
a decoder loss: 0.21231
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:34
train iter: 532
num of updates: 53300
vae loss: 0.21338
kl loss: 0.00021
a decoder loss: 0.21317
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:35
train iter: 533
num of updates: 53400
vae loss: 0.21355
kl loss: 0.00021
a decoder loss: 0.21335
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:36
train iter: 534
num of updates: 53500
vae loss: 0.21405
kl loss: 0.00021
a decoder loss: 0.21384
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:37
train iter: 535
num of updates: 53600
vae loss: 0.21345
kl loss: 0.00020
a decoder loss: 0.21325
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:38
train iter: 536
num of updates: 53700
vae loss: 0.21311
kl loss: 0.00021
a decoder loss: 0.21291
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:39
train iter: 537
num of updates: 53800
vae loss: 0.21359
kl loss: 0.00020
a decoder loss: 0.21339
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:40
train iter: 538
num of updates: 53900
vae loss: 0.21341
kl loss: 0.00020
a decoder loss: 0.21321
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:41
train iter: 539
num of updates: 54000
vae loss: 0.21360
kl loss: 0.00020
a decoder loss: 0.21340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:42
train iter: 540
num of updates: 54100
vae loss: 0.21399
kl loss: 0.00020
a decoder loss: 0.21379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:43
train iter: 541
num of updates: 54200
vae loss: 0.21409
kl loss: 0.00020
a decoder loss: 0.21389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:44
train iter: 542
num of updates: 54300
vae loss: 0.21281
kl loss: 0.00020
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:45
train iter: 543
num of updates: 54400
vae loss: 0.21329
kl loss: 0.00020
a decoder loss: 0.21309
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:46
train iter: 544
num of updates: 54500
vae loss: 0.21371
kl loss: 0.00020
a decoder loss: 0.21351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:47
train iter: 545
num of updates: 54600
vae loss: 0.21308
kl loss: 0.00020
a decoder loss: 0.21289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:48
train iter: 546
num of updates: 54700
vae loss: 0.21417
kl loss: 0.00020
a decoder loss: 0.21397
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:49
train iter: 547
num of updates: 54800
vae loss: 0.21346
kl loss: 0.00020
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:50
train iter: 548
num of updates: 54900
vae loss: 0.21247
kl loss: 0.00019
a decoder loss: 0.21227
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:51
train iter: 549
num of updates: 55000
vae loss: 0.21392
kl loss: 0.00020
a decoder loss: 0.21373
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:52
train iter: 550
num of updates: 55100
vae loss: 0.21326
kl loss: 0.00020
a decoder loss: 0.21306
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:53
train iter: 551
num of updates: 55200
vae loss: 0.21298
kl loss: 0.00019
a decoder loss: 0.21279
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:54
train iter: 552
num of updates: 55300
vae loss: 0.21239
kl loss: 0.00019
a decoder loss: 0.21220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:55
train iter: 553
num of updates: 55400
vae loss: 0.21386
kl loss: 0.00019
a decoder loss: 0.21367
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:56
train iter: 554
num of updates: 55500
vae loss: 0.21273
kl loss: 0.00019
a decoder loss: 0.21254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:57
train iter: 555
num of updates: 55600
vae loss: 0.21381
kl loss: 0.00019
a decoder loss: 0.21362
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:58
train iter: 556
num of updates: 55700
vae loss: 0.21264
kl loss: 0.00019
a decoder loss: 0.21245
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:59
train iter: 557
num of updates: 55800
vae loss: 0.21314
kl loss: 0.00019
a decoder loss: 0.21295
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:00
train iter: 558
num of updates: 55900
vae loss: 0.21251
kl loss: 0.00019
a decoder loss: 0.21232
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:01
train iter: 559
num of updates: 56000
vae loss: 0.21327
kl loss: 0.00019
a decoder loss: 0.21309
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:02
train iter: 560
num of updates: 56100
vae loss: 0.21188
kl loss: 0.00019
a decoder loss: 0.21169
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:03
train iter: 561
num of updates: 56200
vae loss: 0.21339
kl loss: 0.00019
a decoder loss: 0.21320
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:05
train iter: 562
num of updates: 56300
vae loss: 0.21252
kl loss: 0.00019
a decoder loss: 0.21233
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:06
train iter: 563
num of updates: 56400
vae loss: 0.21273
kl loss: 0.00019
a decoder loss: 0.21254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:07
train iter: 564
num of updates: 56500
vae loss: 0.21287
kl loss: 0.00019
a decoder loss: 0.21269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:08
train iter: 565
num of updates: 56600
vae loss: 0.21220
kl loss: 0.00019
a decoder loss: 0.21202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:09
train iter: 566
num of updates: 56700
vae loss: 0.21236
kl loss: 0.00018
a decoder loss: 0.21218
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:10
train iter: 567
num of updates: 56800
vae loss: 0.21230
kl loss: 0.00018
a decoder loss: 0.21211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:11
train iter: 568
num of updates: 56900
vae loss: 0.21309
kl loss: 0.00018
a decoder loss: 0.21290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:12
train iter: 569
num of updates: 57000
vae loss: 0.21367
kl loss: 0.00018
a decoder loss: 0.21349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:13
train iter: 570
num of updates: 57100
vae loss: 0.21273
kl loss: 0.00018
a decoder loss: 0.21255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:14
train iter: 571
num of updates: 57200
vae loss: 0.21346
kl loss: 0.00018
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:15
train iter: 572
num of updates: 57300
vae loss: 0.21232
kl loss: 0.00018
a decoder loss: 0.21214
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:16
train iter: 573
num of updates: 57400
vae loss: 0.21253
kl loss: 0.00018
a decoder loss: 0.21235
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:17
train iter: 574
num of updates: 57500
vae loss: 0.21303
kl loss: 0.00018
a decoder loss: 0.21285
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:18
train iter: 575
num of updates: 57600
vae loss: 0.21315
kl loss: 0.00018
a decoder loss: 0.21297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:19
train iter: 576
num of updates: 57700
vae loss: 0.21299
kl loss: 0.00018
a decoder loss: 0.21281
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:20
train iter: 577
num of updates: 57800
vae loss: 0.21226
kl loss: 0.00018
a decoder loss: 0.21208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:21
train iter: 578
num of updates: 57900
vae loss: 0.21224
kl loss: 0.00018
a decoder loss: 0.21206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:22
train iter: 579
num of updates: 58000
vae loss: 0.21220
kl loss: 0.00018
a decoder loss: 0.21202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:23
train iter: 580
num of updates: 58100
vae loss: 0.21323
kl loss: 0.00018
a decoder loss: 0.21305
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:24
train iter: 581
num of updates: 58200
vae loss: 0.21256
kl loss: 0.00018
a decoder loss: 0.21238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:25
train iter: 582
num of updates: 58300
vae loss: 0.21202
kl loss: 0.00018
a decoder loss: 0.21185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:26
train iter: 583
num of updates: 58400
vae loss: 0.21234
kl loss: 0.00018
a decoder loss: 0.21216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:27
train iter: 584
num of updates: 58500
vae loss: 0.21263
kl loss: 0.00017
a decoder loss: 0.21246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:28
train iter: 585
num of updates: 58600
vae loss: 0.21264
kl loss: 0.00017
a decoder loss: 0.21246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:29
train iter: 586
num of updates: 58700
vae loss: 0.21195
kl loss: 0.00017
a decoder loss: 0.21178
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:30
train iter: 587
num of updates: 58800
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:31
train iter: 588
num of updates: 58900
vae loss: 0.21146
kl loss: 0.00017
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:32
train iter: 589
num of updates: 59000
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:33
train iter: 590
num of updates: 59100
vae loss: 0.21179
kl loss: 0.00017
a decoder loss: 0.21162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:34
train iter: 591
num of updates: 59200
vae loss: 0.21184
kl loss: 0.00017
a decoder loss: 0.21167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:35
train iter: 592
num of updates: 59300
vae loss: 0.21233
kl loss: 0.00017
a decoder loss: 0.21215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:36
train iter: 593
num of updates: 59400
vae loss: 0.21183
kl loss: 0.00017
a decoder loss: 0.21166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:37
train iter: 594
num of updates: 59500
vae loss: 0.21186
kl loss: 0.00017
a decoder loss: 0.21169
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:38
train iter: 595
num of updates: 59600
vae loss: 0.21227
kl loss: 0.00017
a decoder loss: 0.21210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:39
train iter: 596
num of updates: 59700
vae loss: 0.21265
kl loss: 0.00017
a decoder loss: 0.21248
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:40
train iter: 597
num of updates: 59800
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21262
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:41
train iter: 598
num of updates: 59900
vae loss: 0.21212
kl loss: 0.00017
a decoder loss: 0.21195
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:42
train iter: 599
num of updates: 60000
vae loss: 0.21266
kl loss: 0.00017
a decoder loss: 0.21249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:43
train iter: 600
num of updates: 60100
vae loss: 0.21215
kl loss: 0.00017
a decoder loss: 0.21198
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:44
train iter: 601
num of updates: 60200
vae loss: 0.21191
kl loss: 0.00017
a decoder loss: 0.21174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:45
train iter: 602
num of updates: 60300
vae loss: 0.21222
kl loss: 0.00017
a decoder loss: 0.21205
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:46
train iter: 603
num of updates: 60400
vae loss: 0.21125
kl loss: 0.00016
a decoder loss: 0.21109
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:47
train iter: 604
num of updates: 60500
vae loss: 0.21234
kl loss: 0.00017
a decoder loss: 0.21217
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:48
train iter: 605
num of updates: 60600
vae loss: 0.21135
kl loss: 0.00016
a decoder loss: 0.21119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:49
train iter: 606
num of updates: 60700
vae loss: 0.21258
kl loss: 0.00016
a decoder loss: 0.21242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:50
train iter: 607
num of updates: 60800
vae loss: 0.21230
kl loss: 0.00016
a decoder loss: 0.21213
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:51
train iter: 608
num of updates: 60900
vae loss: 0.21141
kl loss: 0.00016
a decoder loss: 0.21125
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:52
train iter: 609
num of updates: 61000
vae loss: 0.21163
kl loss: 0.00016
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:53
train iter: 610
num of updates: 61100
vae loss: 0.21205
kl loss: 0.00016
a decoder loss: 0.21189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:54
train iter: 611
num of updates: 61200
vae loss: 0.21294
kl loss: 0.00016
a decoder loss: 0.21278
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:55
train iter: 612
num of updates: 61300
vae loss: 0.21187
kl loss: 0.00016
a decoder loss: 0.21171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:56
train iter: 613
num of updates: 61400
vae loss: 0.21241
kl loss: 0.00016
a decoder loss: 0.21225
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:57
train iter: 614
num of updates: 61500
vae loss: 0.21210
kl loss: 0.00016
a decoder loss: 0.21194
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:58
train iter: 615
num of updates: 61600
vae loss: 0.21232
kl loss: 0.00016
a decoder loss: 0.21216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:59
train iter: 616
num of updates: 61700
vae loss: 0.21177
kl loss: 0.00016
a decoder loss: 0.21161
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:00
train iter: 617
num of updates: 61800
vae loss: 0.21127
kl loss: 0.00016
a decoder loss: 0.21111
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:01
train iter: 618
num of updates: 61900
vae loss: 0.21257
kl loss: 0.00016
a decoder loss: 0.21241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:02
train iter: 619
num of updates: 62000
vae loss: 0.21163
kl loss: 0.00016
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:03
train iter: 620
num of updates: 62100
vae loss: 0.21083
kl loss: 0.00016
a decoder loss: 0.21067
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:04
train iter: 621
num of updates: 62200
vae loss: 0.21235
kl loss: 0.00016
a decoder loss: 0.21219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:05
train iter: 622
num of updates: 62300
vae loss: 0.21112
kl loss: 0.00016
a decoder loss: 0.21096
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:06
train iter: 623
num of updates: 62400
vae loss: 0.21165
kl loss: 0.00016
a decoder loss: 0.21149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:07
train iter: 624
num of updates: 62500
vae loss: 0.21158
kl loss: 0.00016
a decoder loss: 0.21142
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:08
train iter: 625
num of updates: 62600
vae loss: 0.21168
kl loss: 0.00015
a decoder loss: 0.21152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:10
train iter: 626
num of updates: 62700
vae loss: 0.21218
kl loss: 0.00015
a decoder loss: 0.21203
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:11
train iter: 627
num of updates: 62800
vae loss: 0.21200
kl loss: 0.00016
a decoder loss: 0.21185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:12
train iter: 628
num of updates: 62900
vae loss: 0.21101
kl loss: 0.00015
a decoder loss: 0.21086
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:13
train iter: 629
num of updates: 63000
vae loss: 0.21094
kl loss: 0.00015
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:14
train iter: 630
num of updates: 63100
vae loss: 0.21168
kl loss: 0.00015
a decoder loss: 0.21152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:15
train iter: 631
num of updates: 63200
vae loss: 0.21093
kl loss: 0.00015
a decoder loss: 0.21077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:16
train iter: 632
num of updates: 63300
vae loss: 0.21148
kl loss: 0.00015
a decoder loss: 0.21133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:17
train iter: 633
num of updates: 63400
vae loss: 0.21190
kl loss: 0.00015
a decoder loss: 0.21175
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:18
train iter: 634
num of updates: 63500
vae loss: 0.21113
kl loss: 0.00015
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:19
train iter: 635
num of updates: 63600
vae loss: 0.21112
kl loss: 0.00015
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:20
train iter: 636
num of updates: 63700
vae loss: 0.21186
kl loss: 0.00015
a decoder loss: 0.21171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:21
train iter: 637
num of updates: 63800
vae loss: 0.21193
kl loss: 0.00015
a decoder loss: 0.21178
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:22
train iter: 638
num of updates: 63900
vae loss: 0.21197
kl loss: 0.00015
a decoder loss: 0.21182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:23
train iter: 639
num of updates: 64000
vae loss: 0.21219
kl loss: 0.00015
a decoder loss: 0.21204
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:24
train iter: 640
num of updates: 64100
vae loss: 0.21158
kl loss: 0.00015
a decoder loss: 0.21143
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:25
train iter: 641
num of updates: 64200
vae loss: 0.21081
kl loss: 0.00015
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:26
train iter: 642
num of updates: 64300
vae loss: 0.21129
kl loss: 0.00015
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:27
train iter: 643
num of updates: 64400
vae loss: 0.21155
kl loss: 0.00015
a decoder loss: 0.21140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:28
train iter: 644
num of updates: 64500
vae loss: 0.21107
kl loss: 0.00015
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:29
train iter: 645
num of updates: 64600
vae loss: 0.21170
kl loss: 0.00015
a decoder loss: 0.21155
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:30
train iter: 646
num of updates: 64700
vae loss: 0.21222
kl loss: 0.00015
a decoder loss: 0.21208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:31
train iter: 647
num of updates: 64800
vae loss: 0.21188
kl loss: 0.00015
a decoder loss: 0.21173
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:32
train iter: 648
num of updates: 64900
vae loss: 0.21106
kl loss: 0.00015
a decoder loss: 0.21091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:33
train iter: 649
num of updates: 65000
vae loss: 0.21068
kl loss: 0.00015
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:34
train iter: 650
num of updates: 65100
vae loss: 0.21119
kl loss: 0.00015
a decoder loss: 0.21104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:35
train iter: 651
num of updates: 65200
vae loss: 0.21204
kl loss: 0.00014
a decoder loss: 0.21190
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:36
train iter: 652
num of updates: 65300
vae loss: 0.21083
kl loss: 0.00015
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:37
train iter: 653
num of updates: 65400
vae loss: 0.21115
kl loss: 0.00014
a decoder loss: 0.21100
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:38
train iter: 654
num of updates: 65500
vae loss: 0.21096
kl loss: 0.00014
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:39
train iter: 655
num of updates: 65600
vae loss: 0.21101
kl loss: 0.00014
a decoder loss: 0.21087
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:40
train iter: 656
num of updates: 65700
vae loss: 0.21175
kl loss: 0.00014
a decoder loss: 0.21160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:41
train iter: 657
num of updates: 65800
vae loss: 0.21148
kl loss: 0.00014
a decoder loss: 0.21133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:42
train iter: 658
num of updates: 65900
vae loss: 0.21132
kl loss: 0.00014
a decoder loss: 0.21118
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:43
train iter: 659
num of updates: 66000
vae loss: 0.21095
kl loss: 0.00014
a decoder loss: 0.21081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:44
train iter: 660
num of updates: 66100
vae loss: 0.21143
kl loss: 0.00014
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:45
train iter: 661
num of updates: 66200
vae loss: 0.21153
kl loss: 0.00014
a decoder loss: 0.21139
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:46
train iter: 662
num of updates: 66300
vae loss: 0.21035
kl loss: 0.00014
a decoder loss: 0.21020
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:47
train iter: 663
num of updates: 66400
vae loss: 0.21052
kl loss: 0.00014
a decoder loss: 0.21038
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:48
train iter: 664
num of updates: 66500
vae loss: 0.21138
kl loss: 0.00014
a decoder loss: 0.21124
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:49
train iter: 665
num of updates: 66600
vae loss: 0.21176
kl loss: 0.00014
a decoder loss: 0.21162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:50
train iter: 666
num of updates: 66700
vae loss: 0.21130
kl loss: 0.00014
a decoder loss: 0.21116
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:51
train iter: 667
num of updates: 66800
vae loss: 0.21082
kl loss: 0.00014
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:52
train iter: 668
num of updates: 66900
vae loss: 0.21108
kl loss: 0.00014
a decoder loss: 0.21094
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:53
train iter: 669
num of updates: 67000
vae loss: 0.21075
kl loss: 0.00014
a decoder loss: 0.21061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:54
train iter: 670
num of updates: 67100
vae loss: 0.21112
kl loss: 0.00014
a decoder loss: 0.21098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:55
train iter: 671
num of updates: 67200
vae loss: 0.21111
kl loss: 0.00014
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:56
train iter: 672
num of updates: 67300
vae loss: 0.21143
kl loss: 0.00014
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:57
train iter: 673
num of updates: 67400
vae loss: 0.21098
kl loss: 0.00014
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:58
train iter: 674
num of updates: 67500
vae loss: 0.21054
kl loss: 0.00014
a decoder loss: 0.21040
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:59
train iter: 675
num of updates: 67600
vae loss: 0.21078
kl loss: 0.00014
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:00
train iter: 676
num of updates: 67700
vae loss: 0.21092
kl loss: 0.00014
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:01
train iter: 677
num of updates: 67800
vae loss: 0.21079
kl loss: 0.00014
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:02
train iter: 678
num of updates: 67900
vae loss: 0.21106
kl loss: 0.00014
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:03
train iter: 679
num of updates: 68000
vae loss: 0.21159
kl loss: 0.00014
a decoder loss: 0.21146
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:04
train iter: 680
num of updates: 68100
vae loss: 0.21065
kl loss: 0.00014
a decoder loss: 0.21052
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:05
train iter: 681
num of updates: 68200
vae loss: 0.21130
kl loss: 0.00013
a decoder loss: 0.21117
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:06
train iter: 682
num of updates: 68300
vae loss: 0.21127
kl loss: 0.00013
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:07
train iter: 683
num of updates: 68400
vae loss: 0.21106
kl loss: 0.00013
a decoder loss: 0.21093
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:08
train iter: 684
num of updates: 68500
vae loss: 0.21030
kl loss: 0.00013
a decoder loss: 0.21016
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:09
train iter: 685
num of updates: 68600
vae loss: 0.21115
kl loss: 0.00013
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:10
train iter: 686
num of updates: 68700
vae loss: 0.21158
kl loss: 0.00014
a decoder loss: 0.21145
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:11
train iter: 687
num of updates: 68800
vae loss: 0.21117
kl loss: 0.00013
a decoder loss: 0.21104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:12
train iter: 688
num of updates: 68900
vae loss: 0.21099
kl loss: 0.00013
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:13
train iter: 689
num of updates: 69000
vae loss: 0.21095
kl loss: 0.00013
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:15
train iter: 690
num of updates: 69100
vae loss: 0.21045
kl loss: 0.00013
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:16
train iter: 691
num of updates: 69200
vae loss: 0.21084
kl loss: 0.00013
a decoder loss: 0.21071
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:17
train iter: 692
num of updates: 69300
vae loss: 0.21068
kl loss: 0.00013
a decoder loss: 0.21055
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:18
train iter: 693
num of updates: 69400
vae loss: 0.21071
kl loss: 0.00013
a decoder loss: 0.21058
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:19
train iter: 694
num of updates: 69500
vae loss: 0.21062
kl loss: 0.00013
a decoder loss: 0.21049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:20
train iter: 695
num of updates: 69600
vae loss: 0.21039
kl loss: 0.00013
a decoder loss: 0.21026
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:21
train iter: 696
num of updates: 69700
vae loss: 0.21214
kl loss: 0.00013
a decoder loss: 0.21201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:22
train iter: 697
num of updates: 69800
vae loss: 0.21067
kl loss: 0.00013
a decoder loss: 0.21054
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:23
train iter: 698
num of updates: 69900
vae loss: 0.21087
kl loss: 0.00013
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:24
train iter: 699
num of updates: 70000
vae loss: 0.21102
kl loss: 0.00013
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:25
train iter: 700
num of updates: 70100
vae loss: 0.20980
kl loss: 0.00013
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:26
train iter: 701
num of updates: 70200
vae loss: 0.21077
kl loss: 0.00013
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:27
train iter: 702
num of updates: 70300
vae loss: 0.21125
kl loss: 0.00013
a decoder loss: 0.21112
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:28
train iter: 703
num of updates: 70400
vae loss: 0.21115
kl loss: 0.00013
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:29
train iter: 704
num of updates: 70500
vae loss: 0.21127
kl loss: 0.00013
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:30
train iter: 705
num of updates: 70600
vae loss: 0.21091
kl loss: 0.00013
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:31
train iter: 706
num of updates: 70700
vae loss: 0.21007
kl loss: 0.00013
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:32
train iter: 707
num of updates: 70800
vae loss: 0.21055
kl loss: 0.00013
a decoder loss: 0.21043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:33
train iter: 708
num of updates: 70900
vae loss: 0.20956
kl loss: 0.00013
a decoder loss: 0.20943
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:34
train iter: 709
num of updates: 71000
vae loss: 0.20981
kl loss: 0.00013
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:35
train iter: 710
num of updates: 71100
vae loss: 0.21028
kl loss: 0.00013
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:36
train iter: 711
num of updates: 71200
vae loss: 0.21043
kl loss: 0.00013
a decoder loss: 0.21031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:37
train iter: 712
num of updates: 71300
vae loss: 0.21094
kl loss: 0.00013
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:38
train iter: 713
num of updates: 71400
vae loss: 0.21017
kl loss: 0.00013
a decoder loss: 0.21004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:39
train iter: 714
num of updates: 71500
vae loss: 0.20995
kl loss: 0.00013
a decoder loss: 0.20983
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:40
train iter: 715
num of updates: 71600
vae loss: 0.21031
kl loss: 0.00013
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:41
train iter: 716
num of updates: 71700
vae loss: 0.21033
kl loss: 0.00012
a decoder loss: 0.21021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:42
train iter: 717
num of updates: 71800
vae loss: 0.21015
kl loss: 0.00012
a decoder loss: 0.21003
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:43
train iter: 718
num of updates: 71900
vae loss: 0.21132
kl loss: 0.00012
a decoder loss: 0.21120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:44
train iter: 719
num of updates: 72000
vae loss: 0.21081
kl loss: 0.00012
a decoder loss: 0.21069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:45
train iter: 720
num of updates: 72100
vae loss: 0.21084
kl loss: 0.00012
a decoder loss: 0.21072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:46
train iter: 721
num of updates: 72200
vae loss: 0.21108
kl loss: 0.00012
a decoder loss: 0.21095
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:47
train iter: 722
num of updates: 72300
vae loss: 0.21042
kl loss: 0.00012
a decoder loss: 0.21029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:48
train iter: 723
num of updates: 72400
vae loss: 0.21049
kl loss: 0.00012
a decoder loss: 0.21037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:49
train iter: 724
num of updates: 72500
vae loss: 0.21054
kl loss: 0.00012
a decoder loss: 0.21042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:50
train iter: 725
num of updates: 72600
vae loss: 0.21086
kl loss: 0.00012
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:51
train iter: 726
num of updates: 72700
vae loss: 0.20980
kl loss: 0.00012
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:52
train iter: 727
num of updates: 72800
vae loss: 0.21061
kl loss: 0.00012
a decoder loss: 0.21049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:53
train iter: 728
num of updates: 72900
vae loss: 0.21056
kl loss: 0.00012
a decoder loss: 0.21044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:54
train iter: 729
num of updates: 73000
vae loss: 0.21101
kl loss: 0.00012
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:55
train iter: 730
num of updates: 73100
vae loss: 0.21091
kl loss: 0.00012
a decoder loss: 0.21079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:56
train iter: 731
num of updates: 73200
vae loss: 0.21016
kl loss: 0.00012
a decoder loss: 0.21004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:57
train iter: 732
num of updates: 73300
vae loss: 0.21141
kl loss: 0.00012
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:58
train iter: 733
num of updates: 73400
vae loss: 0.21048
kl loss: 0.00012
a decoder loss: 0.21036
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:59
train iter: 734
num of updates: 73500
vae loss: 0.21034
kl loss: 0.00012
a decoder loss: 0.21022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:00
train iter: 735
num of updates: 73600
vae loss: 0.21081
kl loss: 0.00012
a decoder loss: 0.21069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:01
train iter: 736
num of updates: 73700
vae loss: 0.21008
kl loss: 0.00012
a decoder loss: 0.20996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:02
train iter: 737
num of updates: 73800
vae loss: 0.21000
kl loss: 0.00012
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:03
train iter: 738
num of updates: 73900
vae loss: 0.20994
kl loss: 0.00012
a decoder loss: 0.20982
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:04
train iter: 739
num of updates: 74000
vae loss: 0.20998
kl loss: 0.00012
a decoder loss: 0.20986
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:05
train iter: 740
num of updates: 74100
vae loss: 0.20991
kl loss: 0.00012
a decoder loss: 0.20979
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:06
train iter: 741
num of updates: 74200
vae loss: 0.21031
kl loss: 0.00012
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:07
train iter: 742
num of updates: 74300
vae loss: 0.21074
kl loss: 0.00012
a decoder loss: 0.21062
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:08
train iter: 743
num of updates: 74400
vae loss: 0.21053
kl loss: 0.00012
a decoder loss: 0.21042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:09
train iter: 744
num of updates: 74500
vae loss: 0.21072
kl loss: 0.00012
a decoder loss: 0.21061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:10
train iter: 745
num of updates: 74600
vae loss: 0.21027
kl loss: 0.00012
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:11
train iter: 746
num of updates: 74700
vae loss: 0.21031
kl loss: 0.00012
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:12
train iter: 747
num of updates: 74800
vae loss: 0.20951
kl loss: 0.00012
a decoder loss: 0.20939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:13
train iter: 748
num of updates: 74900
vae loss: 0.20950
kl loss: 0.00012
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:14
train iter: 749
num of updates: 75000
vae loss: 0.20960
kl loss: 0.00012
a decoder loss: 0.20948
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:15
train iter: 750
num of updates: 75100
vae loss: 0.21092
kl loss: 0.00012
a decoder loss: 0.21080
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:16
train iter: 751
num of updates: 75200
vae loss: 0.21105
kl loss: 0.00012
a decoder loss: 0.21093
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:17
train iter: 752
num of updates: 75300
vae loss: 0.20931
kl loss: 0.00012
a decoder loss: 0.20920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:18
train iter: 753
num of updates: 75400
vae loss: 0.20972
kl loss: 0.00012
a decoder loss: 0.20961
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:20
train iter: 754
num of updates: 75500
vae loss: 0.20902
kl loss: 0.00012
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:21
train iter: 755
num of updates: 75600
vae loss: 0.20978
kl loss: 0.00011
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:22
train iter: 756
num of updates: 75700
vae loss: 0.21092
kl loss: 0.00011
a decoder loss: 0.21081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:23
train iter: 757
num of updates: 75800
vae loss: 0.21094
kl loss: 0.00011
a decoder loss: 0.21083
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:24
train iter: 758
num of updates: 75900
vae loss: 0.20981
kl loss: 0.00011
a decoder loss: 0.20970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:25
train iter: 759
num of updates: 76000
vae loss: 0.20988
kl loss: 0.00011
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:26
train iter: 760
num of updates: 76100
vae loss: 0.21111
kl loss: 0.00011
a decoder loss: 0.21100
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:27
train iter: 761
num of updates: 76200
vae loss: 0.21008
kl loss: 0.00011
a decoder loss: 0.20997
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:28
train iter: 762
num of updates: 76300
vae loss: 0.21046
kl loss: 0.00011
a decoder loss: 0.21035
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:29
train iter: 763
num of updates: 76400
vae loss: 0.20895
kl loss: 0.00011
a decoder loss: 0.20884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:30
train iter: 764
num of updates: 76500
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:31
train iter: 765
num of updates: 76600
vae loss: 0.20950
kl loss: 0.00011
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:32
train iter: 766
num of updates: 76700
vae loss: 0.20948
kl loss: 0.00011
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:33
train iter: 767
num of updates: 76800
vae loss: 0.21075
kl loss: 0.00011
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:34
train iter: 768
num of updates: 76900
vae loss: 0.21003
kl loss: 0.00011
a decoder loss: 0.20992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:35
train iter: 769
num of updates: 77000
vae loss: 0.21058
kl loss: 0.00011
a decoder loss: 0.21047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:36
train iter: 770
num of updates: 77100
vae loss: 0.20977
kl loss: 0.00011
a decoder loss: 0.20966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:37
train iter: 771
num of updates: 77200
vae loss: 0.21000
kl loss: 0.00011
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:38
train iter: 772
num of updates: 77300
vae loss: 0.21075
kl loss: 0.00011
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:39
train iter: 773
num of updates: 77400
vae loss: 0.21009
kl loss: 0.00011
a decoder loss: 0.20998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:40
train iter: 774
num of updates: 77500
vae loss: 0.20921
kl loss: 0.00011
a decoder loss: 0.20910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:41
train iter: 775
num of updates: 77600
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:42
train iter: 776
num of updates: 77700
vae loss: 0.20935
kl loss: 0.00011
a decoder loss: 0.20924
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:43
train iter: 777
num of updates: 77800
vae loss: 0.20977
kl loss: 0.00011
a decoder loss: 0.20966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:44
train iter: 778
num of updates: 77900
vae loss: 0.21005
kl loss: 0.00011
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:45
train iter: 779
num of updates: 78000
vae loss: 0.20916
kl loss: 0.00011
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:46
train iter: 780
num of updates: 78100
vae loss: 0.20949
kl loss: 0.00011
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:47
train iter: 781
num of updates: 78200
vae loss: 0.21064
kl loss: 0.00011
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:48
train iter: 782
num of updates: 78300
vae loss: 0.20962
kl loss: 0.00011
a decoder loss: 0.20951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:49
train iter: 783
num of updates: 78400
vae loss: 0.20933
kl loss: 0.00011
a decoder loss: 0.20922
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:50
train iter: 784
num of updates: 78500
vae loss: 0.20984
kl loss: 0.00011
a decoder loss: 0.20973
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:51
train iter: 785
num of updates: 78600
vae loss: 0.20957
kl loss: 0.00011
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:52
train iter: 786
num of updates: 78700
vae loss: 0.20948
kl loss: 0.00011
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:53
train iter: 787
num of updates: 78800
vae loss: 0.20982
kl loss: 0.00011
a decoder loss: 0.20972
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:54
train iter: 788
num of updates: 78900
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:55
train iter: 789
num of updates: 79000
vae loss: 0.20973
kl loss: 0.00011
a decoder loss: 0.20962
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:56
train iter: 790
num of updates: 79100
vae loss: 0.20991
kl loss: 0.00011
a decoder loss: 0.20980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:57
train iter: 791
num of updates: 79200
vae loss: 0.20955
kl loss: 0.00011
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:58
train iter: 792
num of updates: 79300
vae loss: 0.21007
kl loss: 0.00011
a decoder loss: 0.20996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:59
train iter: 793
num of updates: 79400
vae loss: 0.20995
kl loss: 0.00011
a decoder loss: 0.20984
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:00
train iter: 794
num of updates: 79500
vae loss: 0.21054
kl loss: 0.00010
a decoder loss: 0.21043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:01
train iter: 795
num of updates: 79600
vae loss: 0.20963
kl loss: 0.00011
a decoder loss: 0.20952
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:02
train iter: 796
num of updates: 79700
vae loss: 0.20908
kl loss: 0.00011
a decoder loss: 0.20898
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:03
train iter: 797
num of updates: 79800
vae loss: 0.21043
kl loss: 0.00011
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:04
train iter: 798
num of updates: 79900
vae loss: 0.20945
kl loss: 0.00011
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:05
train iter: 799
num of updates: 80000
vae loss: 0.20913
kl loss: 0.00010
a decoder loss: 0.20902
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:06
train iter: 800
num of updates: 80100
vae loss: 0.21027
kl loss: 0.00010
a decoder loss: 0.21016
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:07
train iter: 801
num of updates: 80200
vae loss: 0.20951
kl loss: 0.00010
a decoder loss: 0.20941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:08
train iter: 802
num of updates: 80300
vae loss: 0.21019
kl loss: 0.00010
a decoder loss: 0.21009
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:09
train iter: 803
num of updates: 80400
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20913
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:10
train iter: 804
num of updates: 80500
vae loss: 0.20966
kl loss: 0.00010
a decoder loss: 0.20955
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:11
train iter: 805
num of updates: 80600
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:12
train iter: 806
num of updates: 80700
vae loss: 0.21001
kl loss: 0.00010
a decoder loss: 0.20991
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:13
train iter: 807
num of updates: 80800
vae loss: 0.20943
kl loss: 0.00010
a decoder loss: 0.20933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:14
train iter: 808
num of updates: 80900
vae loss: 0.20937
kl loss: 0.00010
a decoder loss: 0.20927
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:15
train iter: 809
num of updates: 81000
vae loss: 0.20982
kl loss: 0.00010
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:16
train iter: 810
num of updates: 81100
vae loss: 0.21004
kl loss: 0.00010
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:17
train iter: 811
num of updates: 81200
vae loss: 0.20981
kl loss: 0.00010
a decoder loss: 0.20970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:18
train iter: 812
num of updates: 81300
vae loss: 0.21003
kl loss: 0.00010
a decoder loss: 0.20993
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:19
train iter: 813
num of updates: 81400
vae loss: 0.20938
kl loss: 0.00010
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:20
train iter: 814
num of updates: 81500
vae loss: 0.20991
kl loss: 0.00010
a decoder loss: 0.20980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:21
train iter: 815
num of updates: 81600
vae loss: 0.21002
kl loss: 0.00010
a decoder loss: 0.20992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:22
train iter: 816
num of updates: 81700
vae loss: 0.21010
kl loss: 0.00010
a decoder loss: 0.20999
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:23
train iter: 817
num of updates: 81800
vae loss: 0.21035
kl loss: 0.00010
a decoder loss: 0.21025
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:24
train iter: 818
num of updates: 81900
vae loss: 0.20965
kl loss: 0.00010
a decoder loss: 0.20954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:26
train iter: 819
num of updates: 82000
vae loss: 0.20964
kl loss: 0.00010
a decoder loss: 0.20954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:27
train iter: 820
num of updates: 82100
vae loss: 0.20981
kl loss: 0.00010
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:28
train iter: 821
num of updates: 82200
vae loss: 0.20835
kl loss: 0.00010
a decoder loss: 0.20825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:29
train iter: 822
num of updates: 82300
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:30
train iter: 823
num of updates: 82400
vae loss: 0.20956
kl loss: 0.00010
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:31
train iter: 824
num of updates: 82500
vae loss: 0.20918
kl loss: 0.00010
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:32
train iter: 825
num of updates: 82600
vae loss: 0.20938
kl loss: 0.00010
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:33
train iter: 826
num of updates: 82700
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:34
train iter: 827
num of updates: 82800
vae loss: 0.20903
kl loss: 0.00010
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:35
train iter: 828
num of updates: 82900
vae loss: 0.20922
kl loss: 0.00010
a decoder loss: 0.20912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:36
train iter: 829
num of updates: 83000
vae loss: 0.20944
kl loss: 0.00010
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:37
train iter: 830
num of updates: 83100
vae loss: 0.20919
kl loss: 0.00010
a decoder loss: 0.20909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:38
train iter: 831
num of updates: 83200
vae loss: 0.20970
kl loss: 0.00010
a decoder loss: 0.20960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:39
train iter: 832
num of updates: 83300
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:40
train iter: 833
num of updates: 83400
vae loss: 0.20943
kl loss: 0.00010
a decoder loss: 0.20933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:41
train iter: 834
num of updates: 83500
vae loss: 0.20901
kl loss: 0.00010
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:42
train iter: 835
num of updates: 83600
vae loss: 0.20999
kl loss: 0.00010
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:43
train iter: 836
num of updates: 83700
vae loss: 0.20896
kl loss: 0.00010
a decoder loss: 0.20887
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:44
train iter: 837
num of updates: 83800
vae loss: 0.20978
kl loss: 0.00010
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:45
train iter: 838
num of updates: 83900
vae loss: 0.20830
kl loss: 0.00010
a decoder loss: 0.20820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:46
train iter: 839
num of updates: 84000
vae loss: 0.20950
kl loss: 0.00010
a decoder loss: 0.20940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:47
train iter: 840
num of updates: 84100
vae loss: 0.20966
kl loss: 0.00010
a decoder loss: 0.20956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:48
train iter: 841
num of updates: 84200
vae loss: 0.20944
kl loss: 0.00010
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:49
train iter: 842
num of updates: 84300
vae loss: 0.20905
kl loss: 0.00010
a decoder loss: 0.20896
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:50
train iter: 843
num of updates: 84400
vae loss: 0.20863
kl loss: 0.00010
a decoder loss: 0.20854
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:51
train iter: 844
num of updates: 84500
vae loss: 0.20985
kl loss: 0.00010
a decoder loss: 0.20975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:52
train iter: 845
num of updates: 84600
vae loss: 0.20899
kl loss: 0.00010
a decoder loss: 0.20889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:53
train iter: 846
num of updates: 84700
vae loss: 0.20955
kl loss: 0.00010
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:54
train iter: 847
num of updates: 84800
vae loss: 0.20887
kl loss: 0.00010
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:55
train iter: 848
num of updates: 84900
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:56
train iter: 849
num of updates: 85000
vae loss: 0.20913
kl loss: 0.00010
a decoder loss: 0.20903
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:57
train iter: 850
num of updates: 85100
vae loss: 0.20895
kl loss: 0.00010
a decoder loss: 0.20885
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:58
train iter: 851
num of updates: 85200
vae loss: 0.20954
kl loss: 0.00010
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:59
train iter: 852
num of updates: 85300
vae loss: 0.20893
kl loss: 0.00009
a decoder loss: 0.20884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:00
train iter: 853
num of updates: 85400
vae loss: 0.20977
kl loss: 0.00009
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:01
train iter: 854
num of updates: 85500
vae loss: 0.20922
kl loss: 0.00010
a decoder loss: 0.20912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:02
train iter: 855
num of updates: 85600
vae loss: 0.20941
kl loss: 0.00009
a decoder loss: 0.20932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:03
train iter: 856
num of updates: 85700
vae loss: 0.20985
kl loss: 0.00009
a decoder loss: 0.20975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:04
train iter: 857
num of updates: 85800
vae loss: 0.20927
kl loss: 0.00010
a decoder loss: 0.20918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:05
train iter: 858
num of updates: 85900
vae loss: 0.20949
kl loss: 0.00009
a decoder loss: 0.20940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:06
train iter: 859
num of updates: 86000
vae loss: 0.20945
kl loss: 0.00009
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:07
train iter: 860
num of updates: 86100
vae loss: 0.20916
kl loss: 0.00009
a decoder loss: 0.20907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:08
train iter: 861
num of updates: 86200
vae loss: 0.20930
kl loss: 0.00009
a decoder loss: 0.20921
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:09
train iter: 862
num of updates: 86300
vae loss: 0.20884
kl loss: 0.00009
a decoder loss: 0.20875
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:10
train iter: 863
num of updates: 86400
vae loss: 0.20997
kl loss: 0.00009
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:11
train iter: 864
num of updates: 86500
vae loss: 0.20866
kl loss: 0.00009
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:12
train iter: 865
num of updates: 86600
vae loss: 0.20986
kl loss: 0.00009
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:13
train iter: 866
num of updates: 86700
vae loss: 0.20932
kl loss: 0.00009
a decoder loss: 0.20923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:14
train iter: 867
num of updates: 86800
vae loss: 0.20918
kl loss: 0.00009
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:15
train iter: 868
num of updates: 86900
vae loss: 0.20920
kl loss: 0.00009
a decoder loss: 0.20911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:16
train iter: 869
num of updates: 87000
vae loss: 0.20906
kl loss: 0.00009
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:17
train iter: 870
num of updates: 87100
vae loss: 0.20899
kl loss: 0.00009
a decoder loss: 0.20889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:18
train iter: 871
num of updates: 87200
vae loss: 0.20940
kl loss: 0.00009
a decoder loss: 0.20931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:19
train iter: 872
num of updates: 87300
vae loss: 0.20832
kl loss: 0.00009
a decoder loss: 0.20823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:20
train iter: 873
num of updates: 87400
vae loss: 0.20897
kl loss: 0.00009
a decoder loss: 0.20888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:21
train iter: 874
num of updates: 87500
vae loss: 0.20915
kl loss: 0.00009
a decoder loss: 0.20906
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:22
train iter: 875
num of updates: 87600
vae loss: 0.20901
kl loss: 0.00009
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:23
train iter: 876
num of updates: 87700
vae loss: 0.20841
kl loss: 0.00009
a decoder loss: 0.20832
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:24
train iter: 877
num of updates: 87800
vae loss: 0.20997
kl loss: 0.00009
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:25
train iter: 878
num of updates: 87900
vae loss: 0.20915
kl loss: 0.00009
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:26
train iter: 879
num of updates: 88000
vae loss: 0.20873
kl loss: 0.00009
a decoder loss: 0.20864
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:27
train iter: 880
num of updates: 88100
vae loss: 0.20854
kl loss: 0.00009
a decoder loss: 0.20845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:28
train iter: 881
num of updates: 88200
vae loss: 0.20941
kl loss: 0.00009
a decoder loss: 0.20932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:29
train iter: 882
num of updates: 88300
vae loss: 0.20918
kl loss: 0.00009
a decoder loss: 0.20909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:30
train iter: 883
num of updates: 88400
vae loss: 0.20998
kl loss: 0.00009
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:31
train iter: 884
num of updates: 88500
vae loss: 0.20870
kl loss: 0.00009
a decoder loss: 0.20861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:33
train iter: 885
num of updates: 88600
vae loss: 0.20926
kl loss: 0.00009
a decoder loss: 0.20917
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:34
train iter: 886
num of updates: 88700
vae loss: 0.20919
kl loss: 0.00009
a decoder loss: 0.20910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:35
train iter: 887
num of updates: 88800
vae loss: 0.20914
kl loss: 0.00009
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:36
train iter: 888
num of updates: 88900
vae loss: 0.20845
kl loss: 0.00009
a decoder loss: 0.20837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:37
train iter: 889
num of updates: 89000
vae loss: 0.20860
kl loss: 0.00009
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:38
train iter: 890
num of updates: 89100
vae loss: 0.20825
kl loss: 0.00009
a decoder loss: 0.20816
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:39
train iter: 891
num of updates: 89200
vae loss: 0.20943
kl loss: 0.00009
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:40
train iter: 892
num of updates: 89300
vae loss: 0.20837
kl loss: 0.00009
a decoder loss: 0.20828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:41
train iter: 893
num of updates: 89400
vae loss: 0.20868
kl loss: 0.00009
a decoder loss: 0.20859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:42
train iter: 894
num of updates: 89500
vae loss: 0.20857
kl loss: 0.00009
a decoder loss: 0.20848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:43
train iter: 895
num of updates: 89600
vae loss: 0.20926
kl loss: 0.00009
a decoder loss: 0.20917
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:44
train iter: 896
num of updates: 89700
vae loss: 0.20811
kl loss: 0.00009
a decoder loss: 0.20802
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:45
train iter: 897
num of updates: 89800
vae loss: 0.20976
kl loss: 0.00009
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:46
train iter: 898
num of updates: 89900
vae loss: 0.20909
kl loss: 0.00009
a decoder loss: 0.20900
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:47
train iter: 899
num of updates: 90000
vae loss: 0.20920
kl loss: 0.00009
a decoder loss: 0.20911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:48
train iter: 900
num of updates: 90100
vae loss: 0.20822
kl loss: 0.00009
a decoder loss: 0.20813
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:49
train iter: 901
num of updates: 90200
vae loss: 0.20907
kl loss: 0.00009
a decoder loss: 0.20898
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:50
train iter: 902
num of updates: 90300
vae loss: 0.20869
kl loss: 0.00009
a decoder loss: 0.20860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:51
train iter: 903
num of updates: 90400
vae loss: 0.20878
kl loss: 0.00009
a decoder loss: 0.20869
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:52
train iter: 904
num of updates: 90500
vae loss: 0.20928
kl loss: 0.00009
a decoder loss: 0.20919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:53
train iter: 905
num of updates: 90600
vae loss: 0.20752
kl loss: 0.00009
a decoder loss: 0.20744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:54
train iter: 906
num of updates: 90700
vae loss: 0.20951
kl loss: 0.00009
a decoder loss: 0.20942
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:55
train iter: 907
num of updates: 90800
vae loss: 0.20860
kl loss: 0.00009
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:56
train iter: 908
num of updates: 90900
vae loss: 0.20832
kl loss: 0.00009
a decoder loss: 0.20823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:57
train iter: 909
num of updates: 91000
vae loss: 0.20829
kl loss: 0.00009
a decoder loss: 0.20820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:58
train iter: 910
num of updates: 91100
vae loss: 0.20929
kl loss: 0.00009
a decoder loss: 0.20920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:59
train iter: 911
num of updates: 91200
vae loss: 0.20862
kl loss: 0.00009
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:00
train iter: 912
num of updates: 91300
vae loss: 0.20977
kl loss: 0.00009
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:01
train iter: 913
num of updates: 91400
vae loss: 0.20837
kl loss: 0.00009
a decoder loss: 0.20828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:02
train iter: 914
num of updates: 91500
vae loss: 0.20899
kl loss: 0.00009
a decoder loss: 0.20890
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:03
train iter: 915
num of updates: 91600
vae loss: 0.20865
kl loss: 0.00009
a decoder loss: 0.20856
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:04
train iter: 916
num of updates: 91700
vae loss: 0.20855
kl loss: 0.00009
a decoder loss: 0.20847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:05
train iter: 917
num of updates: 91800
vae loss: 0.20901
kl loss: 0.00008
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:06
train iter: 918
num of updates: 91900
vae loss: 0.20945
kl loss: 0.00009
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:07
train iter: 919
num of updates: 92000
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:08
train iter: 920
num of updates: 92100
vae loss: 0.20861
kl loss: 0.00009
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:09
train iter: 921
num of updates: 92200
vae loss: 0.20876
kl loss: 0.00009
a decoder loss: 0.20868
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:10
train iter: 922
num of updates: 92300
vae loss: 0.20884
kl loss: 0.00008
a decoder loss: 0.20876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:11
train iter: 923
num of updates: 92400
vae loss: 0.20880
kl loss: 0.00009
a decoder loss: 0.20871
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:12
train iter: 924
num of updates: 92500
vae loss: 0.20834
kl loss: 0.00008
a decoder loss: 0.20825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:13
train iter: 925
num of updates: 92600
vae loss: 0.20916
kl loss: 0.00008
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:14
train iter: 926
num of updates: 92700
vae loss: 0.20915
kl loss: 0.00008
a decoder loss: 0.20907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:15
train iter: 927
num of updates: 92800
vae loss: 0.20846
kl loss: 0.00008
a decoder loss: 0.20838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:16
train iter: 928
num of updates: 92900
vae loss: 0.20846
kl loss: 0.00008
a decoder loss: 0.20838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:17
train iter: 929
num of updates: 93000
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20852
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:18
train iter: 930
num of updates: 93100
vae loss: 0.20863
kl loss: 0.00008
a decoder loss: 0.20854
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:19
train iter: 931
num of updates: 93200
vae loss: 0.20875
kl loss: 0.00008
a decoder loss: 0.20867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:20
train iter: 932
num of updates: 93300
vae loss: 0.20823
kl loss: 0.00008
a decoder loss: 0.20815
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:21
train iter: 933
num of updates: 93400
vae loss: 0.20927
kl loss: 0.00008
a decoder loss: 0.20918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:22
train iter: 934
num of updates: 93500
vae loss: 0.20827
kl loss: 0.00008
a decoder loss: 0.20819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:23
train iter: 935
num of updates: 93600
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:24
train iter: 936
num of updates: 93700
vae loss: 0.20898
kl loss: 0.00008
a decoder loss: 0.20890
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:25
train iter: 937
num of updates: 93800
vae loss: 0.20792
kl loss: 0.00008
a decoder loss: 0.20784
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:26
train iter: 938
num of updates: 93900
vae loss: 0.20976
kl loss: 0.00008
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:27
train iter: 939
num of updates: 94000
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20843
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:28
train iter: 940
num of updates: 94100
vae loss: 0.20882
kl loss: 0.00008
a decoder loss: 0.20874
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:29
train iter: 941
num of updates: 94200
vae loss: 0.20794
kl loss: 0.00008
a decoder loss: 0.20786
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:30
train iter: 942
num of updates: 94300
vae loss: 0.20865
kl loss: 0.00008
a decoder loss: 0.20856
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:31
train iter: 943
num of updates: 94400
vae loss: 0.20875
kl loss: 0.00008
a decoder loss: 0.20867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:32
train iter: 944
num of updates: 94500
vae loss: 0.20954
kl loss: 0.00008
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:33
train iter: 945
num of updates: 94600
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20842
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:34
train iter: 946
num of updates: 94700
vae loss: 0.20895
kl loss: 0.00008
a decoder loss: 0.20887
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:35
train iter: 947
num of updates: 94800
vae loss: 0.20814
kl loss: 0.00008
a decoder loss: 0.20806
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:36
train iter: 948
num of updates: 94900
vae loss: 0.20847
kl loss: 0.00008
a decoder loss: 0.20839
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:37
train iter: 949
num of updates: 95000
vae loss: 0.20835
kl loss: 0.00008
a decoder loss: 0.20827
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:39
train iter: 950
num of updates: 95100
vae loss: 0.20777
kl loss: 0.00008
a decoder loss: 0.20769
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:40
train iter: 951
num of updates: 95200
vae loss: 0.20923
kl loss: 0.00008
a decoder loss: 0.20915
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:41
train iter: 952
num of updates: 95300
vae loss: 0.20862
kl loss: 0.00008
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:42
train iter: 953
num of updates: 95400
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:43
train iter: 954
num of updates: 95500
vae loss: 0.20906
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:44
train iter: 955
num of updates: 95600
vae loss: 0.20812
kl loss: 0.00008
a decoder loss: 0.20804
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:45
train iter: 956
num of updates: 95700
vae loss: 0.20952
kl loss: 0.00008
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:46
train iter: 957
num of updates: 95800
vae loss: 0.20867
kl loss: 0.00008
a decoder loss: 0.20859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:47
train iter: 958
num of updates: 95900
vae loss: 0.20746
kl loss: 0.00008
a decoder loss: 0.20738
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:48
train iter: 959
num of updates: 96000
vae loss: 0.20838
kl loss: 0.00008
a decoder loss: 0.20830
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:49
train iter: 960
num of updates: 96100
vae loss: 0.20865
kl loss: 0.00008
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:50
train iter: 961
num of updates: 96200
vae loss: 0.20829
kl loss: 0.00008
a decoder loss: 0.20821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:51
train iter: 962
num of updates: 96300
vae loss: 0.20857
kl loss: 0.00008
a decoder loss: 0.20849
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:52
train iter: 963
num of updates: 96400
vae loss: 0.20852
kl loss: 0.00008
a decoder loss: 0.20844
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:53
train iter: 964
num of updates: 96500
vae loss: 0.20825
kl loss: 0.00008
a decoder loss: 0.20817
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:54
train iter: 965
num of updates: 96600
vae loss: 0.20905
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:55
train iter: 966
num of updates: 96700
vae loss: 0.20820
kl loss: 0.00008
a decoder loss: 0.20812
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:56
train iter: 967
num of updates: 96800
vae loss: 0.20889
kl loss: 0.00008
a decoder loss: 0.20881
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:57
train iter: 968
num of updates: 96900
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:58
train iter: 969
num of updates: 97000
vae loss: 0.20869
kl loss: 0.00008
a decoder loss: 0.20861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:59
train iter: 970
num of updates: 97100
vae loss: 0.20817
kl loss: 0.00008
a decoder loss: 0.20809
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:00
train iter: 971
num of updates: 97200
vae loss: 0.20944
kl loss: 0.00008
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:01
train iter: 972
num of updates: 97300
vae loss: 0.20902
kl loss: 0.00008
a decoder loss: 0.20894
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:02
train iter: 973
num of updates: 97400
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:03
train iter: 974
num of updates: 97500
vae loss: 0.20876
kl loss: 0.00008
a decoder loss: 0.20868
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:04
train iter: 975
num of updates: 97600
vae loss: 0.20901
kl loss: 0.00008
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:05
train iter: 976
num of updates: 97700
vae loss: 0.20796
kl loss: 0.00008
a decoder loss: 0.20788
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:06
train iter: 977
num of updates: 97800
vae loss: 0.20815
kl loss: 0.00008
a decoder loss: 0.20807
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:07
train iter: 978
num of updates: 97900
vae loss: 0.20850
kl loss: 0.00008
a decoder loss: 0.20842
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:08
train iter: 979
num of updates: 98000
vae loss: 0.20905
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:09
train iter: 980
num of updates: 98100
vae loss: 0.20783
kl loss: 0.00008
a decoder loss: 0.20775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:10
train iter: 981
num of updates: 98200
vae loss: 0.20880
kl loss: 0.00008
a decoder loss: 0.20872
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:11
train iter: 982
num of updates: 98300
vae loss: 0.20907
kl loss: 0.00008
a decoder loss: 0.20899
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:12
train iter: 983
num of updates: 98400
vae loss: 0.20890
kl loss: 0.00008
a decoder loss: 0.20882
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:13
train iter: 984
num of updates: 98500
vae loss: 0.20834
kl loss: 0.00008
a decoder loss: 0.20826
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:14
train iter: 985
num of updates: 98600
vae loss: 0.20821
kl loss: 0.00008
a decoder loss: 0.20813
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:15
train iter: 986
num of updates: 98700
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:16
train iter: 987
num of updates: 98800
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:17
train iter: 988
num of updates: 98900
vae loss: 0.20842
kl loss: 0.00008
a decoder loss: 0.20834
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:18
train iter: 989
num of updates: 99000
vae loss: 0.20867
kl loss: 0.00008
a decoder loss: 0.20860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:19
train iter: 990
num of updates: 99100
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20843
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:20
train iter: 991
num of updates: 99200
vae loss: 0.20858
kl loss: 0.00008
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:21
train iter: 992
num of updates: 99300
vae loss: 0.20884
kl loss: 0.00008
a decoder loss: 0.20877
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:22
train iter: 993
num of updates: 99400
vae loss: 0.20811
kl loss: 0.00008
a decoder loss: 0.20803
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:23
train iter: 994
num of updates: 99500
vae loss: 0.20864
kl loss: 0.00008
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:24
train iter: 995
num of updates: 99600
vae loss: 0.20830
kl loss: 0.00008
a decoder loss: 0.20822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:25
train iter: 996
num of updates: 99700
vae loss: 0.20773
kl loss: 0.00008
a decoder loss: 0.20765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:26
train iter: 997
num of updates: 99800
vae loss: 0.20845
kl loss: 0.00008
a decoder loss: 0.20837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:27
train iter: 998
num of updates: 99900
vae loss: 0.20813
kl loss: 0.00007
a decoder loss: 0.20806
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:28
train iter: 999
num of updates: 100000
vae loss: 0.20890
kl loss: 0.00008
a decoder loss: 0.20883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/vae_model_100000.pt
============================================================
finished training vae!
============================================================
started training vae at: 25-09-28-00-51-36
finished training vae at: 25-09-28-01-59-16
total vae training time: 1:07:40
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/vae_model.pt
============================================================
2025-09-28 01:59:19.854886: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:59:22.004399: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 40 bytes spill stores, 40 bytes spill loads

2025-09-28 01:59:22.322031: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 20 bytes spill stores, 20 bytes spill loads

2025-09-28 01:59:24.516362: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:59:25.000399: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:59:28.638245: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 01:59:29.071125: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 01:59:29.545294: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 01:59:31.318266: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:59:32.604374: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 404 bytes spill stores, 404 bytes spill loads

2025-09-28 01:59:35.311805: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 504 bytes spill stores, 460 bytes spill loads

2025-09-28 01:59:35.509696: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 908 bytes spill stores, 668 bytes spill loads

2025-09-28 01:59:36.761187: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 236 bytes spill stores, 236 bytes spill loads

2025-09-28 01:59:37.203750: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 1868 bytes spill stores, 1352 bytes spill loads

2025-09-28 01:59:38.090267: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:59:40.765264: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 24 bytes spill stores, 24 bytes spill loads

Error executing job with overrides: ['state_dep_prior=True', 'learn_dynamics_std=True', 'autonomous=False', 'n_dynamics_ensembles=5']
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/jax_dt/train_dt.py", line 1286, in train
    _vae_params = load_params(load_current_model_path)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 75, in load_params
    with File(path, 'rb') as fin:
         ^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 59, in __init__
    self.f = open(fileName, mode)
             ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-51-36/vae_model_1000000.pt'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrelocate-expert-v1-985440[0m at: [34mhttps://wandb.ai/james-gatsby/jax_dt/runs/1b3wv9by[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250928_005229-1b3wv9by/logs[0m
Exception ignored in: <function OffScreenViewer.__del__ at 0x79bef9ee49a0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/platform/baseplatform.py", line 487, in __call__
    return self(*args, **named)
           ^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x79bebe005750>,
		<OpenGL._opaque.EGLContext_pointer object at 0x79bebe005bd0>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x79bf06970fe0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x79bebe005750>,
		<OpenGL._opaque.EGLContext_pointer object at 0x79bebe005bd0>,
	),
	result = 0
)
Exception ignored in: <function OffScreenViewer.__del__ at 0x79bef9ee49a0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x79bebe005750>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x79bf06915550>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x79bf06915550>,
		<OpenGL._opaque.EGLContext_pointer object at 0x79bf069152d0>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x79bf06970fe0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x79bebe005750>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x79bf06915550>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x79bf06915550>,
		<OpenGL._opaque.EGLContext_pointer object at 0x79bf069152d0>,
	),
	result = 0
)
