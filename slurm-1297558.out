Launching a python run
Sun Sep 28 12:54:23 AM UTC 2025
Active conda env: /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/python3
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/pip
2025-09-28 00:54:45.300286: I external/xla/xla/pjrt/pjrt_api.cc:115] GetPjrtApi was found for cuda at /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/jax_plugins/xla_cuda12/xla_cuda_plugin.so
2025-09-28 00:54:45.301447: I external/xla/xla/pjrt/pjrt_api.cc:93] PJRT_Api is set for device type cuda
2025-09-28 00:54:45.355829: I external/xla/xla/pjrt/pjrt_api.cc:161] The PJRT plugin has PJRT API version 0.70. The framework PJRT API version is 0.70.
2025-09-28 00:54:45.792046: I external/xla/xla/service/service.cc:153] XLA service 0x61ab768b1720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-09-28 00:54:45.792094: I external/xla/xla/service/service.cc:161]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2025-09-28 00:54:45.825624: I external/xla/xla/pjrt/pjrt_c_api_client.cc:130] PjRtCApiClient created.
[CudaDevice(id=0)]
/nfs/nhome/live/jheald/jax_dt/train_dt.py:50: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path=cfg_path, config_name="config.yaml")
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
============================================================
start time: 25-09-28-00-54-49
============================================================
dataset path: data//relocate-expert-v1-fullnextstate.pkl
log csv save path: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/log.csv
[2025-09-28 00:54:50,140][OpenGL.acceleratesupport][INFO] - No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'
wandb: Currently logged in as: james-heald (james-gatsby) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /nfs/nhome/live/jheald/jax_dt/outputs/2025-09-28/00-54-46/wandb/run-20250928_005541-q9pj043v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run relocate-expert-v1-985440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/james-gatsby/jax_dt
wandb: üöÄ View run at https://wandb.ai/james-gatsby/jax_dt/runs/q9pj043v
2025-09-28 00:55:51.672942: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 12 bytes spill stores, 12 bytes spill loads

2025-09-28 00:55:53.885323: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 1016 bytes spill stores, 1016 bytes spill loads

2025-09-28 00:55:56.309531: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 16008 bytes spill stores, 16296 bytes spill loads

2025-09-28 00:55:57.216712: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 5912 bytes spill stores, 5776 bytes spill loads

2025-09-28 00:56:00.413319: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 14984 bytes spill stores, 14840 bytes spill loads

============================================================
time elapsed: 0:01:18
train iter: 0
num of updates: 100
dynamics loss: 3.11587

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/dynamics_model_100.pt
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = _fork_exec(
============================================================
time elapsed: 0:01:29
train iter: 1
num of updates: 200
dynamics loss: 3.11469

============================================================
time elapsed: 0:01:31
train iter: 2
num of updates: 300
dynamics loss: 3.11237

============================================================
time elapsed: 0:01:34
train iter: 3
num of updates: 400
dynamics loss: 3.10842

============================================================
time elapsed: 0:01:37
train iter: 4
num of updates: 500
dynamics loss: 3.10467

============================================================
time elapsed: 0:01:40
train iter: 5
num of updates: 600
dynamics loss: 3.09905

============================================================
time elapsed: 0:01:43
train iter: 6
num of updates: 700
dynamics loss: 3.09299

============================================================
time elapsed: 0:01:46
train iter: 7
num of updates: 800
dynamics loss: 3.08564

============================================================
time elapsed: 0:01:49
train iter: 8
num of updates: 900
dynamics loss: 3.07799

============================================================
time elapsed: 0:01:51
train iter: 9
num of updates: 1000
dynamics loss: 3.06857

============================================================
time elapsed: 0:01:54
train iter: 10
num of updates: 1100
dynamics loss: 3.05875

============================================================
time elapsed: 0:01:57
train iter: 11
num of updates: 1200
dynamics loss: 3.04819

============================================================
time elapsed: 0:02:00
train iter: 12
num of updates: 1300
dynamics loss: 3.03723

============================================================
time elapsed: 0:02:03
train iter: 13
num of updates: 1400
dynamics loss: 3.02584

============================================================
time elapsed: 0:02:06
train iter: 14
num of updates: 1500
dynamics loss: 3.01367

============================================================
time elapsed: 0:02:09
train iter: 15
num of updates: 1600
dynamics loss: 3.00118

============================================================
time elapsed: 0:02:11
train iter: 16
num of updates: 1700
dynamics loss: 2.98816

============================================================
time elapsed: 0:02:14
train iter: 17
num of updates: 1800
dynamics loss: 2.97580

============================================================
time elapsed: 0:02:17
train iter: 18
num of updates: 1900
dynamics loss: 2.96180

============================================================
time elapsed: 0:02:20
train iter: 19
num of updates: 2000
dynamics loss: 2.94805

============================================================
time elapsed: 0:02:23
train iter: 20
num of updates: 2100
dynamics loss: 2.93391

============================================================
time elapsed: 0:02:26
train iter: 21
num of updates: 2200
dynamics loss: 2.91994

============================================================
time elapsed: 0:02:29
train iter: 22
num of updates: 2300
dynamics loss: 2.90551

============================================================
time elapsed: 0:02:32
train iter: 23
num of updates: 2400
dynamics loss: 2.89152

============================================================
time elapsed: 0:02:34
train iter: 24
num of updates: 2500
dynamics loss: 2.87737

============================================================
time elapsed: 0:02:37
train iter: 25
num of updates: 2600
dynamics loss: 2.86253

============================================================
time elapsed: 0:02:40
train iter: 26
num of updates: 2700
dynamics loss: 2.84806

============================================================
time elapsed: 0:02:43
train iter: 27
num of updates: 2800
dynamics loss: 2.83389

============================================================
time elapsed: 0:02:46
train iter: 28
num of updates: 2900
dynamics loss: 2.81981

============================================================
time elapsed: 0:02:49
train iter: 29
num of updates: 3000
dynamics loss: 2.80561

============================================================
time elapsed: 0:02:52
train iter: 30
num of updates: 3100
dynamics loss: 2.79119

============================================================
time elapsed: 0:02:54
train iter: 31
num of updates: 3200
dynamics loss: 2.77749

============================================================
time elapsed: 0:02:57
train iter: 32
num of updates: 3300
dynamics loss: 2.76315

============================================================
time elapsed: 0:03:00
train iter: 33
num of updates: 3400
dynamics loss: 2.74942

============================================================
time elapsed: 0:03:03
train iter: 34
num of updates: 3500
dynamics loss: 2.73541

============================================================
time elapsed: 0:03:06
train iter: 35
num of updates: 3600
dynamics loss: 2.72203

============================================================
time elapsed: 0:03:09
train iter: 36
num of updates: 3700
dynamics loss: 2.70835

============================================================
time elapsed: 0:03:12
train iter: 37
num of updates: 3800
dynamics loss: 2.69512

============================================================
time elapsed: 0:03:14
train iter: 38
num of updates: 3900
dynamics loss: 2.68182

============================================================
time elapsed: 0:03:17
train iter: 39
num of updates: 4000
dynamics loss: 2.66838

============================================================
time elapsed: 0:03:20
train iter: 40
num of updates: 4100
dynamics loss: 2.65522

============================================================
time elapsed: 0:03:23
train iter: 41
num of updates: 4200
dynamics loss: 2.64230

============================================================
time elapsed: 0:03:26
train iter: 42
num of updates: 4300
dynamics loss: 2.62926

============================================================
time elapsed: 0:03:29
train iter: 43
num of updates: 4400
dynamics loss: 2.61630

============================================================
time elapsed: 0:03:32
train iter: 44
num of updates: 4500
dynamics loss: 2.60379

============================================================
time elapsed: 0:03:35
train iter: 45
num of updates: 4600
dynamics loss: 2.59115

============================================================
time elapsed: 0:03:37
train iter: 46
num of updates: 4700
dynamics loss: 2.57837

============================================================
time elapsed: 0:03:40
train iter: 47
num of updates: 4800
dynamics loss: 2.56619

============================================================
time elapsed: 0:03:43
train iter: 48
num of updates: 4900
dynamics loss: 2.55338

============================================================
time elapsed: 0:03:46
train iter: 49
num of updates: 5000
dynamics loss: 2.54115

============================================================
time elapsed: 0:03:49
train iter: 50
num of updates: 5100
dynamics loss: 2.52862

============================================================
time elapsed: 0:03:52
train iter: 51
num of updates: 5200
dynamics loss: 2.51628

============================================================
time elapsed: 0:03:55
train iter: 52
num of updates: 5300
dynamics loss: 2.50369

============================================================
time elapsed: 0:03:57
train iter: 53
num of updates: 5400
dynamics loss: 2.49138

============================================================
time elapsed: 0:04:00
train iter: 54
num of updates: 5500
dynamics loss: 2.47917

============================================================
time elapsed: 0:04:03
train iter: 55
num of updates: 5600
dynamics loss: 2.46673

============================================================
time elapsed: 0:04:06
train iter: 56
num of updates: 5700
dynamics loss: 2.45452

============================================================
time elapsed: 0:04:09
train iter: 57
num of updates: 5800
dynamics loss: 2.44211

============================================================
time elapsed: 0:04:12
train iter: 58
num of updates: 5900
dynamics loss: 2.42942

============================================================
time elapsed: 0:04:15
train iter: 59
num of updates: 6000
dynamics loss: 2.41687

============================================================
time elapsed: 0:04:18
train iter: 60
num of updates: 6100
dynamics loss: 2.40427

============================================================
time elapsed: 0:04:20
train iter: 61
num of updates: 6200
dynamics loss: 2.39194

============================================================
time elapsed: 0:04:23
train iter: 62
num of updates: 6300
dynamics loss: 2.37934

============================================================
time elapsed: 0:04:26
train iter: 63
num of updates: 6400
dynamics loss: 2.36656

============================================================
time elapsed: 0:04:29
train iter: 64
num of updates: 6500
dynamics loss: 2.35382

============================================================
time elapsed: 0:04:32
train iter: 65
num of updates: 6600
dynamics loss: 2.34091

============================================================
time elapsed: 0:04:35
train iter: 66
num of updates: 6700
dynamics loss: 2.32825

============================================================
time elapsed: 0:04:38
train iter: 67
num of updates: 6800
dynamics loss: 2.31510

============================================================
time elapsed: 0:04:40
train iter: 68
num of updates: 6900
dynamics loss: 2.30223

============================================================
time elapsed: 0:04:43
train iter: 69
num of updates: 7000
dynamics loss: 2.28899

============================================================
time elapsed: 0:04:46
train iter: 70
num of updates: 7100
dynamics loss: 2.27596

============================================================
time elapsed: 0:04:49
train iter: 71
num of updates: 7200
dynamics loss: 2.26272

============================================================
time elapsed: 0:04:52
train iter: 72
num of updates: 7300
dynamics loss: 2.24949

============================================================
time elapsed: 0:04:55
train iter: 73
num of updates: 7400
dynamics loss: 2.23617

============================================================
time elapsed: 0:04:58
train iter: 74
num of updates: 7500
dynamics loss: 2.22249

============================================================
time elapsed: 0:05:00
train iter: 75
num of updates: 7600
dynamics loss: 2.20917

============================================================
time elapsed: 0:05:03
train iter: 76
num of updates: 7700
dynamics loss: 2.19571

============================================================
time elapsed: 0:05:06
train iter: 77
num of updates: 7800
dynamics loss: 2.18194

============================================================
time elapsed: 0:05:09
train iter: 78
num of updates: 7900
dynamics loss: 2.16838

============================================================
time elapsed: 0:05:12
train iter: 79
num of updates: 8000
dynamics loss: 2.15477

============================================================
time elapsed: 0:05:15
train iter: 80
num of updates: 8100
dynamics loss: 2.14099

============================================================
time elapsed: 0:05:18
train iter: 81
num of updates: 8200
dynamics loss: 2.12739

============================================================
time elapsed: 0:05:20
train iter: 82
num of updates: 8300
dynamics loss: 2.11324

============================================================
time elapsed: 0:05:23
train iter: 83
num of updates: 8400
dynamics loss: 2.09955

============================================================
time elapsed: 0:05:26
train iter: 84
num of updates: 8500
dynamics loss: 2.08570

============================================================
time elapsed: 0:05:29
train iter: 85
num of updates: 8600
dynamics loss: 2.07200

============================================================
time elapsed: 0:05:32
train iter: 86
num of updates: 8700
dynamics loss: 2.05802

============================================================
time elapsed: 0:05:35
train iter: 87
num of updates: 8800
dynamics loss: 2.04381

============================================================
time elapsed: 0:05:38
train iter: 88
num of updates: 8900
dynamics loss: 2.02984

============================================================
time elapsed: 0:05:41
train iter: 89
num of updates: 9000
dynamics loss: 2.01580

============================================================
time elapsed: 0:05:43
train iter: 90
num of updates: 9100
dynamics loss: 2.00165

============================================================
time elapsed: 0:05:46
train iter: 91
num of updates: 9200
dynamics loss: 1.98742

============================================================
time elapsed: 0:05:49
train iter: 92
num of updates: 9300
dynamics loss: 1.97379

============================================================
time elapsed: 0:05:52
train iter: 93
num of updates: 9400
dynamics loss: 1.95957

============================================================
time elapsed: 0:05:55
train iter: 94
num of updates: 9500
dynamics loss: 1.94537

============================================================
time elapsed: 0:05:58
train iter: 95
num of updates: 9600
dynamics loss: 1.93120

============================================================
time elapsed: 0:06:01
train iter: 96
num of updates: 9700
dynamics loss: 1.91719

============================================================
time elapsed: 0:06:03
train iter: 97
num of updates: 9800
dynamics loss: 1.90338

============================================================
time elapsed: 0:06:06
train iter: 98
num of updates: 9900
dynamics loss: 1.88923

============================================================
time elapsed: 0:06:09
train iter: 99
num of updates: 10000
dynamics loss: 1.87538

============================================================
time elapsed: 0:06:12
train iter: 100
num of updates: 10100
dynamics loss: 1.86158

============================================================
time elapsed: 0:06:15
train iter: 101
num of updates: 10200
dynamics loss: 1.84784

============================================================
time elapsed: 0:06:18
train iter: 102
num of updates: 10300
dynamics loss: 1.83410

============================================================
time elapsed: 0:06:21
train iter: 103
num of updates: 10400
dynamics loss: 1.82047

============================================================
time elapsed: 0:06:24
train iter: 104
num of updates: 10500
dynamics loss: 1.80696

============================================================
time elapsed: 0:06:26
train iter: 105
num of updates: 10600
dynamics loss: 1.79401

============================================================
time elapsed: 0:06:29
train iter: 106
num of updates: 10700
dynamics loss: 1.78124

============================================================
time elapsed: 0:06:32
train iter: 107
num of updates: 10800
dynamics loss: 1.76861

============================================================
time elapsed: 0:06:35
train iter: 108
num of updates: 10900
dynamics loss: 1.75561

============================================================
time elapsed: 0:06:38
train iter: 109
num of updates: 11000
dynamics loss: 1.74309

============================================================
time elapsed: 0:06:41
train iter: 110
num of updates: 11100
dynamics loss: 1.73092

============================================================
time elapsed: 0:06:44
train iter: 111
num of updates: 11200
dynamics loss: 1.71851

============================================================
time elapsed: 0:06:46
train iter: 112
num of updates: 11300
dynamics loss: 1.70675

============================================================
time elapsed: 0:06:49
train iter: 113
num of updates: 11400
dynamics loss: 1.69444

============================================================
time elapsed: 0:06:52
train iter: 114
num of updates: 11500
dynamics loss: 1.68333

============================================================
time elapsed: 0:06:55
train iter: 115
num of updates: 11600
dynamics loss: 1.67153

============================================================
time elapsed: 0:06:58
train iter: 116
num of updates: 11700
dynamics loss: 1.66041

============================================================
time elapsed: 0:07:01
train iter: 117
num of updates: 11800
dynamics loss: 1.64903

============================================================
time elapsed: 0:07:04
train iter: 118
num of updates: 11900
dynamics loss: 1.63808

============================================================
time elapsed: 0:07:06
train iter: 119
num of updates: 12000
dynamics loss: 1.62732

============================================================
time elapsed: 0:07:09
train iter: 120
num of updates: 12100
dynamics loss: 1.61617

============================================================
time elapsed: 0:07:12
train iter: 121
num of updates: 12200
dynamics loss: 1.60565

============================================================
time elapsed: 0:07:15
train iter: 122
num of updates: 12300
dynamics loss: 1.59490

============================================================
time elapsed: 0:07:18
train iter: 123
num of updates: 12400
dynamics loss: 1.58458

============================================================
time elapsed: 0:07:21
train iter: 124
num of updates: 12500
dynamics loss: 1.57437

============================================================
time elapsed: 0:07:24
train iter: 125
num of updates: 12600
dynamics loss: 1.56425

============================================================
time elapsed: 0:07:27
train iter: 126
num of updates: 12700
dynamics loss: 1.55455

============================================================
time elapsed: 0:07:29
train iter: 127
num of updates: 12800
dynamics loss: 1.54494

============================================================
time elapsed: 0:07:32
train iter: 128
num of updates: 12900
dynamics loss: 1.53523

============================================================
time elapsed: 0:07:35
train iter: 129
num of updates: 13000
dynamics loss: 1.52547

============================================================
time elapsed: 0:07:38
train iter: 130
num of updates: 13100
dynamics loss: 1.51619

============================================================
time elapsed: 0:07:41
train iter: 131
num of updates: 13200
dynamics loss: 1.50681

============================================================
time elapsed: 0:07:44
train iter: 132
num of updates: 13300
dynamics loss: 1.49749

============================================================
time elapsed: 0:07:47
train iter: 133
num of updates: 13400
dynamics loss: 1.48883

============================================================
time elapsed: 0:07:49
train iter: 134
num of updates: 13500
dynamics loss: 1.47963

============================================================
time elapsed: 0:07:52
train iter: 135
num of updates: 13600
dynamics loss: 1.47137

============================================================
time elapsed: 0:07:55
train iter: 136
num of updates: 13700
dynamics loss: 1.46264

============================================================
time elapsed: 0:07:58
train iter: 137
num of updates: 13800
dynamics loss: 1.45424

============================================================
time elapsed: 0:08:01
train iter: 138
num of updates: 13900
dynamics loss: 1.44588

============================================================
time elapsed: 0:08:04
train iter: 139
num of updates: 14000
dynamics loss: 1.43771

============================================================
time elapsed: 0:08:07
train iter: 140
num of updates: 14100
dynamics loss: 1.42960

============================================================
time elapsed: 0:08:09
train iter: 141
num of updates: 14200
dynamics loss: 1.42140

============================================================
time elapsed: 0:08:12
train iter: 142
num of updates: 14300
dynamics loss: 1.41367

============================================================
time elapsed: 0:08:15
train iter: 143
num of updates: 14400
dynamics loss: 1.40623

============================================================
time elapsed: 0:08:18
train iter: 144
num of updates: 14500
dynamics loss: 1.39825

============================================================
time elapsed: 0:08:21
train iter: 145
num of updates: 14600
dynamics loss: 1.39084

============================================================
time elapsed: 0:08:24
train iter: 146
num of updates: 14700
dynamics loss: 1.38335

============================================================
time elapsed: 0:08:27
train iter: 147
num of updates: 14800
dynamics loss: 1.37625

============================================================
time elapsed: 0:08:29
train iter: 148
num of updates: 14900
dynamics loss: 1.36975

============================================================
time elapsed: 0:08:32
train iter: 149
num of updates: 15000
dynamics loss: 1.36227

============================================================
time elapsed: 0:08:35
train iter: 150
num of updates: 15100
dynamics loss: 1.35587

============================================================
time elapsed: 0:08:38
train iter: 151
num of updates: 15200
dynamics loss: 1.34843

============================================================
time elapsed: 0:08:41
train iter: 152
num of updates: 15300
dynamics loss: 1.34175

============================================================
time elapsed: 0:08:44
train iter: 153
num of updates: 15400
dynamics loss: 1.33519

============================================================
time elapsed: 0:08:47
train iter: 154
num of updates: 15500
dynamics loss: 1.32899

============================================================
time elapsed: 0:08:50
train iter: 155
num of updates: 15600
dynamics loss: 1.32246

============================================================
time elapsed: 0:08:52
train iter: 156
num of updates: 15700
dynamics loss: 1.31568

============================================================
time elapsed: 0:08:55
train iter: 157
num of updates: 15800
dynamics loss: 1.30922

============================================================
time elapsed: 0:08:58
train iter: 158
num of updates: 15900
dynamics loss: 1.30365

============================================================
time elapsed: 0:09:01
train iter: 159
num of updates: 16000
dynamics loss: 1.29782

============================================================
time elapsed: 0:09:04
train iter: 160
num of updates: 16100
dynamics loss: 1.29162

============================================================
time elapsed: 0:09:07
train iter: 161
num of updates: 16200
dynamics loss: 1.28660

============================================================
time elapsed: 0:09:10
train iter: 162
num of updates: 16300
dynamics loss: 1.28055

============================================================
time elapsed: 0:09:12
train iter: 163
num of updates: 16400
dynamics loss: 1.27489

============================================================
time elapsed: 0:09:15
train iter: 164
num of updates: 16500
dynamics loss: 1.26946

============================================================
time elapsed: 0:09:18
train iter: 165
num of updates: 16600
dynamics loss: 1.26342

============================================================
time elapsed: 0:09:21
train iter: 166
num of updates: 16700
dynamics loss: 1.25832

============================================================
time elapsed: 0:09:24
train iter: 167
num of updates: 16800
dynamics loss: 1.25325

============================================================
time elapsed: 0:09:27
train iter: 168
num of updates: 16900
dynamics loss: 1.24773

============================================================
time elapsed: 0:09:30
train iter: 169
num of updates: 17000
dynamics loss: 1.24280

============================================================
time elapsed: 0:09:33
train iter: 170
num of updates: 17100
dynamics loss: 1.23756

============================================================
time elapsed: 0:09:35
train iter: 171
num of updates: 17200
dynamics loss: 1.23270

============================================================
time elapsed: 0:09:38
train iter: 172
num of updates: 17300
dynamics loss: 1.22850

============================================================
time elapsed: 0:09:41
train iter: 173
num of updates: 17400
dynamics loss: 1.22309

============================================================
time elapsed: 0:09:44
train iter: 174
num of updates: 17500
dynamics loss: 1.21885

============================================================
time elapsed: 0:09:47
train iter: 175
num of updates: 17600
dynamics loss: 1.21372

============================================================
time elapsed: 0:09:50
train iter: 176
num of updates: 17700
dynamics loss: 1.20931

============================================================
time elapsed: 0:09:53
train iter: 177
num of updates: 17800
dynamics loss: 1.20461

============================================================
time elapsed: 0:09:55
train iter: 178
num of updates: 17900
dynamics loss: 1.19987

============================================================
time elapsed: 0:09:58
train iter: 179
num of updates: 18000
dynamics loss: 1.19588

============================================================
time elapsed: 0:10:01
train iter: 180
num of updates: 18100
dynamics loss: 1.19161

============================================================
time elapsed: 0:10:04
train iter: 181
num of updates: 18200
dynamics loss: 1.18709

============================================================
time elapsed: 0:10:07
train iter: 182
num of updates: 18300
dynamics loss: 1.18283

============================================================
time elapsed: 0:10:10
train iter: 183
num of updates: 18400
dynamics loss: 1.17880

============================================================
time elapsed: 0:10:13
train iter: 184
num of updates: 18500
dynamics loss: 1.17494

============================================================
time elapsed: 0:10:15
train iter: 185
num of updates: 18600
dynamics loss: 1.17052

============================================================
time elapsed: 0:10:18
train iter: 186
num of updates: 18700
dynamics loss: 1.16711

============================================================
time elapsed: 0:10:21
train iter: 187
num of updates: 18800
dynamics loss: 1.16309

============================================================
time elapsed: 0:10:24
train iter: 188
num of updates: 18900
dynamics loss: 1.15931

============================================================
time elapsed: 0:10:27
train iter: 189
num of updates: 19000
dynamics loss: 1.15503

============================================================
time elapsed: 0:10:30
train iter: 190
num of updates: 19100
dynamics loss: 1.15197

============================================================
time elapsed: 0:10:33
train iter: 191
num of updates: 19200
dynamics loss: 1.14869

============================================================
time elapsed: 0:10:36
train iter: 192
num of updates: 19300
dynamics loss: 1.14413

============================================================
time elapsed: 0:10:38
train iter: 193
num of updates: 19400
dynamics loss: 1.14027

============================================================
time elapsed: 0:10:41
train iter: 194
num of updates: 19500
dynamics loss: 1.13745

============================================================
time elapsed: 0:10:44
train iter: 195
num of updates: 19600
dynamics loss: 1.13397

============================================================
time elapsed: 0:10:47
train iter: 196
num of updates: 19700
dynamics loss: 1.13022

============================================================
time elapsed: 0:10:50
train iter: 197
num of updates: 19800
dynamics loss: 1.12673

============================================================
time elapsed: 0:10:53
train iter: 198
num of updates: 19900
dynamics loss: 1.12310

============================================================
time elapsed: 0:10:56
train iter: 199
num of updates: 20000
dynamics loss: 1.12038

============================================================
time elapsed: 0:10:58
train iter: 200
num of updates: 20100
dynamics loss: 1.11703

============================================================
time elapsed: 0:11:01
train iter: 201
num of updates: 20200
dynamics loss: 1.11346

============================================================
time elapsed: 0:11:04
train iter: 202
num of updates: 20300
dynamics loss: 1.11051

============================================================
time elapsed: 0:11:07
train iter: 203
num of updates: 20400
dynamics loss: 1.10744

============================================================
time elapsed: 0:11:10
train iter: 204
num of updates: 20500
dynamics loss: 1.10468

============================================================
time elapsed: 0:11:13
train iter: 205
num of updates: 20600
dynamics loss: 1.10146

============================================================
time elapsed: 0:11:16
train iter: 206
num of updates: 20700
dynamics loss: 1.09903

============================================================
time elapsed: 0:11:18
train iter: 207
num of updates: 20800
dynamics loss: 1.09560

============================================================
time elapsed: 0:11:21
train iter: 208
num of updates: 20900
dynamics loss: 1.09286

============================================================
time elapsed: 0:11:24
train iter: 209
num of updates: 21000
dynamics loss: 1.09013

============================================================
time elapsed: 0:11:27
train iter: 210
num of updates: 21100
dynamics loss: 1.08742

============================================================
time elapsed: 0:11:30
train iter: 211
num of updates: 21200
dynamics loss: 1.08492

============================================================
time elapsed: 0:11:33
train iter: 212
num of updates: 21300
dynamics loss: 1.08128

============================================================
time elapsed: 0:11:36
train iter: 213
num of updates: 21400
dynamics loss: 1.07909

============================================================
time elapsed: 0:11:39
train iter: 214
num of updates: 21500
dynamics loss: 1.07619

============================================================
time elapsed: 0:11:41
train iter: 215
num of updates: 21600
dynamics loss: 1.07423

============================================================
time elapsed: 0:11:44
train iter: 216
num of updates: 21700
dynamics loss: 1.07135

============================================================
time elapsed: 0:11:47
train iter: 217
num of updates: 21800
dynamics loss: 1.06856

============================================================
time elapsed: 0:11:50
train iter: 218
num of updates: 21900
dynamics loss: 1.06572

============================================================
time elapsed: 0:11:53
train iter: 219
num of updates: 22000
dynamics loss: 1.06371

============================================================
time elapsed: 0:11:56
train iter: 220
num of updates: 22100
dynamics loss: 1.06081

============================================================
time elapsed: 0:11:59
train iter: 221
num of updates: 22200
dynamics loss: 1.05912

============================================================
time elapsed: 0:12:01
train iter: 222
num of updates: 22300
dynamics loss: 1.05618

============================================================
time elapsed: 0:12:04
train iter: 223
num of updates: 22400
dynamics loss: 1.05384

============================================================
time elapsed: 0:12:07
train iter: 224
num of updates: 22500
dynamics loss: 1.05153

============================================================
time elapsed: 0:12:10
train iter: 225
num of updates: 22600
dynamics loss: 1.04978

============================================================
time elapsed: 0:12:13
train iter: 226
num of updates: 22700
dynamics loss: 1.04688

============================================================
time elapsed: 0:12:16
train iter: 227
num of updates: 22800
dynamics loss: 1.04448

============================================================
time elapsed: 0:12:19
train iter: 228
num of updates: 22900
dynamics loss: 1.04233

============================================================
time elapsed: 0:12:21
train iter: 229
num of updates: 23000
dynamics loss: 1.04001

============================================================
time elapsed: 0:12:24
train iter: 230
num of updates: 23100
dynamics loss: 1.03782

============================================================
time elapsed: 0:12:27
train iter: 231
num of updates: 23200
dynamics loss: 1.03567

============================================================
time elapsed: 0:12:30
train iter: 232
num of updates: 23300
dynamics loss: 1.03388

============================================================
time elapsed: 0:12:33
train iter: 233
num of updates: 23400
dynamics loss: 1.03149

============================================================
time elapsed: 0:12:36
train iter: 234
num of updates: 23500
dynamics loss: 1.02900

============================================================
time elapsed: 0:12:39
train iter: 235
num of updates: 23600
dynamics loss: 1.02739

============================================================
time elapsed: 0:12:42
train iter: 236
num of updates: 23700
dynamics loss: 1.02578

============================================================
time elapsed: 0:12:44
train iter: 237
num of updates: 23800
dynamics loss: 1.02387

============================================================
time elapsed: 0:12:47
train iter: 238
num of updates: 23900
dynamics loss: 1.02098

============================================================
time elapsed: 0:12:50
train iter: 239
num of updates: 24000
dynamics loss: 1.01929

============================================================
time elapsed: 0:12:53
train iter: 240
num of updates: 24100
dynamics loss: 1.01811

============================================================
time elapsed: 0:12:56
train iter: 241
num of updates: 24200
dynamics loss: 1.01603

============================================================
time elapsed: 0:12:59
train iter: 242
num of updates: 24300
dynamics loss: 1.01395

============================================================
time elapsed: 0:13:02
train iter: 243
num of updates: 24400
dynamics loss: 1.01164

============================================================
time elapsed: 0:13:04
train iter: 244
num of updates: 24500
dynamics loss: 1.01008

============================================================
time elapsed: 0:13:07
train iter: 245
num of updates: 24600
dynamics loss: 1.00810

============================================================
time elapsed: 0:13:10
train iter: 246
num of updates: 24700
dynamics loss: 1.00686

============================================================
time elapsed: 0:13:13
train iter: 247
num of updates: 24800
dynamics loss: 1.00534

============================================================
time elapsed: 0:13:16
train iter: 248
num of updates: 24900
dynamics loss: 1.00285

============================================================
time elapsed: 0:13:19
train iter: 249
num of updates: 25000
dynamics loss: 1.00167

============================================================
time elapsed: 0:13:22
train iter: 250
num of updates: 25100
dynamics loss: 0.99997

============================================================
time elapsed: 0:13:24
train iter: 251
num of updates: 25200
dynamics loss: 0.99840

============================================================
time elapsed: 0:13:27
train iter: 252
num of updates: 25300
dynamics loss: 0.99627

============================================================
time elapsed: 0:13:30
train iter: 253
num of updates: 25400
dynamics loss: 0.99502

============================================================
time elapsed: 0:13:33
train iter: 254
num of updates: 25500
dynamics loss: 0.99262

============================================================
time elapsed: 0:13:36
train iter: 255
num of updates: 25600
dynamics loss: 0.99123

============================================================
time elapsed: 0:13:39
train iter: 256
num of updates: 25700
dynamics loss: 0.98941

============================================================
time elapsed: 0:13:42
train iter: 257
num of updates: 25800
dynamics loss: 0.98806

============================================================
time elapsed: 0:13:44
train iter: 258
num of updates: 25900
dynamics loss: 0.98653

============================================================
time elapsed: 0:13:47
train iter: 259
num of updates: 26000
dynamics loss: 0.98520

============================================================
time elapsed: 0:13:50
train iter: 260
num of updates: 26100
dynamics loss: 0.98329

============================================================
time elapsed: 0:13:53
train iter: 261
num of updates: 26200
dynamics loss: 0.98221

============================================================
time elapsed: 0:13:56
train iter: 262
num of updates: 26300
dynamics loss: 0.98040

============================================================
time elapsed: 0:13:59
train iter: 263
num of updates: 26400
dynamics loss: 0.97908

============================================================
time elapsed: 0:14:02
train iter: 264
num of updates: 26500
dynamics loss: 0.97781

============================================================
time elapsed: 0:14:05
train iter: 265
num of updates: 26600
dynamics loss: 0.97695

============================================================
time elapsed: 0:14:07
train iter: 266
num of updates: 26700
dynamics loss: 0.97407

============================================================
time elapsed: 0:14:10
train iter: 267
num of updates: 26800
dynamics loss: 0.97348

============================================================
time elapsed: 0:14:13
train iter: 268
num of updates: 26900
dynamics loss: 0.97198

============================================================
time elapsed: 0:14:16
train iter: 269
num of updates: 27000
dynamics loss: 0.97066

============================================================
time elapsed: 0:14:19
train iter: 270
num of updates: 27100
dynamics loss: 0.96927

============================================================
time elapsed: 0:14:22
train iter: 271
num of updates: 27200
dynamics loss: 0.96723

============================================================
time elapsed: 0:14:25
train iter: 272
num of updates: 27300
dynamics loss: 0.96627

============================================================
time elapsed: 0:14:27
train iter: 273
num of updates: 27400
dynamics loss: 0.96481

============================================================
time elapsed: 0:14:30
train iter: 274
num of updates: 27500
dynamics loss: 0.96370

============================================================
time elapsed: 0:14:33
train iter: 275
num of updates: 27600
dynamics loss: 0.96166

============================================================
time elapsed: 0:14:36
train iter: 276
num of updates: 27700
dynamics loss: 0.96130

============================================================
time elapsed: 0:14:39
train iter: 277
num of updates: 27800
dynamics loss: 0.95912

============================================================
time elapsed: 0:14:42
train iter: 278
num of updates: 27900
dynamics loss: 0.95885

============================================================
time elapsed: 0:14:45
train iter: 279
num of updates: 28000
dynamics loss: 0.95718

============================================================
time elapsed: 0:14:48
train iter: 280
num of updates: 28100
dynamics loss: 0.95584

============================================================
time elapsed: 0:14:50
train iter: 281
num of updates: 28200
dynamics loss: 0.95412

============================================================
time elapsed: 0:14:53
train iter: 282
num of updates: 28300
dynamics loss: 0.95328

============================================================
time elapsed: 0:14:56
train iter: 283
num of updates: 28400
dynamics loss: 0.95236

============================================================
time elapsed: 0:14:59
train iter: 284
num of updates: 28500
dynamics loss: 0.95132

============================================================
time elapsed: 0:15:02
train iter: 285
num of updates: 28600
dynamics loss: 0.95018

============================================================
time elapsed: 0:15:05
train iter: 286
num of updates: 28700
dynamics loss: 0.94907

============================================================
time elapsed: 0:15:08
train iter: 287
num of updates: 28800
dynamics loss: 0.94688

============================================================
time elapsed: 0:15:10
train iter: 288
num of updates: 28900
dynamics loss: 0.94621

============================================================
time elapsed: 0:15:13
train iter: 289
num of updates: 29000
dynamics loss: 0.94568

============================================================
time elapsed: 0:15:16
train iter: 290
num of updates: 29100
dynamics loss: 0.94392

============================================================
time elapsed: 0:15:19
train iter: 291
num of updates: 29200
dynamics loss: 0.94332

============================================================
time elapsed: 0:15:22
train iter: 292
num of updates: 29300
dynamics loss: 0.94242

============================================================
time elapsed: 0:15:25
train iter: 293
num of updates: 29400
dynamics loss: 0.94061

============================================================
time elapsed: 0:15:28
train iter: 294
num of updates: 29500
dynamics loss: 0.94025

============================================================
time elapsed: 0:15:31
train iter: 295
num of updates: 29600
dynamics loss: 0.93823

============================================================
time elapsed: 0:15:33
train iter: 296
num of updates: 29700
dynamics loss: 0.93754

============================================================
time elapsed: 0:15:36
train iter: 297
num of updates: 29800
dynamics loss: 0.93650

============================================================
time elapsed: 0:15:39
train iter: 298
num of updates: 29900
dynamics loss: 0.93552

============================================================
time elapsed: 0:15:42
train iter: 299
num of updates: 30000
dynamics loss: 0.93476

============================================================
time elapsed: 0:15:45
train iter: 300
num of updates: 30100
dynamics loss: 0.93395

============================================================
time elapsed: 0:15:48
train iter: 301
num of updates: 30200
dynamics loss: 0.93250

============================================================
time elapsed: 0:15:51
train iter: 302
num of updates: 30300
dynamics loss: 0.93142

============================================================
time elapsed: 0:15:53
train iter: 303
num of updates: 30400
dynamics loss: 0.92976

============================================================
time elapsed: 0:15:56
train iter: 304
num of updates: 30500
dynamics loss: 0.92995

============================================================
time elapsed: 0:15:59
train iter: 305
num of updates: 30600
dynamics loss: 0.92846

============================================================
time elapsed: 0:16:02
train iter: 306
num of updates: 30700
dynamics loss: 0.92759

============================================================
time elapsed: 0:16:05
train iter: 307
num of updates: 30800
dynamics loss: 0.92647

============================================================
time elapsed: 0:16:08
train iter: 308
num of updates: 30900
dynamics loss: 0.92545

============================================================
time elapsed: 0:16:11
train iter: 309
num of updates: 31000
dynamics loss: 0.92424

============================================================
time elapsed: 0:16:13
train iter: 310
num of updates: 31100
dynamics loss: 0.92389

============================================================
time elapsed: 0:16:16
train iter: 311
num of updates: 31200
dynamics loss: 0.92290

============================================================
time elapsed: 0:16:19
train iter: 312
num of updates: 31300
dynamics loss: 0.92167

============================================================
time elapsed: 0:16:22
train iter: 313
num of updates: 31400
dynamics loss: 0.92113

============================================================
time elapsed: 0:16:25
train iter: 314
num of updates: 31500
dynamics loss: 0.91959

============================================================
time elapsed: 0:16:28
train iter: 315
num of updates: 31600
dynamics loss: 0.91886

============================================================
time elapsed: 0:16:31
train iter: 316
num of updates: 31700
dynamics loss: 0.91763

============================================================
time elapsed: 0:16:34
train iter: 317
num of updates: 31800
dynamics loss: 0.91705

============================================================
time elapsed: 0:16:36
train iter: 318
num of updates: 31900
dynamics loss: 0.91668

============================================================
time elapsed: 0:16:39
train iter: 319
num of updates: 32000
dynamics loss: 0.91481

============================================================
time elapsed: 0:16:42
train iter: 320
num of updates: 32100
dynamics loss: 0.91498

============================================================
time elapsed: 0:16:45
train iter: 321
num of updates: 32200
dynamics loss: 0.91358

============================================================
time elapsed: 0:16:48
train iter: 322
num of updates: 32300
dynamics loss: 0.91282

============================================================
time elapsed: 0:16:51
train iter: 323
num of updates: 32400
dynamics loss: 0.91198

============================================================
time elapsed: 0:16:54
train iter: 324
num of updates: 32500
dynamics loss: 0.91123

============================================================
time elapsed: 0:16:56
train iter: 325
num of updates: 32600
dynamics loss: 0.91042

============================================================
time elapsed: 0:16:59
train iter: 326
num of updates: 32700
dynamics loss: 0.90922

============================================================
time elapsed: 0:17:02
train iter: 327
num of updates: 32800
dynamics loss: 0.90841

============================================================
time elapsed: 0:17:05
train iter: 328
num of updates: 32900
dynamics loss: 0.90815

============================================================
time elapsed: 0:17:08
train iter: 329
num of updates: 33000
dynamics loss: 0.90678

============================================================
time elapsed: 0:17:11
train iter: 330
num of updates: 33100
dynamics loss: 0.90604

============================================================
time elapsed: 0:17:14
train iter: 331
num of updates: 33200
dynamics loss: 0.90551

============================================================
time elapsed: 0:17:17
train iter: 332
num of updates: 33300
dynamics loss: 0.90458

============================================================
time elapsed: 0:17:19
train iter: 333
num of updates: 33400
dynamics loss: 0.90425

============================================================
time elapsed: 0:17:22
train iter: 334
num of updates: 33500
dynamics loss: 0.90291

============================================================
time elapsed: 0:17:25
train iter: 335
num of updates: 33600
dynamics loss: 0.90212

============================================================
time elapsed: 0:17:28
train iter: 336
num of updates: 33700
dynamics loss: 0.90120

============================================================
time elapsed: 0:17:31
train iter: 337
num of updates: 33800
dynamics loss: 0.90065

============================================================
time elapsed: 0:17:34
train iter: 338
num of updates: 33900
dynamics loss: 0.89983

============================================================
time elapsed: 0:17:37
train iter: 339
num of updates: 34000
dynamics loss: 0.89940

============================================================
time elapsed: 0:17:39
train iter: 340
num of updates: 34100
dynamics loss: 0.89825

============================================================
time elapsed: 0:17:42
train iter: 341
num of updates: 34200
dynamics loss: 0.89757

============================================================
time elapsed: 0:17:45
train iter: 342
num of updates: 34300
dynamics loss: 0.89725

============================================================
time elapsed: 0:17:48
train iter: 343
num of updates: 34400
dynamics loss: 0.89605

============================================================
time elapsed: 0:17:51
train iter: 344
num of updates: 34500
dynamics loss: 0.89550

============================================================
time elapsed: 0:17:54
train iter: 345
num of updates: 34600
dynamics loss: 0.89472

============================================================
time elapsed: 0:17:57
train iter: 346
num of updates: 34700
dynamics loss: 0.89376

============================================================
time elapsed: 0:18:00
train iter: 347
num of updates: 34800
dynamics loss: 0.89318

============================================================
time elapsed: 0:18:02
train iter: 348
num of updates: 34900
dynamics loss: 0.89254

============================================================
time elapsed: 0:18:05
train iter: 349
num of updates: 35000
dynamics loss: 0.89174

============================================================
time elapsed: 0:18:08
train iter: 350
num of updates: 35100
dynamics loss: 0.89080

============================================================
time elapsed: 0:18:11
train iter: 351
num of updates: 35200
dynamics loss: 0.89039

============================================================
time elapsed: 0:18:14
train iter: 352
num of updates: 35300
dynamics loss: 0.88977

============================================================
time elapsed: 0:18:17
train iter: 353
num of updates: 35400
dynamics loss: 0.88917

============================================================
time elapsed: 0:18:20
train iter: 354
num of updates: 35500
dynamics loss: 0.88830

============================================================
time elapsed: 0:18:22
train iter: 355
num of updates: 35600
dynamics loss: 0.88783

============================================================
time elapsed: 0:18:25
train iter: 356
num of updates: 35700
dynamics loss: 0.88691

============================================================
time elapsed: 0:18:28
train iter: 357
num of updates: 35800
dynamics loss: 0.88667

============================================================
time elapsed: 0:18:31
train iter: 358
num of updates: 35900
dynamics loss: 0.88513

============================================================
time elapsed: 0:18:34
train iter: 359
num of updates: 36000
dynamics loss: 0.88514

============================================================
time elapsed: 0:18:37
train iter: 360
num of updates: 36100
dynamics loss: 0.88420

============================================================
time elapsed: 0:18:40
train iter: 361
num of updates: 36200
dynamics loss: 0.88309

============================================================
time elapsed: 0:18:42
train iter: 362
num of updates: 36300
dynamics loss: 0.88280

============================================================
time elapsed: 0:18:45
train iter: 363
num of updates: 36400
dynamics loss: 0.88211

============================================================
time elapsed: 0:18:48
train iter: 364
num of updates: 36500
dynamics loss: 0.88147

============================================================
time elapsed: 0:18:51
train iter: 365
num of updates: 36600
dynamics loss: 0.88102

============================================================
time elapsed: 0:18:54
train iter: 366
num of updates: 36700
dynamics loss: 0.88046

============================================================
time elapsed: 0:18:57
train iter: 367
num of updates: 36800
dynamics loss: 0.87961

============================================================
time elapsed: 0:19:00
train iter: 368
num of updates: 36900
dynamics loss: 0.87841

============================================================
time elapsed: 0:19:03
train iter: 369
num of updates: 37000
dynamics loss: 0.87830

============================================================
time elapsed: 0:19:05
train iter: 370
num of updates: 37100
dynamics loss: 0.87731

============================================================
time elapsed: 0:19:08
train iter: 371
num of updates: 37200
dynamics loss: 0.87650

============================================================
time elapsed: 0:19:11
train iter: 372
num of updates: 37300
dynamics loss: 0.87642

============================================================
time elapsed: 0:19:14
train iter: 373
num of updates: 37400
dynamics loss: 0.87586

============================================================
time elapsed: 0:19:17
train iter: 374
num of updates: 37500
dynamics loss: 0.87541

============================================================
time elapsed: 0:19:20
train iter: 375
num of updates: 37600
dynamics loss: 0.87458

============================================================
time elapsed: 0:19:23
train iter: 376
num of updates: 37700
dynamics loss: 0.87373

============================================================
time elapsed: 0:19:25
train iter: 377
num of updates: 37800
dynamics loss: 0.87388

============================================================
time elapsed: 0:19:28
train iter: 378
num of updates: 37900
dynamics loss: 0.87239

============================================================
time elapsed: 0:19:31
train iter: 379
num of updates: 38000
dynamics loss: 0.87238

============================================================
time elapsed: 0:19:34
train iter: 380
num of updates: 38100
dynamics loss: 0.87133

============================================================
time elapsed: 0:19:37
train iter: 381
num of updates: 38200
dynamics loss: 0.87063

============================================================
time elapsed: 0:19:40
train iter: 382
num of updates: 38300
dynamics loss: 0.87101

============================================================
time elapsed: 0:19:43
train iter: 383
num of updates: 38400
dynamics loss: 0.86982

============================================================
time elapsed: 0:19:46
train iter: 384
num of updates: 38500
dynamics loss: 0.86940

============================================================
time elapsed: 0:19:48
train iter: 385
num of updates: 38600
dynamics loss: 0.86830

============================================================
time elapsed: 0:19:51
train iter: 386
num of updates: 38700
dynamics loss: 0.86778

============================================================
time elapsed: 0:19:54
train iter: 387
num of updates: 38800
dynamics loss: 0.86748

============================================================
time elapsed: 0:19:57
train iter: 388
num of updates: 38900
dynamics loss: 0.86640

============================================================
time elapsed: 0:20:00
train iter: 389
num of updates: 39000
dynamics loss: 0.86610

============================================================
time elapsed: 0:20:03
train iter: 390
num of updates: 39100
dynamics loss: 0.86529

============================================================
time elapsed: 0:20:06
train iter: 391
num of updates: 39200
dynamics loss: 0.86517

============================================================
time elapsed: 0:20:08
train iter: 392
num of updates: 39300
dynamics loss: 0.86452

============================================================
time elapsed: 0:20:11
train iter: 393
num of updates: 39400
dynamics loss: 0.86380

============================================================
time elapsed: 0:20:14
train iter: 394
num of updates: 39500
dynamics loss: 0.86377

============================================================
time elapsed: 0:20:17
train iter: 395
num of updates: 39600
dynamics loss: 0.86258

============================================================
time elapsed: 0:20:20
train iter: 396
num of updates: 39700
dynamics loss: 0.86227

============================================================
time elapsed: 0:20:23
train iter: 397
num of updates: 39800
dynamics loss: 0.86165

============================================================
time elapsed: 0:20:26
train iter: 398
num of updates: 39900
dynamics loss: 0.86071

============================================================
time elapsed: 0:20:29
train iter: 399
num of updates: 40000
dynamics loss: 0.86060

============================================================
time elapsed: 0:20:31
train iter: 400
num of updates: 40100
dynamics loss: 0.85973

============================================================
time elapsed: 0:20:34
train iter: 401
num of updates: 40200
dynamics loss: 0.85981

============================================================
time elapsed: 0:20:37
train iter: 402
num of updates: 40300
dynamics loss: 0.85922

============================================================
time elapsed: 0:20:40
train iter: 403
num of updates: 40400
dynamics loss: 0.85869

============================================================
time elapsed: 0:20:43
train iter: 404
num of updates: 40500
dynamics loss: 0.85786

============================================================
time elapsed: 0:20:46
train iter: 405
num of updates: 40600
dynamics loss: 0.85732

============================================================
time elapsed: 0:20:49
train iter: 406
num of updates: 40700
dynamics loss: 0.85666

============================================================
time elapsed: 0:20:51
train iter: 407
num of updates: 40800
dynamics loss: 0.85649

============================================================
time elapsed: 0:20:54
train iter: 408
num of updates: 40900
dynamics loss: 0.85568

============================================================
time elapsed: 0:20:57
train iter: 409
num of updates: 41000
dynamics loss: 0.85502

============================================================
time elapsed: 0:21:00
train iter: 410
num of updates: 41100
dynamics loss: 0.85488

============================================================
time elapsed: 0:21:03
train iter: 411
num of updates: 41200
dynamics loss: 0.85473

============================================================
time elapsed: 0:21:06
train iter: 412
num of updates: 41300
dynamics loss: 0.85308

============================================================
time elapsed: 0:21:09
train iter: 413
num of updates: 41400
dynamics loss: 0.85268

============================================================
time elapsed: 0:21:11
train iter: 414
num of updates: 41500
dynamics loss: 0.85238

============================================================
time elapsed: 0:21:14
train iter: 415
num of updates: 41600
dynamics loss: 0.85161

============================================================
time elapsed: 0:21:17
train iter: 416
num of updates: 41700
dynamics loss: 0.85100

============================================================
time elapsed: 0:21:20
train iter: 417
num of updates: 41800
dynamics loss: 0.85086

============================================================
time elapsed: 0:21:23
train iter: 418
num of updates: 41900
dynamics loss: 0.85012

============================================================
time elapsed: 0:21:26
train iter: 419
num of updates: 42000
dynamics loss: 0.85004

============================================================
time elapsed: 0:21:29
train iter: 420
num of updates: 42100
dynamics loss: 0.84941

============================================================
time elapsed: 0:21:32
train iter: 421
num of updates: 42200
dynamics loss: 0.84921

============================================================
time elapsed: 0:21:34
train iter: 422
num of updates: 42300
dynamics loss: 0.84798

============================================================
time elapsed: 0:21:37
train iter: 423
num of updates: 42400
dynamics loss: 0.84797

============================================================
time elapsed: 0:21:40
train iter: 424
num of updates: 42500
dynamics loss: 0.84720

============================================================
time elapsed: 0:21:43
train iter: 425
num of updates: 42600
dynamics loss: 0.84727

============================================================
time elapsed: 0:21:46
train iter: 426
num of updates: 42700
dynamics loss: 0.84614

============================================================
time elapsed: 0:21:49
train iter: 427
num of updates: 42800
dynamics loss: 0.84593

============================================================
time elapsed: 0:21:52
train iter: 428
num of updates: 42900
dynamics loss: 0.84583

============================================================
time elapsed: 0:21:54
train iter: 429
num of updates: 43000
dynamics loss: 0.84520

============================================================
time elapsed: 0:21:57
train iter: 430
num of updates: 43100
dynamics loss: 0.84479

============================================================
time elapsed: 0:22:00
train iter: 431
num of updates: 43200
dynamics loss: 0.84365

============================================================
time elapsed: 0:22:03
train iter: 432
num of updates: 43300
dynamics loss: 0.84333

============================================================
time elapsed: 0:22:06
train iter: 433
num of updates: 43400
dynamics loss: 0.84283

============================================================
time elapsed: 0:22:09
train iter: 434
num of updates: 43500
dynamics loss: 0.84263

============================================================
time elapsed: 0:22:12
train iter: 435
num of updates: 43600
dynamics loss: 0.84165

============================================================
time elapsed: 0:22:15
train iter: 436
num of updates: 43700
dynamics loss: 0.84166

============================================================
time elapsed: 0:22:17
train iter: 437
num of updates: 43800
dynamics loss: 0.84085

============================================================
time elapsed: 0:22:20
train iter: 438
num of updates: 43900
dynamics loss: 0.84103

============================================================
time elapsed: 0:22:23
train iter: 439
num of updates: 44000
dynamics loss: 0.83989

============================================================
time elapsed: 0:22:26
train iter: 440
num of updates: 44100
dynamics loss: 0.83991

============================================================
time elapsed: 0:22:29
train iter: 441
num of updates: 44200
dynamics loss: 0.83873

============================================================
time elapsed: 0:22:32
train iter: 442
num of updates: 44300
dynamics loss: 0.83854

============================================================
time elapsed: 0:22:35
train iter: 443
num of updates: 44400
dynamics loss: 0.83763

============================================================
time elapsed: 0:22:37
train iter: 444
num of updates: 44500
dynamics loss: 0.83718

============================================================
time elapsed: 0:22:40
train iter: 445
num of updates: 44600
dynamics loss: 0.83660

============================================================
time elapsed: 0:22:43
train iter: 446
num of updates: 44700
dynamics loss: 0.83716

============================================================
time elapsed: 0:22:46
train iter: 447
num of updates: 44800
dynamics loss: 0.83643

============================================================
time elapsed: 0:22:49
train iter: 448
num of updates: 44900
dynamics loss: 0.83585

============================================================
time elapsed: 0:22:52
train iter: 449
num of updates: 45000
dynamics loss: 0.83511

============================================================
time elapsed: 0:22:55
train iter: 450
num of updates: 45100
dynamics loss: 0.83468

============================================================
time elapsed: 0:22:57
train iter: 451
num of updates: 45200
dynamics loss: 0.83461

============================================================
time elapsed: 0:23:00
train iter: 452
num of updates: 45300
dynamics loss: 0.83415

============================================================
time elapsed: 0:23:03
train iter: 453
num of updates: 45400
dynamics loss: 0.83353

============================================================
time elapsed: 0:23:06
train iter: 454
num of updates: 45500
dynamics loss: 0.83324

============================================================
time elapsed: 0:23:09
train iter: 455
num of updates: 45600
dynamics loss: 0.83233

============================================================
time elapsed: 0:23:12
train iter: 456
num of updates: 45700
dynamics loss: 0.83218

============================================================
time elapsed: 0:23:15
train iter: 457
num of updates: 45800
dynamics loss: 0.83120

============================================================
time elapsed: 0:23:18
train iter: 458
num of updates: 45900
dynamics loss: 0.83116

============================================================
time elapsed: 0:23:20
train iter: 459
num of updates: 46000
dynamics loss: 0.83040

============================================================
time elapsed: 0:23:23
train iter: 460
num of updates: 46100
dynamics loss: 0.83009

============================================================
time elapsed: 0:23:26
train iter: 461
num of updates: 46200
dynamics loss: 0.82987

============================================================
time elapsed: 0:23:29
train iter: 462
num of updates: 46300
dynamics loss: 0.82948

============================================================
time elapsed: 0:23:32
train iter: 463
num of updates: 46400
dynamics loss: 0.82913

============================================================
time elapsed: 0:23:35
train iter: 464
num of updates: 46500
dynamics loss: 0.82796

============================================================
time elapsed: 0:23:38
train iter: 465
num of updates: 46600
dynamics loss: 0.82779

============================================================
time elapsed: 0:23:40
train iter: 466
num of updates: 46700
dynamics loss: 0.82750

============================================================
time elapsed: 0:23:43
train iter: 467
num of updates: 46800
dynamics loss: 0.82678

============================================================
time elapsed: 0:23:46
train iter: 468
num of updates: 46900
dynamics loss: 0.82661

============================================================
time elapsed: 0:23:49
train iter: 469
num of updates: 47000
dynamics loss: 0.82635

============================================================
time elapsed: 0:23:52
train iter: 470
num of updates: 47100
dynamics loss: 0.82583

============================================================
time elapsed: 0:23:55
train iter: 471
num of updates: 47200
dynamics loss: 0.82538

============================================================
time elapsed: 0:23:58
train iter: 472
num of updates: 47300
dynamics loss: 0.82486

============================================================
time elapsed: 0:24:00
train iter: 473
num of updates: 47400
dynamics loss: 0.82460

============================================================
time elapsed: 0:24:03
train iter: 474
num of updates: 47500
dynamics loss: 0.82406

============================================================
time elapsed: 0:24:06
train iter: 475
num of updates: 47600
dynamics loss: 0.82301

============================================================
time elapsed: 0:24:09
train iter: 476
num of updates: 47700
dynamics loss: 0.82300

============================================================
time elapsed: 0:24:12
train iter: 477
num of updates: 47800
dynamics loss: 0.82345

============================================================
time elapsed: 0:24:15
train iter: 478
num of updates: 47900
dynamics loss: 0.82146

============================================================
time elapsed: 0:24:18
train iter: 479
num of updates: 48000
dynamics loss: 0.82123

============================================================
time elapsed: 0:24:21
train iter: 480
num of updates: 48100
dynamics loss: 0.82084

============================================================
time elapsed: 0:24:23
train iter: 481
num of updates: 48200
dynamics loss: 0.82089

============================================================
time elapsed: 0:24:26
train iter: 482
num of updates: 48300
dynamics loss: 0.82047

============================================================
time elapsed: 0:24:29
train iter: 483
num of updates: 48400
dynamics loss: 0.81999

============================================================
time elapsed: 0:24:32
train iter: 484
num of updates: 48500
dynamics loss: 0.81940

============================================================
time elapsed: 0:24:35
train iter: 485
num of updates: 48600
dynamics loss: 0.81919

============================================================
time elapsed: 0:24:38
train iter: 486
num of updates: 48700
dynamics loss: 0.81869

============================================================
time elapsed: 0:24:41
train iter: 487
num of updates: 48800
dynamics loss: 0.81869

============================================================
time elapsed: 0:24:43
train iter: 488
num of updates: 48900
dynamics loss: 0.81765

============================================================
time elapsed: 0:24:46
train iter: 489
num of updates: 49000
dynamics loss: 0.81728

============================================================
time elapsed: 0:24:49
train iter: 490
num of updates: 49100
dynamics loss: 0.81716

============================================================
time elapsed: 0:24:52
train iter: 491
num of updates: 49200
dynamics loss: 0.81645

============================================================
time elapsed: 0:24:55
train iter: 492
num of updates: 49300
dynamics loss: 0.81604

============================================================
time elapsed: 0:24:58
train iter: 493
num of updates: 49400
dynamics loss: 0.81551

============================================================
time elapsed: 0:25:01
train iter: 494
num of updates: 49500
dynamics loss: 0.81483

============================================================
time elapsed: 0:25:03
train iter: 495
num of updates: 49600
dynamics loss: 0.81525

============================================================
time elapsed: 0:25:06
train iter: 496
num of updates: 49700
dynamics loss: 0.81467

============================================================
time elapsed: 0:25:09
train iter: 497
num of updates: 49800
dynamics loss: 0.81414

============================================================
time elapsed: 0:25:12
train iter: 498
num of updates: 49900
dynamics loss: 0.81355

============================================================
time elapsed: 0:25:15
train iter: 499
num of updates: 50000
dynamics loss: 0.81339

============================================================
time elapsed: 0:25:18
train iter: 500
num of updates: 50100
dynamics loss: 0.81245

============================================================
time elapsed: 0:25:21
train iter: 501
num of updates: 50200
dynamics loss: 0.81254

============================================================
time elapsed: 0:25:24
train iter: 502
num of updates: 50300
dynamics loss: 0.81164

============================================================
time elapsed: 0:25:26
train iter: 503
num of updates: 50400
dynamics loss: 0.81124

============================================================
time elapsed: 0:25:29
train iter: 504
num of updates: 50500
dynamics loss: 0.81073

============================================================
time elapsed: 0:25:32
train iter: 505
num of updates: 50600
dynamics loss: 0.81090

============================================================
time elapsed: 0:25:35
train iter: 506
num of updates: 50700
dynamics loss: 0.80997

============================================================
time elapsed: 0:25:38
train iter: 507
num of updates: 50800
dynamics loss: 0.80987

============================================================
time elapsed: 0:25:41
train iter: 508
num of updates: 50900
dynamics loss: 0.80935

============================================================
time elapsed: 0:25:44
train iter: 509
num of updates: 51000
dynamics loss: 0.80914

============================================================
time elapsed: 0:25:46
train iter: 510
num of updates: 51100
dynamics loss: 0.80883

============================================================
time elapsed: 0:25:49
train iter: 511
num of updates: 51200
dynamics loss: 0.80809

============================================================
time elapsed: 0:25:52
train iter: 512
num of updates: 51300
dynamics loss: 0.80787

============================================================
time elapsed: 0:25:55
train iter: 513
num of updates: 51400
dynamics loss: 0.80732

============================================================
time elapsed: 0:25:58
train iter: 514
num of updates: 51500
dynamics loss: 0.80703

============================================================
time elapsed: 0:26:01
train iter: 515
num of updates: 51600
dynamics loss: 0.80681

============================================================
time elapsed: 0:26:04
train iter: 516
num of updates: 51700
dynamics loss: 0.80592

============================================================
time elapsed: 0:26:06
train iter: 517
num of updates: 51800
dynamics loss: 0.80577

============================================================
time elapsed: 0:26:09
train iter: 518
num of updates: 51900
dynamics loss: 0.80553

============================================================
time elapsed: 0:26:12
train iter: 519
num of updates: 52000
dynamics loss: 0.80442

============================================================
time elapsed: 0:26:15
train iter: 520
num of updates: 52100
dynamics loss: 0.80449

============================================================
time elapsed: 0:26:18
train iter: 521
num of updates: 52200
dynamics loss: 0.80469

============================================================
time elapsed: 0:26:21
train iter: 522
num of updates: 52300
dynamics loss: 0.80364

============================================================
time elapsed: 0:26:24
train iter: 523
num of updates: 52400
dynamics loss: 0.80331

============================================================
time elapsed: 0:26:27
train iter: 524
num of updates: 52500
dynamics loss: 0.80240

============================================================
time elapsed: 0:26:29
train iter: 525
num of updates: 52600
dynamics loss: 0.80264

============================================================
time elapsed: 0:26:32
train iter: 526
num of updates: 52700
dynamics loss: 0.80237

============================================================
time elapsed: 0:26:35
train iter: 527
num of updates: 52800
dynamics loss: 0.80153

============================================================
time elapsed: 0:26:38
train iter: 528
num of updates: 52900
dynamics loss: 0.80100

============================================================
time elapsed: 0:26:41
train iter: 529
num of updates: 53000
dynamics loss: 0.80112

============================================================
time elapsed: 0:26:44
train iter: 530
num of updates: 53100
dynamics loss: 0.80102

============================================================
time elapsed: 0:26:47
train iter: 531
num of updates: 53200
dynamics loss: 0.80021

============================================================
time elapsed: 0:26:49
train iter: 532
num of updates: 53300
dynamics loss: 0.79944

============================================================
time elapsed: 0:26:52
train iter: 533
num of updates: 53400
dynamics loss: 0.79974

============================================================
time elapsed: 0:26:55
train iter: 534
num of updates: 53500
dynamics loss: 0.79895

============================================================
time elapsed: 0:26:58
train iter: 535
num of updates: 53600
dynamics loss: 0.79864

============================================================
time elapsed: 0:27:01
train iter: 536
num of updates: 53700
dynamics loss: 0.79851

============================================================
time elapsed: 0:27:04
train iter: 537
num of updates: 53800
dynamics loss: 0.79794

============================================================
time elapsed: 0:27:07
train iter: 538
num of updates: 53900
dynamics loss: 0.79734

============================================================
time elapsed: 0:27:09
train iter: 539
num of updates: 54000
dynamics loss: 0.79746

============================================================
time elapsed: 0:27:12
train iter: 540
num of updates: 54100
dynamics loss: 0.79679

============================================================
time elapsed: 0:27:15
train iter: 541
num of updates: 54200
dynamics loss: 0.79653

============================================================
time elapsed: 0:27:18
train iter: 542
num of updates: 54300
dynamics loss: 0.79553

============================================================
time elapsed: 0:27:21
train iter: 543
num of updates: 54400
dynamics loss: 0.79504

============================================================
time elapsed: 0:27:24
train iter: 544
num of updates: 54500
dynamics loss: 0.79471

============================================================
time elapsed: 0:27:27
train iter: 545
num of updates: 54600
dynamics loss: 0.79470

============================================================
time elapsed: 0:27:30
train iter: 546
num of updates: 54700
dynamics loss: 0.79384

============================================================
time elapsed: 0:27:32
train iter: 547
num of updates: 54800
dynamics loss: 0.79396

============================================================
time elapsed: 0:27:35
train iter: 548
num of updates: 54900
dynamics loss: 0.79386

============================================================
time elapsed: 0:27:38
train iter: 549
num of updates: 55000
dynamics loss: 0.79273

============================================================
time elapsed: 0:27:41
train iter: 550
num of updates: 55100
dynamics loss: 0.79236

============================================================
time elapsed: 0:27:44
train iter: 551
num of updates: 55200
dynamics loss: 0.79263

============================================================
time elapsed: 0:27:47
train iter: 552
num of updates: 55300
dynamics loss: 0.79198

============================================================
time elapsed: 0:27:50
train iter: 553
num of updates: 55400
dynamics loss: 0.79142

============================================================
time elapsed: 0:27:52
train iter: 554
num of updates: 55500
dynamics loss: 0.79086

============================================================
time elapsed: 0:27:55
train iter: 555
num of updates: 55600
dynamics loss: 0.79045

============================================================
time elapsed: 0:27:58
train iter: 556
num of updates: 55700
dynamics loss: 0.79024

============================================================
time elapsed: 0:28:01
train iter: 557
num of updates: 55800
dynamics loss: 0.78985

============================================================
time elapsed: 0:28:04
train iter: 558
num of updates: 55900
dynamics loss: 0.78950

============================================================
time elapsed: 0:28:07
train iter: 559
num of updates: 56000
dynamics loss: 0.78903

============================================================
time elapsed: 0:28:10
train iter: 560
num of updates: 56100
dynamics loss: 0.78898

============================================================
time elapsed: 0:28:13
train iter: 561
num of updates: 56200
dynamics loss: 0.78826

============================================================
time elapsed: 0:28:15
train iter: 562
num of updates: 56300
dynamics loss: 0.78777

============================================================
time elapsed: 0:28:18
train iter: 563
num of updates: 56400
dynamics loss: 0.78762

============================================================
time elapsed: 0:28:21
train iter: 564
num of updates: 56500
dynamics loss: 0.78695

============================================================
time elapsed: 0:28:24
train iter: 565
num of updates: 56600
dynamics loss: 0.78642

============================================================
time elapsed: 0:28:27
train iter: 566
num of updates: 56700
dynamics loss: 0.78651

============================================================
time elapsed: 0:28:30
train iter: 567
num of updates: 56800
dynamics loss: 0.78619

============================================================
time elapsed: 0:28:33
train iter: 568
num of updates: 56900
dynamics loss: 0.78587

============================================================
time elapsed: 0:28:35
train iter: 569
num of updates: 57000
dynamics loss: 0.78501

============================================================
time elapsed: 0:28:38
train iter: 570
num of updates: 57100
dynamics loss: 0.78484

============================================================
time elapsed: 0:28:41
train iter: 571
num of updates: 57200
dynamics loss: 0.78489

============================================================
time elapsed: 0:28:44
train iter: 572
num of updates: 57300
dynamics loss: 0.78406

============================================================
time elapsed: 0:28:47
train iter: 573
num of updates: 57400
dynamics loss: 0.78423

============================================================
time elapsed: 0:28:50
train iter: 574
num of updates: 57500
dynamics loss: 0.78397

============================================================
time elapsed: 0:28:53
train iter: 575
num of updates: 57600
dynamics loss: 0.78309

============================================================
time elapsed: 0:28:55
train iter: 576
num of updates: 57700
dynamics loss: 0.78295

============================================================
time elapsed: 0:28:58
train iter: 577
num of updates: 57800
dynamics loss: 0.78188

============================================================
time elapsed: 0:29:01
train iter: 578
num of updates: 57900
dynamics loss: 0.78196

============================================================
time elapsed: 0:29:04
train iter: 579
num of updates: 58000
dynamics loss: 0.78128

============================================================
time elapsed: 0:29:07
train iter: 580
num of updates: 58100
dynamics loss: 0.78074

============================================================
time elapsed: 0:29:10
train iter: 581
num of updates: 58200
dynamics loss: 0.78049

============================================================
time elapsed: 0:29:13
train iter: 582
num of updates: 58300
dynamics loss: 0.78044

============================================================
time elapsed: 0:29:16
train iter: 583
num of updates: 58400
dynamics loss: 0.77977

============================================================
time elapsed: 0:29:18
train iter: 584
num of updates: 58500
dynamics loss: 0.77962

============================================================
time elapsed: 0:29:21
train iter: 585
num of updates: 58600
dynamics loss: 0.77943

============================================================
time elapsed: 0:29:24
train iter: 586
num of updates: 58700
dynamics loss: 0.77847

============================================================
time elapsed: 0:29:27
train iter: 587
num of updates: 58800
dynamics loss: 0.77817

============================================================
time elapsed: 0:29:30
train iter: 588
num of updates: 58900
dynamics loss: 0.77791

============================================================
time elapsed: 0:29:33
train iter: 589
num of updates: 59000
dynamics loss: 0.77769

============================================================
time elapsed: 0:29:36
train iter: 590
num of updates: 59100
dynamics loss: 0.77696

============================================================
time elapsed: 0:29:38
train iter: 591
num of updates: 59200
dynamics loss: 0.77693

============================================================
time elapsed: 0:29:41
train iter: 592
num of updates: 59300
dynamics loss: 0.77618

============================================================
time elapsed: 0:29:44
train iter: 593
num of updates: 59400
dynamics loss: 0.77587

============================================================
time elapsed: 0:29:47
train iter: 594
num of updates: 59500
dynamics loss: 0.77595

============================================================
time elapsed: 0:29:50
train iter: 595
num of updates: 59600
dynamics loss: 0.77588

============================================================
time elapsed: 0:29:53
train iter: 596
num of updates: 59700
dynamics loss: 0.77469

============================================================
time elapsed: 0:29:56
train iter: 597
num of updates: 59800
dynamics loss: 0.77481

============================================================
time elapsed: 0:29:58
train iter: 598
num of updates: 59900
dynamics loss: 0.77432

============================================================
time elapsed: 0:30:01
train iter: 599
num of updates: 60000
dynamics loss: 0.77375

============================================================
time elapsed: 0:30:04
train iter: 600
num of updates: 60100
dynamics loss: 0.77326

============================================================
time elapsed: 0:30:07
train iter: 601
num of updates: 60200
dynamics loss: 0.77334

============================================================
time elapsed: 0:30:10
train iter: 602
num of updates: 60300
dynamics loss: 0.77272

============================================================
time elapsed: 0:30:13
train iter: 603
num of updates: 60400
dynamics loss: 0.77269

============================================================
time elapsed: 0:30:16
train iter: 604
num of updates: 60500
dynamics loss: 0.77191

============================================================
time elapsed: 0:30:19
train iter: 605
num of updates: 60600
dynamics loss: 0.77128

============================================================
time elapsed: 0:30:21
train iter: 606
num of updates: 60700
dynamics loss: 0.77089

============================================================
time elapsed: 0:30:24
train iter: 607
num of updates: 60800
dynamics loss: 0.77077

============================================================
time elapsed: 0:30:27
train iter: 608
num of updates: 60900
dynamics loss: 0.77074

============================================================
time elapsed: 0:30:30
train iter: 609
num of updates: 61000
dynamics loss: 0.77025

============================================================
time elapsed: 0:30:33
train iter: 610
num of updates: 61100
dynamics loss: 0.76970

============================================================
time elapsed: 0:30:36
train iter: 611
num of updates: 61200
dynamics loss: 0.76921

============================================================
time elapsed: 0:30:39
train iter: 612
num of updates: 61300
dynamics loss: 0.76906

============================================================
time elapsed: 0:30:41
train iter: 613
num of updates: 61400
dynamics loss: 0.76856

============================================================
time elapsed: 0:30:44
train iter: 614
num of updates: 61500
dynamics loss: 0.76818

============================================================
time elapsed: 0:30:47
train iter: 615
num of updates: 61600
dynamics loss: 0.76804

============================================================
time elapsed: 0:30:50
train iter: 616
num of updates: 61700
dynamics loss: 0.76752

============================================================
time elapsed: 0:30:53
train iter: 617
num of updates: 61800
dynamics loss: 0.76708

============================================================
time elapsed: 0:30:56
train iter: 618
num of updates: 61900
dynamics loss: 0.76641

============================================================
time elapsed: 0:30:59
train iter: 619
num of updates: 62000
dynamics loss: 0.76627

============================================================
time elapsed: 0:31:02
train iter: 620
num of updates: 62100
dynamics loss: 0.76573

============================================================
time elapsed: 0:31:04
train iter: 621
num of updates: 62200
dynamics loss: 0.76551

============================================================
time elapsed: 0:31:07
train iter: 622
num of updates: 62300
dynamics loss: 0.76485

============================================================
time elapsed: 0:31:10
train iter: 623
num of updates: 62400
dynamics loss: 0.76521

============================================================
time elapsed: 0:31:13
train iter: 624
num of updates: 62500
dynamics loss: 0.76488

============================================================
time elapsed: 0:31:16
train iter: 625
num of updates: 62600
dynamics loss: 0.76421

============================================================
time elapsed: 0:31:19
train iter: 626
num of updates: 62700
dynamics loss: 0.76377

============================================================
time elapsed: 0:31:22
train iter: 627
num of updates: 62800
dynamics loss: 0.76355

============================================================
time elapsed: 0:31:24
train iter: 628
num of updates: 62900
dynamics loss: 0.76312

============================================================
time elapsed: 0:31:27
train iter: 629
num of updates: 63000
dynamics loss: 0.76283

============================================================
time elapsed: 0:31:30
train iter: 630
num of updates: 63100
dynamics loss: 0.76218

============================================================
time elapsed: 0:31:33
train iter: 631
num of updates: 63200
dynamics loss: 0.76160

============================================================
time elapsed: 0:31:36
train iter: 632
num of updates: 63300
dynamics loss: 0.76180

============================================================
time elapsed: 0:31:39
train iter: 633
num of updates: 63400
dynamics loss: 0.76151

============================================================
time elapsed: 0:31:42
train iter: 634
num of updates: 63500
dynamics loss: 0.76042

============================================================
time elapsed: 0:31:44
train iter: 635
num of updates: 63600
dynamics loss: 0.76051

============================================================
time elapsed: 0:31:47
train iter: 636
num of updates: 63700
dynamics loss: 0.75935

============================================================
time elapsed: 0:31:50
train iter: 637
num of updates: 63800
dynamics loss: 0.75964

============================================================
time elapsed: 0:31:53
train iter: 638
num of updates: 63900
dynamics loss: 0.75961

============================================================
time elapsed: 0:31:56
train iter: 639
num of updates: 64000
dynamics loss: 0.75878

============================================================
time elapsed: 0:31:59
train iter: 640
num of updates: 64100
dynamics loss: 0.75876

============================================================
time elapsed: 0:32:02
train iter: 641
num of updates: 64200
dynamics loss: 0.75794

============================================================
time elapsed: 0:32:05
train iter: 642
num of updates: 64300
dynamics loss: 0.75774

============================================================
time elapsed: 0:32:07
train iter: 643
num of updates: 64400
dynamics loss: 0.75722

============================================================
time elapsed: 0:32:10
train iter: 644
num of updates: 64500
dynamics loss: 0.75745

============================================================
time elapsed: 0:32:13
train iter: 645
num of updates: 64600
dynamics loss: 0.75677

============================================================
time elapsed: 0:32:16
train iter: 646
num of updates: 64700
dynamics loss: 0.75666

============================================================
time elapsed: 0:32:19
train iter: 647
num of updates: 64800
dynamics loss: 0.75639

============================================================
time elapsed: 0:32:22
train iter: 648
num of updates: 64900
dynamics loss: 0.75561

============================================================
time elapsed: 0:32:25
train iter: 649
num of updates: 65000
dynamics loss: 0.75526

============================================================
time elapsed: 0:32:27
train iter: 650
num of updates: 65100
dynamics loss: 0.75458

============================================================
time elapsed: 0:32:30
train iter: 651
num of updates: 65200
dynamics loss: 0.75485

============================================================
time elapsed: 0:32:33
train iter: 652
num of updates: 65300
dynamics loss: 0.75405

============================================================
time elapsed: 0:32:36
train iter: 653
num of updates: 65400
dynamics loss: 0.75382

============================================================
time elapsed: 0:32:39
train iter: 654
num of updates: 65500
dynamics loss: 0.75376

============================================================
time elapsed: 0:32:42
train iter: 655
num of updates: 65600
dynamics loss: 0.75328

============================================================
time elapsed: 0:32:45
train iter: 656
num of updates: 65700
dynamics loss: 0.75293

============================================================
time elapsed: 0:32:47
train iter: 657
num of updates: 65800
dynamics loss: 0.75305

============================================================
time elapsed: 0:32:50
train iter: 658
num of updates: 65900
dynamics loss: 0.75204

============================================================
time elapsed: 0:32:53
train iter: 659
num of updates: 66000
dynamics loss: 0.75127

============================================================
time elapsed: 0:32:56
train iter: 660
num of updates: 66100
dynamics loss: 0.75163

============================================================
time elapsed: 0:32:59
train iter: 661
num of updates: 66200
dynamics loss: 0.75082

============================================================
time elapsed: 0:33:02
train iter: 662
num of updates: 66300
dynamics loss: 0.75050

============================================================
time elapsed: 0:33:05
train iter: 663
num of updates: 66400
dynamics loss: 0.75004

============================================================
time elapsed: 0:33:08
train iter: 664
num of updates: 66500
dynamics loss: 0.74972

============================================================
time elapsed: 0:33:10
train iter: 665
num of updates: 66600
dynamics loss: 0.74920

============================================================
time elapsed: 0:33:13
train iter: 666
num of updates: 66700
dynamics loss: 0.74898

============================================================
time elapsed: 0:33:16
train iter: 667
num of updates: 66800
dynamics loss: 0.74879

============================================================
time elapsed: 0:33:19
train iter: 668
num of updates: 66900
dynamics loss: 0.74818

============================================================
time elapsed: 0:33:22
train iter: 669
num of updates: 67000
dynamics loss: 0.74807

============================================================
time elapsed: 0:33:25
train iter: 670
num of updates: 67100
dynamics loss: 0.74806

============================================================
time elapsed: 0:33:28
train iter: 671
num of updates: 67200
dynamics loss: 0.74713

============================================================
time elapsed: 0:33:30
train iter: 672
num of updates: 67300
dynamics loss: 0.74706

============================================================
time elapsed: 0:33:33
train iter: 673
num of updates: 67400
dynamics loss: 0.74649

============================================================
time elapsed: 0:33:36
train iter: 674
num of updates: 67500
dynamics loss: 0.74605

============================================================
time elapsed: 0:33:39
train iter: 675
num of updates: 67600
dynamics loss: 0.74545

============================================================
time elapsed: 0:33:42
train iter: 676
num of updates: 67700
dynamics loss: 0.74495

============================================================
time elapsed: 0:33:45
train iter: 677
num of updates: 67800
dynamics loss: 0.74537

============================================================
time elapsed: 0:33:48
train iter: 678
num of updates: 67900
dynamics loss: 0.74418

============================================================
time elapsed: 0:33:51
train iter: 679
num of updates: 68000
dynamics loss: 0.74442

============================================================
time elapsed: 0:33:53
train iter: 680
num of updates: 68100
dynamics loss: 0.74376

============================================================
time elapsed: 0:33:56
train iter: 681
num of updates: 68200
dynamics loss: 0.74323

============================================================
time elapsed: 0:33:59
train iter: 682
num of updates: 68300
dynamics loss: 0.74265

============================================================
time elapsed: 0:34:02
train iter: 683
num of updates: 68400
dynamics loss: 0.74251

============================================================
time elapsed: 0:34:05
train iter: 684
num of updates: 68500
dynamics loss: 0.74250

============================================================
time elapsed: 0:34:08
train iter: 685
num of updates: 68600
dynamics loss: 0.74188

============================================================
time elapsed: 0:34:11
train iter: 686
num of updates: 68700
dynamics loss: 0.74188

============================================================
time elapsed: 0:34:13
train iter: 687
num of updates: 68800
dynamics loss: 0.74126

============================================================
time elapsed: 0:34:16
train iter: 688
num of updates: 68900
dynamics loss: 0.74049

============================================================
time elapsed: 0:34:19
train iter: 689
num of updates: 69000
dynamics loss: 0.74029

============================================================
time elapsed: 0:34:22
train iter: 690
num of updates: 69100
dynamics loss: 0.73959

============================================================
time elapsed: 0:34:25
train iter: 691
num of updates: 69200
dynamics loss: 0.73930

============================================================
time elapsed: 0:34:28
train iter: 692
num of updates: 69300
dynamics loss: 0.73941

============================================================
time elapsed: 0:34:31
train iter: 693
num of updates: 69400
dynamics loss: 0.73910

============================================================
time elapsed: 0:34:33
train iter: 694
num of updates: 69500
dynamics loss: 0.73852

============================================================
time elapsed: 0:34:36
train iter: 695
num of updates: 69600
dynamics loss: 0.73820

============================================================
time elapsed: 0:34:39
train iter: 696
num of updates: 69700
dynamics loss: 0.73770

============================================================
time elapsed: 0:34:42
train iter: 697
num of updates: 69800
dynamics loss: 0.73778

============================================================
time elapsed: 0:34:45
train iter: 698
num of updates: 69900
dynamics loss: 0.73759

============================================================
time elapsed: 0:34:48
train iter: 699
num of updates: 70000
dynamics loss: 0.73685

============================================================
time elapsed: 0:34:51
train iter: 700
num of updates: 70100
dynamics loss: 0.73584

============================================================
time elapsed: 0:34:54
train iter: 701
num of updates: 70200
dynamics loss: 0.73559

============================================================
time elapsed: 0:34:56
train iter: 702
num of updates: 70300
dynamics loss: 0.73585

============================================================
time elapsed: 0:34:59
train iter: 703
num of updates: 70400
dynamics loss: 0.73526

============================================================
time elapsed: 0:35:02
train iter: 704
num of updates: 70500
dynamics loss: 0.73476

============================================================
time elapsed: 0:35:05
train iter: 705
num of updates: 70600
dynamics loss: 0.73466

============================================================
time elapsed: 0:35:08
train iter: 706
num of updates: 70700
dynamics loss: 0.73414

============================================================
time elapsed: 0:35:11
train iter: 707
num of updates: 70800
dynamics loss: 0.73405

============================================================
time elapsed: 0:35:14
train iter: 708
num of updates: 70900
dynamics loss: 0.73342

============================================================
time elapsed: 0:35:16
train iter: 709
num of updates: 71000
dynamics loss: 0.73305

============================================================
time elapsed: 0:35:19
train iter: 710
num of updates: 71100
dynamics loss: 0.73271

============================================================
time elapsed: 0:35:22
train iter: 711
num of updates: 71200
dynamics loss: 0.73279

============================================================
time elapsed: 0:35:25
train iter: 712
num of updates: 71300
dynamics loss: 0.73226

============================================================
time elapsed: 0:35:28
train iter: 713
num of updates: 71400
dynamics loss: 0.73124

============================================================
time elapsed: 0:35:31
train iter: 714
num of updates: 71500
dynamics loss: 0.73129

============================================================
time elapsed: 0:35:34
train iter: 715
num of updates: 71600
dynamics loss: 0.73093

============================================================
time elapsed: 0:35:36
train iter: 716
num of updates: 71700
dynamics loss: 0.73089

============================================================
time elapsed: 0:35:39
train iter: 717
num of updates: 71800
dynamics loss: 0.73006

============================================================
time elapsed: 0:35:42
train iter: 718
num of updates: 71900
dynamics loss: 0.72949

============================================================
time elapsed: 0:35:45
train iter: 719
num of updates: 72000
dynamics loss: 0.72850

============================================================
time elapsed: 0:35:48
train iter: 720
num of updates: 72100
dynamics loss: 0.72905

============================================================
time elapsed: 0:35:51
train iter: 721
num of updates: 72200
dynamics loss: 0.72863

============================================================
time elapsed: 0:35:54
train iter: 722
num of updates: 72300
dynamics loss: 0.72838

============================================================
time elapsed: 0:35:56
train iter: 723
num of updates: 72400
dynamics loss: 0.72778

============================================================
time elapsed: 0:35:59
train iter: 724
num of updates: 72500
dynamics loss: 0.72730

============================================================
time elapsed: 0:36:02
train iter: 725
num of updates: 72600
dynamics loss: 0.72668

============================================================
time elapsed: 0:36:05
train iter: 726
num of updates: 72700
dynamics loss: 0.72688

============================================================
time elapsed: 0:36:08
train iter: 727
num of updates: 72800
dynamics loss: 0.72649

============================================================
time elapsed: 0:36:11
train iter: 728
num of updates: 72900
dynamics loss: 0.72630

============================================================
time elapsed: 0:36:14
train iter: 729
num of updates: 73000
dynamics loss: 0.72503

============================================================
time elapsed: 0:36:17
train iter: 730
num of updates: 73100
dynamics loss: 0.72516

============================================================
time elapsed: 0:36:19
train iter: 731
num of updates: 73200
dynamics loss: 0.72472

============================================================
time elapsed: 0:36:22
train iter: 732
num of updates: 73300
dynamics loss: 0.72406

============================================================
time elapsed: 0:36:25
train iter: 733
num of updates: 73400
dynamics loss: 0.72430

============================================================
time elapsed: 0:36:28
train iter: 734
num of updates: 73500
dynamics loss: 0.72360

============================================================
time elapsed: 0:36:31
train iter: 735
num of updates: 73600
dynamics loss: 0.72319

============================================================
time elapsed: 0:36:34
train iter: 736
num of updates: 73700
dynamics loss: 0.72356

============================================================
time elapsed: 0:36:37
train iter: 737
num of updates: 73800
dynamics loss: 0.72271

============================================================
time elapsed: 0:36:39
train iter: 738
num of updates: 73900
dynamics loss: 0.72233

============================================================
time elapsed: 0:36:42
train iter: 739
num of updates: 74000
dynamics loss: 0.72144

============================================================
time elapsed: 0:36:45
train iter: 740
num of updates: 74100
dynamics loss: 0.72142

============================================================
time elapsed: 0:36:48
train iter: 741
num of updates: 74200
dynamics loss: 0.72085

============================================================
time elapsed: 0:36:51
train iter: 742
num of updates: 74300
dynamics loss: 0.72023

============================================================
time elapsed: 0:36:54
train iter: 743
num of updates: 74400
dynamics loss: 0.72009

============================================================
time elapsed: 0:36:57
train iter: 744
num of updates: 74500
dynamics loss: 0.72017

============================================================
time elapsed: 0:36:59
train iter: 745
num of updates: 74600
dynamics loss: 0.71970

============================================================
time elapsed: 0:37:02
train iter: 746
num of updates: 74700
dynamics loss: 0.71919

============================================================
time elapsed: 0:37:05
train iter: 747
num of updates: 74800
dynamics loss: 0.71863

============================================================
time elapsed: 0:37:08
train iter: 748
num of updates: 74900
dynamics loss: 0.71843

============================================================
time elapsed: 0:37:11
train iter: 749
num of updates: 75000
dynamics loss: 0.71747

============================================================
time elapsed: 0:37:14
train iter: 750
num of updates: 75100
dynamics loss: 0.71759

============================================================
time elapsed: 0:37:17
train iter: 751
num of updates: 75200
dynamics loss: 0.71708

============================================================
time elapsed: 0:37:20
train iter: 752
num of updates: 75300
dynamics loss: 0.71615

============================================================
time elapsed: 0:37:22
train iter: 753
num of updates: 75400
dynamics loss: 0.71685

============================================================
time elapsed: 0:37:25
train iter: 754
num of updates: 75500
dynamics loss: 0.71595

============================================================
time elapsed: 0:37:28
train iter: 755
num of updates: 75600
dynamics loss: 0.71583

============================================================
time elapsed: 0:37:31
train iter: 756
num of updates: 75700
dynamics loss: 0.71567

============================================================
time elapsed: 0:37:34
train iter: 757
num of updates: 75800
dynamics loss: 0.71455

============================================================
time elapsed: 0:37:37
train iter: 758
num of updates: 75900
dynamics loss: 0.71429

============================================================
time elapsed: 0:37:40
train iter: 759
num of updates: 76000
dynamics loss: 0.71416

============================================================
time elapsed: 0:37:42
train iter: 760
num of updates: 76100
dynamics loss: 0.71338

============================================================
time elapsed: 0:37:45
train iter: 761
num of updates: 76200
dynamics loss: 0.71329

============================================================
time elapsed: 0:37:48
train iter: 762
num of updates: 76300
dynamics loss: 0.71275

============================================================
time elapsed: 0:37:51
train iter: 763
num of updates: 76400
dynamics loss: 0.71280

============================================================
time elapsed: 0:37:54
train iter: 764
num of updates: 76500
dynamics loss: 0.71195

============================================================
time elapsed: 0:37:57
train iter: 765
num of updates: 76600
dynamics loss: 0.71180

============================================================
time elapsed: 0:38:00
train iter: 766
num of updates: 76700
dynamics loss: 0.71148

============================================================
time elapsed: 0:38:02
train iter: 767
num of updates: 76800
dynamics loss: 0.71106

============================================================
time elapsed: 0:38:05
train iter: 768
num of updates: 76900
dynamics loss: 0.71082

============================================================
time elapsed: 0:38:08
train iter: 769
num of updates: 77000
dynamics loss: 0.71037

============================================================
time elapsed: 0:38:11
train iter: 770
num of updates: 77100
dynamics loss: 0.70950

============================================================
time elapsed: 0:38:14
train iter: 771
num of updates: 77200
dynamics loss: 0.70967

============================================================
time elapsed: 0:38:17
train iter: 772
num of updates: 77300
dynamics loss: 0.70899

============================================================
time elapsed: 0:38:20
train iter: 773
num of updates: 77400
dynamics loss: 0.70927

============================================================
time elapsed: 0:38:23
train iter: 774
num of updates: 77500
dynamics loss: 0.70816

============================================================
time elapsed: 0:38:25
train iter: 775
num of updates: 77600
dynamics loss: 0.70780

============================================================
time elapsed: 0:38:28
train iter: 776
num of updates: 77700
dynamics loss: 0.70784

============================================================
time elapsed: 0:38:31
train iter: 777
num of updates: 77800
dynamics loss: 0.70710

============================================================
time elapsed: 0:38:34
train iter: 778
num of updates: 77900
dynamics loss: 0.70676

============================================================
time elapsed: 0:38:37
train iter: 779
num of updates: 78000
dynamics loss: 0.70639

============================================================
time elapsed: 0:38:40
train iter: 780
num of updates: 78100
dynamics loss: 0.70585

============================================================
time elapsed: 0:38:43
train iter: 781
num of updates: 78200
dynamics loss: 0.70544

============================================================
time elapsed: 0:38:45
train iter: 782
num of updates: 78300
dynamics loss: 0.70518

============================================================
time elapsed: 0:38:48
train iter: 783
num of updates: 78400
dynamics loss: 0.70449

============================================================
time elapsed: 0:38:51
train iter: 784
num of updates: 78500
dynamics loss: 0.70468

============================================================
time elapsed: 0:38:54
train iter: 785
num of updates: 78600
dynamics loss: 0.70435

============================================================
time elapsed: 0:38:57
train iter: 786
num of updates: 78700
dynamics loss: 0.70316

============================================================
time elapsed: 0:39:00
train iter: 787
num of updates: 78800
dynamics loss: 0.70331

============================================================
time elapsed: 0:39:03
train iter: 788
num of updates: 78900
dynamics loss: 0.70239

============================================================
time elapsed: 0:39:05
train iter: 789
num of updates: 79000
dynamics loss: 0.70245

============================================================
time elapsed: 0:39:08
train iter: 790
num of updates: 79100
dynamics loss: 0.70236

============================================================
time elapsed: 0:39:11
train iter: 791
num of updates: 79200
dynamics loss: 0.70151

============================================================
time elapsed: 0:39:14
train iter: 792
num of updates: 79300
dynamics loss: 0.70090

============================================================
time elapsed: 0:39:17
train iter: 793
num of updates: 79400
dynamics loss: 0.70119

============================================================
time elapsed: 0:39:20
train iter: 794
num of updates: 79500
dynamics loss: 0.70040

============================================================
time elapsed: 0:39:23
train iter: 795
num of updates: 79600
dynamics loss: 0.70053

============================================================
time elapsed: 0:39:26
train iter: 796
num of updates: 79700
dynamics loss: 0.70006

============================================================
time elapsed: 0:39:28
train iter: 797
num of updates: 79800
dynamics loss: 0.69953

============================================================
time elapsed: 0:39:31
train iter: 798
num of updates: 79900
dynamics loss: 0.69856

============================================================
time elapsed: 0:39:34
train iter: 799
num of updates: 80000
dynamics loss: 0.69828

============================================================
time elapsed: 0:39:37
train iter: 800
num of updates: 80100
dynamics loss: 0.69769

============================================================
time elapsed: 0:39:40
train iter: 801
num of updates: 80200
dynamics loss: 0.69715

============================================================
time elapsed: 0:39:43
train iter: 802
num of updates: 80300
dynamics loss: 0.69729

============================================================
time elapsed: 0:39:46
train iter: 803
num of updates: 80400
dynamics loss: 0.69721

============================================================
time elapsed: 0:39:48
train iter: 804
num of updates: 80500
dynamics loss: 0.69578

============================================================
time elapsed: 0:39:51
train iter: 805
num of updates: 80600
dynamics loss: 0.69544

============================================================
time elapsed: 0:39:54
train iter: 806
num of updates: 80700
dynamics loss: 0.69558

============================================================
time elapsed: 0:39:57
train iter: 807
num of updates: 80800
dynamics loss: 0.69528

============================================================
time elapsed: 0:40:00
train iter: 808
num of updates: 80900
dynamics loss: 0.69502

============================================================
time elapsed: 0:40:03
train iter: 809
num of updates: 81000
dynamics loss: 0.69459

============================================================
time elapsed: 0:40:06
train iter: 810
num of updates: 81100
dynamics loss: 0.69417

============================================================
time elapsed: 0:40:09
train iter: 811
num of updates: 81200
dynamics loss: 0.69404

============================================================
time elapsed: 0:40:11
train iter: 812
num of updates: 81300
dynamics loss: 0.69324

============================================================
time elapsed: 0:40:14
train iter: 813
num of updates: 81400
dynamics loss: 0.69283

============================================================
time elapsed: 0:40:17
train iter: 814
num of updates: 81500
dynamics loss: 0.69218

============================================================
time elapsed: 0:40:20
train iter: 815
num of updates: 81600
dynamics loss: 0.69186

============================================================
time elapsed: 0:40:23
train iter: 816
num of updates: 81700
dynamics loss: 0.69126

============================================================
time elapsed: 0:40:26
train iter: 817
num of updates: 81800
dynamics loss: 0.69122

============================================================
time elapsed: 0:40:29
train iter: 818
num of updates: 81900
dynamics loss: 0.69069

============================================================
time elapsed: 0:40:31
train iter: 819
num of updates: 82000
dynamics loss: 0.69006

============================================================
time elapsed: 0:40:34
train iter: 820
num of updates: 82100
dynamics loss: 0.69021

============================================================
time elapsed: 0:40:37
train iter: 821
num of updates: 82200
dynamics loss: 0.68961

============================================================
time elapsed: 0:40:40
train iter: 822
num of updates: 82300
dynamics loss: 0.68892

============================================================
time elapsed: 0:40:43
train iter: 823
num of updates: 82400
dynamics loss: 0.68862

============================================================
time elapsed: 0:40:46
train iter: 824
num of updates: 82500
dynamics loss: 0.68836

============================================================
time elapsed: 0:40:49
train iter: 825
num of updates: 82600
dynamics loss: 0.68828

============================================================
time elapsed: 0:40:51
train iter: 826
num of updates: 82700
dynamics loss: 0.68750

============================================================
time elapsed: 0:40:54
train iter: 827
num of updates: 82800
dynamics loss: 0.68721

============================================================
time elapsed: 0:40:57
train iter: 828
num of updates: 82900
dynamics loss: 0.68685

============================================================
time elapsed: 0:41:00
train iter: 829
num of updates: 83000
dynamics loss: 0.68642

============================================================
time elapsed: 0:41:03
train iter: 830
num of updates: 83100
dynamics loss: 0.68595

============================================================
time elapsed: 0:41:06
train iter: 831
num of updates: 83200
dynamics loss: 0.68539

============================================================
time elapsed: 0:41:09
train iter: 832
num of updates: 83300
dynamics loss: 0.68471

============================================================
time elapsed: 0:41:12
train iter: 833
num of updates: 83400
dynamics loss: 0.68469

============================================================
time elapsed: 0:41:14
train iter: 834
num of updates: 83500
dynamics loss: 0.68412

============================================================
time elapsed: 0:41:17
train iter: 835
num of updates: 83600
dynamics loss: 0.68370

============================================================
time elapsed: 0:41:20
train iter: 836
num of updates: 83700
dynamics loss: 0.68344

============================================================
time elapsed: 0:41:23
train iter: 837
num of updates: 83800
dynamics loss: 0.68298

============================================================
time elapsed: 0:41:26
train iter: 838
num of updates: 83900
dynamics loss: 0.68275

============================================================
time elapsed: 0:41:29
train iter: 839
num of updates: 84000
dynamics loss: 0.68195

============================================================
time elapsed: 0:41:32
train iter: 840
num of updates: 84100
dynamics loss: 0.68211

============================================================
time elapsed: 0:41:34
train iter: 841
num of updates: 84200
dynamics loss: 0.68111

============================================================
time elapsed: 0:41:37
train iter: 842
num of updates: 84300
dynamics loss: 0.68095

============================================================
time elapsed: 0:41:40
train iter: 843
num of updates: 84400
dynamics loss: 0.68006

============================================================
time elapsed: 0:41:43
train iter: 844
num of updates: 84500
dynamics loss: 0.68030

============================================================
time elapsed: 0:41:46
train iter: 845
num of updates: 84600
dynamics loss: 0.67977

============================================================
time elapsed: 0:41:49
train iter: 846
num of updates: 84700
dynamics loss: 0.67955

============================================================
time elapsed: 0:41:52
train iter: 847
num of updates: 84800
dynamics loss: 0.67912

============================================================
time elapsed: 0:41:54
train iter: 848
num of updates: 84900
dynamics loss: 0.67854

============================================================
time elapsed: 0:41:57
train iter: 849
num of updates: 85000
dynamics loss: 0.67804

============================================================
time elapsed: 0:42:00
train iter: 850
num of updates: 85100
dynamics loss: 0.67750

============================================================
time elapsed: 0:42:03
train iter: 851
num of updates: 85200
dynamics loss: 0.67714

============================================================
time elapsed: 0:42:06
train iter: 852
num of updates: 85300
dynamics loss: 0.67677

============================================================
time elapsed: 0:42:09
train iter: 853
num of updates: 85400
dynamics loss: 0.67557

============================================================
time elapsed: 0:42:12
train iter: 854
num of updates: 85500
dynamics loss: 0.67583

============================================================
time elapsed: 0:42:15
train iter: 855
num of updates: 85600
dynamics loss: 0.67551

============================================================
time elapsed: 0:42:17
train iter: 856
num of updates: 85700
dynamics loss: 0.67482

============================================================
time elapsed: 0:42:20
train iter: 857
num of updates: 85800
dynamics loss: 0.67436

============================================================
time elapsed: 0:42:23
train iter: 858
num of updates: 85900
dynamics loss: 0.67408

============================================================
time elapsed: 0:42:26
train iter: 859
num of updates: 86000
dynamics loss: 0.67369

============================================================
time elapsed: 0:42:29
train iter: 860
num of updates: 86100
dynamics loss: 0.67315

============================================================
time elapsed: 0:42:32
train iter: 861
num of updates: 86200
dynamics loss: 0.67307

============================================================
time elapsed: 0:42:35
train iter: 862
num of updates: 86300
dynamics loss: 0.67236

============================================================
time elapsed: 0:42:37
train iter: 863
num of updates: 86400
dynamics loss: 0.67191

============================================================
time elapsed: 0:42:40
train iter: 864
num of updates: 86500
dynamics loss: 0.67127

============================================================
time elapsed: 0:42:43
train iter: 865
num of updates: 86600
dynamics loss: 0.67070

============================================================
time elapsed: 0:42:46
train iter: 866
num of updates: 86700
dynamics loss: 0.67044

============================================================
time elapsed: 0:42:49
train iter: 867
num of updates: 86800
dynamics loss: 0.67059

============================================================
time elapsed: 0:42:52
train iter: 868
num of updates: 86900
dynamics loss: 0.66998

============================================================
time elapsed: 0:42:55
train iter: 869
num of updates: 87000
dynamics loss: 0.67041

============================================================
time elapsed: 0:42:58
train iter: 870
num of updates: 87100
dynamics loss: 0.66859

============================================================
time elapsed: 0:43:00
train iter: 871
num of updates: 87200
dynamics loss: 0.66871

============================================================
time elapsed: 0:43:03
train iter: 872
num of updates: 87300
dynamics loss: 0.66799

============================================================
time elapsed: 0:43:06
train iter: 873
num of updates: 87400
dynamics loss: 0.66795

============================================================
time elapsed: 0:43:09
train iter: 874
num of updates: 87500
dynamics loss: 0.66743

============================================================
time elapsed: 0:43:12
train iter: 875
num of updates: 87600
dynamics loss: 0.66682

============================================================
time elapsed: 0:43:15
train iter: 876
num of updates: 87700
dynamics loss: 0.66659

============================================================
time elapsed: 0:43:18
train iter: 877
num of updates: 87800
dynamics loss: 0.66570

============================================================
time elapsed: 0:43:20
train iter: 878
num of updates: 87900
dynamics loss: 0.66588

============================================================
time elapsed: 0:43:23
train iter: 879
num of updates: 88000
dynamics loss: 0.66493

============================================================
time elapsed: 0:43:26
train iter: 880
num of updates: 88100
dynamics loss: 0.66500

============================================================
time elapsed: 0:43:29
train iter: 881
num of updates: 88200
dynamics loss: 0.66425

============================================================
time elapsed: 0:43:32
train iter: 882
num of updates: 88300
dynamics loss: 0.66414

============================================================
time elapsed: 0:43:35
train iter: 883
num of updates: 88400
dynamics loss: 0.66384

============================================================
time elapsed: 0:43:38
train iter: 884
num of updates: 88500
dynamics loss: 0.66297

============================================================
time elapsed: 0:43:40
train iter: 885
num of updates: 88600
dynamics loss: 0.66238

============================================================
time elapsed: 0:43:43
train iter: 886
num of updates: 88700
dynamics loss: 0.66203

============================================================
time elapsed: 0:43:46
train iter: 887
num of updates: 88800
dynamics loss: 0.66129

============================================================
time elapsed: 0:43:49
train iter: 888
num of updates: 88900
dynamics loss: 0.66101

============================================================
time elapsed: 0:43:52
train iter: 889
num of updates: 89000
dynamics loss: 0.66096

============================================================
time elapsed: 0:43:55
train iter: 890
num of updates: 89100
dynamics loss: 0.65989

============================================================
time elapsed: 0:43:58
train iter: 891
num of updates: 89200
dynamics loss: 0.66002

============================================================
time elapsed: 0:44:01
train iter: 892
num of updates: 89300
dynamics loss: 0.65907

============================================================
time elapsed: 0:44:03
train iter: 893
num of updates: 89400
dynamics loss: 0.65890

============================================================
time elapsed: 0:44:06
train iter: 894
num of updates: 89500
dynamics loss: 0.65852

============================================================
time elapsed: 0:44:09
train iter: 895
num of updates: 89600
dynamics loss: 0.65800

============================================================
time elapsed: 0:44:12
train iter: 896
num of updates: 89700
dynamics loss: 0.65758

============================================================
time elapsed: 0:44:15
train iter: 897
num of updates: 89800
dynamics loss: 0.65703

============================================================
time elapsed: 0:44:18
train iter: 898
num of updates: 89900
dynamics loss: 0.65682

============================================================
time elapsed: 0:44:21
train iter: 899
num of updates: 90000
dynamics loss: 0.65650

============================================================
time elapsed: 0:44:23
train iter: 900
num of updates: 90100
dynamics loss: 0.65605

============================================================
time elapsed: 0:44:26
train iter: 901
num of updates: 90200
dynamics loss: 0.65544

============================================================
time elapsed: 0:44:29
train iter: 902
num of updates: 90300
dynamics loss: 0.65538

============================================================
time elapsed: 0:44:32
train iter: 903
num of updates: 90400
dynamics loss: 0.65417

============================================================
time elapsed: 0:44:35
train iter: 904
num of updates: 90500
dynamics loss: 0.65403

============================================================
time elapsed: 0:44:38
train iter: 905
num of updates: 90600
dynamics loss: 0.65370

============================================================
time elapsed: 0:44:41
train iter: 906
num of updates: 90700
dynamics loss: 0.65301

============================================================
time elapsed: 0:44:43
train iter: 907
num of updates: 90800
dynamics loss: 0.65234

============================================================
time elapsed: 0:44:46
train iter: 908
num of updates: 90900
dynamics loss: 0.65269

============================================================
time elapsed: 0:44:49
train iter: 909
num of updates: 91000
dynamics loss: 0.65212

============================================================
time elapsed: 0:44:52
train iter: 910
num of updates: 91100
dynamics loss: 0.65150

============================================================
time elapsed: 0:44:55
train iter: 911
num of updates: 91200
dynamics loss: 0.65086

============================================================
time elapsed: 0:44:58
train iter: 912
num of updates: 91300
dynamics loss: 0.65104

============================================================
time elapsed: 0:45:01
train iter: 913
num of updates: 91400
dynamics loss: 0.65014

============================================================
time elapsed: 0:45:04
train iter: 914
num of updates: 91500
dynamics loss: 0.64974

============================================================
time elapsed: 0:45:06
train iter: 915
num of updates: 91600
dynamics loss: 0.64904

============================================================
time elapsed: 0:45:09
train iter: 916
num of updates: 91700
dynamics loss: 0.64850

============================================================
time elapsed: 0:45:12
train iter: 917
num of updates: 91800
dynamics loss: 0.64770

============================================================
time elapsed: 0:45:15
train iter: 918
num of updates: 91900
dynamics loss: 0.64780

============================================================
time elapsed: 0:45:18
train iter: 919
num of updates: 92000
dynamics loss: 0.64732

============================================================
time elapsed: 0:45:21
train iter: 920
num of updates: 92100
dynamics loss: 0.64718

============================================================
time elapsed: 0:45:24
train iter: 921
num of updates: 92200
dynamics loss: 0.64594

============================================================
time elapsed: 0:45:26
train iter: 922
num of updates: 92300
dynamics loss: 0.64589

============================================================
time elapsed: 0:45:29
train iter: 923
num of updates: 92400
dynamics loss: 0.64560

============================================================
time elapsed: 0:45:32
train iter: 924
num of updates: 92500
dynamics loss: 0.64509

============================================================
time elapsed: 0:45:35
train iter: 925
num of updates: 92600
dynamics loss: 0.64440

============================================================
time elapsed: 0:45:38
train iter: 926
num of updates: 92700
dynamics loss: 0.64382

============================================================
time elapsed: 0:45:41
train iter: 927
num of updates: 92800
dynamics loss: 0.64371

============================================================
time elapsed: 0:45:44
train iter: 928
num of updates: 92900
dynamics loss: 0.64270

============================================================
time elapsed: 0:45:46
train iter: 929
num of updates: 93000
dynamics loss: 0.64241

============================================================
time elapsed: 0:45:49
train iter: 930
num of updates: 93100
dynamics loss: 0.64213

============================================================
time elapsed: 0:45:52
train iter: 931
num of updates: 93200
dynamics loss: 0.64180

============================================================
time elapsed: 0:45:55
train iter: 932
num of updates: 93300
dynamics loss: 0.64168

============================================================
time elapsed: 0:45:58
train iter: 933
num of updates: 93400
dynamics loss: 0.64110

============================================================
time elapsed: 0:46:01
train iter: 934
num of updates: 93500
dynamics loss: 0.64060

============================================================
time elapsed: 0:46:04
train iter: 935
num of updates: 93600
dynamics loss: 0.63925

============================================================
time elapsed: 0:46:07
train iter: 936
num of updates: 93700
dynamics loss: 0.63933

============================================================
time elapsed: 0:46:09
train iter: 937
num of updates: 93800
dynamics loss: 0.63851

============================================================
time elapsed: 0:46:12
train iter: 938
num of updates: 93900
dynamics loss: 0.63851

============================================================
time elapsed: 0:46:15
train iter: 939
num of updates: 94000
dynamics loss: 0.63799

============================================================
time elapsed: 0:46:18
train iter: 940
num of updates: 94100
dynamics loss: 0.63765

============================================================
time elapsed: 0:46:21
train iter: 941
num of updates: 94200
dynamics loss: 0.63672

============================================================
time elapsed: 0:46:24
train iter: 942
num of updates: 94300
dynamics loss: 0.63652

============================================================
time elapsed: 0:46:27
train iter: 943
num of updates: 94400
dynamics loss: 0.63635

============================================================
time elapsed: 0:46:29
train iter: 944
num of updates: 94500
dynamics loss: 0.63570

============================================================
time elapsed: 0:46:32
train iter: 945
num of updates: 94600
dynamics loss: 0.63500

============================================================
time elapsed: 0:46:35
train iter: 946
num of updates: 94700
dynamics loss: 0.63427

============================================================
time elapsed: 0:46:38
train iter: 947
num of updates: 94800
dynamics loss: 0.63389

============================================================
time elapsed: 0:46:41
train iter: 948
num of updates: 94900
dynamics loss: 0.63387

============================================================
time elapsed: 0:46:44
train iter: 949
num of updates: 95000
dynamics loss: 0.63393

============================================================
time elapsed: 0:46:47
train iter: 950
num of updates: 95100
dynamics loss: 0.63279

============================================================
time elapsed: 0:46:50
train iter: 951
num of updates: 95200
dynamics loss: 0.63234

============================================================
time elapsed: 0:46:52
train iter: 952
num of updates: 95300
dynamics loss: 0.63191

============================================================
time elapsed: 0:46:55
train iter: 953
num of updates: 95400
dynamics loss: 0.63132

============================================================
time elapsed: 0:46:58
train iter: 954
num of updates: 95500
dynamics loss: 0.63101

============================================================
time elapsed: 0:47:01
train iter: 955
num of updates: 95600
dynamics loss: 0.63036

============================================================
time elapsed: 0:47:04
train iter: 956
num of updates: 95700
dynamics loss: 0.62977

============================================================
time elapsed: 0:47:07
train iter: 957
num of updates: 95800
dynamics loss: 0.62973

============================================================
time elapsed: 0:47:10
train iter: 958
num of updates: 95900
dynamics loss: 0.62895

============================================================
time elapsed: 0:47:12
train iter: 959
num of updates: 96000
dynamics loss: 0.62844

============================================================
time elapsed: 0:47:15
train iter: 960
num of updates: 96100
dynamics loss: 0.62790

============================================================
time elapsed: 0:47:18
train iter: 961
num of updates: 96200
dynamics loss: 0.62755

============================================================
time elapsed: 0:47:21
train iter: 962
num of updates: 96300
dynamics loss: 0.62729

============================================================
time elapsed: 0:47:24
train iter: 963
num of updates: 96400
dynamics loss: 0.62677

============================================================
time elapsed: 0:47:27
train iter: 964
num of updates: 96500
dynamics loss: 0.62526

============================================================
time elapsed: 0:47:30
train iter: 965
num of updates: 96600
dynamics loss: 0.62509

============================================================
time elapsed: 0:47:33
train iter: 966
num of updates: 96700
dynamics loss: 0.62550

============================================================
time elapsed: 0:47:35
train iter: 967
num of updates: 96800
dynamics loss: 0.62475

============================================================
time elapsed: 0:47:38
train iter: 968
num of updates: 96900
dynamics loss: 0.62449

============================================================
time elapsed: 0:47:41
train iter: 969
num of updates: 97000
dynamics loss: 0.62304

============================================================
time elapsed: 0:47:44
train iter: 970
num of updates: 97100
dynamics loss: 0.62303

============================================================
time elapsed: 0:47:47
train iter: 971
num of updates: 97200
dynamics loss: 0.62278

============================================================
time elapsed: 0:47:50
train iter: 972
num of updates: 97300
dynamics loss: 0.62197

============================================================
time elapsed: 0:47:53
train iter: 973
num of updates: 97400
dynamics loss: 0.62160

============================================================
time elapsed: 0:47:55
train iter: 974
num of updates: 97500
dynamics loss: 0.62151

============================================================
time elapsed: 0:47:58
train iter: 975
num of updates: 97600
dynamics loss: 0.62093

============================================================
time elapsed: 0:48:01
train iter: 976
num of updates: 97700
dynamics loss: 0.62023

============================================================
time elapsed: 0:48:04
train iter: 977
num of updates: 97800
dynamics loss: 0.62006

============================================================
time elapsed: 0:48:07
train iter: 978
num of updates: 97900
dynamics loss: 0.61881

============================================================
time elapsed: 0:48:10
train iter: 979
num of updates: 98000
dynamics loss: 0.61865

============================================================
time elapsed: 0:48:13
train iter: 980
num of updates: 98100
dynamics loss: 0.61778

============================================================
time elapsed: 0:48:16
train iter: 981
num of updates: 98200
dynamics loss: 0.61770

============================================================
time elapsed: 0:48:18
train iter: 982
num of updates: 98300
dynamics loss: 0.61720

============================================================
time elapsed: 0:48:21
train iter: 983
num of updates: 98400
dynamics loss: 0.61676

============================================================
time elapsed: 0:48:24
train iter: 984
num of updates: 98500
dynamics loss: 0.61645

============================================================
time elapsed: 0:48:27
train iter: 985
num of updates: 98600
dynamics loss: 0.61627

============================================================
time elapsed: 0:48:30
train iter: 986
num of updates: 98700
dynamics loss: 0.61538

============================================================
time elapsed: 0:48:33
train iter: 987
num of updates: 98800
dynamics loss: 0.61434

============================================================
time elapsed: 0:48:36
train iter: 988
num of updates: 98900
dynamics loss: 0.61441

============================================================
time elapsed: 0:48:38
train iter: 989
num of updates: 99000
dynamics loss: 0.61401

============================================================
time elapsed: 0:48:41
train iter: 990
num of updates: 99100
dynamics loss: 0.61384

============================================================
time elapsed: 0:48:44
train iter: 991
num of updates: 99200
dynamics loss: 0.61271

============================================================
time elapsed: 0:48:47
train iter: 992
num of updates: 99300
dynamics loss: 0.61221

============================================================
time elapsed: 0:48:50
train iter: 993
num of updates: 99400
dynamics loss: 0.61194

============================================================
time elapsed: 0:48:53
train iter: 994
num of updates: 99500
dynamics loss: 0.61165

============================================================
time elapsed: 0:48:56
train iter: 995
num of updates: 99600
dynamics loss: 0.61055

============================================================
time elapsed: 0:48:58
train iter: 996
num of updates: 99700
dynamics loss: 0.61041

============================================================
time elapsed: 0:49:01
train iter: 997
num of updates: 99800
dynamics loss: 0.61002

============================================================
time elapsed: 0:49:04
train iter: 998
num of updates: 99900
dynamics loss: 0.60975

============================================================
time elapsed: 0:49:07
train iter: 999
num of updates: 100000
dynamics loss: 0.60888

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/dynamics_model_100000.pt
============================================================
finished training dynamics!
============================================================
started training dynamics at: 25-09-28-00-54-49
finished training dynamics at: 25-09-28-01-44-01
total dynamics training time: 0:49:12
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/dynamics_model.pt
============================================================
2025-09-28 01:44:11.265997: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:13.662575: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:44:15.659432: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 324 bytes spill stores, 324 bytes spill loads

num_vae_param: 459172
2025-09-28 01:44:20.446131: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:20.446311: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:20.446366: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:20.446605: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:21.989780: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_117', 320 bytes spill stores, 220 bytes spill loads

2025-09-28 01:44:23.012935: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_117', 388 bytes spill stores, 384 bytes spill loads

2025-09-28 01:44:24.722407: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_117', 1736 bytes spill stores, 1312 bytes spill loads

2025-09-28 01:44:26.346905: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_117', 820 bytes spill stores, 564 bytes spill loads

2025-09-28 01:44:30.337520: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15', 4 bytes spill stores, 4 bytes spill loads

2025-09-28 01:44:34.202923: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_156', 8 bytes spill stores, 8 bytes spill loads

2025-09-28 01:44:36.235484: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_156', 108 bytes spill stores, 108 bytes spill loads

2025-09-28 01:44:36.241851: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_156', 200 bytes spill stores, 200 bytes spill loads

2025-09-28 01:44:37.211157: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_156', 292 bytes spill stores, 292 bytes spill loads

============================================================
time elapsed: 0:49:59
train iter: 0
num of updates: 100
vae loss: 2.30507
kl loss: 0.21858
a decoder loss: 2.08649
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/vae_model_100.pt
2025-09-28 01:44:49.357477: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:51.524008: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 324 bytes spill stores, 324 bytes spill loads

2025-09-28 01:44:52.168955: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads

============================================================
time elapsed: 0:50:15
train iter: 1
num of updates: 200
vae loss: 2.30719
kl loss: 0.21896
a decoder loss: 2.08823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:16
train iter: 2
num of updates: 300
vae loss: 2.29975
kl loss: 0.21624
a decoder loss: 2.08351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:17
train iter: 3
num of updates: 400
vae loss: 2.29512
kl loss: 0.21539
a decoder loss: 2.07973
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:18
train iter: 4
num of updates: 500
vae loss: 2.29154
kl loss: 0.21245
a decoder loss: 2.07910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:19
train iter: 5
num of updates: 600
vae loss: 2.28857
kl loss: 0.20932
a decoder loss: 2.07925
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:20
train iter: 6
num of updates: 700
vae loss: 2.28100
kl loss: 0.20495
a decoder loss: 2.07605
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:21
train iter: 7
num of updates: 800
vae loss: 2.27103
kl loss: 0.20103
a decoder loss: 2.07000
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:22
train iter: 8
num of updates: 900
vae loss: 2.25996
kl loss: 0.19592
a decoder loss: 2.06404
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:23
train iter: 9
num of updates: 1000
vae loss: 2.24351
kl loss: 0.19098
a decoder loss: 2.05254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:24
train iter: 10
num of updates: 1100
vae loss: 2.23588
kl loss: 0.18551
a decoder loss: 2.05037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:25
train iter: 11
num of updates: 1200
vae loss: 2.21340
kl loss: 0.17980
a decoder loss: 2.03360
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:26
train iter: 12
num of updates: 1300
vae loss: 2.20986
kl loss: 0.17359
a decoder loss: 2.03627
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:27
train iter: 13
num of updates: 1400
vae loss: 2.20058
kl loss: 0.16673
a decoder loss: 2.03385
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:28
train iter: 14
num of updates: 1500
vae loss: 2.17539
kl loss: 0.16094
a decoder loss: 2.01445
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:29
train iter: 15
num of updates: 1600
vae loss: 2.15927
kl loss: 0.15423
a decoder loss: 2.00504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:30
train iter: 16
num of updates: 1700
vae loss: 2.13164
kl loss: 0.14824
a decoder loss: 1.98340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:31
train iter: 17
num of updates: 1800
vae loss: 2.11873
kl loss: 0.14119
a decoder loss: 1.97754
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:32
train iter: 18
num of updates: 1900
vae loss: 2.10368
kl loss: 0.13566
a decoder loss: 1.96803
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:33
train iter: 19
num of updates: 2000
vae loss: 2.08695
kl loss: 0.12888
a decoder loss: 1.95807
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:34
train iter: 20
num of updates: 2100
vae loss: 2.07296
kl loss: 0.12266
a decoder loss: 1.95030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:35
train iter: 21
num of updates: 2200
vae loss: 2.04213
kl loss: 0.11681
a decoder loss: 1.92532
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:36
train iter: 22
num of updates: 2300
vae loss: 2.02159
kl loss: 0.11120
a decoder loss: 1.91038
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:37
train iter: 23
num of updates: 2400
vae loss: 2.00489
kl loss: 0.10536
a decoder loss: 1.89953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:38
train iter: 24
num of updates: 2500
vae loss: 1.98617
kl loss: 0.09994
a decoder loss: 1.88623
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:39
train iter: 25
num of updates: 2600
vae loss: 1.95869
kl loss: 0.09424
a decoder loss: 1.86445
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:40
train iter: 26
num of updates: 2700
vae loss: 1.93646
kl loss: 0.08942
a decoder loss: 1.84703
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:41
train iter: 27
num of updates: 2800
vae loss: 1.91357
kl loss: 0.08498
a decoder loss: 1.82858
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:42
train iter: 28
num of updates: 2900
vae loss: 1.89337
kl loss: 0.08043
a decoder loss: 1.81294
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:43
train iter: 29
num of updates: 3000
vae loss: 1.87334
kl loss: 0.07592
a decoder loss: 1.79741
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:44
train iter: 30
num of updates: 3100
vae loss: 1.85224
kl loss: 0.07175
a decoder loss: 1.78049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:45
train iter: 31
num of updates: 3200
vae loss: 1.82647
kl loss: 0.06829
a decoder loss: 1.75818
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:46
train iter: 32
num of updates: 3300
vae loss: 1.80891
kl loss: 0.06443
a decoder loss: 1.74448
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:47
train iter: 33
num of updates: 3400
vae loss: 1.78717
kl loss: 0.06113
a decoder loss: 1.72605
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:48
train iter: 34
num of updates: 3500
vae loss: 1.76171
kl loss: 0.05843
a decoder loss: 1.70327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:49
train iter: 35
num of updates: 3600
vae loss: 1.73907
kl loss: 0.05526
a decoder loss: 1.68381
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:50
train iter: 36
num of updates: 3700
vae loss: 1.71423
kl loss: 0.05276
a decoder loss: 1.66147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:51
train iter: 37
num of updates: 3800
vae loss: 1.68584
kl loss: 0.05060
a decoder loss: 1.63525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:52
train iter: 38
num of updates: 3900
vae loss: 1.67439
kl loss: 0.04866
a decoder loss: 1.62573
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:53
train iter: 39
num of updates: 4000
vae loss: 1.65025
kl loss: 0.04683
a decoder loss: 1.60342
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:54
train iter: 40
num of updates: 4100
vae loss: 1.62363
kl loss: 0.04525
a decoder loss: 1.57838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:55
train iter: 41
num of updates: 4200
vae loss: 1.61061
kl loss: 0.04382
a decoder loss: 1.56679
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:56
train iter: 42
num of updates: 4300
vae loss: 1.59046
kl loss: 0.04276
a decoder loss: 1.54770
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:57
train iter: 43
num of updates: 4400
vae loss: 1.56787
kl loss: 0.04183
a decoder loss: 1.52605
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:58
train iter: 44
num of updates: 4500
vae loss: 1.55451
kl loss: 0.04095
a decoder loss: 1.51356
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:50:59
train iter: 45
num of updates: 4600
vae loss: 1.53362
kl loss: 0.04047
a decoder loss: 1.49315
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:00
train iter: 46
num of updates: 4700
vae loss: 1.51037
kl loss: 0.03996
a decoder loss: 1.47041
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:01
train iter: 47
num of updates: 4800
vae loss: 1.49777
kl loss: 0.03966
a decoder loss: 1.45810
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:02
train iter: 48
num of updates: 4900
vae loss: 1.47553
kl loss: 0.03940
a decoder loss: 1.43613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:03
train iter: 49
num of updates: 5000
vae loss: 1.45359
kl loss: 0.03939
a decoder loss: 1.41420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:04
train iter: 50
num of updates: 5100
vae loss: 1.44115
kl loss: 0.03940
a decoder loss: 1.40175
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:05
train iter: 51
num of updates: 5200
vae loss: 1.41875
kl loss: 0.03939
a decoder loss: 1.37937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:06
train iter: 52
num of updates: 5300
vae loss: 1.39861
kl loss: 0.03965
a decoder loss: 1.35897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:07
train iter: 53
num of updates: 5400
vae loss: 1.37651
kl loss: 0.03980
a decoder loss: 1.33670
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:08
train iter: 54
num of updates: 5500
vae loss: 1.36681
kl loss: 0.04004
a decoder loss: 1.32677
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:09
train iter: 55
num of updates: 5600
vae loss: 1.34710
kl loss: 0.04029
a decoder loss: 1.30681
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:10
train iter: 56
num of updates: 5700
vae loss: 1.33538
kl loss: 0.04057
a decoder loss: 1.29481
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:11
train iter: 57
num of updates: 5800
vae loss: 1.30864
kl loss: 0.04082
a decoder loss: 1.26782
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:12
train iter: 58
num of updates: 5900
vae loss: 1.29430
kl loss: 0.04114
a decoder loss: 1.25316
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:13
train iter: 59
num of updates: 6000
vae loss: 1.28261
kl loss: 0.04146
a decoder loss: 1.24115
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:14
train iter: 60
num of updates: 6100
vae loss: 1.26318
kl loss: 0.04169
a decoder loss: 1.22149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:15
train iter: 61
num of updates: 6200
vae loss: 1.24900
kl loss: 0.04190
a decoder loss: 1.20710
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:16
train iter: 62
num of updates: 6300
vae loss: 1.22979
kl loss: 0.04235
a decoder loss: 1.18744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:17
train iter: 63
num of updates: 6400
vae loss: 1.21114
kl loss: 0.04247
a decoder loss: 1.16867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:18
train iter: 64
num of updates: 6500
vae loss: 1.19672
kl loss: 0.04281
a decoder loss: 1.15391
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:19
train iter: 65
num of updates: 6600
vae loss: 1.18238
kl loss: 0.04314
a decoder loss: 1.13923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:20
train iter: 66
num of updates: 6700
vae loss: 1.16466
kl loss: 0.04321
a decoder loss: 1.12145
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:21
train iter: 67
num of updates: 6800
vae loss: 1.14808
kl loss: 0.04344
a decoder loss: 1.10464
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:22
train iter: 68
num of updates: 6900
vae loss: 1.12976
kl loss: 0.04362
a decoder loss: 1.08614
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:23
train iter: 69
num of updates: 7000
vae loss: 1.11552
kl loss: 0.04385
a decoder loss: 1.07167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:24
train iter: 70
num of updates: 7100
vae loss: 1.10317
kl loss: 0.04406
a decoder loss: 1.05912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:25
train iter: 71
num of updates: 7200
vae loss: 1.08679
kl loss: 0.04427
a decoder loss: 1.04252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:26
train iter: 72
num of updates: 7300
vae loss: 1.06718
kl loss: 0.04427
a decoder loss: 1.02291
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:27
train iter: 73
num of updates: 7400
vae loss: 1.05679
kl loss: 0.04455
a decoder loss: 1.01225
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:28
train iter: 74
num of updates: 7500
vae loss: 1.03865
kl loss: 0.04462
a decoder loss: 0.99403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:29
train iter: 75
num of updates: 7600
vae loss: 1.03163
kl loss: 0.04502
a decoder loss: 0.98661
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:30
train iter: 76
num of updates: 7700
vae loss: 1.01587
kl loss: 0.04519
a decoder loss: 0.97067
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:31
train iter: 77
num of updates: 7800
vae loss: 0.99635
kl loss: 0.04518
a decoder loss: 0.95117
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:32
train iter: 78
num of updates: 7900
vae loss: 0.97843
kl loss: 0.04529
a decoder loss: 0.93315
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:33
train iter: 79
num of updates: 8000
vae loss: 0.97249
kl loss: 0.04554
a decoder loss: 0.92695
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:34
train iter: 80
num of updates: 8100
vae loss: 0.95586
kl loss: 0.04549
a decoder loss: 0.91037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:35
train iter: 81
num of updates: 8200
vae loss: 0.94419
kl loss: 0.04562
a decoder loss: 0.89857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:36
train iter: 82
num of updates: 8300
vae loss: 0.92860
kl loss: 0.04563
a decoder loss: 0.88296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:37
train iter: 83
num of updates: 8400
vae loss: 0.91583
kl loss: 0.04554
a decoder loss: 0.87029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:38
train iter: 84
num of updates: 8500
vae loss: 0.90169
kl loss: 0.04529
a decoder loss: 0.85640
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:39
train iter: 85
num of updates: 8600
vae loss: 0.89003
kl loss: 0.04530
a decoder loss: 0.84473
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:40
train iter: 86
num of updates: 8700
vae loss: 0.87899
kl loss: 0.04531
a decoder loss: 0.83369
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:41
train iter: 87
num of updates: 8800
vae loss: 0.86277
kl loss: 0.04502
a decoder loss: 0.81775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:42
train iter: 88
num of updates: 8900
vae loss: 0.85230
kl loss: 0.04509
a decoder loss: 0.80722
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:43
train iter: 89
num of updates: 9000
vae loss: 0.83871
kl loss: 0.04481
a decoder loss: 0.79389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:44
train iter: 90
num of updates: 9100
vae loss: 0.82555
kl loss: 0.04451
a decoder loss: 0.78104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:45
train iter: 91
num of updates: 9200
vae loss: 0.81392
kl loss: 0.04432
a decoder loss: 0.76960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:46
train iter: 92
num of updates: 9300
vae loss: 0.80149
kl loss: 0.04385
a decoder loss: 0.75764
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:47
train iter: 93
num of updates: 9400
vae loss: 0.78657
kl loss: 0.04358
a decoder loss: 0.74299
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:48
train iter: 94
num of updates: 9500
vae loss: 0.77388
kl loss: 0.04320
a decoder loss: 0.73068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:49
train iter: 95
num of updates: 9600
vae loss: 0.76569
kl loss: 0.04254
a decoder loss: 0.72315
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:50
train iter: 96
num of updates: 9700
vae loss: 0.75451
kl loss: 0.04234
a decoder loss: 0.71217
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:51
train iter: 97
num of updates: 9800
vae loss: 0.74135
kl loss: 0.04175
a decoder loss: 0.69960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:52
train iter: 98
num of updates: 9900
vae loss: 0.73666
kl loss: 0.04174
a decoder loss: 0.69493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:53
train iter: 99
num of updates: 10000
vae loss: 0.72233
kl loss: 0.04109
a decoder loss: 0.68124
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:54
train iter: 100
num of updates: 10100
vae loss: 0.71125
kl loss: 0.04055
a decoder loss: 0.67070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:55
train iter: 101
num of updates: 10200
vae loss: 0.70175
kl loss: 0.03998
a decoder loss: 0.66177
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:56
train iter: 102
num of updates: 10300
vae loss: 0.69021
kl loss: 0.03939
a decoder loss: 0.65082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:57
train iter: 103
num of updates: 10400
vae loss: 0.68351
kl loss: 0.03908
a decoder loss: 0.64443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:58
train iter: 104
num of updates: 10500
vae loss: 0.67022
kl loss: 0.03815
a decoder loss: 0.63207
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:59
train iter: 105
num of updates: 10600
vae loss: 0.66055
kl loss: 0.03756
a decoder loss: 0.62300
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:00
train iter: 106
num of updates: 10700
vae loss: 0.65141
kl loss: 0.03719
a decoder loss: 0.61422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:01
train iter: 107
num of updates: 10800
vae loss: 0.64372
kl loss: 0.03669
a decoder loss: 0.60703
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:02
train iter: 108
num of updates: 10900
vae loss: 0.63337
kl loss: 0.03603
a decoder loss: 0.59734
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:03
train iter: 109
num of updates: 11000
vae loss: 0.62692
kl loss: 0.03547
a decoder loss: 0.59144
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:04
train iter: 110
num of updates: 11100
vae loss: 0.62111
kl loss: 0.03498
a decoder loss: 0.58613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:05
train iter: 111
num of updates: 11200
vae loss: 0.60837
kl loss: 0.03440
a decoder loss: 0.57397
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:06
train iter: 112
num of updates: 11300
vae loss: 0.60280
kl loss: 0.03391
a decoder loss: 0.56889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:07
train iter: 113
num of updates: 11400
vae loss: 0.59491
kl loss: 0.03305
a decoder loss: 0.56186
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:08
train iter: 114
num of updates: 11500
vae loss: 0.58716
kl loss: 0.03248
a decoder loss: 0.55468
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:09
train iter: 115
num of updates: 11600
vae loss: 0.58065
kl loss: 0.03200
a decoder loss: 0.54866
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:10
train iter: 116
num of updates: 11700
vae loss: 0.57395
kl loss: 0.03121
a decoder loss: 0.54274
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:11
train iter: 117
num of updates: 11800
vae loss: 0.56400
kl loss: 0.03057
a decoder loss: 0.53343
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:12
train iter: 118
num of updates: 11900
vae loss: 0.56137
kl loss: 0.03023
a decoder loss: 0.53114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:13
train iter: 119
num of updates: 12000
vae loss: 0.55747
kl loss: 0.02969
a decoder loss: 0.52779
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:14
train iter: 120
num of updates: 12100
vae loss: 0.54792
kl loss: 0.02901
a decoder loss: 0.51891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:15
train iter: 121
num of updates: 12200
vae loss: 0.54023
kl loss: 0.02835
a decoder loss: 0.51188
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:16
train iter: 122
num of updates: 12300
vae loss: 0.53751
kl loss: 0.02792
a decoder loss: 0.50960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:17
train iter: 123
num of updates: 12400
vae loss: 0.52856
kl loss: 0.02722
a decoder loss: 0.50134
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:18
train iter: 124
num of updates: 12500
vae loss: 0.52293
kl loss: 0.02658
a decoder loss: 0.49635
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:19
train iter: 125
num of updates: 12600
vae loss: 0.51620
kl loss: 0.02606
a decoder loss: 0.49013
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:20
train iter: 126
num of updates: 12700
vae loss: 0.51100
kl loss: 0.02551
a decoder loss: 0.48548
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:21
train iter: 127
num of updates: 12800
vae loss: 0.50536
kl loss: 0.02466
a decoder loss: 0.48070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:22
train iter: 128
num of updates: 12900
vae loss: 0.49812
kl loss: 0.02416
a decoder loss: 0.47396
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:23
train iter: 129
num of updates: 13000
vae loss: 0.49700
kl loss: 0.02368
a decoder loss: 0.47333
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:24
train iter: 130
num of updates: 13100
vae loss: 0.49201
kl loss: 0.02331
a decoder loss: 0.46870
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:25
train iter: 131
num of updates: 13200
vae loss: 0.48536
kl loss: 0.02267
a decoder loss: 0.46269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:27
train iter: 132
num of updates: 13300
vae loss: 0.48187
kl loss: 0.02224
a decoder loss: 0.45963
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:27
train iter: 133
num of updates: 13400
vae loss: 0.47813
kl loss: 0.02175
a decoder loss: 0.45638
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:29
train iter: 134
num of updates: 13500
vae loss: 0.46988
kl loss: 0.02111
a decoder loss: 0.44877
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:30
train iter: 135
num of updates: 13600
vae loss: 0.46733
kl loss: 0.02074
a decoder loss: 0.44659
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:31
train iter: 136
num of updates: 13700
vae loss: 0.46182
kl loss: 0.02024
a decoder loss: 0.44159
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:32
train iter: 137
num of updates: 13800
vae loss: 0.45842
kl loss: 0.01965
a decoder loss: 0.43877
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:33
train iter: 138
num of updates: 13900
vae loss: 0.45439
kl loss: 0.01935
a decoder loss: 0.43504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:34
train iter: 139
num of updates: 14000
vae loss: 0.45183
kl loss: 0.01880
a decoder loss: 0.43303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:35
train iter: 140
num of updates: 14100
vae loss: 0.44808
kl loss: 0.01828
a decoder loss: 0.42980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:36
train iter: 141
num of updates: 14200
vae loss: 0.44004
kl loss: 0.01778
a decoder loss: 0.42226
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:37
train iter: 142
num of updates: 14300
vae loss: 0.43768
kl loss: 0.01748
a decoder loss: 0.42019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:38
train iter: 143
num of updates: 14400
vae loss: 0.43557
kl loss: 0.01710
a decoder loss: 0.41846
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:39
train iter: 144
num of updates: 14500
vae loss: 0.43323
kl loss: 0.01680
a decoder loss: 0.41643
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:40
train iter: 145
num of updates: 14600
vae loss: 0.42673
kl loss: 0.01619
a decoder loss: 0.41054
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:41
train iter: 146
num of updates: 14700
vae loss: 0.42458
kl loss: 0.01588
a decoder loss: 0.40870
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:42
train iter: 147
num of updates: 14800
vae loss: 0.42006
kl loss: 0.01532
a decoder loss: 0.40474
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:43
train iter: 148
num of updates: 14900
vae loss: 0.41906
kl loss: 0.01526
a decoder loss: 0.40380
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:44
train iter: 149
num of updates: 15000
vae loss: 0.41524
kl loss: 0.01487
a decoder loss: 0.40037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:45
train iter: 150
num of updates: 15100
vae loss: 0.41255
kl loss: 0.01450
a decoder loss: 0.39805
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:46
train iter: 151
num of updates: 15200
vae loss: 0.40756
kl loss: 0.01398
a decoder loss: 0.39358
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:47
train iter: 152
num of updates: 15300
vae loss: 0.40581
kl loss: 0.01381
a decoder loss: 0.39200
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:48
train iter: 153
num of updates: 15400
vae loss: 0.40334
kl loss: 0.01349
a decoder loss: 0.38985
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:49
train iter: 154
num of updates: 15500
vae loss: 0.39980
kl loss: 0.01298
a decoder loss: 0.38682
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:50
train iter: 155
num of updates: 15600
vae loss: 0.39736
kl loss: 0.01286
a decoder loss: 0.38450
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:51
train iter: 156
num of updates: 15700
vae loss: 0.39257
kl loss: 0.01234
a decoder loss: 0.38023
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:52
train iter: 157
num of updates: 15800
vae loss: 0.39014
kl loss: 0.01213
a decoder loss: 0.37801
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:53
train iter: 158
num of updates: 15900
vae loss: 0.38723
kl loss: 0.01190
a decoder loss: 0.37533
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:54
train iter: 159
num of updates: 16000
vae loss: 0.38560
kl loss: 0.01158
a decoder loss: 0.37402
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:55
train iter: 160
num of updates: 16100
vae loss: 0.38147
kl loss: 0.01125
a decoder loss: 0.37021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:56
train iter: 161
num of updates: 16200
vae loss: 0.37863
kl loss: 0.01094
a decoder loss: 0.36769
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:57
train iter: 162
num of updates: 16300
vae loss: 0.37603
kl loss: 0.01070
a decoder loss: 0.36533
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:58
train iter: 163
num of updates: 16400
vae loss: 0.37473
kl loss: 0.01044
a decoder loss: 0.36429
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:59
train iter: 164
num of updates: 16500
vae loss: 0.37374
kl loss: 0.01022
a decoder loss: 0.36351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:00
train iter: 165
num of updates: 16600
vae loss: 0.37020
kl loss: 0.01001
a decoder loss: 0.36019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:01
train iter: 166
num of updates: 16700
vae loss: 0.36625
kl loss: 0.00968
a decoder loss: 0.35657
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:02
train iter: 167
num of updates: 16800
vae loss: 0.36706
kl loss: 0.00948
a decoder loss: 0.35759
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:03
train iter: 168
num of updates: 16900
vae loss: 0.36278
kl loss: 0.00923
a decoder loss: 0.35354
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:04
train iter: 169
num of updates: 17000
vae loss: 0.36182
kl loss: 0.00900
a decoder loss: 0.35282
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:05
train iter: 170
num of updates: 17100
vae loss: 0.35846
kl loss: 0.00881
a decoder loss: 0.34965
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:06
train iter: 171
num of updates: 17200
vae loss: 0.35729
kl loss: 0.00859
a decoder loss: 0.34870
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:07
train iter: 172
num of updates: 17300
vae loss: 0.35411
kl loss: 0.00828
a decoder loss: 0.34583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:08
train iter: 173
num of updates: 17400
vae loss: 0.35398
kl loss: 0.00810
a decoder loss: 0.34588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:09
train iter: 174
num of updates: 17500
vae loss: 0.35227
kl loss: 0.00797
a decoder loss: 0.34430
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:10
train iter: 175
num of updates: 17600
vae loss: 0.34854
kl loss: 0.00772
a decoder loss: 0.34082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:11
train iter: 176
num of updates: 17700
vae loss: 0.34781
kl loss: 0.00755
a decoder loss: 0.34026
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:12
train iter: 177
num of updates: 17800
vae loss: 0.34585
kl loss: 0.00738
a decoder loss: 0.33847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:13
train iter: 178
num of updates: 17900
vae loss: 0.34468
kl loss: 0.00717
a decoder loss: 0.33751
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:14
train iter: 179
num of updates: 18000
vae loss: 0.34137
kl loss: 0.00703
a decoder loss: 0.33434
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:15
train iter: 180
num of updates: 18100
vae loss: 0.34096
kl loss: 0.00684
a decoder loss: 0.33412
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:16
train iter: 181
num of updates: 18200
vae loss: 0.33885
kl loss: 0.00665
a decoder loss: 0.33221
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:17
train iter: 182
num of updates: 18300
vae loss: 0.33458
kl loss: 0.00638
a decoder loss: 0.32820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:18
train iter: 183
num of updates: 18400
vae loss: 0.33576
kl loss: 0.00637
a decoder loss: 0.32939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:19
train iter: 184
num of updates: 18500
vae loss: 0.33356
kl loss: 0.00615
a decoder loss: 0.32741
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:20
train iter: 185
num of updates: 18600
vae loss: 0.33194
kl loss: 0.00599
a decoder loss: 0.32594
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:21
train iter: 186
num of updates: 18700
vae loss: 0.33093
kl loss: 0.00587
a decoder loss: 0.32506
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:22
train iter: 187
num of updates: 18800
vae loss: 0.32712
kl loss: 0.00560
a decoder loss: 0.32152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:23
train iter: 188
num of updates: 18900
vae loss: 0.32485
kl loss: 0.00545
a decoder loss: 0.31940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:24
train iter: 189
num of updates: 19000
vae loss: 0.32533
kl loss: 0.00539
a decoder loss: 0.31993
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:25
train iter: 190
num of updates: 19100
vae loss: 0.32456
kl loss: 0.00522
a decoder loss: 0.31934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:26
train iter: 191
num of updates: 19200
vae loss: 0.32224
kl loss: 0.00508
a decoder loss: 0.31717
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:27
train iter: 192
num of updates: 19300
vae loss: 0.32148
kl loss: 0.00494
a decoder loss: 0.31654
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:28
train iter: 193
num of updates: 19400
vae loss: 0.31809
kl loss: 0.00481
a decoder loss: 0.31328
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:29
train iter: 194
num of updates: 19500
vae loss: 0.31794
kl loss: 0.00472
a decoder loss: 0.31322
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:30
train iter: 195
num of updates: 19600
vae loss: 0.31629
kl loss: 0.00457
a decoder loss: 0.31171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:31
train iter: 196
num of updates: 19700
vae loss: 0.31405
kl loss: 0.00440
a decoder loss: 0.30965
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:32
train iter: 197
num of updates: 19800
vae loss: 0.31478
kl loss: 0.00436
a decoder loss: 0.31043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:33
train iter: 198
num of updates: 19900
vae loss: 0.31287
kl loss: 0.00420
a decoder loss: 0.30867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:34
train iter: 199
num of updates: 20000
vae loss: 0.31008
kl loss: 0.00410
a decoder loss: 0.30598
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:35
train iter: 200
num of updates: 20100
vae loss: 0.30971
kl loss: 0.00398
a decoder loss: 0.30573
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:36
train iter: 201
num of updates: 20200
vae loss: 0.30855
kl loss: 0.00392
a decoder loss: 0.30463
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:37
train iter: 202
num of updates: 20300
vae loss: 0.30780
kl loss: 0.00384
a decoder loss: 0.30396
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:38
train iter: 203
num of updates: 20400
vae loss: 0.30511
kl loss: 0.00369
a decoder loss: 0.30142
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:39
train iter: 204
num of updates: 20500
vae loss: 0.30501
kl loss: 0.00360
a decoder loss: 0.30141
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:40
train iter: 205
num of updates: 20600
vae loss: 0.30341
kl loss: 0.00350
a decoder loss: 0.29991
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:41
train iter: 206
num of updates: 20700
vae loss: 0.30397
kl loss: 0.00344
a decoder loss: 0.30053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:42
train iter: 207
num of updates: 20800
vae loss: 0.29998
kl loss: 0.00329
a decoder loss: 0.29669
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:43
train iter: 208
num of updates: 20900
vae loss: 0.29886
kl loss: 0.00322
a decoder loss: 0.29564
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:44
train iter: 209
num of updates: 21000
vae loss: 0.29888
kl loss: 0.00314
a decoder loss: 0.29574
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:45
train iter: 210
num of updates: 21100
vae loss: 0.29864
kl loss: 0.00306
a decoder loss: 0.29558
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:46
train iter: 211
num of updates: 21200
vae loss: 0.29757
kl loss: 0.00297
a decoder loss: 0.29460
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:47
train iter: 212
num of updates: 21300
vae loss: 0.29600
kl loss: 0.00288
a decoder loss: 0.29312
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:48
train iter: 213
num of updates: 21400
vae loss: 0.29587
kl loss: 0.00285
a decoder loss: 0.29303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:49
train iter: 214
num of updates: 21500
vae loss: 0.29354
kl loss: 0.00273
a decoder loss: 0.29081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:50
train iter: 215
num of updates: 21600
vae loss: 0.29292
kl loss: 0.00266
a decoder loss: 0.29025
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:51
train iter: 216
num of updates: 21700
vae loss: 0.29291
kl loss: 0.00258
a decoder loss: 0.29032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:52
train iter: 217
num of updates: 21800
vae loss: 0.29224
kl loss: 0.00255
a decoder loss: 0.28969
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:53
train iter: 218
num of updates: 21900
vae loss: 0.28929
kl loss: 0.00246
a decoder loss: 0.28683
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:54
train iter: 219
num of updates: 22000
vae loss: 0.28893
kl loss: 0.00239
a decoder loss: 0.28653
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:55
train iter: 220
num of updates: 22100
vae loss: 0.28929
kl loss: 0.00237
a decoder loss: 0.28693
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:56
train iter: 221
num of updates: 22200
vae loss: 0.28783
kl loss: 0.00231
a decoder loss: 0.28552
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:57
train iter: 222
num of updates: 22300
vae loss: 0.28504
kl loss: 0.00221
a decoder loss: 0.28284
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:58
train iter: 223
num of updates: 22400
vae loss: 0.28618
kl loss: 0.00217
a decoder loss: 0.28400
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:59
train iter: 224
num of updates: 22500
vae loss: 0.28563
kl loss: 0.00212
a decoder loss: 0.28350
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:00
train iter: 225
num of updates: 22600
vae loss: 0.28490
kl loss: 0.00208
a decoder loss: 0.28282
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:01
train iter: 226
num of updates: 22700
vae loss: 0.28341
kl loss: 0.00203
a decoder loss: 0.28138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:02
train iter: 227
num of updates: 22800
vae loss: 0.28226
kl loss: 0.00196
a decoder loss: 0.28030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:03
train iter: 228
num of updates: 22900
vae loss: 0.28127
kl loss: 0.00192
a decoder loss: 0.27936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:04
train iter: 229
num of updates: 23000
vae loss: 0.28009
kl loss: 0.00187
a decoder loss: 0.27822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:05
train iter: 230
num of updates: 23100
vae loss: 0.28014
kl loss: 0.00181
a decoder loss: 0.27833
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:06
train iter: 231
num of updates: 23200
vae loss: 0.27941
kl loss: 0.00179
a decoder loss: 0.27763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:07
train iter: 232
num of updates: 23300
vae loss: 0.27871
kl loss: 0.00173
a decoder loss: 0.27698
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:08
train iter: 233
num of updates: 23400
vae loss: 0.27725
kl loss: 0.00169
a decoder loss: 0.27556
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:09
train iter: 234
num of updates: 23500
vae loss: 0.27787
kl loss: 0.00165
a decoder loss: 0.27622
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:10
train iter: 235
num of updates: 23600
vae loss: 0.27568
kl loss: 0.00160
a decoder loss: 0.27408
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:11
train iter: 236
num of updates: 23700
vae loss: 0.27548
kl loss: 0.00158
a decoder loss: 0.27391
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:12
train iter: 237
num of updates: 23800
vae loss: 0.27503
kl loss: 0.00153
a decoder loss: 0.27350
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:13
train iter: 238
num of updates: 23900
vae loss: 0.27230
kl loss: 0.00148
a decoder loss: 0.27082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:14
train iter: 239
num of updates: 24000
vae loss: 0.27267
kl loss: 0.00145
a decoder loss: 0.27122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:15
train iter: 240
num of updates: 24100
vae loss: 0.27252
kl loss: 0.00143
a decoder loss: 0.27109
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:16
train iter: 241
num of updates: 24200
vae loss: 0.27177
kl loss: 0.00140
a decoder loss: 0.27037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:17
train iter: 242
num of updates: 24300
vae loss: 0.27159
kl loss: 0.00136
a decoder loss: 0.27023
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:18
train iter: 243
num of updates: 24400
vae loss: 0.27098
kl loss: 0.00132
a decoder loss: 0.26965
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:19
train iter: 244
num of updates: 24500
vae loss: 0.26927
kl loss: 0.00129
a decoder loss: 0.26798
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:20
train iter: 245
num of updates: 24600
vae loss: 0.26904
kl loss: 0.00127
a decoder loss: 0.26777
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:21
train iter: 246
num of updates: 24700
vae loss: 0.26886
kl loss: 0.00124
a decoder loss: 0.26762
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:22
train iter: 247
num of updates: 24800
vae loss: 0.26883
kl loss: 0.00122
a decoder loss: 0.26761
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:23
train iter: 248
num of updates: 24900
vae loss: 0.26845
kl loss: 0.00121
a decoder loss: 0.26725
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:24
train iter: 249
num of updates: 25000
vae loss: 0.26676
kl loss: 0.00116
a decoder loss: 0.26560
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:25
train iter: 250
num of updates: 25100
vae loss: 0.26531
kl loss: 0.00113
a decoder loss: 0.26418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:26
train iter: 251
num of updates: 25200
vae loss: 0.26451
kl loss: 0.00111
a decoder loss: 0.26340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:27
train iter: 252
num of updates: 25300
vae loss: 0.26621
kl loss: 0.00110
a decoder loss: 0.26511
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:28
train iter: 253
num of updates: 25400
vae loss: 0.26514
kl loss: 0.00108
a decoder loss: 0.26406
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:29
train iter: 254
num of updates: 25500
vae loss: 0.26406
kl loss: 0.00104
a decoder loss: 0.26302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:30
train iter: 255
num of updates: 25600
vae loss: 0.26483
kl loss: 0.00102
a decoder loss: 0.26380
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:31
train iter: 256
num of updates: 25700
vae loss: 0.26128
kl loss: 0.00100
a decoder loss: 0.26029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:32
train iter: 257
num of updates: 25800
vae loss: 0.26266
kl loss: 0.00099
a decoder loss: 0.26167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:33
train iter: 258
num of updates: 25900
vae loss: 0.26240
kl loss: 0.00097
a decoder loss: 0.26143
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:34
train iter: 259
num of updates: 26000
vae loss: 0.26098
kl loss: 0.00094
a decoder loss: 0.26004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:35
train iter: 260
num of updates: 26100
vae loss: 0.25999
kl loss: 0.00092
a decoder loss: 0.25907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:36
train iter: 261
num of updates: 26200
vae loss: 0.25959
kl loss: 0.00090
a decoder loss: 0.25869
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:37
train iter: 262
num of updates: 26300
vae loss: 0.26023
kl loss: 0.00089
a decoder loss: 0.25934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:38
train iter: 263
num of updates: 26400
vae loss: 0.25908
kl loss: 0.00088
a decoder loss: 0.25820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:39
train iter: 264
num of updates: 26500
vae loss: 0.25901
kl loss: 0.00086
a decoder loss: 0.25815
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:40
train iter: 265
num of updates: 26600
vae loss: 0.25995
kl loss: 0.00085
a decoder loss: 0.25910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:41
train iter: 266
num of updates: 26700
vae loss: 0.25813
kl loss: 0.00082
a decoder loss: 0.25732
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:42
train iter: 267
num of updates: 26800
vae loss: 0.25809
kl loss: 0.00081
a decoder loss: 0.25728
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:43
train iter: 268
num of updates: 26900
vae loss: 0.25804
kl loss: 0.00080
a decoder loss: 0.25724
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:44
train iter: 269
num of updates: 27000
vae loss: 0.25745
kl loss: 0.00078
a decoder loss: 0.25667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:45
train iter: 270
num of updates: 27100
vae loss: 0.25558
kl loss: 0.00076
a decoder loss: 0.25482
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:46
train iter: 271
num of updates: 27200
vae loss: 0.25596
kl loss: 0.00075
a decoder loss: 0.25521
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:47
train iter: 272
num of updates: 27300
vae loss: 0.25575
kl loss: 0.00074
a decoder loss: 0.25501
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:48
train iter: 273
num of updates: 27400
vae loss: 0.25519
kl loss: 0.00072
a decoder loss: 0.25446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:49
train iter: 274
num of updates: 27500
vae loss: 0.25443
kl loss: 0.00071
a decoder loss: 0.25372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:50
train iter: 275
num of updates: 27600
vae loss: 0.25479
kl loss: 0.00070
a decoder loss: 0.25409
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:51
train iter: 276
num of updates: 27700
vae loss: 0.25462
kl loss: 0.00069
a decoder loss: 0.25394
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:52
train iter: 277
num of updates: 27800
vae loss: 0.25314
kl loss: 0.00067
a decoder loss: 0.25247
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:53
train iter: 278
num of updates: 27900
vae loss: 0.25282
kl loss: 0.00067
a decoder loss: 0.25216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:54
train iter: 279
num of updates: 28000
vae loss: 0.25257
kl loss: 0.00066
a decoder loss: 0.25191
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:55
train iter: 280
num of updates: 28100
vae loss: 0.25213
kl loss: 0.00064
a decoder loss: 0.25149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:56
train iter: 281
num of updates: 28200
vae loss: 0.25177
kl loss: 0.00063
a decoder loss: 0.25114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:57
train iter: 282
num of updates: 28300
vae loss: 0.25187
kl loss: 0.00063
a decoder loss: 0.25125
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:58
train iter: 283
num of updates: 28400
vae loss: 0.24993
kl loss: 0.00060
a decoder loss: 0.24933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:59
train iter: 284
num of updates: 28500
vae loss: 0.25001
kl loss: 0.00060
a decoder loss: 0.24941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:00
train iter: 285
num of updates: 28600
vae loss: 0.25012
kl loss: 0.00059
a decoder loss: 0.24953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:01
train iter: 286
num of updates: 28700
vae loss: 0.25059
kl loss: 0.00059
a decoder loss: 0.25001
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:02
train iter: 287
num of updates: 28800
vae loss: 0.24821
kl loss: 0.00057
a decoder loss: 0.24764
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:03
train iter: 288
num of updates: 28900
vae loss: 0.24915
kl loss: 0.00057
a decoder loss: 0.24858
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:04
train iter: 289
num of updates: 29000
vae loss: 0.24977
kl loss: 0.00056
a decoder loss: 0.24921
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:05
train iter: 290
num of updates: 29100
vae loss: 0.24852
kl loss: 0.00054
a decoder loss: 0.24798
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:06
train iter: 291
num of updates: 29200
vae loss: 0.24779
kl loss: 0.00054
a decoder loss: 0.24726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:07
train iter: 292
num of updates: 29300
vae loss: 0.24749
kl loss: 0.00053
a decoder loss: 0.24696
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:08
train iter: 293
num of updates: 29400
vae loss: 0.24719
kl loss: 0.00052
a decoder loss: 0.24667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:09
train iter: 294
num of updates: 29500
vae loss: 0.24725
kl loss: 0.00051
a decoder loss: 0.24674
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:10
train iter: 295
num of updates: 29600
vae loss: 0.24713
kl loss: 0.00050
a decoder loss: 0.24663
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:11
train iter: 296
num of updates: 29700
vae loss: 0.24632
kl loss: 0.00049
a decoder loss: 0.24582
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:12
train iter: 297
num of updates: 29800
vae loss: 0.24565
kl loss: 0.00049
a decoder loss: 0.24516
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:13
train iter: 298
num of updates: 29900
vae loss: 0.24508
kl loss: 0.00048
a decoder loss: 0.24460
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:14
train iter: 299
num of updates: 30000
vae loss: 0.24407
kl loss: 0.00047
a decoder loss: 0.24360
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:15
train iter: 300
num of updates: 30100
vae loss: 0.24548
kl loss: 0.00047
a decoder loss: 0.24501
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:16
train iter: 301
num of updates: 30200
vae loss: 0.24615
kl loss: 0.00047
a decoder loss: 0.24569
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:17
train iter: 302
num of updates: 30300
vae loss: 0.24434
kl loss: 0.00045
a decoder loss: 0.24389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:18
train iter: 303
num of updates: 30400
vae loss: 0.24457
kl loss: 0.00045
a decoder loss: 0.24412
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:19
train iter: 304
num of updates: 30500
vae loss: 0.24452
kl loss: 0.00044
a decoder loss: 0.24408
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:20
train iter: 305
num of updates: 30600
vae loss: 0.24401
kl loss: 0.00043
a decoder loss: 0.24358
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:21
train iter: 306
num of updates: 30700
vae loss: 0.24315
kl loss: 0.00042
a decoder loss: 0.24273
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:22
train iter: 307
num of updates: 30800
vae loss: 0.24253
kl loss: 0.00042
a decoder loss: 0.24211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:23
train iter: 308
num of updates: 30900
vae loss: 0.24258
kl loss: 0.00042
a decoder loss: 0.24216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:24
train iter: 309
num of updates: 31000
vae loss: 0.24280
kl loss: 0.00041
a decoder loss: 0.24239
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:25
train iter: 310
num of updates: 31100
vae loss: 0.24284
kl loss: 0.00041
a decoder loss: 0.24243
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:26
train iter: 311
num of updates: 31200
vae loss: 0.24222
kl loss: 0.00040
a decoder loss: 0.24182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:27
train iter: 312
num of updates: 31300
vae loss: 0.24220
kl loss: 0.00040
a decoder loss: 0.24180
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:28
train iter: 313
num of updates: 31400
vae loss: 0.24140
kl loss: 0.00039
a decoder loss: 0.24101
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:29
train iter: 314
num of updates: 31500
vae loss: 0.24124
kl loss: 0.00038
a decoder loss: 0.24085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:30
train iter: 315
num of updates: 31600
vae loss: 0.24128
kl loss: 0.00038
a decoder loss: 0.24090
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:31
train iter: 316
num of updates: 31700
vae loss: 0.24087
kl loss: 0.00037
a decoder loss: 0.24049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:32
train iter: 317
num of updates: 31800
vae loss: 0.24129
kl loss: 0.00037
a decoder loss: 0.24092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:33
train iter: 318
num of updates: 31900
vae loss: 0.23950
kl loss: 0.00036
a decoder loss: 0.23914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:34
train iter: 319
num of updates: 32000
vae loss: 0.24045
kl loss: 0.00036
a decoder loss: 0.24009
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:35
train iter: 320
num of updates: 32100
vae loss: 0.24005
kl loss: 0.00036
a decoder loss: 0.23969
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:36
train iter: 321
num of updates: 32200
vae loss: 0.24015
kl loss: 0.00035
a decoder loss: 0.23980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:37
train iter: 322
num of updates: 32300
vae loss: 0.23949
kl loss: 0.00035
a decoder loss: 0.23914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:38
train iter: 323
num of updates: 32400
vae loss: 0.23987
kl loss: 0.00034
a decoder loss: 0.23953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:39
train iter: 324
num of updates: 32500
vae loss: 0.23862
kl loss: 0.00034
a decoder loss: 0.23828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:40
train iter: 325
num of updates: 32600
vae loss: 0.23864
kl loss: 0.00034
a decoder loss: 0.23831
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:41
train iter: 326
num of updates: 32700
vae loss: 0.23910
kl loss: 0.00033
a decoder loss: 0.23876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:42
train iter: 327
num of updates: 32800
vae loss: 0.23855
kl loss: 0.00032
a decoder loss: 0.23822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:43
train iter: 328
num of updates: 32900
vae loss: 0.23826
kl loss: 0.00032
a decoder loss: 0.23794
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:44
train iter: 329
num of updates: 33000
vae loss: 0.23802
kl loss: 0.00032
a decoder loss: 0.23770
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:45
train iter: 330
num of updates: 33100
vae loss: 0.23698
kl loss: 0.00031
a decoder loss: 0.23667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:46
train iter: 331
num of updates: 33200
vae loss: 0.23766
kl loss: 0.00031
a decoder loss: 0.23735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:47
train iter: 332
num of updates: 33300
vae loss: 0.23662
kl loss: 0.00030
a decoder loss: 0.23631
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:48
train iter: 333
num of updates: 33400
vae loss: 0.23634
kl loss: 0.00030
a decoder loss: 0.23603
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:49
train iter: 334
num of updates: 33500
vae loss: 0.23697
kl loss: 0.00030
a decoder loss: 0.23667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:50
train iter: 335
num of updates: 33600
vae loss: 0.23559
kl loss: 0.00029
a decoder loss: 0.23530
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:51
train iter: 336
num of updates: 33700
vae loss: 0.23585
kl loss: 0.00029
a decoder loss: 0.23556
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:52
train iter: 337
num of updates: 33800
vae loss: 0.23518
kl loss: 0.00028
a decoder loss: 0.23490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:53
train iter: 338
num of updates: 33900
vae loss: 0.23632
kl loss: 0.00029
a decoder loss: 0.23603
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:54
train iter: 339
num of updates: 34000
vae loss: 0.23637
kl loss: 0.00028
a decoder loss: 0.23609
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:55
train iter: 340
num of updates: 34100
vae loss: 0.23531
kl loss: 0.00028
a decoder loss: 0.23504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:56
train iter: 341
num of updates: 34200
vae loss: 0.23576
kl loss: 0.00027
a decoder loss: 0.23549
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:57
train iter: 342
num of updates: 34300
vae loss: 0.23560
kl loss: 0.00027
a decoder loss: 0.23533
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:58
train iter: 343
num of updates: 34400
vae loss: 0.23516
kl loss: 0.00026
a decoder loss: 0.23490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:59
train iter: 344
num of updates: 34500
vae loss: 0.23456
kl loss: 0.00026
a decoder loss: 0.23429
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:00
train iter: 345
num of updates: 34600
vae loss: 0.23532
kl loss: 0.00026
a decoder loss: 0.23506
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:01
train iter: 346
num of updates: 34700
vae loss: 0.23351
kl loss: 0.00026
a decoder loss: 0.23326
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:02
train iter: 347
num of updates: 34800
vae loss: 0.23381
kl loss: 0.00025
a decoder loss: 0.23355
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:03
train iter: 348
num of updates: 34900
vae loss: 0.23438
kl loss: 0.00025
a decoder loss: 0.23413
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:04
train iter: 349
num of updates: 35000
vae loss: 0.23351
kl loss: 0.00025
a decoder loss: 0.23326
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:05
train iter: 350
num of updates: 35100
vae loss: 0.23417
kl loss: 0.00025
a decoder loss: 0.23393
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:06
train iter: 351
num of updates: 35200
vae loss: 0.23269
kl loss: 0.00024
a decoder loss: 0.23245
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:07
train iter: 352
num of updates: 35300
vae loss: 0.23323
kl loss: 0.00024
a decoder loss: 0.23299
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:08
train iter: 353
num of updates: 35400
vae loss: 0.23316
kl loss: 0.00024
a decoder loss: 0.23292
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:09
train iter: 354
num of updates: 35500
vae loss: 0.23333
kl loss: 0.00024
a decoder loss: 0.23310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:10
train iter: 355
num of updates: 35600
vae loss: 0.23152
kl loss: 0.00023
a decoder loss: 0.23129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:11
train iter: 356
num of updates: 35700
vae loss: 0.23300
kl loss: 0.00023
a decoder loss: 0.23277
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:12
train iter: 357
num of updates: 35800
vae loss: 0.23125
kl loss: 0.00023
a decoder loss: 0.23103
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:13
train iter: 358
num of updates: 35900
vae loss: 0.23281
kl loss: 0.00023
a decoder loss: 0.23259
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:14
train iter: 359
num of updates: 36000
vae loss: 0.23236
kl loss: 0.00022
a decoder loss: 0.23214
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:15
train iter: 360
num of updates: 36100
vae loss: 0.22997
kl loss: 0.00022
a decoder loss: 0.22975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:16
train iter: 361
num of updates: 36200
vae loss: 0.23155
kl loss: 0.00022
a decoder loss: 0.23133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:17
train iter: 362
num of updates: 36300
vae loss: 0.23174
kl loss: 0.00022
a decoder loss: 0.23153
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:18
train iter: 363
num of updates: 36400
vae loss: 0.23055
kl loss: 0.00021
a decoder loss: 0.23034
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:19
train iter: 364
num of updates: 36500
vae loss: 0.23157
kl loss: 0.00021
a decoder loss: 0.23136
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:20
train iter: 365
num of updates: 36600
vae loss: 0.23125
kl loss: 0.00021
a decoder loss: 0.23104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:21
train iter: 366
num of updates: 36700
vae loss: 0.23098
kl loss: 0.00021
a decoder loss: 0.23077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:22
train iter: 367
num of updates: 36800
vae loss: 0.23142
kl loss: 0.00020
a decoder loss: 0.23121
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:23
train iter: 368
num of updates: 36900
vae loss: 0.23087
kl loss: 0.00020
a decoder loss: 0.23067
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:24
train iter: 369
num of updates: 37000
vae loss: 0.23079
kl loss: 0.00020
a decoder loss: 0.23059
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:25
train iter: 370
num of updates: 37100
vae loss: 0.22972
kl loss: 0.00020
a decoder loss: 0.22952
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:26
train iter: 371
num of updates: 37200
vae loss: 0.23066
kl loss: 0.00019
a decoder loss: 0.23047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:27
train iter: 372
num of updates: 37300
vae loss: 0.23074
kl loss: 0.00020
a decoder loss: 0.23054
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:28
train iter: 373
num of updates: 37400
vae loss: 0.23071
kl loss: 0.00020
a decoder loss: 0.23052
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:29
train iter: 374
num of updates: 37500
vae loss: 0.22878
kl loss: 0.00019
a decoder loss: 0.22859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:30
train iter: 375
num of updates: 37600
vae loss: 0.22994
kl loss: 0.00019
a decoder loss: 0.22975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:31
train iter: 376
num of updates: 37700
vae loss: 0.22965
kl loss: 0.00018
a decoder loss: 0.22947
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:32
train iter: 377
num of updates: 37800
vae loss: 0.22919
kl loss: 0.00018
a decoder loss: 0.22901
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:33
train iter: 378
num of updates: 37900
vae loss: 0.22941
kl loss: 0.00018
a decoder loss: 0.22923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:34
train iter: 379
num of updates: 38000
vae loss: 0.22842
kl loss: 0.00018
a decoder loss: 0.22824
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:35
train iter: 380
num of updates: 38100
vae loss: 0.23005
kl loss: 0.00018
a decoder loss: 0.22987
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:36
train iter: 381
num of updates: 38200
vae loss: 0.22913
kl loss: 0.00018
a decoder loss: 0.22895
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:38
train iter: 382
num of updates: 38300
vae loss: 0.22836
kl loss: 0.00018
a decoder loss: 0.22818
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:39
train iter: 383
num of updates: 38400
vae loss: 0.22777
kl loss: 0.00017
a decoder loss: 0.22760
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:40
train iter: 384
num of updates: 38500
vae loss: 0.22925
kl loss: 0.00017
a decoder loss: 0.22907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:41
train iter: 385
num of updates: 38600
vae loss: 0.22841
kl loss: 0.00017
a decoder loss: 0.22824
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:42
train iter: 386
num of updates: 38700
vae loss: 0.22729
kl loss: 0.00017
a decoder loss: 0.22713
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:43
train iter: 387
num of updates: 38800
vae loss: 0.22731
kl loss: 0.00017
a decoder loss: 0.22714
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:44
train iter: 388
num of updates: 38900
vae loss: 0.22791
kl loss: 0.00016
a decoder loss: 0.22775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:45
train iter: 389
num of updates: 39000
vae loss: 0.22860
kl loss: 0.00016
a decoder loss: 0.22844
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:46
train iter: 390
num of updates: 39100
vae loss: 0.22720
kl loss: 0.00016
a decoder loss: 0.22704
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:47
train iter: 391
num of updates: 39200
vae loss: 0.22715
kl loss: 0.00016
a decoder loss: 0.22699
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:48
train iter: 392
num of updates: 39300
vae loss: 0.22624
kl loss: 0.00016
a decoder loss: 0.22608
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:49
train iter: 393
num of updates: 39400
vae loss: 0.22702
kl loss: 0.00016
a decoder loss: 0.22686
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:50
train iter: 394
num of updates: 39500
vae loss: 0.22629
kl loss: 0.00016
a decoder loss: 0.22613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:51
train iter: 395
num of updates: 39600
vae loss: 0.22686
kl loss: 0.00015
a decoder loss: 0.22670
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:52
train iter: 396
num of updates: 39700
vae loss: 0.22639
kl loss: 0.00015
a decoder loss: 0.22624
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:53
train iter: 397
num of updates: 39800
vae loss: 0.22684
kl loss: 0.00015
a decoder loss: 0.22669
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:54
train iter: 398
num of updates: 39900
vae loss: 0.22552
kl loss: 0.00015
a decoder loss: 0.22537
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:55
train iter: 399
num of updates: 40000
vae loss: 0.22595
kl loss: 0.00015
a decoder loss: 0.22581
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:56
train iter: 400
num of updates: 40100
vae loss: 0.22648
kl loss: 0.00015
a decoder loss: 0.22633
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:57
train iter: 401
num of updates: 40200
vae loss: 0.22643
kl loss: 0.00015
a decoder loss: 0.22628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:58
train iter: 402
num of updates: 40300
vae loss: 0.22593
kl loss: 0.00015
a decoder loss: 0.22579
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:59
train iter: 403
num of updates: 40400
vae loss: 0.22565
kl loss: 0.00014
a decoder loss: 0.22550
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:00
train iter: 404
num of updates: 40500
vae loss: 0.22529
kl loss: 0.00014
a decoder loss: 0.22514
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:01
train iter: 405
num of updates: 40600
vae loss: 0.22596
kl loss: 0.00014
a decoder loss: 0.22582
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:02
train iter: 406
num of updates: 40700
vae loss: 0.22597
kl loss: 0.00014
a decoder loss: 0.22583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:03
train iter: 407
num of updates: 40800
vae loss: 0.22608
kl loss: 0.00014
a decoder loss: 0.22594
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:04
train iter: 408
num of updates: 40900
vae loss: 0.22512
kl loss: 0.00014
a decoder loss: 0.22498
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:05
train iter: 409
num of updates: 41000
vae loss: 0.22516
kl loss: 0.00014
a decoder loss: 0.22502
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:06
train iter: 410
num of updates: 41100
vae loss: 0.22494
kl loss: 0.00013
a decoder loss: 0.22480
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:07
train iter: 411
num of updates: 41200
vae loss: 0.22593
kl loss: 0.00013
a decoder loss: 0.22579
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:08
train iter: 412
num of updates: 41300
vae loss: 0.22506
kl loss: 0.00013
a decoder loss: 0.22493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:09
train iter: 413
num of updates: 41400
vae loss: 0.22342
kl loss: 0.00013
a decoder loss: 0.22329
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:10
train iter: 414
num of updates: 41500
vae loss: 0.22459
kl loss: 0.00013
a decoder loss: 0.22446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:11
train iter: 415
num of updates: 41600
vae loss: 0.22520
kl loss: 0.00013
a decoder loss: 0.22507
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:12
train iter: 416
num of updates: 41700
vae loss: 0.22454
kl loss: 0.00013
a decoder loss: 0.22441
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:13
train iter: 417
num of updates: 41800
vae loss: 0.22399
kl loss: 0.00013
a decoder loss: 0.22386
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:14
train iter: 418
num of updates: 41900
vae loss: 0.22467
kl loss: 0.00013
a decoder loss: 0.22455
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:15
train iter: 419
num of updates: 42000
vae loss: 0.22454
kl loss: 0.00012
a decoder loss: 0.22441
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:16
train iter: 420
num of updates: 42100
vae loss: 0.22430
kl loss: 0.00012
a decoder loss: 0.22417
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:17
train iter: 421
num of updates: 42200
vae loss: 0.22572
kl loss: 0.00012
a decoder loss: 0.22560
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:18
train iter: 422
num of updates: 42300
vae loss: 0.22461
kl loss: 0.00012
a decoder loss: 0.22448
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:19
train iter: 423
num of updates: 42400
vae loss: 0.22302
kl loss: 0.00012
a decoder loss: 0.22290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:20
train iter: 424
num of updates: 42500
vae loss: 0.22416
kl loss: 0.00012
a decoder loss: 0.22404
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:21
train iter: 425
num of updates: 42600
vae loss: 0.22411
kl loss: 0.00012
a decoder loss: 0.22399
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:22
train iter: 426
num of updates: 42700
vae loss: 0.22315
kl loss: 0.00012
a decoder loss: 0.22303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:23
train iter: 427
num of updates: 42800
vae loss: 0.22360
kl loss: 0.00012
a decoder loss: 0.22348
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:24
train iter: 428
num of updates: 42900
vae loss: 0.22421
kl loss: 0.00012
a decoder loss: 0.22410
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:25
train iter: 429
num of updates: 43000
vae loss: 0.22362
kl loss: 0.00011
a decoder loss: 0.22351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:26
train iter: 430
num of updates: 43100
vae loss: 0.22240
kl loss: 0.00011
a decoder loss: 0.22229
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:27
train iter: 431
num of updates: 43200
vae loss: 0.22277
kl loss: 0.00011
a decoder loss: 0.22266
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:28
train iter: 432
num of updates: 43300
vae loss: 0.22288
kl loss: 0.00011
a decoder loss: 0.22277
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:29
train iter: 433
num of updates: 43400
vae loss: 0.22267
kl loss: 0.00011
a decoder loss: 0.22257
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:30
train iter: 434
num of updates: 43500
vae loss: 0.22314
kl loss: 0.00011
a decoder loss: 0.22303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:31
train iter: 435
num of updates: 43600
vae loss: 0.22247
kl loss: 0.00011
a decoder loss: 0.22237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:32
train iter: 436
num of updates: 43700
vae loss: 0.22283
kl loss: 0.00011
a decoder loss: 0.22272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:33
train iter: 437
num of updates: 43800
vae loss: 0.22321
kl loss: 0.00011
a decoder loss: 0.22311
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:34
train iter: 438
num of updates: 43900
vae loss: 0.22345
kl loss: 0.00011
a decoder loss: 0.22334
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:35
train iter: 439
num of updates: 44000
vae loss: 0.22247
kl loss: 0.00011
a decoder loss: 0.22237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:36
train iter: 440
num of updates: 44100
vae loss: 0.22280
kl loss: 0.00010
a decoder loss: 0.22269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:37
train iter: 441
num of updates: 44200
vae loss: 0.22291
kl loss: 0.00010
a decoder loss: 0.22280
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:38
train iter: 442
num of updates: 44300
vae loss: 0.22176
kl loss: 0.00010
a decoder loss: 0.22166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:39
train iter: 443
num of updates: 44400
vae loss: 0.22298
kl loss: 0.00010
a decoder loss: 0.22288
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:40
train iter: 444
num of updates: 44500
vae loss: 0.22181
kl loss: 0.00010
a decoder loss: 0.22171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:41
train iter: 445
num of updates: 44600
vae loss: 0.22265
kl loss: 0.00010
a decoder loss: 0.22255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:42
train iter: 446
num of updates: 44700
vae loss: 0.22181
kl loss: 0.00010
a decoder loss: 0.22171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:43
train iter: 447
num of updates: 44800
vae loss: 0.22296
kl loss: 0.00010
a decoder loss: 0.22285
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:44
train iter: 448
num of updates: 44900
vae loss: 0.22213
kl loss: 0.00010
a decoder loss: 0.22203
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:45
train iter: 449
num of updates: 45000
vae loss: 0.22265
kl loss: 0.00010
a decoder loss: 0.22255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:46
train iter: 450
num of updates: 45100
vae loss: 0.22171
kl loss: 0.00010
a decoder loss: 0.22162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:47
train iter: 451
num of updates: 45200
vae loss: 0.22167
kl loss: 0.00009
a decoder loss: 0.22157
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:48
train iter: 452
num of updates: 45300
vae loss: 0.22124
kl loss: 0.00009
a decoder loss: 0.22114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:49
train iter: 453
num of updates: 45400
vae loss: 0.22136
kl loss: 0.00009
a decoder loss: 0.22126
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:50
train iter: 454
num of updates: 45500
vae loss: 0.22117
kl loss: 0.00009
a decoder loss: 0.22107
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:51
train iter: 455
num of updates: 45600
vae loss: 0.22131
kl loss: 0.00009
a decoder loss: 0.22122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:52
train iter: 456
num of updates: 45700
vae loss: 0.22161
kl loss: 0.00009
a decoder loss: 0.22152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:53
train iter: 457
num of updates: 45800
vae loss: 0.22056
kl loss: 0.00009
a decoder loss: 0.22047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:54
train iter: 458
num of updates: 45900
vae loss: 0.22190
kl loss: 0.00009
a decoder loss: 0.22181
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:55
train iter: 459
num of updates: 46000
vae loss: 0.22061
kl loss: 0.00009
a decoder loss: 0.22052
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:56
train iter: 460
num of updates: 46100
vae loss: 0.22075
kl loss: 0.00009
a decoder loss: 0.22066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:57
train iter: 461
num of updates: 46200
vae loss: 0.22061
kl loss: 0.00009
a decoder loss: 0.22052
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:58
train iter: 462
num of updates: 46300
vae loss: 0.22188
kl loss: 0.00009
a decoder loss: 0.22179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:59
train iter: 463
num of updates: 46400
vae loss: 0.21989
kl loss: 0.00009
a decoder loss: 0.21981
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:00
train iter: 464
num of updates: 46500
vae loss: 0.22140
kl loss: 0.00009
a decoder loss: 0.22132
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:01
train iter: 465
num of updates: 46600
vae loss: 0.22049
kl loss: 0.00009
a decoder loss: 0.22040
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:02
train iter: 466
num of updates: 46700
vae loss: 0.22065
kl loss: 0.00009
a decoder loss: 0.22056
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:03
train iter: 467
num of updates: 46800
vae loss: 0.22000
kl loss: 0.00009
a decoder loss: 0.21991
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:04
train iter: 468
num of updates: 46900
vae loss: 0.21976
kl loss: 0.00008
a decoder loss: 0.21967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:05
train iter: 469
num of updates: 47000
vae loss: 0.21965
kl loss: 0.00008
a decoder loss: 0.21956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:06
train iter: 470
num of updates: 47100
vae loss: 0.22048
kl loss: 0.00008
a decoder loss: 0.22040
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:07
train iter: 471
num of updates: 47200
vae loss: 0.22080
kl loss: 0.00008
a decoder loss: 0.22072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:08
train iter: 472
num of updates: 47300
vae loss: 0.21988
kl loss: 0.00008
a decoder loss: 0.21980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:09
train iter: 473
num of updates: 47400
vae loss: 0.22067
kl loss: 0.00008
a decoder loss: 0.22058
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:10
train iter: 474
num of updates: 47500
vae loss: 0.22065
kl loss: 0.00008
a decoder loss: 0.22057
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:11
train iter: 475
num of updates: 47600
vae loss: 0.22024
kl loss: 0.00008
a decoder loss: 0.22016
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:12
train iter: 476
num of updates: 47700
vae loss: 0.21891
kl loss: 0.00008
a decoder loss: 0.21883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:13
train iter: 477
num of updates: 47800
vae loss: 0.21934
kl loss: 0.00008
a decoder loss: 0.21927
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:14
train iter: 478
num of updates: 47900
vae loss: 0.22018
kl loss: 0.00008
a decoder loss: 0.22010
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:15
train iter: 479
num of updates: 48000
vae loss: 0.21998
kl loss: 0.00008
a decoder loss: 0.21990
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:16
train iter: 480
num of updates: 48100
vae loss: 0.21943
kl loss: 0.00008
a decoder loss: 0.21936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:17
train iter: 481
num of updates: 48200
vae loss: 0.21887
kl loss: 0.00008
a decoder loss: 0.21879
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:18
train iter: 482
num of updates: 48300
vae loss: 0.21998
kl loss: 0.00008
a decoder loss: 0.21990
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:19
train iter: 483
num of updates: 48400
vae loss: 0.21961
kl loss: 0.00008
a decoder loss: 0.21954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:20
train iter: 484
num of updates: 48500
vae loss: 0.22020
kl loss: 0.00008
a decoder loss: 0.22013
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:21
train iter: 485
num of updates: 48600
vae loss: 0.21800
kl loss: 0.00007
a decoder loss: 0.21792
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:22
train iter: 486
num of updates: 48700
vae loss: 0.21977
kl loss: 0.00007
a decoder loss: 0.21970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:23
train iter: 487
num of updates: 48800
vae loss: 0.21948
kl loss: 0.00007
a decoder loss: 0.21941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:24
train iter: 488
num of updates: 48900
vae loss: 0.21901
kl loss: 0.00007
a decoder loss: 0.21894
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:25
train iter: 489
num of updates: 49000
vae loss: 0.21956
kl loss: 0.00007
a decoder loss: 0.21949
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:26
train iter: 490
num of updates: 49100
vae loss: 0.21878
kl loss: 0.00007
a decoder loss: 0.21871
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:27
train iter: 491
num of updates: 49200
vae loss: 0.21913
kl loss: 0.00007
a decoder loss: 0.21906
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:28
train iter: 492
num of updates: 49300
vae loss: 0.21832
kl loss: 0.00007
a decoder loss: 0.21825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:29
train iter: 493
num of updates: 49400
vae loss: 0.21854
kl loss: 0.00007
a decoder loss: 0.21847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:30
train iter: 494
num of updates: 49500
vae loss: 0.21873
kl loss: 0.00007
a decoder loss: 0.21866
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:31
train iter: 495
num of updates: 49600
vae loss: 0.21916
kl loss: 0.00007
a decoder loss: 0.21909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:32
train iter: 496
num of updates: 49700
vae loss: 0.21873
kl loss: 0.00007
a decoder loss: 0.21866
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:33
train iter: 497
num of updates: 49800
vae loss: 0.21871
kl loss: 0.00007
a decoder loss: 0.21864
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:34
train iter: 498
num of updates: 49900
vae loss: 0.21942
kl loss: 0.00007
a decoder loss: 0.21935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:35
train iter: 499
num of updates: 50000
vae loss: 0.21888
kl loss: 0.00007
a decoder loss: 0.21881
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:36
train iter: 500
num of updates: 50100
vae loss: 0.21940
kl loss: 0.00007
a decoder loss: 0.21933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:37
train iter: 501
num of updates: 50200
vae loss: 0.21818
kl loss: 0.00007
a decoder loss: 0.21811
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:38
train iter: 502
num of updates: 50300
vae loss: 0.21810
kl loss: 0.00007
a decoder loss: 0.21803
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:39
train iter: 503
num of updates: 50400
vae loss: 0.21781
kl loss: 0.00007
a decoder loss: 0.21774
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:40
train iter: 504
num of updates: 50500
vae loss: 0.21758
kl loss: 0.00007
a decoder loss: 0.21751
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:41
train iter: 505
num of updates: 50600
vae loss: 0.21854
kl loss: 0.00007
a decoder loss: 0.21848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:42
train iter: 506
num of updates: 50700
vae loss: 0.21694
kl loss: 0.00006
a decoder loss: 0.21688
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:43
train iter: 507
num of updates: 50800
vae loss: 0.21795
kl loss: 0.00007
a decoder loss: 0.21789
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:44
train iter: 508
num of updates: 50900
vae loss: 0.21869
kl loss: 0.00006
a decoder loss: 0.21863
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:45
train iter: 509
num of updates: 51000
vae loss: 0.21809
kl loss: 0.00006
a decoder loss: 0.21802
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:46
train iter: 510
num of updates: 51100
vae loss: 0.21840
kl loss: 0.00006
a decoder loss: 0.21834
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:47
train iter: 511
num of updates: 51200
vae loss: 0.21739
kl loss: 0.00006
a decoder loss: 0.21733
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:48
train iter: 512
num of updates: 51300
vae loss: 0.21755
kl loss: 0.00006
a decoder loss: 0.21748
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:49
train iter: 513
num of updates: 51400
vae loss: 0.21716
kl loss: 0.00006
a decoder loss: 0.21710
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:50
train iter: 514
num of updates: 51500
vae loss: 0.21805
kl loss: 0.00006
a decoder loss: 0.21799
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:51
train iter: 515
num of updates: 51600
vae loss: 0.21837
kl loss: 0.00006
a decoder loss: 0.21831
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:52
train iter: 516
num of updates: 51700
vae loss: 0.21791
kl loss: 0.00006
a decoder loss: 0.21785
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:53
train iter: 517
num of updates: 51800
vae loss: 0.21680
kl loss: 0.00006
a decoder loss: 0.21674
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:54
train iter: 518
num of updates: 51900
vae loss: 0.21775
kl loss: 0.00006
a decoder loss: 0.21769
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:55
train iter: 519
num of updates: 52000
vae loss: 0.21732
kl loss: 0.00006
a decoder loss: 0.21726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:56
train iter: 520
num of updates: 52100
vae loss: 0.21734
kl loss: 0.00006
a decoder loss: 0.21728
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:57
train iter: 521
num of updates: 52200
vae loss: 0.21757
kl loss: 0.00006
a decoder loss: 0.21751
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:58
train iter: 522
num of updates: 52300
vae loss: 0.21727
kl loss: 0.00006
a decoder loss: 0.21721
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:59
train iter: 523
num of updates: 52400
vae loss: 0.21771
kl loss: 0.00006
a decoder loss: 0.21766
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:00
train iter: 524
num of updates: 52500
vae loss: 0.21722
kl loss: 0.00006
a decoder loss: 0.21716
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:01
train iter: 525
num of updates: 52600
vae loss: 0.21687
kl loss: 0.00006
a decoder loss: 0.21681
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:02
train iter: 526
num of updates: 52700
vae loss: 0.21721
kl loss: 0.00006
a decoder loss: 0.21715
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:03
train iter: 527
num of updates: 52800
vae loss: 0.21803
kl loss: 0.00006
a decoder loss: 0.21797
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:04
train iter: 528
num of updates: 52900
vae loss: 0.21713
kl loss: 0.00006
a decoder loss: 0.21707
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:05
train iter: 529
num of updates: 53000
vae loss: 0.21680
kl loss: 0.00006
a decoder loss: 0.21674
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:06
train iter: 530
num of updates: 53100
vae loss: 0.21662
kl loss: 0.00005
a decoder loss: 0.21656
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:07
train iter: 531
num of updates: 53200
vae loss: 0.21588
kl loss: 0.00005
a decoder loss: 0.21582
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:08
train iter: 532
num of updates: 53300
vae loss: 0.21676
kl loss: 0.00006
a decoder loss: 0.21670
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:09
train iter: 533
num of updates: 53400
vae loss: 0.21697
kl loss: 0.00005
a decoder loss: 0.21692
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:10
train iter: 534
num of updates: 53500
vae loss: 0.21750
kl loss: 0.00005
a decoder loss: 0.21744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:11
train iter: 535
num of updates: 53600
vae loss: 0.21688
kl loss: 0.00005
a decoder loss: 0.21683
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:12
train iter: 536
num of updates: 53700
vae loss: 0.21656
kl loss: 0.00005
a decoder loss: 0.21651
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:13
train iter: 537
num of updates: 53800
vae loss: 0.21692
kl loss: 0.00005
a decoder loss: 0.21687
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:14
train iter: 538
num of updates: 53900
vae loss: 0.21675
kl loss: 0.00005
a decoder loss: 0.21669
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:15
train iter: 539
num of updates: 54000
vae loss: 0.21686
kl loss: 0.00005
a decoder loss: 0.21681
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:16
train iter: 540
num of updates: 54100
vae loss: 0.21739
kl loss: 0.00005
a decoder loss: 0.21734
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:17
train iter: 541
num of updates: 54200
vae loss: 0.21732
kl loss: 0.00005
a decoder loss: 0.21727
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:18
train iter: 542
num of updates: 54300
vae loss: 0.21601
kl loss: 0.00005
a decoder loss: 0.21596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:19
train iter: 543
num of updates: 54400
vae loss: 0.21653
kl loss: 0.00005
a decoder loss: 0.21648
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:20
train iter: 544
num of updates: 54500
vae loss: 0.21694
kl loss: 0.00005
a decoder loss: 0.21689
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:21
train iter: 545
num of updates: 54600
vae loss: 0.21630
kl loss: 0.00005
a decoder loss: 0.21625
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:22
train iter: 546
num of updates: 54700
vae loss: 0.21738
kl loss: 0.00005
a decoder loss: 0.21733
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:23
train iter: 547
num of updates: 54800
vae loss: 0.21660
kl loss: 0.00005
a decoder loss: 0.21655
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:24
train iter: 548
num of updates: 54900
vae loss: 0.21565
kl loss: 0.00005
a decoder loss: 0.21560
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:25
train iter: 549
num of updates: 55000
vae loss: 0.21714
kl loss: 0.00005
a decoder loss: 0.21708
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:26
train iter: 550
num of updates: 55100
vae loss: 0.21639
kl loss: 0.00005
a decoder loss: 0.21634
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:27
train iter: 551
num of updates: 55200
vae loss: 0.21621
kl loss: 0.00005
a decoder loss: 0.21617
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:28
train iter: 552
num of updates: 55300
vae loss: 0.21555
kl loss: 0.00005
a decoder loss: 0.21550
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:29
train iter: 553
num of updates: 55400
vae loss: 0.21705
kl loss: 0.00005
a decoder loss: 0.21700
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:30
train iter: 554
num of updates: 55500
vae loss: 0.21583
kl loss: 0.00005
a decoder loss: 0.21578
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:31
train iter: 555
num of updates: 55600
vae loss: 0.21682
kl loss: 0.00005
a decoder loss: 0.21677
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:32
train iter: 556
num of updates: 55700
vae loss: 0.21570
kl loss: 0.00005
a decoder loss: 0.21566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:33
train iter: 557
num of updates: 55800
vae loss: 0.21620
kl loss: 0.00005
a decoder loss: 0.21615
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:34
train iter: 558
num of updates: 55900
vae loss: 0.21549
kl loss: 0.00005
a decoder loss: 0.21544
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:35
train iter: 559
num of updates: 56000
vae loss: 0.21630
kl loss: 0.00005
a decoder loss: 0.21625
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:36
train iter: 560
num of updates: 56100
vae loss: 0.21489
kl loss: 0.00005
a decoder loss: 0.21484
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:37
train iter: 561
num of updates: 56200
vae loss: 0.21637
kl loss: 0.00005
a decoder loss: 0.21632
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:38
train iter: 562
num of updates: 56300
vae loss: 0.21552
kl loss: 0.00005
a decoder loss: 0.21547
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:39
train iter: 563
num of updates: 56400
vae loss: 0.21576
kl loss: 0.00005
a decoder loss: 0.21572
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:40
train iter: 564
num of updates: 56500
vae loss: 0.21578
kl loss: 0.00005
a decoder loss: 0.21573
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:41
train iter: 565
num of updates: 56600
vae loss: 0.21517
kl loss: 0.00005
a decoder loss: 0.21512
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:42
train iter: 566
num of updates: 56700
vae loss: 0.21524
kl loss: 0.00005
a decoder loss: 0.21520
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:43
train iter: 567
num of updates: 56800
vae loss: 0.21519
kl loss: 0.00005
a decoder loss: 0.21514
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:44
train iter: 568
num of updates: 56900
vae loss: 0.21599
kl loss: 0.00005
a decoder loss: 0.21594
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:45
train iter: 569
num of updates: 57000
vae loss: 0.21662
kl loss: 0.00005
a decoder loss: 0.21657
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:46
train iter: 570
num of updates: 57100
vae loss: 0.21561
kl loss: 0.00005
a decoder loss: 0.21556
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:47
train iter: 571
num of updates: 57200
vae loss: 0.21633
kl loss: 0.00005
a decoder loss: 0.21629
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:48
train iter: 572
num of updates: 57300
vae loss: 0.21511
kl loss: 0.00004
a decoder loss: 0.21507
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:49
train iter: 573
num of updates: 57400
vae loss: 0.21527
kl loss: 0.00004
a decoder loss: 0.21523
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:50
train iter: 574
num of updates: 57500
vae loss: 0.21587
kl loss: 0.00004
a decoder loss: 0.21583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:51
train iter: 575
num of updates: 57600
vae loss: 0.21595
kl loss: 0.00004
a decoder loss: 0.21591
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:52
train iter: 576
num of updates: 57700
vae loss: 0.21577
kl loss: 0.00004
a decoder loss: 0.21573
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:53
train iter: 577
num of updates: 57800
vae loss: 0.21503
kl loss: 0.00004
a decoder loss: 0.21499
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:54
train iter: 578
num of updates: 57900
vae loss: 0.21501
kl loss: 0.00004
a decoder loss: 0.21497
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:55
train iter: 579
num of updates: 58000
vae loss: 0.21497
kl loss: 0.00004
a decoder loss: 0.21493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:56
train iter: 580
num of updates: 58100
vae loss: 0.21597
kl loss: 0.00004
a decoder loss: 0.21593
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:57
train iter: 581
num of updates: 58200
vae loss: 0.21525
kl loss: 0.00004
a decoder loss: 0.21521
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:58
train iter: 582
num of updates: 58300
vae loss: 0.21472
kl loss: 0.00004
a decoder loss: 0.21468
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:59
train iter: 583
num of updates: 58400
vae loss: 0.21500
kl loss: 0.00004
a decoder loss: 0.21496
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:00
train iter: 584
num of updates: 58500
vae loss: 0.21532
kl loss: 0.00004
a decoder loss: 0.21527
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:01
train iter: 585
num of updates: 58600
vae loss: 0.21539
kl loss: 0.00004
a decoder loss: 0.21535
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:02
train iter: 586
num of updates: 58700
vae loss: 0.21459
kl loss: 0.00004
a decoder loss: 0.21455
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:03
train iter: 587
num of updates: 58800
vae loss: 0.21538
kl loss: 0.00004
a decoder loss: 0.21534
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:04
train iter: 588
num of updates: 58900
vae loss: 0.21406
kl loss: 0.00004
a decoder loss: 0.21402
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:05
train iter: 589
num of updates: 59000
vae loss: 0.21540
kl loss: 0.00004
a decoder loss: 0.21536
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:06
train iter: 590
num of updates: 59100
vae loss: 0.21443
kl loss: 0.00004
a decoder loss: 0.21439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:07
train iter: 591
num of updates: 59200
vae loss: 0.21441
kl loss: 0.00004
a decoder loss: 0.21437
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:08
train iter: 592
num of updates: 59300
vae loss: 0.21496
kl loss: 0.00004
a decoder loss: 0.21492
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:09
train iter: 593
num of updates: 59400
vae loss: 0.21435
kl loss: 0.00004
a decoder loss: 0.21431
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:10
train iter: 594
num of updates: 59500
vae loss: 0.21444
kl loss: 0.00004
a decoder loss: 0.21440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:11
train iter: 595
num of updates: 59600
vae loss: 0.21481
kl loss: 0.00004
a decoder loss: 0.21477
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:12
train iter: 596
num of updates: 59700
vae loss: 0.21517
kl loss: 0.00004
a decoder loss: 0.21513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:13
train iter: 597
num of updates: 59800
vae loss: 0.21532
kl loss: 0.00004
a decoder loss: 0.21528
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:14
train iter: 598
num of updates: 59900
vae loss: 0.21467
kl loss: 0.00004
a decoder loss: 0.21463
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:15
train iter: 599
num of updates: 60000
vae loss: 0.21516
kl loss: 0.00004
a decoder loss: 0.21512
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:16
train iter: 600
num of updates: 60100
vae loss: 0.21466
kl loss: 0.00004
a decoder loss: 0.21463
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:17
train iter: 601
num of updates: 60200
vae loss: 0.21433
kl loss: 0.00004
a decoder loss: 0.21429
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:18
train iter: 602
num of updates: 60300
vae loss: 0.21476
kl loss: 0.00004
a decoder loss: 0.21472
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:19
train iter: 603
num of updates: 60400
vae loss: 0.21360
kl loss: 0.00004
a decoder loss: 0.21356
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:20
train iter: 604
num of updates: 60500
vae loss: 0.21480
kl loss: 0.00004
a decoder loss: 0.21477
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:21
train iter: 605
num of updates: 60600
vae loss: 0.21374
kl loss: 0.00004
a decoder loss: 0.21371
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:22
train iter: 606
num of updates: 60700
vae loss: 0.21503
kl loss: 0.00004
a decoder loss: 0.21499
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:23
train iter: 607
num of updates: 60800
vae loss: 0.21470
kl loss: 0.00004
a decoder loss: 0.21467
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:24
train iter: 608
num of updates: 60900
vae loss: 0.21379
kl loss: 0.00004
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:25
train iter: 609
num of updates: 61000
vae loss: 0.21395
kl loss: 0.00004
a decoder loss: 0.21392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:26
train iter: 610
num of updates: 61100
vae loss: 0.21445
kl loss: 0.00004
a decoder loss: 0.21441
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:27
train iter: 611
num of updates: 61200
vae loss: 0.21537
kl loss: 0.00004
a decoder loss: 0.21533
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:28
train iter: 612
num of updates: 61300
vae loss: 0.21421
kl loss: 0.00004
a decoder loss: 0.21417
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:29
train iter: 613
num of updates: 61400
vae loss: 0.21480
kl loss: 0.00004
a decoder loss: 0.21476
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:30
train iter: 614
num of updates: 61500
vae loss: 0.21445
kl loss: 0.00004
a decoder loss: 0.21442
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:31
train iter: 615
num of updates: 61600
vae loss: 0.21465
kl loss: 0.00004
a decoder loss: 0.21461
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:32
train iter: 616
num of updates: 61700
vae loss: 0.21416
kl loss: 0.00004
a decoder loss: 0.21412
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:33
train iter: 617
num of updates: 61800
vae loss: 0.21363
kl loss: 0.00004
a decoder loss: 0.21359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:34
train iter: 618
num of updates: 61900
vae loss: 0.21491
kl loss: 0.00004
a decoder loss: 0.21488
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:35
train iter: 619
num of updates: 62000
vae loss: 0.21393
kl loss: 0.00004
a decoder loss: 0.21389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:36
train iter: 620
num of updates: 62100
vae loss: 0.21316
kl loss: 0.00003
a decoder loss: 0.21313
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:37
train iter: 621
num of updates: 62200
vae loss: 0.21473
kl loss: 0.00004
a decoder loss: 0.21469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:38
train iter: 622
num of updates: 62300
vae loss: 0.21337
kl loss: 0.00003
a decoder loss: 0.21334
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:39
train iter: 623
num of updates: 62400
vae loss: 0.21396
kl loss: 0.00003
a decoder loss: 0.21393
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:40
train iter: 624
num of updates: 62500
vae loss: 0.21385
kl loss: 0.00003
a decoder loss: 0.21382
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:41
train iter: 625
num of updates: 62600
vae loss: 0.21388
kl loss: 0.00003
a decoder loss: 0.21385
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:42
train iter: 626
num of updates: 62700
vae loss: 0.21437
kl loss: 0.00003
a decoder loss: 0.21433
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:43
train iter: 627
num of updates: 62800
vae loss: 0.21432
kl loss: 0.00004
a decoder loss: 0.21428
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:44
train iter: 628
num of updates: 62900
vae loss: 0.21316
kl loss: 0.00003
a decoder loss: 0.21313
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:45
train iter: 629
num of updates: 63000
vae loss: 0.21314
kl loss: 0.00003
a decoder loss: 0.21311
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:46
train iter: 630
num of updates: 63100
vae loss: 0.21385
kl loss: 0.00003
a decoder loss: 0.21382
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:47
train iter: 631
num of updates: 63200
vae loss: 0.21309
kl loss: 0.00003
a decoder loss: 0.21305
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:48
train iter: 632
num of updates: 63300
vae loss: 0.21363
kl loss: 0.00003
a decoder loss: 0.21359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:49
train iter: 633
num of updates: 63400
vae loss: 0.21406
kl loss: 0.00003
a decoder loss: 0.21403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:50
train iter: 634
num of updates: 63500
vae loss: 0.21324
kl loss: 0.00003
a decoder loss: 0.21321
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:51
train iter: 635
num of updates: 63600
vae loss: 0.21328
kl loss: 0.00003
a decoder loss: 0.21324
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:52
train iter: 636
num of updates: 63700
vae loss: 0.21411
kl loss: 0.00003
a decoder loss: 0.21407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:53
train iter: 637
num of updates: 63800
vae loss: 0.21409
kl loss: 0.00003
a decoder loss: 0.21406
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:55
train iter: 638
num of updates: 63900
vae loss: 0.21409
kl loss: 0.00003
a decoder loss: 0.21406
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:56
train iter: 639
num of updates: 64000
vae loss: 0.21438
kl loss: 0.00003
a decoder loss: 0.21435
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:57
train iter: 640
num of updates: 64100
vae loss: 0.21364
kl loss: 0.00003
a decoder loss: 0.21361
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:58
train iter: 641
num of updates: 64200
vae loss: 0.21294
kl loss: 0.00003
a decoder loss: 0.21290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:59
train iter: 642
num of updates: 64300
vae loss: 0.21340
kl loss: 0.00003
a decoder loss: 0.21337
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:00
train iter: 643
num of updates: 64400
vae loss: 0.21364
kl loss: 0.00003
a decoder loss: 0.21361
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:01
train iter: 644
num of updates: 64500
vae loss: 0.21322
kl loss: 0.00003
a decoder loss: 0.21319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:02
train iter: 645
num of updates: 64600
vae loss: 0.21376
kl loss: 0.00003
a decoder loss: 0.21373
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:03
train iter: 646
num of updates: 64700
vae loss: 0.21434
kl loss: 0.00003
a decoder loss: 0.21431
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:04
train iter: 647
num of updates: 64800
vae loss: 0.21395
kl loss: 0.00003
a decoder loss: 0.21392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:05
train iter: 648
num of updates: 64900
vae loss: 0.21318
kl loss: 0.00003
a decoder loss: 0.21315
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:06
train iter: 649
num of updates: 65000
vae loss: 0.21272
kl loss: 0.00003
a decoder loss: 0.21269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:07
train iter: 650
num of updates: 65100
vae loss: 0.21321
kl loss: 0.00003
a decoder loss: 0.21318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:08
train iter: 651
num of updates: 65200
vae loss: 0.21410
kl loss: 0.00003
a decoder loss: 0.21407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:09
train iter: 652
num of updates: 65300
vae loss: 0.21284
kl loss: 0.00003
a decoder loss: 0.21280
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:10
train iter: 653
num of updates: 65400
vae loss: 0.21321
kl loss: 0.00003
a decoder loss: 0.21318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:11
train iter: 654
num of updates: 65500
vae loss: 0.21298
kl loss: 0.00003
a decoder loss: 0.21295
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:12
train iter: 655
num of updates: 65600
vae loss: 0.21294
kl loss: 0.00003
a decoder loss: 0.21291
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:13
train iter: 656
num of updates: 65700
vae loss: 0.21374
kl loss: 0.00003
a decoder loss: 0.21371
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:14
train iter: 657
num of updates: 65800
vae loss: 0.21343
kl loss: 0.00003
a decoder loss: 0.21340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:15
train iter: 658
num of updates: 65900
vae loss: 0.21333
kl loss: 0.00003
a decoder loss: 0.21330
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:16
train iter: 659
num of updates: 66000
vae loss: 0.21286
kl loss: 0.00003
a decoder loss: 0.21283
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:17
train iter: 660
num of updates: 66100
vae loss: 0.21340
kl loss: 0.00003
a decoder loss: 0.21337
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:18
train iter: 661
num of updates: 66200
vae loss: 0.21349
kl loss: 0.00003
a decoder loss: 0.21346
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:19
train iter: 662
num of updates: 66300
vae loss: 0.21233
kl loss: 0.00003
a decoder loss: 0.21230
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:20
train iter: 663
num of updates: 66400
vae loss: 0.21246
kl loss: 0.00003
a decoder loss: 0.21243
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:21
train iter: 664
num of updates: 66500
vae loss: 0.21326
kl loss: 0.00003
a decoder loss: 0.21324
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:22
train iter: 665
num of updates: 66600
vae loss: 0.21377
kl loss: 0.00003
a decoder loss: 0.21374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:23
train iter: 666
num of updates: 66700
vae loss: 0.21316
kl loss: 0.00003
a decoder loss: 0.21313
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:24
train iter: 667
num of updates: 66800
vae loss: 0.21272
kl loss: 0.00003
a decoder loss: 0.21270
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:25
train iter: 668
num of updates: 66900
vae loss: 0.21297
kl loss: 0.00003
a decoder loss: 0.21295
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:26
train iter: 669
num of updates: 67000
vae loss: 0.21259
kl loss: 0.00003
a decoder loss: 0.21256
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:27
train iter: 670
num of updates: 67100
vae loss: 0.21301
kl loss: 0.00003
a decoder loss: 0.21298
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:28
train iter: 671
num of updates: 67200
vae loss: 0.21298
kl loss: 0.00003
a decoder loss: 0.21296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:29
train iter: 672
num of updates: 67300
vae loss: 0.21335
kl loss: 0.00003
a decoder loss: 0.21332
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:30
train iter: 673
num of updates: 67400
vae loss: 0.21279
kl loss: 0.00003
a decoder loss: 0.21276
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:31
train iter: 674
num of updates: 67500
vae loss: 0.21240
kl loss: 0.00003
a decoder loss: 0.21237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:32
train iter: 675
num of updates: 67600
vae loss: 0.21258
kl loss: 0.00003
a decoder loss: 0.21255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:33
train iter: 676
num of updates: 67700
vae loss: 0.21282
kl loss: 0.00003
a decoder loss: 0.21279
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:34
train iter: 677
num of updates: 67800
vae loss: 0.21264
kl loss: 0.00003
a decoder loss: 0.21262
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:35
train iter: 678
num of updates: 67900
vae loss: 0.21288
kl loss: 0.00003
a decoder loss: 0.21285
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:36
train iter: 679
num of updates: 68000
vae loss: 0.21343
kl loss: 0.00003
a decoder loss: 0.21341
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:37
train iter: 680
num of updates: 68100
vae loss: 0.21245
kl loss: 0.00003
a decoder loss: 0.21242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:38
train iter: 681
num of updates: 68200
vae loss: 0.21312
kl loss: 0.00003
a decoder loss: 0.21310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:39
train iter: 682
num of updates: 68300
vae loss: 0.21318
kl loss: 0.00003
a decoder loss: 0.21315
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:40
train iter: 683
num of updates: 68400
vae loss: 0.21281
kl loss: 0.00003
a decoder loss: 0.21278
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:41
train iter: 684
num of updates: 68500
vae loss: 0.21211
kl loss: 0.00003
a decoder loss: 0.21208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:42
train iter: 685
num of updates: 68600
vae loss: 0.21293
kl loss: 0.00003
a decoder loss: 0.21290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:43
train iter: 686
num of updates: 68700
vae loss: 0.21346
kl loss: 0.00003
a decoder loss: 0.21343
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:44
train iter: 687
num of updates: 68800
vae loss: 0.21301
kl loss: 0.00003
a decoder loss: 0.21298
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:45
train iter: 688
num of updates: 68900
vae loss: 0.21278
kl loss: 0.00003
a decoder loss: 0.21275
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:46
train iter: 689
num of updates: 69000
vae loss: 0.21272
kl loss: 0.00003
a decoder loss: 0.21269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:47
train iter: 690
num of updates: 69100
vae loss: 0.21217
kl loss: 0.00003
a decoder loss: 0.21215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:48
train iter: 691
num of updates: 69200
vae loss: 0.21259
kl loss: 0.00003
a decoder loss: 0.21256
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:49
train iter: 692
num of updates: 69300
vae loss: 0.21243
kl loss: 0.00003
a decoder loss: 0.21241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:50
train iter: 693
num of updates: 69400
vae loss: 0.21252
kl loss: 0.00003
a decoder loss: 0.21249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:51
train iter: 694
num of updates: 69500
vae loss: 0.21241
kl loss: 0.00003
a decoder loss: 0.21238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:52
train iter: 695
num of updates: 69600
vae loss: 0.21210
kl loss: 0.00003
a decoder loss: 0.21207
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:53
train iter: 696
num of updates: 69700
vae loss: 0.21390
kl loss: 0.00003
a decoder loss: 0.21388
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:54
train iter: 697
num of updates: 69800
vae loss: 0.21245
kl loss: 0.00003
a decoder loss: 0.21242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:55
train iter: 698
num of updates: 69900
vae loss: 0.21260
kl loss: 0.00003
a decoder loss: 0.21258
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:56
train iter: 699
num of updates: 70000
vae loss: 0.21267
kl loss: 0.00003
a decoder loss: 0.21264
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:57
train iter: 700
num of updates: 70100
vae loss: 0.21147
kl loss: 0.00003
a decoder loss: 0.21145
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:58
train iter: 701
num of updates: 70200
vae loss: 0.21250
kl loss: 0.00003
a decoder loss: 0.21247
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:59
train iter: 702
num of updates: 70300
vae loss: 0.21298
kl loss: 0.00003
a decoder loss: 0.21296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:00
train iter: 703
num of updates: 70400
vae loss: 0.21280
kl loss: 0.00003
a decoder loss: 0.21278
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:01
train iter: 704
num of updates: 70500
vae loss: 0.21300
kl loss: 0.00003
a decoder loss: 0.21298
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:02
train iter: 705
num of updates: 70600
vae loss: 0.21254
kl loss: 0.00002
a decoder loss: 0.21251
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:03
train iter: 706
num of updates: 70700
vae loss: 0.21174
kl loss: 0.00003
a decoder loss: 0.21171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:04
train iter: 707
num of updates: 70800
vae loss: 0.21222
kl loss: 0.00002
a decoder loss: 0.21220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:05
train iter: 708
num of updates: 70900
vae loss: 0.21125
kl loss: 0.00002
a decoder loss: 0.21122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:06
train iter: 709
num of updates: 71000
vae loss: 0.21150
kl loss: 0.00002
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:07
train iter: 710
num of updates: 71100
vae loss: 0.21189
kl loss: 0.00002
a decoder loss: 0.21187
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:08
train iter: 711
num of updates: 71200
vae loss: 0.21212
kl loss: 0.00002
a decoder loss: 0.21209
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:09
train iter: 712
num of updates: 71300
vae loss: 0.21254
kl loss: 0.00002
a decoder loss: 0.21252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:10
train iter: 713
num of updates: 71400
vae loss: 0.21183
kl loss: 0.00002
a decoder loss: 0.21181
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:11
train iter: 714
num of updates: 71500
vae loss: 0.21158
kl loss: 0.00002
a decoder loss: 0.21156
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:12
train iter: 715
num of updates: 71600
vae loss: 0.21192
kl loss: 0.00002
a decoder loss: 0.21189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:13
train iter: 716
num of updates: 71700
vae loss: 0.21197
kl loss: 0.00002
a decoder loss: 0.21195
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:14
train iter: 717
num of updates: 71800
vae loss: 0.21179
kl loss: 0.00002
a decoder loss: 0.21176
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:15
train iter: 718
num of updates: 71900
vae loss: 0.21292
kl loss: 0.00002
a decoder loss: 0.21290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:16
train iter: 719
num of updates: 72000
vae loss: 0.21245
kl loss: 0.00002
a decoder loss: 0.21242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:17
train iter: 720
num of updates: 72100
vae loss: 0.21248
kl loss: 0.00002
a decoder loss: 0.21245
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:18
train iter: 721
num of updates: 72200
vae loss: 0.21266
kl loss: 0.00002
a decoder loss: 0.21263
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:19
train iter: 722
num of updates: 72300
vae loss: 0.21190
kl loss: 0.00002
a decoder loss: 0.21187
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:20
train iter: 723
num of updates: 72400
vae loss: 0.21208
kl loss: 0.00002
a decoder loss: 0.21206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:21
train iter: 724
num of updates: 72500
vae loss: 0.21212
kl loss: 0.00002
a decoder loss: 0.21209
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:22
train iter: 725
num of updates: 72600
vae loss: 0.21240
kl loss: 0.00002
a decoder loss: 0.21238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:23
train iter: 726
num of updates: 72700
vae loss: 0.21136
kl loss: 0.00002
a decoder loss: 0.21134
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:24
train iter: 727
num of updates: 72800
vae loss: 0.21220
kl loss: 0.00002
a decoder loss: 0.21218
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:25
train iter: 728
num of updates: 72900
vae loss: 0.21213
kl loss: 0.00002
a decoder loss: 0.21210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:26
train iter: 729
num of updates: 73000
vae loss: 0.21257
kl loss: 0.00002
a decoder loss: 0.21255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:27
train iter: 730
num of updates: 73100
vae loss: 0.21251
kl loss: 0.00002
a decoder loss: 0.21248
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:28
train iter: 731
num of updates: 73200
vae loss: 0.21168
kl loss: 0.00002
a decoder loss: 0.21166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:29
train iter: 732
num of updates: 73300
vae loss: 0.21297
kl loss: 0.00002
a decoder loss: 0.21294
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:30
train iter: 733
num of updates: 73400
vae loss: 0.21204
kl loss: 0.00002
a decoder loss: 0.21201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:31
train iter: 734
num of updates: 73500
vae loss: 0.21184
kl loss: 0.00002
a decoder loss: 0.21182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:32
train iter: 735
num of updates: 73600
vae loss: 0.21239
kl loss: 0.00002
a decoder loss: 0.21237
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:33
train iter: 736
num of updates: 73700
vae loss: 0.21156
kl loss: 0.00002
a decoder loss: 0.21154
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:34
train iter: 737
num of updates: 73800
vae loss: 0.21151
kl loss: 0.00002
a decoder loss: 0.21149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:35
train iter: 738
num of updates: 73900
vae loss: 0.21140
kl loss: 0.00002
a decoder loss: 0.21138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:36
train iter: 739
num of updates: 74000
vae loss: 0.21149
kl loss: 0.00002
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:37
train iter: 740
num of updates: 74100
vae loss: 0.21136
kl loss: 0.00002
a decoder loss: 0.21134
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:38
train iter: 741
num of updates: 74200
vae loss: 0.21179
kl loss: 0.00002
a decoder loss: 0.21177
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:39
train iter: 742
num of updates: 74300
vae loss: 0.21223
kl loss: 0.00002
a decoder loss: 0.21221
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:40
train iter: 743
num of updates: 74400
vae loss: 0.21199
kl loss: 0.00002
a decoder loss: 0.21197
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:41
train iter: 744
num of updates: 74500
vae loss: 0.21218
kl loss: 0.00002
a decoder loss: 0.21216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:42
train iter: 745
num of updates: 74600
vae loss: 0.21176
kl loss: 0.00002
a decoder loss: 0.21174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:43
train iter: 746
num of updates: 74700
vae loss: 0.21186
kl loss: 0.00002
a decoder loss: 0.21183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:44
train iter: 747
num of updates: 74800
vae loss: 0.21102
kl loss: 0.00002
a decoder loss: 0.21100
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:45
train iter: 748
num of updates: 74900
vae loss: 0.21095
kl loss: 0.00002
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:46
train iter: 749
num of updates: 75000
vae loss: 0.21105
kl loss: 0.00002
a decoder loss: 0.21103
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:47
train iter: 750
num of updates: 75100
vae loss: 0.21237
kl loss: 0.00002
a decoder loss: 0.21235
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:48
train iter: 751
num of updates: 75200
vae loss: 0.21253
kl loss: 0.00002
a decoder loss: 0.21251
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:49
train iter: 752
num of updates: 75300
vae loss: 0.21074
kl loss: 0.00002
a decoder loss: 0.21072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:50
train iter: 753
num of updates: 75400
vae loss: 0.21116
kl loss: 0.00002
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:51
train iter: 754
num of updates: 75500
vae loss: 0.21046
kl loss: 0.00002
a decoder loss: 0.21044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:52
train iter: 755
num of updates: 75600
vae loss: 0.21128
kl loss: 0.00002
a decoder loss: 0.21126
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:53
train iter: 756
num of updates: 75700
vae loss: 0.21236
kl loss: 0.00002
a decoder loss: 0.21233
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:54
train iter: 757
num of updates: 75800
vae loss: 0.21238
kl loss: 0.00002
a decoder loss: 0.21236
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:55
train iter: 758
num of updates: 75900
vae loss: 0.21122
kl loss: 0.00002
a decoder loss: 0.21120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:56
train iter: 759
num of updates: 76000
vae loss: 0.21129
kl loss: 0.00002
a decoder loss: 0.21127
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:57
train iter: 760
num of updates: 76100
vae loss: 0.21255
kl loss: 0.00002
a decoder loss: 0.21252
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:58
train iter: 761
num of updates: 76200
vae loss: 0.21148
kl loss: 0.00002
a decoder loss: 0.21146
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:59
train iter: 762
num of updates: 76300
vae loss: 0.21186
kl loss: 0.00002
a decoder loss: 0.21184
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:00
train iter: 763
num of updates: 76400
vae loss: 0.21034
kl loss: 0.00002
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:01
train iter: 764
num of updates: 76500
vae loss: 0.21186
kl loss: 0.00002
a decoder loss: 0.21184
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:02
train iter: 765
num of updates: 76600
vae loss: 0.21087
kl loss: 0.00002
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:03
train iter: 766
num of updates: 76700
vae loss: 0.21087
kl loss: 0.00002
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:04
train iter: 767
num of updates: 76800
vae loss: 0.21217
kl loss: 0.00002
a decoder loss: 0.21215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:05
train iter: 768
num of updates: 76900
vae loss: 0.21148
kl loss: 0.00002
a decoder loss: 0.21146
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:06
train iter: 769
num of updates: 77000
vae loss: 0.21190
kl loss: 0.00002
a decoder loss: 0.21188
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:07
train iter: 770
num of updates: 77100
vae loss: 0.21121
kl loss: 0.00002
a decoder loss: 0.21119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:08
train iter: 771
num of updates: 77200
vae loss: 0.21138
kl loss: 0.00002
a decoder loss: 0.21136
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:09
train iter: 772
num of updates: 77300
vae loss: 0.21213
kl loss: 0.00002
a decoder loss: 0.21211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:10
train iter: 773
num of updates: 77400
vae loss: 0.21135
kl loss: 0.00002
a decoder loss: 0.21133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:11
train iter: 774
num of updates: 77500
vae loss: 0.21061
kl loss: 0.00002
a decoder loss: 0.21059
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:12
train iter: 775
num of updates: 77600
vae loss: 0.21183
kl loss: 0.00002
a decoder loss: 0.21181
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:13
train iter: 776
num of updates: 77700
vae loss: 0.21066
kl loss: 0.00002
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:14
train iter: 777
num of updates: 77800
vae loss: 0.21114
kl loss: 0.00002
a decoder loss: 0.21112
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:15
train iter: 778
num of updates: 77900
vae loss: 0.21140
kl loss: 0.00002
a decoder loss: 0.21138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:16
train iter: 779
num of updates: 78000
vae loss: 0.21053
kl loss: 0.00002
a decoder loss: 0.21051
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:17
train iter: 780
num of updates: 78100
vae loss: 0.21076
kl loss: 0.00002
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:18
train iter: 781
num of updates: 78200
vae loss: 0.21207
kl loss: 0.00002
a decoder loss: 0.21205
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:19
train iter: 782
num of updates: 78300
vae loss: 0.21098
kl loss: 0.00002
a decoder loss: 0.21096
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:20
train iter: 783
num of updates: 78400
vae loss: 0.21068
kl loss: 0.00002
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:21
train iter: 784
num of updates: 78500
vae loss: 0.21116
kl loss: 0.00002
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:22
train iter: 785
num of updates: 78600
vae loss: 0.21091
kl loss: 0.00002
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:23
train iter: 786
num of updates: 78700
vae loss: 0.21083
kl loss: 0.00002
a decoder loss: 0.21081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:24
train iter: 787
num of updates: 78800
vae loss: 0.21117
kl loss: 0.00002
a decoder loss: 0.21115
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:25
train iter: 788
num of updates: 78900
vae loss: 0.21179
kl loss: 0.00002
a decoder loss: 0.21177
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:26
train iter: 789
num of updates: 79000
vae loss: 0.21105
kl loss: 0.00002
a decoder loss: 0.21103
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:27
train iter: 790
num of updates: 79100
vae loss: 0.21130
kl loss: 0.00002
a decoder loss: 0.21128
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:28
train iter: 791
num of updates: 79200
vae loss: 0.21087
kl loss: 0.00002
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:29
train iter: 792
num of updates: 79300
vae loss: 0.21143
kl loss: 0.00002
a decoder loss: 0.21141
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:30
train iter: 793
num of updates: 79400
vae loss: 0.21127
kl loss: 0.00002
a decoder loss: 0.21125
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:31
train iter: 794
num of updates: 79500
vae loss: 0.21186
kl loss: 0.00002
a decoder loss: 0.21184
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:32
train iter: 795
num of updates: 79600
vae loss: 0.21092
kl loss: 0.00002
a decoder loss: 0.21090
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:33
train iter: 796
num of updates: 79700
vae loss: 0.21038
kl loss: 0.00002
a decoder loss: 0.21036
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:34
train iter: 797
num of updates: 79800
vae loss: 0.21179
kl loss: 0.00002
a decoder loss: 0.21177
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:35
train iter: 798
num of updates: 79900
vae loss: 0.21070
kl loss: 0.00002
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:36
train iter: 799
num of updates: 80000
vae loss: 0.21035
kl loss: 0.00002
a decoder loss: 0.21033
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:37
train iter: 800
num of updates: 80100
vae loss: 0.21158
kl loss: 0.00002
a decoder loss: 0.21156
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:38
train iter: 801
num of updates: 80200
vae loss: 0.21072
kl loss: 0.00002
a decoder loss: 0.21070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:39
train iter: 802
num of updates: 80300
vae loss: 0.21150
kl loss: 0.00002
a decoder loss: 0.21148
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:40
train iter: 803
num of updates: 80400
vae loss: 0.21047
kl loss: 0.00002
a decoder loss: 0.21046
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:41
train iter: 804
num of updates: 80500
vae loss: 0.21094
kl loss: 0.00002
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:42
train iter: 805
num of updates: 80600
vae loss: 0.21067
kl loss: 0.00002
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:43
train iter: 806
num of updates: 80700
vae loss: 0.21131
kl loss: 0.00002
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:44
train iter: 807
num of updates: 80800
vae loss: 0.21069
kl loss: 0.00002
a decoder loss: 0.21067
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:45
train iter: 808
num of updates: 80900
vae loss: 0.21064
kl loss: 0.00002
a decoder loss: 0.21063
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:46
train iter: 809
num of updates: 81000
vae loss: 0.21107
kl loss: 0.00002
a decoder loss: 0.21105
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:47
train iter: 810
num of updates: 81100
vae loss: 0.21129
kl loss: 0.00002
a decoder loss: 0.21127
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:48
train iter: 811
num of updates: 81200
vae loss: 0.21104
kl loss: 0.00002
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:49
train iter: 812
num of updates: 81300
vae loss: 0.21124
kl loss: 0.00002
a decoder loss: 0.21123
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:50
train iter: 813
num of updates: 81400
vae loss: 0.21062
kl loss: 0.00002
a decoder loss: 0.21060
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:51
train iter: 814
num of updates: 81500
vae loss: 0.21116
kl loss: 0.00002
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:52
train iter: 815
num of updates: 81600
vae loss: 0.21126
kl loss: 0.00002
a decoder loss: 0.21124
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:53
train iter: 816
num of updates: 81700
vae loss: 0.21133
kl loss: 0.00002
a decoder loss: 0.21131
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:54
train iter: 817
num of updates: 81800
vae loss: 0.21162
kl loss: 0.00002
a decoder loss: 0.21160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:55
train iter: 818
num of updates: 81900
vae loss: 0.21087
kl loss: 0.00002
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:56
train iter: 819
num of updates: 82000
vae loss: 0.21087
kl loss: 0.00002
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:57
train iter: 820
num of updates: 82100
vae loss: 0.21105
kl loss: 0.00002
a decoder loss: 0.21103
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:58
train iter: 821
num of updates: 82200
vae loss: 0.20959
kl loss: 0.00002
a decoder loss: 0.20957
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:59
train iter: 822
num of updates: 82300
vae loss: 0.21044
kl loss: 0.00002
a decoder loss: 0.21042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:00
train iter: 823
num of updates: 82400
vae loss: 0.21076
kl loss: 0.00002
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:01
train iter: 824
num of updates: 82500
vae loss: 0.21040
kl loss: 0.00002
a decoder loss: 0.21038
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:02
train iter: 825
num of updates: 82600
vae loss: 0.21063
kl loss: 0.00002
a decoder loss: 0.21061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:03
train iter: 826
num of updates: 82700
vae loss: 0.21074
kl loss: 0.00002
a decoder loss: 0.21073
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:04
train iter: 827
num of updates: 82800
vae loss: 0.21020
kl loss: 0.00002
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:05
train iter: 828
num of updates: 82900
vae loss: 0.21046
kl loss: 0.00002
a decoder loss: 0.21044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:06
train iter: 829
num of updates: 83000
vae loss: 0.21068
kl loss: 0.00002
a decoder loss: 0.21067
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:07
train iter: 830
num of updates: 83100
vae loss: 0.21041
kl loss: 0.00002
a decoder loss: 0.21039
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:08
train iter: 831
num of updates: 83200
vae loss: 0.21091
kl loss: 0.00002
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:09
train iter: 832
num of updates: 83300
vae loss: 0.21066
kl loss: 0.00002
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:10
train iter: 833
num of updates: 83400
vae loss: 0.21072
kl loss: 0.00002
a decoder loss: 0.21071
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:11
train iter: 834
num of updates: 83500
vae loss: 0.21019
kl loss: 0.00002
a decoder loss: 0.21017
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:12
train iter: 835
num of updates: 83600
vae loss: 0.21127
kl loss: 0.00002
a decoder loss: 0.21125
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:13
train iter: 836
num of updates: 83700
vae loss: 0.21009
kl loss: 0.00002
a decoder loss: 0.21008
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:14
train iter: 837
num of updates: 83800
vae loss: 0.21093
kl loss: 0.00002
a decoder loss: 0.21091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:15
train iter: 838
num of updates: 83900
vae loss: 0.20947
kl loss: 0.00002
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:16
train iter: 839
num of updates: 84000
vae loss: 0.21068
kl loss: 0.00002
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:17
train iter: 840
num of updates: 84100
vae loss: 0.21083
kl loss: 0.00002
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:18
train iter: 841
num of updates: 84200
vae loss: 0.21058
kl loss: 0.00002
a decoder loss: 0.21056
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:19
train iter: 842
num of updates: 84300
vae loss: 0.21017
kl loss: 0.00002
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:20
train iter: 843
num of updates: 84400
vae loss: 0.20982
kl loss: 0.00002
a decoder loss: 0.20980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:21
train iter: 844
num of updates: 84500
vae loss: 0.21097
kl loss: 0.00002
a decoder loss: 0.21095
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:22
train iter: 845
num of updates: 84600
vae loss: 0.21015
kl loss: 0.00002
a decoder loss: 0.21013
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:23
train iter: 846
num of updates: 84700
vae loss: 0.21072
kl loss: 0.00002
a decoder loss: 0.21071
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:24
train iter: 847
num of updates: 84800
vae loss: 0.21000
kl loss: 0.00002
a decoder loss: 0.20998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:25
train iter: 848
num of updates: 84900
vae loss: 0.21040
kl loss: 0.00002
a decoder loss: 0.21038
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:26
train iter: 849
num of updates: 85000
vae loss: 0.21019
kl loss: 0.00002
a decoder loss: 0.21017
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:27
train iter: 850
num of updates: 85100
vae loss: 0.21005
kl loss: 0.00002
a decoder loss: 0.21004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:28
train iter: 851
num of updates: 85200
vae loss: 0.21068
kl loss: 0.00002
a decoder loss: 0.21067
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:29
train iter: 852
num of updates: 85300
vae loss: 0.21004
kl loss: 0.00002
a decoder loss: 0.21003
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:30
train iter: 853
num of updates: 85400
vae loss: 0.21093
kl loss: 0.00002
a decoder loss: 0.21091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:31
train iter: 854
num of updates: 85500
vae loss: 0.21035
kl loss: 0.00002
a decoder loss: 0.21033
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:33
train iter: 855
num of updates: 85600
vae loss: 0.21059
kl loss: 0.00002
a decoder loss: 0.21057
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:34
train iter: 856
num of updates: 85700
vae loss: 0.21098
kl loss: 0.00002
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:35
train iter: 857
num of updates: 85800
vae loss: 0.21041
kl loss: 0.00002
a decoder loss: 0.21040
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:36
train iter: 858
num of updates: 85900
vae loss: 0.21055
kl loss: 0.00002
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:37
train iter: 859
num of updates: 86000
vae loss: 0.21058
kl loss: 0.00002
a decoder loss: 0.21056
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:38
train iter: 860
num of updates: 86100
vae loss: 0.21027
kl loss: 0.00002
a decoder loss: 0.21026
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:39
train iter: 861
num of updates: 86200
vae loss: 0.21041
kl loss: 0.00002
a decoder loss: 0.21039
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:40
train iter: 862
num of updates: 86300
vae loss: 0.20999
kl loss: 0.00002
a decoder loss: 0.20998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:41
train iter: 863
num of updates: 86400
vae loss: 0.21110
kl loss: 0.00002
a decoder loss: 0.21109
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:42
train iter: 864
num of updates: 86500
vae loss: 0.20973
kl loss: 0.00002
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:43
train iter: 865
num of updates: 86600
vae loss: 0.21098
kl loss: 0.00002
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:44
train iter: 866
num of updates: 86700
vae loss: 0.21047
kl loss: 0.00002
a decoder loss: 0.21046
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:45
train iter: 867
num of updates: 86800
vae loss: 0.21028
kl loss: 0.00001
a decoder loss: 0.21026
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:46
train iter: 868
num of updates: 86900
vae loss: 0.21025
kl loss: 0.00002
a decoder loss: 0.21024
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:47
train iter: 869
num of updates: 87000
vae loss: 0.21016
kl loss: 0.00002
a decoder loss: 0.21014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:48
train iter: 870
num of updates: 87100
vae loss: 0.21011
kl loss: 0.00002
a decoder loss: 0.21009
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:49
train iter: 871
num of updates: 87200
vae loss: 0.21055
kl loss: 0.00002
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:50
train iter: 872
num of updates: 87300
vae loss: 0.20942
kl loss: 0.00002
a decoder loss: 0.20940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:51
train iter: 873
num of updates: 87400
vae loss: 0.21003
kl loss: 0.00002
a decoder loss: 0.21001
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:52
train iter: 874
num of updates: 87500
vae loss: 0.21024
kl loss: 0.00002
a decoder loss: 0.21022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:53
train iter: 875
num of updates: 87600
vae loss: 0.21009
kl loss: 0.00002
a decoder loss: 0.21008
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:54
train iter: 876
num of updates: 87700
vae loss: 0.20951
kl loss: 0.00002
a decoder loss: 0.20950
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:55
train iter: 877
num of updates: 87800
vae loss: 0.21104
kl loss: 0.00001
a decoder loss: 0.21103
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:56
train iter: 878
num of updates: 87900
vae loss: 0.21022
kl loss: 0.00002
a decoder loss: 0.21021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:57
train iter: 879
num of updates: 88000
vae loss: 0.20980
kl loss: 0.00001
a decoder loss: 0.20978
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:58
train iter: 880
num of updates: 88100
vae loss: 0.20965
kl loss: 0.00001
a decoder loss: 0.20963
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:59
train iter: 881
num of updates: 88200
vae loss: 0.21046
kl loss: 0.00002
a decoder loss: 0.21045
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:00
train iter: 882
num of updates: 88300
vae loss: 0.21027
kl loss: 0.00002
a decoder loss: 0.21025
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:01
train iter: 883
num of updates: 88400
vae loss: 0.21104
kl loss: 0.00002
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:02
train iter: 884
num of updates: 88500
vae loss: 0.20978
kl loss: 0.00001
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:03
train iter: 885
num of updates: 88600
vae loss: 0.21033
kl loss: 0.00001
a decoder loss: 0.21031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:04
train iter: 886
num of updates: 88700
vae loss: 0.21030
kl loss: 0.00002
a decoder loss: 0.21028
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:05
train iter: 887
num of updates: 88800
vae loss: 0.21023
kl loss: 0.00001
a decoder loss: 0.21022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:06
train iter: 888
num of updates: 88900
vae loss: 0.20948
kl loss: 0.00001
a decoder loss: 0.20947
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:07
train iter: 889
num of updates: 89000
vae loss: 0.20968
kl loss: 0.00001
a decoder loss: 0.20966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:08
train iter: 890
num of updates: 89100
vae loss: 0.20932
kl loss: 0.00001
a decoder loss: 0.20931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:09
train iter: 891
num of updates: 89200
vae loss: 0.21045
kl loss: 0.00001
a decoder loss: 0.21044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:10
train iter: 892
num of updates: 89300
vae loss: 0.20940
kl loss: 0.00001
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:11
train iter: 893
num of updates: 89400
vae loss: 0.20973
kl loss: 0.00001
a decoder loss: 0.20972
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:12
train iter: 894
num of updates: 89500
vae loss: 0.20959
kl loss: 0.00001
a decoder loss: 0.20958
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:13
train iter: 895
num of updates: 89600
vae loss: 0.21028
kl loss: 0.00001
a decoder loss: 0.21027
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:14
train iter: 896
num of updates: 89700
vae loss: 0.20914
kl loss: 0.00001
a decoder loss: 0.20912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:15
train iter: 897
num of updates: 89800
vae loss: 0.21080
kl loss: 0.00001
a decoder loss: 0.21079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:16
train iter: 898
num of updates: 89900
vae loss: 0.21010
kl loss: 0.00001
a decoder loss: 0.21009
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:17
train iter: 899
num of updates: 90000
vae loss: 0.21025
kl loss: 0.00001
a decoder loss: 0.21023
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:18
train iter: 900
num of updates: 90100
vae loss: 0.20928
kl loss: 0.00001
a decoder loss: 0.20927
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:19
train iter: 901
num of updates: 90200
vae loss: 0.21008
kl loss: 0.00001
a decoder loss: 0.21007
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:20
train iter: 902
num of updates: 90300
vae loss: 0.20972
kl loss: 0.00001
a decoder loss: 0.20970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:21
train iter: 903
num of updates: 90400
vae loss: 0.20975
kl loss: 0.00001
a decoder loss: 0.20974
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:22
train iter: 904
num of updates: 90500
vae loss: 0.21033
kl loss: 0.00001
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:23
train iter: 905
num of updates: 90600
vae loss: 0.20851
kl loss: 0.00001
a decoder loss: 0.20850
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:24
train iter: 906
num of updates: 90700
vae loss: 0.21053
kl loss: 0.00001
a decoder loss: 0.21051
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:25
train iter: 907
num of updates: 90800
vae loss: 0.20958
kl loss: 0.00001
a decoder loss: 0.20957
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:26
train iter: 908
num of updates: 90900
vae loss: 0.20930
kl loss: 0.00001
a decoder loss: 0.20929
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:27
train iter: 909
num of updates: 91000
vae loss: 0.20936
kl loss: 0.00001
a decoder loss: 0.20935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:28
train iter: 910
num of updates: 91100
vae loss: 0.21038
kl loss: 0.00001
a decoder loss: 0.21036
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:29
train iter: 911
num of updates: 91200
vae loss: 0.20961
kl loss: 0.00001
a decoder loss: 0.20959
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:30
train iter: 912
num of updates: 91300
vae loss: 0.21074
kl loss: 0.00001
a decoder loss: 0.21073
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:31
train iter: 913
num of updates: 91400
vae loss: 0.20933
kl loss: 0.00001
a decoder loss: 0.20932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:32
train iter: 914
num of updates: 91500
vae loss: 0.20997
kl loss: 0.00001
a decoder loss: 0.20995
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:33
train iter: 915
num of updates: 91600
vae loss: 0.20963
kl loss: 0.00001
a decoder loss: 0.20962
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:34
train iter: 916
num of updates: 91700
vae loss: 0.20954
kl loss: 0.00001
a decoder loss: 0.20953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:35
train iter: 917
num of updates: 91800
vae loss: 0.20999
kl loss: 0.00001
a decoder loss: 0.20997
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:36
train iter: 918
num of updates: 91900
vae loss: 0.21050
kl loss: 0.00001
a decoder loss: 0.21048
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:37
train iter: 919
num of updates: 92000
vae loss: 0.20984
kl loss: 0.00001
a decoder loss: 0.20983
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:38
train iter: 920
num of updates: 92100
vae loss: 0.20967
kl loss: 0.00001
a decoder loss: 0.20965
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:39
train iter: 921
num of updates: 92200
vae loss: 0.20974
kl loss: 0.00001
a decoder loss: 0.20972
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:40
train iter: 922
num of updates: 92300
vae loss: 0.20985
kl loss: 0.00001
a decoder loss: 0.20983
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:41
train iter: 923
num of updates: 92400
vae loss: 0.20974
kl loss: 0.00001
a decoder loss: 0.20972
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:42
train iter: 924
num of updates: 92500
vae loss: 0.20930
kl loss: 0.00001
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:43
train iter: 925
num of updates: 92600
vae loss: 0.21014
kl loss: 0.00001
a decoder loss: 0.21012
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:44
train iter: 926
num of updates: 92700
vae loss: 0.21014
kl loss: 0.00001
a decoder loss: 0.21012
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:45
train iter: 927
num of updates: 92800
vae loss: 0.20942
kl loss: 0.00001
a decoder loss: 0.20941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:46
train iter: 928
num of updates: 92900
vae loss: 0.20939
kl loss: 0.00001
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:47
train iter: 929
num of updates: 93000
vae loss: 0.20954
kl loss: 0.00001
a decoder loss: 0.20953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:48
train iter: 930
num of updates: 93100
vae loss: 0.20958
kl loss: 0.00001
a decoder loss: 0.20957
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:49
train iter: 931
num of updates: 93200
vae loss: 0.20972
kl loss: 0.00001
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:50
train iter: 932
num of updates: 93300
vae loss: 0.20922
kl loss: 0.00001
a decoder loss: 0.20921
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:51
train iter: 933
num of updates: 93400
vae loss: 0.21023
kl loss: 0.00001
a decoder loss: 0.21021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:52
train iter: 934
num of updates: 93500
vae loss: 0.20926
kl loss: 0.00001
a decoder loss: 0.20925
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:53
train iter: 935
num of updates: 93600
vae loss: 0.20983
kl loss: 0.00001
a decoder loss: 0.20981
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:54
train iter: 936
num of updates: 93700
vae loss: 0.20990
kl loss: 0.00001
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:55
train iter: 937
num of updates: 93800
vae loss: 0.20882
kl loss: 0.00001
a decoder loss: 0.20881
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:56
train iter: 938
num of updates: 93900
vae loss: 0.21074
kl loss: 0.00001
a decoder loss: 0.21073
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:57
train iter: 939
num of updates: 94000
vae loss: 0.20939
kl loss: 0.00001
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:58
train iter: 940
num of updates: 94100
vae loss: 0.20977
kl loss: 0.00001
a decoder loss: 0.20975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:59
train iter: 941
num of updates: 94200
vae loss: 0.20890
kl loss: 0.00001
a decoder loss: 0.20889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:00
train iter: 942
num of updates: 94300
vae loss: 0.20962
kl loss: 0.00001
a decoder loss: 0.20960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:01
train iter: 943
num of updates: 94400
vae loss: 0.20970
kl loss: 0.00001
a decoder loss: 0.20969
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:02
train iter: 944
num of updates: 94500
vae loss: 0.21048
kl loss: 0.00001
a decoder loss: 0.21047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:03
train iter: 945
num of updates: 94600
vae loss: 0.20940
kl loss: 0.00001
a decoder loss: 0.20939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:04
train iter: 946
num of updates: 94700
vae loss: 0.20984
kl loss: 0.00001
a decoder loss: 0.20983
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:05
train iter: 947
num of updates: 94800
vae loss: 0.20907
kl loss: 0.00001
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:06
train iter: 948
num of updates: 94900
vae loss: 0.20939
kl loss: 0.00001
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:07
train iter: 949
num of updates: 95000
vae loss: 0.20925
kl loss: 0.00001
a decoder loss: 0.20924
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:08
train iter: 950
num of updates: 95100
vae loss: 0.20869
kl loss: 0.00001
a decoder loss: 0.20868
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:09
train iter: 951
num of updates: 95200
vae loss: 0.21016
kl loss: 0.00001
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:10
train iter: 952
num of updates: 95300
vae loss: 0.20959
kl loss: 0.00001
a decoder loss: 0.20958
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:11
train iter: 953
num of updates: 95400
vae loss: 0.20975
kl loss: 0.00001
a decoder loss: 0.20974
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:12
train iter: 954
num of updates: 95500
vae loss: 0.21001
kl loss: 0.00001
a decoder loss: 0.21000
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:13
train iter: 955
num of updates: 95600
vae loss: 0.20901
kl loss: 0.00001
a decoder loss: 0.20900
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:14
train iter: 956
num of updates: 95700
vae loss: 0.21048
kl loss: 0.00001
a decoder loss: 0.21047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:15
train iter: 957
num of updates: 95800
vae loss: 0.20961
kl loss: 0.00001
a decoder loss: 0.20960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:16
train iter: 958
num of updates: 95900
vae loss: 0.20835
kl loss: 0.00001
a decoder loss: 0.20834
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:17
train iter: 959
num of updates: 96000
vae loss: 0.20928
kl loss: 0.00001
a decoder loss: 0.20926
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:18
train iter: 960
num of updates: 96100
vae loss: 0.20955
kl loss: 0.00001
a decoder loss: 0.20954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:19
train iter: 961
num of updates: 96200
vae loss: 0.20919
kl loss: 0.00001
a decoder loss: 0.20918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:20
train iter: 962
num of updates: 96300
vae loss: 0.20946
kl loss: 0.00001
a decoder loss: 0.20945
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:21
train iter: 963
num of updates: 96400
vae loss: 0.20944
kl loss: 0.00001
a decoder loss: 0.20943
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:22
train iter: 964
num of updates: 96500
vae loss: 0.20917
kl loss: 0.00001
a decoder loss: 0.20916
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:23
train iter: 965
num of updates: 96600
vae loss: 0.20995
kl loss: 0.00001
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:24
train iter: 966
num of updates: 96700
vae loss: 0.20909
kl loss: 0.00001
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:25
train iter: 967
num of updates: 96800
vae loss: 0.20978
kl loss: 0.00001
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:26
train iter: 968
num of updates: 96900
vae loss: 0.20977
kl loss: 0.00001
a decoder loss: 0.20976
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:27
train iter: 969
num of updates: 97000
vae loss: 0.20960
kl loss: 0.00001
a decoder loss: 0.20959
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:28
train iter: 970
num of updates: 97100
vae loss: 0.20908
kl loss: 0.00001
a decoder loss: 0.20906
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:29
train iter: 971
num of updates: 97200
vae loss: 0.21037
kl loss: 0.00001
a decoder loss: 0.21036
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:30
train iter: 972
num of updates: 97300
vae loss: 0.20992
kl loss: 0.00001
a decoder loss: 0.20991
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:31
train iter: 973
num of updates: 97400
vae loss: 0.20977
kl loss: 0.00001
a decoder loss: 0.20976
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:32
train iter: 974
num of updates: 97500
vae loss: 0.20972
kl loss: 0.00001
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:33
train iter: 975
num of updates: 97600
vae loss: 0.20991
kl loss: 0.00001
a decoder loss: 0.20990
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:34
train iter: 976
num of updates: 97700
vae loss: 0.20887
kl loss: 0.00001
a decoder loss: 0.20886
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:35
train iter: 977
num of updates: 97800
vae loss: 0.20911
kl loss: 0.00001
a decoder loss: 0.20910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:36
train iter: 978
num of updates: 97900
vae loss: 0.20938
kl loss: 0.00001
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:37
train iter: 979
num of updates: 98000
vae loss: 0.20992
kl loss: 0.00001
a decoder loss: 0.20991
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:38
train iter: 980
num of updates: 98100
vae loss: 0.20869
kl loss: 0.00001
a decoder loss: 0.20867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:39
train iter: 981
num of updates: 98200
vae loss: 0.20966
kl loss: 0.00001
a decoder loss: 0.20964
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:40
train iter: 982
num of updates: 98300
vae loss: 0.20996
kl loss: 0.00001
a decoder loss: 0.20995
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:41
train iter: 983
num of updates: 98400
vae loss: 0.20974
kl loss: 0.00001
a decoder loss: 0.20972
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:42
train iter: 984
num of updates: 98500
vae loss: 0.20924
kl loss: 0.00001
a decoder loss: 0.20923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:43
train iter: 985
num of updates: 98600
vae loss: 0.20909
kl loss: 0.00001
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:44
train iter: 986
num of updates: 98700
vae loss: 0.20948
kl loss: 0.00001
a decoder loss: 0.20947
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:45
train iter: 987
num of updates: 98800
vae loss: 0.20969
kl loss: 0.00001
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:46
train iter: 988
num of updates: 98900
vae loss: 0.20924
kl loss: 0.00001
a decoder loss: 0.20923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:47
train iter: 989
num of updates: 99000
vae loss: 0.20954
kl loss: 0.00001
a decoder loss: 0.20953
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:48
train iter: 990
num of updates: 99100
vae loss: 0.20937
kl loss: 0.00001
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:49
train iter: 991
num of updates: 99200
vae loss: 0.20949
kl loss: 0.00001
a decoder loss: 0.20947
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:50
train iter: 992
num of updates: 99300
vae loss: 0.20975
kl loss: 0.00001
a decoder loss: 0.20974
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:51
train iter: 993
num of updates: 99400
vae loss: 0.20898
kl loss: 0.00001
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:52
train iter: 994
num of updates: 99500
vae loss: 0.20950
kl loss: 0.00001
a decoder loss: 0.20949
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:53
train iter: 995
num of updates: 99600
vae loss: 0.20917
kl loss: 0.00001
a decoder loss: 0.20916
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:54
train iter: 996
num of updates: 99700
vae loss: 0.20858
kl loss: 0.00001
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:55
train iter: 997
num of updates: 99800
vae loss: 0.20930
kl loss: 0.00001
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:56
train iter: 998
num of updates: 99900
vae loss: 0.20903
kl loss: 0.00001
a decoder loss: 0.20902
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:57
train iter: 999
num of updates: 100000
vae loss: 0.20977
kl loss: 0.00001
a decoder loss: 0.20976
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/vae_model_100000.pt
============================================================
finished training vae!
============================================================
started training vae at: 25-09-28-00-54-49
finished training vae at: 25-09-28-02-01-56
total vae training time: 1:07:07
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/vae_model.pt
============================================================
2025-09-28 02:01:59.408361: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:01.545497: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 40 bytes spill stores, 40 bytes spill loads

2025-09-28 02:02:01.604598: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 20 bytes spill stores, 20 bytes spill loads

2025-09-28 02:02:02.979344: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 02:02:04.207309: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:07.087039: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:02:07.556949: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:02:08.035417: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:02:10.308517: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:12.785088: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 236 bytes spill stores, 236 bytes spill loads

2025-09-28 02:02:12.993297: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 404 bytes spill stores, 404 bytes spill loads

2025-09-28 02:02:14.910553: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 908 bytes spill stores, 668 bytes spill loads

2025-09-28 02:02:15.011190: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 1868 bytes spill stores, 1352 bytes spill loads

2025-09-28 02:02:15.914789: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 504 bytes spill stores, 460 bytes spill loads

2025-09-28 02:02:17.049305: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:19.650172: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 24 bytes spill stores, 24 bytes spill loads

Error executing job with overrides: ['state_dep_prior=False', 'learn_dynamics_std=True', 'autonomous=False', 'n_dynamics_ensembles=5']
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/jax_dt/train_dt.py", line 1286, in train
    _vae_params = load_params(load_current_model_path)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 75, in load_params
    with File(path, 'rb') as fin:
         ^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 59, in __init__
    self.f = open(fileName, mode)
             ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-49/vae_model_1000000.pt'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrelocate-expert-v1-985440[0m at: [34mhttps://wandb.ai/james-gatsby/jax_dt/runs/q9pj043v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250928_005541-q9pj043v/logs[0m
Exception ignored in: <function OffScreenViewer.__del__ at 0x735f88b309a0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/platform/baseplatform.py", line 487, in __call__
    return self(*args, **named)
           ^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x735f423ed4d0>,
		<OpenGL._opaque.EGLContext_pointer object at 0x735f423ed950>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x735f8ca8cfe0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x735f423ed4d0>,
		<OpenGL._opaque.EGLContext_pointer object at 0x735f423ed950>,
	),
	result = 0
)
Exception ignored in: <function OffScreenViewer.__del__ at 0x735f88b309a0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x735f423ed4d0>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x735f8d1e9250>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x735f8d1e9250>,
		<OpenGL._opaque.EGLContext_pointer object at 0x735f8d1e8fd0>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x735f8ca8cfe0>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x735f423ed4d0>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x735f8d1e9250>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x735f8d1e9250>,
		<OpenGL._opaque.EGLContext_pointer object at 0x735f8d1e8fd0>,
	),
	result = 0
)
