Launching a python run
Sun Sep 28 01:10:25 PM UTC 2025
Active conda env: /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/python3
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/pip
2025-09-28 13:10:43.543647: I external/xla/xla/pjrt/pjrt_api.cc:115] GetPjrtApi was found for cuda at /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/jax_plugins/xla_cuda12/xla_cuda_plugin.so
2025-09-28 13:10:43.543713: I external/xla/xla/pjrt/pjrt_api.cc:93] PJRT_Api is set for device type cuda
2025-09-28 13:10:43.546902: I external/xla/xla/pjrt/pjrt_api.cc:161] The PJRT plugin has PJRT API version 0.70. The framework PJRT API version is 0.70.
2025-09-28 13:10:43.759553: I external/xla/xla/service/service.cc:153] XLA service 0x5b8fd52e1160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-09-28 13:10:43.759567: I external/xla/xla/service/service.cc:161]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2025-09-28 13:10:43.772137: I external/xla/xla/pjrt/pjrt_c_api_client.cc:130] PjRtCApiClient created.
[CudaDevice(id=0)]
/nfs/nhome/live/jheald/jax_dt/train_dt.py:48: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path=cfg_path, config_name="config.yaml")
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
[2025-09-28 13:10:46,644][OpenGL.acceleratesupport][INFO] - No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'
wandb: Currently logged in as: james-heald (james-gatsby) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /nfs/nhome/live/jheald/jax_dt/outputs/2025-09-28/13-10-45/wandb/run-20250928_131135-4ikd39ml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run relocate-expert-v1-985440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/james-gatsby/jax_dt
wandb: üöÄ View run at https://wandb.ai/james-gatsby/jax_dt/runs/4ikd39ml
2025-09-28 13:11:37.866069: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 13:11:44.124520: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 232 bytes spill stores, 232 bytes spill loads

2025-09-28 13:11:44.888777: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 80 bytes spill stores, 80 bytes spill loads

2025-09-28 13:11:45.153283: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 628 bytes spill stores, 492 bytes spill loads

2025-09-28 13:11:48.004295: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 388 bytes spill stores, 296 bytes spill loads

2025-09-28 13:11:48.449094: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 712 bytes spill stores, 712 bytes spill loads

2025-09-28 13:11:50.964350: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 2140 bytes spill stores, 1648 bytes spill loads

2025-09-28 13:11:51.988018: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 1016 bytes spill stores, 1016 bytes spill loads

2025-09-28 13:11:54.969712: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 16008 bytes spill stores, 16296 bytes spill loads

2025-09-28 13:11:55.425621: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 436 bytes spill stores, 436 bytes spill loads

2025-09-28 13:11:58.026151: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 5912 bytes spill stores, 5776 bytes spill loads

============================================================
time elapsed: 0:01:19
train iter: 0
num of updates: 100
dynamics loss: 361192.09375

saving current model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/dynamics_model_100.pt
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = _fork_exec(
============================================================
time elapsed: 0:01:30
train iter: 1
num of updates: 200
dynamics loss: 360943.75000

============================================================
time elapsed: 0:01:34
train iter: 2
num of updates: 300
dynamics loss: 360568.90625

============================================================
time elapsed: 0:01:38
train iter: 3
num of updates: 400
dynamics loss: 360008.84375

============================================================
time elapsed: 0:01:41
train iter: 4
num of updates: 500
dynamics loss: 359307.59375

============================================================
time elapsed: 0:01:45
train iter: 5
num of updates: 600
dynamics loss: 358347.09375

============================================================
time elapsed: 0:01:48
train iter: 6
num of updates: 700
dynamics loss: 357229.12500

============================================================
time elapsed: 0:01:52
train iter: 7
num of updates: 800
dynamics loss: 355921.93750

============================================================
time elapsed: 0:01:55
train iter: 8
num of updates: 900
dynamics loss: 354529.96875

============================================================
time elapsed: 0:01:59
train iter: 9
num of updates: 1000
dynamics loss: 352779.78125

============================================================
time elapsed: 0:02:02
train iter: 10
num of updates: 1100
dynamics loss: 350948.21875

============================================================
time elapsed: 0:02:06
train iter: 11
num of updates: 1200
dynamics loss: 348978.06250

============================================================
time elapsed: 0:02:09
train iter: 12
num of updates: 1300
dynamics loss: 346694.40625

============================================================
time elapsed: 0:02:13
train iter: 13
num of updates: 1400
dynamics loss: 344479.81250

============================================================
time elapsed: 0:02:16
train iter: 14
num of updates: 1500
dynamics loss: 341858.53125

============================================================
time elapsed: 0:02:20
train iter: 15
num of updates: 1600
dynamics loss: 339247.40625

============================================================
time elapsed: 0:02:23
train iter: 16
num of updates: 1700
dynamics loss: 336414.40625

============================================================
time elapsed: 0:02:27
train iter: 17
num of updates: 1800
dynamics loss: 333371.78125

============================================================
time elapsed: 0:02:30
train iter: 18
num of updates: 1900
dynamics loss: 330213.21875

============================================================
time elapsed: 0:02:34
train iter: 19
num of updates: 2000
dynamics loss: 326972.37500

============================================================
time elapsed: 0:02:37
train iter: 20
num of updates: 2100
dynamics loss: 323507.90625

============================================================
time elapsed: 0:02:41
train iter: 21
num of updates: 2200
dynamics loss: 319955.84375

============================================================
time elapsed: 0:02:44
train iter: 22
num of updates: 2300
dynamics loss: 316205.78125

============================================================
time elapsed: 0:02:48
train iter: 23
num of updates: 2400
dynamics loss: 312467.65625

============================================================
time elapsed: 0:02:52
train iter: 24
num of updates: 2500
dynamics loss: 308454.78125

============================================================
time elapsed: 0:02:55
train iter: 25
num of updates: 2600
dynamics loss: 304462.81250

============================================================
time elapsed: 0:02:59
train iter: 26
num of updates: 2700
dynamics loss: 300180.21875

============================================================
time elapsed: 0:03:02
train iter: 27
num of updates: 2800
dynamics loss: 295979.90625

============================================================
time elapsed: 0:03:06
train iter: 28
num of updates: 2900
dynamics loss: 291515.96875

============================================================
time elapsed: 0:03:09
train iter: 29
num of updates: 3000
dynamics loss: 287020.43750

============================================================
time elapsed: 0:03:13
train iter: 30
num of updates: 3100
dynamics loss: 282487.43750

============================================================
time elapsed: 0:03:16
train iter: 31
num of updates: 3200
dynamics loss: 277814.00000

============================================================
time elapsed: 0:03:20
train iter: 32
num of updates: 3300
dynamics loss: 273071.00000

============================================================
time elapsed: 0:03:23
train iter: 33
num of updates: 3400
dynamics loss: 268305.31250

============================================================
time elapsed: 0:03:27
train iter: 34
num of updates: 3500
dynamics loss: 263388.21875

============================================================
time elapsed: 0:03:30
train iter: 35
num of updates: 3600
dynamics loss: 258506.25000

============================================================
time elapsed: 0:03:34
train iter: 36
num of updates: 3700
dynamics loss: 253542.84375

============================================================
time elapsed: 0:03:37
train iter: 37
num of updates: 3800
dynamics loss: 248498.03125

============================================================
time elapsed: 0:03:41
train iter: 38
num of updates: 3900
dynamics loss: 243518.60938

============================================================
time elapsed: 0:03:44
train iter: 39
num of updates: 4000
dynamics loss: 238390.70312

============================================================
time elapsed: 0:03:48
train iter: 40
num of updates: 4100
dynamics loss: 233329.06250

============================================================
time elapsed: 0:03:51
train iter: 41
num of updates: 4200
dynamics loss: 228322.29688

============================================================
time elapsed: 0:03:55
train iter: 42
num of updates: 4300
dynamics loss: 223178.18750

============================================================
time elapsed: 0:03:58
train iter: 43
num of updates: 4400
dynamics loss: 218113.64062

============================================================
time elapsed: 0:04:02
train iter: 44
num of updates: 4500
dynamics loss: 213025.76562

============================================================
time elapsed: 0:04:05
train iter: 45
num of updates: 4600
dynamics loss: 208010.18750

============================================================
time elapsed: 0:04:09
train iter: 46
num of updates: 4700
dynamics loss: 202915.87500

============================================================
time elapsed: 0:04:12
train iter: 47
num of updates: 4800
dynamics loss: 197922.62500

============================================================
time elapsed: 0:04:16
train iter: 48
num of updates: 4900
dynamics loss: 193009.21875

============================================================
time elapsed: 0:04:20
train iter: 49
num of updates: 5000
dynamics loss: 188103.56250

============================================================
time elapsed: 0:04:23
train iter: 50
num of updates: 5100
dynamics loss: 183212.26562

============================================================
time elapsed: 0:04:27
train iter: 51
num of updates: 5200
dynamics loss: 178462.29688

============================================================
time elapsed: 0:04:30
train iter: 52
num of updates: 5300
dynamics loss: 173730.20312

============================================================
time elapsed: 0:04:34
train iter: 53
num of updates: 5400
dynamics loss: 169034.65625

============================================================
time elapsed: 0:04:37
train iter: 54
num of updates: 5500
dynamics loss: 164516.90625

============================================================
time elapsed: 0:04:41
train iter: 55
num of updates: 5600
dynamics loss: 160037.76562

============================================================
time elapsed: 0:04:44
train iter: 56
num of updates: 5700
dynamics loss: 155619.59375

============================================================
time elapsed: 0:04:48
train iter: 57
num of updates: 5800
dynamics loss: 151270.09375

============================================================
time elapsed: 0:04:51
train iter: 58
num of updates: 5900
dynamics loss: 147131.73438

============================================================
time elapsed: 0:04:55
train iter: 59
num of updates: 6000
dynamics loss: 142996.87500

============================================================
time elapsed: 0:04:58
train iter: 60
num of updates: 6100
dynamics loss: 139058.98438

============================================================
time elapsed: 0:05:02
train iter: 61
num of updates: 6200
dynamics loss: 135172.84375

============================================================
time elapsed: 0:05:05
train iter: 62
num of updates: 6300
dynamics loss: 131378.95312

============================================================
time elapsed: 0:05:09
train iter: 63
num of updates: 6400
dynamics loss: 127820.34375

============================================================
time elapsed: 0:05:12
train iter: 64
num of updates: 6500
dynamics loss: 124263.10938

============================================================
time elapsed: 0:05:16
train iter: 65
num of updates: 6600
dynamics loss: 120804.70312

============================================================
time elapsed: 0:05:19
train iter: 66
num of updates: 6700
dynamics loss: 117567.73438

============================================================
time elapsed: 0:05:23
train iter: 67
num of updates: 6800
dynamics loss: 114369.12500

============================================================
time elapsed: 0:05:26
train iter: 68
num of updates: 6900
dynamics loss: 111369.67188

============================================================
time elapsed: 0:05:30
train iter: 69
num of updates: 7000
dynamics loss: 108430.36719

============================================================
time elapsed: 0:05:33
train iter: 70
num of updates: 7100
dynamics loss: 105606.35938

============================================================
time elapsed: 0:05:37
train iter: 71
num of updates: 7200
dynamics loss: 102961.00000

============================================================
time elapsed: 0:05:40
train iter: 72
num of updates: 7300
dynamics loss: 100332.81250

============================================================
time elapsed: 0:05:44
train iter: 73
num of updates: 7400
dynamics loss: 97876.21094

============================================================
time elapsed: 0:05:47
train iter: 74
num of updates: 7500
dynamics loss: 95484.27344

============================================================
time elapsed: 0:05:51
train iter: 75
num of updates: 7600
dynamics loss: 93158.48438

============================================================
time elapsed: 0:05:55
train iter: 76
num of updates: 7700
dynamics loss: 90989.67188

============================================================
time elapsed: 0:05:58
train iter: 77
num of updates: 7800
dynamics loss: 88904.85156

============================================================
time elapsed: 0:06:02
train iter: 78
num of updates: 7900
dynamics loss: 86917.33594

============================================================
time elapsed: 0:06:05
train iter: 79
num of updates: 8000
dynamics loss: 84994.17969

============================================================
time elapsed: 0:06:09
train iter: 80
num of updates: 8100
dynamics loss: 83109.12500

============================================================
time elapsed: 0:06:12
train iter: 81
num of updates: 8200
dynamics loss: 81309.63281

============================================================
time elapsed: 0:06:16
train iter: 82
num of updates: 8300
dynamics loss: 79559.44531

============================================================
time elapsed: 0:06:19
train iter: 83
num of updates: 8400
dynamics loss: 77941.36719

============================================================
time elapsed: 0:06:23
train iter: 84
num of updates: 8500
dynamics loss: 76280.11719

============================================================
time elapsed: 0:06:26
train iter: 85
num of updates: 8600
dynamics loss: 74753.83594

============================================================
time elapsed: 0:06:30
train iter: 86
num of updates: 8700
dynamics loss: 73221.42969

============================================================
time elapsed: 0:06:33
train iter: 87
num of updates: 8800
dynamics loss: 71786.14062

============================================================
time elapsed: 0:06:37
train iter: 88
num of updates: 8900
dynamics loss: 70363.96094

============================================================
time elapsed: 0:06:40
train iter: 89
num of updates: 9000
dynamics loss: 68996.48438

============================================================
time elapsed: 0:06:44
train iter: 90
num of updates: 9100
dynamics loss: 67671.00000

============================================================
time elapsed: 0:06:47
train iter: 91
num of updates: 9200
dynamics loss: 66365.00781

============================================================
time elapsed: 0:06:51
train iter: 92
num of updates: 9300
dynamics loss: 65093.21094

============================================================
time elapsed: 0:06:54
train iter: 93
num of updates: 9400
dynamics loss: 63938.96484

============================================================
time elapsed: 0:06:58
train iter: 94
num of updates: 9500
dynamics loss: 62748.23828

============================================================
time elapsed: 0:07:01
train iter: 95
num of updates: 9600
dynamics loss: 61558.51562

============================================================
time elapsed: 0:07:05
train iter: 96
num of updates: 9700
dynamics loss: 60485.27344

============================================================
time elapsed: 0:07:08
train iter: 97
num of updates: 9800
dynamics loss: 59449.31641

============================================================
time elapsed: 0:07:12
train iter: 98
num of updates: 9900
dynamics loss: 58358.45703

============================================================
time elapsed: 0:07:15
train iter: 99
num of updates: 10000
dynamics loss: 57379.01953

============================================================
time elapsed: 0:07:19
train iter: 100
num of updates: 10100
dynamics loss: 56377.39453

============================================================
time elapsed: 0:07:22
train iter: 101
num of updates: 10200
dynamics loss: 55436.79297

============================================================
time elapsed: 0:07:26
train iter: 102
num of updates: 10300
dynamics loss: 54506.94531

============================================================
time elapsed: 0:07:30
train iter: 103
num of updates: 10400
dynamics loss: 53611.11719

============================================================
time elapsed: 0:07:33
train iter: 104
num of updates: 10500
dynamics loss: 52736.72266

============================================================
time elapsed: 0:07:37
train iter: 105
num of updates: 10600
dynamics loss: 51944.17969

============================================================
time elapsed: 0:07:40
train iter: 106
num of updates: 10700
dynamics loss: 51156.47656

============================================================
time elapsed: 0:07:44
train iter: 107
num of updates: 10800
dynamics loss: 50421.79297

============================================================
time elapsed: 0:07:47
train iter: 108
num of updates: 10900
dynamics loss: 49666.62109

============================================================
time elapsed: 0:07:51
train iter: 109
num of updates: 11000
dynamics loss: 48967.94531

============================================================
time elapsed: 0:07:54
train iter: 110
num of updates: 11100
dynamics loss: 48270.86328

============================================================
time elapsed: 0:07:58
train iter: 111
num of updates: 11200
dynamics loss: 47587.24219

============================================================
time elapsed: 0:08:01
train iter: 112
num of updates: 11300
dynamics loss: 46937.72656

============================================================
time elapsed: 0:08:05
train iter: 113
num of updates: 11400
dynamics loss: 46275.42188

============================================================
time elapsed: 0:08:08
train iter: 114
num of updates: 11500
dynamics loss: 45708.47266

============================================================
time elapsed: 0:08:12
train iter: 115
num of updates: 11600
dynamics loss: 45123.61328

============================================================
time elapsed: 0:08:15
train iter: 116
num of updates: 11700
dynamics loss: 44567.78125

============================================================
time elapsed: 0:08:19
train iter: 117
num of updates: 11800
dynamics loss: 44022.62500

============================================================
time elapsed: 0:08:22
train iter: 118
num of updates: 11900
dynamics loss: 43479.43359

============================================================
time elapsed: 0:08:26
train iter: 119
num of updates: 12000
dynamics loss: 42980.47266

============================================================
time elapsed: 0:08:29
train iter: 120
num of updates: 12100
dynamics loss: 42465.51562

============================================================
time elapsed: 0:08:33
train iter: 121
num of updates: 12200
dynamics loss: 41977.32031

============================================================
time elapsed: 0:08:36
train iter: 122
num of updates: 12300
dynamics loss: 41501.50781

============================================================
time elapsed: 0:08:40
train iter: 123
num of updates: 12400
dynamics loss: 41056.58594

============================================================
time elapsed: 0:08:43
train iter: 124
num of updates: 12500
dynamics loss: 40594.83203

============================================================
time elapsed: 0:08:47
train iter: 125
num of updates: 12600
dynamics loss: 40161.75781

============================================================
time elapsed: 0:08:50
train iter: 126
num of updates: 12700
dynamics loss: 39761.06250

============================================================
time elapsed: 0:08:54
train iter: 127
num of updates: 12800
dynamics loss: 39347.66797

============================================================
time elapsed: 0:08:58
train iter: 128
num of updates: 12900
dynamics loss: 38971.28906

============================================================
time elapsed: 0:09:01
train iter: 129
num of updates: 13000
dynamics loss: 38589.12891

============================================================
time elapsed: 0:09:05
train iter: 130
num of updates: 13100
dynamics loss: 38185.03906

============================================================
time elapsed: 0:09:08
train iter: 131
num of updates: 13200
dynamics loss: 37841.57422

============================================================
time elapsed: 0:09:12
train iter: 132
num of updates: 13300
dynamics loss: 37454.72266

============================================================
time elapsed: 0:09:15
train iter: 133
num of updates: 13400
dynamics loss: 37165.33203

============================================================
time elapsed: 0:09:19
train iter: 134
num of updates: 13500
dynamics loss: 36799.83203

============================================================
time elapsed: 0:09:22
train iter: 135
num of updates: 13600
dynamics loss: 36506.27734

============================================================
time elapsed: 0:09:26
train iter: 136
num of updates: 13700
dynamics loss: 36198.73828

============================================================
time elapsed: 0:09:29
train iter: 137
num of updates: 13800
dynamics loss: 35894.94922

============================================================
time elapsed: 0:09:33
train iter: 138
num of updates: 13900
dynamics loss: 35554.02734

============================================================
time elapsed: 0:09:36
train iter: 139
num of updates: 14000
dynamics loss: 35283.21094

============================================================
time elapsed: 0:09:40
train iter: 140
num of updates: 14100
dynamics loss: 35033.15625

============================================================
time elapsed: 0:09:43
train iter: 141
num of updates: 14200
dynamics loss: 34745.14844

============================================================
time elapsed: 0:09:47
train iter: 142
num of updates: 14300
dynamics loss: 34481.65234

============================================================
time elapsed: 0:09:50
train iter: 143
num of updates: 14400
dynamics loss: 34242.63281

============================================================
time elapsed: 0:09:54
train iter: 144
num of updates: 14500
dynamics loss: 33937.51953

============================================================
time elapsed: 0:09:57
train iter: 145
num of updates: 14600
dynamics loss: 33711.87109

============================================================
time elapsed: 0:10:01
train iter: 146
num of updates: 14700
dynamics loss: 33488.21094

============================================================
time elapsed: 0:10:04
train iter: 147
num of updates: 14800
dynamics loss: 33233.32422

============================================================
time elapsed: 0:10:08
train iter: 148
num of updates: 14900
dynamics loss: 33035.18750

============================================================
time elapsed: 0:10:11
train iter: 149
num of updates: 15000
dynamics loss: 32790.62891

============================================================
time elapsed: 0:10:15
train iter: 150
num of updates: 15100
dynamics loss: 32603.16797

============================================================
time elapsed: 0:10:18
train iter: 151
num of updates: 15200
dynamics loss: 32374.79297

============================================================
time elapsed: 0:10:22
train iter: 152
num of updates: 15300
dynamics loss: 32167.10156

============================================================
time elapsed: 0:10:26
train iter: 153
num of updates: 15400
dynamics loss: 31986.27930

============================================================
time elapsed: 0:10:29
train iter: 154
num of updates: 15500
dynamics loss: 31787.32812

============================================================
time elapsed: 0:10:33
train iter: 155
num of updates: 15600
dynamics loss: 31599.93359

============================================================
time elapsed: 0:10:36
train iter: 156
num of updates: 15700
dynamics loss: 31413.68555

============================================================
time elapsed: 0:10:40
train iter: 157
num of updates: 15800
dynamics loss: 31213.30664

============================================================
time elapsed: 0:10:43
train iter: 158
num of updates: 15900
dynamics loss: 31050.66602

============================================================
time elapsed: 0:10:47
train iter: 159
num of updates: 16000
dynamics loss: 30904.46875

============================================================
time elapsed: 0:10:50
train iter: 160
num of updates: 16100
dynamics loss: 30731.66797

============================================================
time elapsed: 0:10:54
train iter: 161
num of updates: 16200
dynamics loss: 30586.98242

============================================================
time elapsed: 0:10:57
train iter: 162
num of updates: 16300
dynamics loss: 30396.39453

============================================================
time elapsed: 0:11:01
train iter: 163
num of updates: 16400
dynamics loss: 30250.50195

============================================================
time elapsed: 0:11:04
train iter: 164
num of updates: 16500
dynamics loss: 30128.58789

============================================================
time elapsed: 0:11:08
train iter: 165
num of updates: 16600
dynamics loss: 29951.74609

============================================================
time elapsed: 0:11:11
train iter: 166
num of updates: 16700
dynamics loss: 29802.34961

============================================================
time elapsed: 0:11:15
train iter: 167
num of updates: 16800
dynamics loss: 29666.24023

============================================================
time elapsed: 0:11:18
train iter: 168
num of updates: 16900
dynamics loss: 29528.43359

============================================================
time elapsed: 0:11:22
train iter: 169
num of updates: 17000
dynamics loss: 29390.61133

============================================================
time elapsed: 0:11:25
train iter: 170
num of updates: 17100
dynamics loss: 29250.60352

============================================================
time elapsed: 0:11:29
train iter: 171
num of updates: 17200
dynamics loss: 29136.55859

============================================================
time elapsed: 0:11:32
train iter: 172
num of updates: 17300
dynamics loss: 29013.28906

============================================================
time elapsed: 0:11:36
train iter: 173
num of updates: 17400
dynamics loss: 28882.52930

============================================================
time elapsed: 0:11:39
train iter: 174
num of updates: 17500
dynamics loss: 28758.10547

============================================================
time elapsed: 0:11:43
train iter: 175
num of updates: 17600
dynamics loss: 28648.16797

============================================================
time elapsed: 0:11:46
train iter: 176
num of updates: 17700
dynamics loss: 28544.83398

============================================================
time elapsed: 0:11:50
train iter: 177
num of updates: 17800
dynamics loss: 28418.50000

============================================================
time elapsed: 0:11:53
train iter: 178
num of updates: 17900
dynamics loss: 28296.78906

============================================================
time elapsed: 0:11:57
train iter: 179
num of updates: 18000
dynamics loss: 28199.16602

============================================================
time elapsed: 0:12:01
train iter: 180
num of updates: 18100
dynamics loss: 28093.43359

============================================================
time elapsed: 0:12:04
train iter: 181
num of updates: 18200
dynamics loss: 27966.86328

============================================================
time elapsed: 0:12:08
train iter: 182
num of updates: 18300
dynamics loss: 27880.00781

============================================================
time elapsed: 0:12:11
train iter: 183
num of updates: 18400
dynamics loss: 27779.92578

============================================================
time elapsed: 0:12:15
train iter: 184
num of updates: 18500
dynamics loss: 27684.87695

============================================================
time elapsed: 0:12:18
train iter: 185
num of updates: 18600
dynamics loss: 27572.68750

============================================================
time elapsed: 0:12:22
train iter: 186
num of updates: 18700
dynamics loss: 27489.54883

============================================================
time elapsed: 0:12:25
train iter: 187
num of updates: 18800
dynamics loss: 27390.16211

============================================================
time elapsed: 0:12:29
train iter: 188
num of updates: 18900
dynamics loss: 27288.97266

============================================================
time elapsed: 0:12:32
train iter: 189
num of updates: 19000
dynamics loss: 27197.94141

============================================================
time elapsed: 0:12:36
train iter: 190
num of updates: 19100
dynamics loss: 27139.54688

============================================================
time elapsed: 0:12:39
train iter: 191
num of updates: 19200
dynamics loss: 27064.41016

============================================================
time elapsed: 0:12:43
train iter: 192
num of updates: 19300
dynamics loss: 26952.12500

============================================================
time elapsed: 0:12:46
train iter: 193
num of updates: 19400
dynamics loss: 26845.69336

============================================================
time elapsed: 0:12:50
train iter: 194
num of updates: 19500
dynamics loss: 26771.88867

============================================================
time elapsed: 0:12:53
train iter: 195
num of updates: 19600
dynamics loss: 26706.05859

============================================================
time elapsed: 0:12:57
train iter: 196
num of updates: 19700
dynamics loss: 26615.63672

============================================================
time elapsed: 0:13:00
train iter: 197
num of updates: 19800
dynamics loss: 26528.69922

============================================================
time elapsed: 0:13:04
train iter: 198
num of updates: 19900
dynamics loss: 26455.12695

============================================================
time elapsed: 0:13:07
train iter: 199
num of updates: 20000
dynamics loss: 26394.83594

============================================================
time elapsed: 0:13:11
train iter: 200
num of updates: 20100
dynamics loss: 26308.02148

============================================================
time elapsed: 0:13:14
train iter: 201
num of updates: 20200
dynamics loss: 26216.07422

============================================================
time elapsed: 0:13:18
train iter: 202
num of updates: 20300
dynamics loss: 26170.06641

============================================================
time elapsed: 0:13:21
train iter: 203
num of updates: 20400
dynamics loss: 26094.89648

============================================================
time elapsed: 0:13:25
train iter: 204
num of updates: 20500
dynamics loss: 26026.32812

============================================================
time elapsed: 0:13:29
train iter: 205
num of updates: 20600
dynamics loss: 25927.91016

============================================================
time elapsed: 0:13:32
train iter: 206
num of updates: 20700
dynamics loss: 25897.56641

============================================================
time elapsed: 0:13:36
train iter: 207
num of updates: 20800
dynamics loss: 25806.93750

============================================================
time elapsed: 0:13:39
train iter: 208
num of updates: 20900
dynamics loss: 25761.02930

============================================================
time elapsed: 0:13:43
train iter: 209
num of updates: 21000
dynamics loss: 25696.64844

============================================================
time elapsed: 0:13:46
train iter: 210
num of updates: 21100
dynamics loss: 25636.20508

============================================================
time elapsed: 0:13:50
train iter: 211
num of updates: 21200
dynamics loss: 25562.62695

============================================================
time elapsed: 0:13:53
train iter: 212
num of updates: 21300
dynamics loss: 25509.62109

============================================================
time elapsed: 0:13:57
train iter: 213
num of updates: 21400
dynamics loss: 25444.20117

============================================================
time elapsed: 0:14:00
train iter: 214
num of updates: 21500
dynamics loss: 25395.47656

============================================================
time elapsed: 0:14:04
train iter: 215
num of updates: 21600
dynamics loss: 25324.01367

============================================================
time elapsed: 0:14:07
train iter: 216
num of updates: 21700
dynamics loss: 25281.63867

============================================================
time elapsed: 0:14:11
train iter: 217
num of updates: 21800
dynamics loss: 25199.58203

============================================================
time elapsed: 0:14:14
train iter: 218
num of updates: 21900
dynamics loss: 25152.95508

============================================================
time elapsed: 0:14:18
train iter: 219
num of updates: 22000
dynamics loss: 25102.30078

============================================================
time elapsed: 0:14:21
train iter: 220
num of updates: 22100
dynamics loss: 25021.97852

============================================================
time elapsed: 0:14:25
train iter: 221
num of updates: 22200
dynamics loss: 25011.13281

============================================================
time elapsed: 0:14:28
train iter: 222
num of updates: 22300
dynamics loss: 24921.00195

============================================================
time elapsed: 0:14:32
train iter: 223
num of updates: 22400
dynamics loss: 24877.41406

============================================================
time elapsed: 0:14:35
train iter: 224
num of updates: 22500
dynamics loss: 24828.66797

============================================================
time elapsed: 0:14:39
train iter: 225
num of updates: 22600
dynamics loss: 24778.44922

============================================================
time elapsed: 0:14:42
train iter: 226
num of updates: 22700
dynamics loss: 24713.42578

============================================================
time elapsed: 0:14:46
train iter: 227
num of updates: 22800
dynamics loss: 24671.54883

============================================================
time elapsed: 0:14:50
train iter: 228
num of updates: 22900
dynamics loss: 24643.01758

============================================================
time elapsed: 0:14:53
train iter: 229
num of updates: 23000
dynamics loss: 24569.48438

============================================================
time elapsed: 0:14:57
train iter: 230
num of updates: 23100
dynamics loss: 24540.58984

============================================================
time elapsed: 0:15:00
train iter: 231
num of updates: 23200
dynamics loss: 24483.53711

============================================================
time elapsed: 0:15:04
train iter: 232
num of updates: 23300
dynamics loss: 24439.17383

============================================================
time elapsed: 0:15:07
train iter: 233
num of updates: 23400
dynamics loss: 24380.95312

============================================================
time elapsed: 0:15:11
train iter: 234
num of updates: 23500
dynamics loss: 24319.03711

============================================================
time elapsed: 0:15:14
train iter: 235
num of updates: 23600
dynamics loss: 24297.05859

============================================================
time elapsed: 0:15:18
train iter: 236
num of updates: 23700
dynamics loss: 24254.37695

============================================================
time elapsed: 0:15:21
train iter: 237
num of updates: 23800
dynamics loss: 24213.44141

============================================================
time elapsed: 0:15:25
train iter: 238
num of updates: 23900
dynamics loss: 24131.29688

============================================================
time elapsed: 0:15:28
train iter: 239
num of updates: 24000
dynamics loss: 24106.26953

============================================================
time elapsed: 0:15:32
train iter: 240
num of updates: 24100
dynamics loss: 24066.08984

============================================================
time elapsed: 0:15:35
train iter: 241
num of updates: 24200
dynamics loss: 24048.58984

============================================================
time elapsed: 0:15:39
train iter: 242
num of updates: 24300
dynamics loss: 23993.42578

============================================================
time elapsed: 0:15:42
train iter: 243
num of updates: 24400
dynamics loss: 23932.94922

============================================================
time elapsed: 0:15:46
train iter: 244
num of updates: 24500
dynamics loss: 23893.76953

============================================================
time elapsed: 0:15:49
train iter: 245
num of updates: 24600
dynamics loss: 23852.77344

============================================================
time elapsed: 0:15:53
train iter: 246
num of updates: 24700
dynamics loss: 23820.60156

============================================================
time elapsed: 0:15:56
train iter: 247
num of updates: 24800
dynamics loss: 23794.90234

============================================================
time elapsed: 0:16:00
train iter: 248
num of updates: 24900
dynamics loss: 23734.98047

============================================================
time elapsed: 0:16:03
train iter: 249
num of updates: 25000
dynamics loss: 23722.95703

============================================================
time elapsed: 0:16:07
train iter: 250
num of updates: 25100
dynamics loss: 23658.99219

============================================================
time elapsed: 0:16:10
train iter: 251
num of updates: 25200
dynamics loss: 23632.99219

============================================================
time elapsed: 0:16:14
train iter: 252
num of updates: 25300
dynamics loss: 23582.38086

============================================================
time elapsed: 0:16:17
train iter: 253
num of updates: 25400
dynamics loss: 23560.08594

============================================================
time elapsed: 0:16:21
train iter: 254
num of updates: 25500
dynamics loss: 23516.99805

============================================================
time elapsed: 0:16:25
train iter: 255
num of updates: 25600
dynamics loss: 23471.99219

============================================================
time elapsed: 0:16:28
train iter: 256
num of updates: 25700
dynamics loss: 23428.59180

============================================================
time elapsed: 0:16:32
train iter: 257
num of updates: 25800
dynamics loss: 23395.94141

============================================================
time elapsed: 0:16:35
train iter: 258
num of updates: 25900
dynamics loss: 23351.09766

============================================================
time elapsed: 0:16:39
train iter: 259
num of updates: 26000
dynamics loss: 23346.85547

============================================================
time elapsed: 0:16:42
train iter: 260
num of updates: 26100
dynamics loss: 23282.69336

============================================================
time elapsed: 0:16:46
train iter: 261
num of updates: 26200
dynamics loss: 23292.66992

============================================================
time elapsed: 0:16:49
train iter: 262
num of updates: 26300
dynamics loss: 23241.02148

============================================================
time elapsed: 0:16:53
train iter: 263
num of updates: 26400
dynamics loss: 23186.18164

============================================================
time elapsed: 0:16:56
train iter: 264
num of updates: 26500
dynamics loss: 23168.87891

============================================================
time elapsed: 0:17:00
train iter: 265
num of updates: 26600
dynamics loss: 23146.67773

============================================================
time elapsed: 0:17:03
train iter: 266
num of updates: 26700
dynamics loss: 23085.03711

============================================================
time elapsed: 0:17:07
train iter: 267
num of updates: 26800
dynamics loss: 23059.97656

============================================================
time elapsed: 0:17:10
train iter: 268
num of updates: 26900
dynamics loss: 23042.11523

============================================================
time elapsed: 0:17:14
train iter: 269
num of updates: 27000
dynamics loss: 22990.60742

============================================================
time elapsed: 0:17:17
train iter: 270
num of updates: 27100
dynamics loss: 22958.91602

============================================================
time elapsed: 0:17:21
train iter: 271
num of updates: 27200
dynamics loss: 22931.43750

============================================================
time elapsed: 0:17:24
train iter: 272
num of updates: 27300
dynamics loss: 22920.12500

============================================================
time elapsed: 0:17:28
train iter: 273
num of updates: 27400
dynamics loss: 22870.27148

============================================================
time elapsed: 0:17:31
train iter: 274
num of updates: 27500
dynamics loss: 22820.53711

============================================================
time elapsed: 0:17:35
train iter: 275
num of updates: 27600
dynamics loss: 22781.45703

============================================================
time elapsed: 0:17:38
train iter: 276
num of updates: 27700
dynamics loss: 22779.76953

============================================================
time elapsed: 0:17:42
train iter: 277
num of updates: 27800
dynamics loss: 22735.42969

============================================================
time elapsed: 0:17:45
train iter: 278
num of updates: 27900
dynamics loss: 22718.96875

============================================================
time elapsed: 0:17:49
train iter: 279
num of updates: 28000
dynamics loss: 22667.53125

============================================================
time elapsed: 0:17:52
train iter: 280
num of updates: 28100
dynamics loss: 22668.04492

============================================================
time elapsed: 0:17:56
train iter: 281
num of updates: 28200
dynamics loss: 22596.83789

============================================================
time elapsed: 0:18:00
train iter: 282
num of updates: 28300
dynamics loss: 22594.16211

============================================================
time elapsed: 0:18:03
train iter: 283
num of updates: 28400
dynamics loss: 22565.04102

============================================================
time elapsed: 0:18:07
train iter: 284
num of updates: 28500
dynamics loss: 22524.33594

============================================================
time elapsed: 0:18:10
train iter: 285
num of updates: 28600
dynamics loss: 22531.11523

============================================================
time elapsed: 0:18:14
train iter: 286
num of updates: 28700
dynamics loss: 22487.22852

============================================================
time elapsed: 0:18:17
train iter: 287
num of updates: 28800
dynamics loss: 22442.53516

============================================================
time elapsed: 0:18:21
train iter: 288
num of updates: 28900
dynamics loss: 22411.31836

============================================================
time elapsed: 0:18:24
train iter: 289
num of updates: 29000
dynamics loss: 22406.19727

============================================================
time elapsed: 0:18:28
train iter: 290
num of updates: 29100
dynamics loss: 22359.33789

============================================================
time elapsed: 0:18:31
train iter: 291
num of updates: 29200
dynamics loss: 22339.22461

============================================================
time elapsed: 0:18:35
train iter: 292
num of updates: 29300
dynamics loss: 22330.72656

============================================================
time elapsed: 0:18:38
train iter: 293
num of updates: 29400
dynamics loss: 22261.80273

============================================================
time elapsed: 0:18:42
train iter: 294
num of updates: 29500
dynamics loss: 22276.39648

============================================================
time elapsed: 0:18:45
train iter: 295
num of updates: 29600
dynamics loss: 22221.64844

============================================================
time elapsed: 0:18:49
train iter: 296
num of updates: 29700
dynamics loss: 22208.46875

============================================================
time elapsed: 0:18:52
train iter: 297
num of updates: 29800
dynamics loss: 22179.93359

============================================================
time elapsed: 0:18:56
train iter: 298
num of updates: 29900
dynamics loss: 22150.14844

============================================================
time elapsed: 0:18:59
train iter: 299
num of updates: 30000
dynamics loss: 22152.47070

============================================================
time elapsed: 0:19:03
train iter: 300
num of updates: 30100
dynamics loss: 22122.99219

============================================================
time elapsed: 0:19:06
train iter: 301
num of updates: 30200
dynamics loss: 22080.15039

============================================================
time elapsed: 0:19:10
train iter: 302
num of updates: 30300
dynamics loss: 22045.80273

============================================================
time elapsed: 0:19:13
train iter: 303
num of updates: 30400
dynamics loss: 21990.28125

============================================================
time elapsed: 0:19:17
train iter: 304
num of updates: 30500
dynamics loss: 21979.34375

============================================================
time elapsed: 0:19:20
train iter: 305
num of updates: 30600
dynamics loss: 21970.06445

============================================================
time elapsed: 0:19:24
train iter: 306
num of updates: 30700
dynamics loss: 21945.19922

============================================================
time elapsed: 0:19:27
train iter: 307
num of updates: 30800
dynamics loss: 21926.02539

============================================================
time elapsed: 0:19:31
train iter: 308
num of updates: 30900
dynamics loss: 21894.55664

============================================================
time elapsed: 0:19:35
train iter: 309
num of updates: 31000
dynamics loss: 21850.92578

============================================================
time elapsed: 0:19:38
train iter: 310
num of updates: 31100
dynamics loss: 21862.56641

============================================================
time elapsed: 0:19:42
train iter: 311
num of updates: 31200
dynamics loss: 21837.07617

============================================================
time elapsed: 0:19:45
train iter: 312
num of updates: 31300
dynamics loss: 21794.46289

============================================================
time elapsed: 0:19:49
train iter: 313
num of updates: 31400
dynamics loss: 21797.87891

============================================================
time elapsed: 0:19:52
train iter: 314
num of updates: 31500
dynamics loss: 21753.61328

============================================================
time elapsed: 0:19:56
train iter: 315
num of updates: 31600
dynamics loss: 21728.82227

============================================================
time elapsed: 0:19:59
train iter: 316
num of updates: 31700
dynamics loss: 21705.35742

============================================================
time elapsed: 0:20:03
train iter: 317
num of updates: 31800
dynamics loss: 21669.98047

============================================================
time elapsed: 0:20:06
train iter: 318
num of updates: 31900
dynamics loss: 21664.06055

============================================================
time elapsed: 0:20:10
train iter: 319
num of updates: 32000
dynamics loss: 21624.60742

============================================================
time elapsed: 0:20:13
train iter: 320
num of updates: 32100
dynamics loss: 21635.46680

============================================================
time elapsed: 0:20:17
train iter: 321
num of updates: 32200
dynamics loss: 21587.89453

============================================================
time elapsed: 0:20:20
train iter: 322
num of updates: 32300
dynamics loss: 21584.43750

============================================================
time elapsed: 0:20:24
train iter: 323
num of updates: 32400
dynamics loss: 21532.18359

============================================================
time elapsed: 0:20:27
train iter: 324
num of updates: 32500
dynamics loss: 21537.97852

============================================================
time elapsed: 0:20:31
train iter: 325
num of updates: 32600
dynamics loss: 21501.54492

============================================================
time elapsed: 0:20:34
train iter: 326
num of updates: 32700
dynamics loss: 21471.33789

============================================================
time elapsed: 0:20:38
train iter: 327
num of updates: 32800
dynamics loss: 21460.45312

============================================================
time elapsed: 0:20:41
train iter: 328
num of updates: 32900
dynamics loss: 21428.12109

============================================================
time elapsed: 0:20:45
train iter: 329
num of updates: 33000
dynamics loss: 21409.29688

============================================================
time elapsed: 0:20:48
train iter: 330
num of updates: 33100
dynamics loss: 21375.47656

============================================================
time elapsed: 0:20:52
train iter: 331
num of updates: 33200
dynamics loss: 21375.59375

============================================================
time elapsed: 0:20:56
train iter: 332
num of updates: 33300
dynamics loss: 21333.68750

============================================================
time elapsed: 0:20:59
train iter: 333
num of updates: 33400
dynamics loss: 21339.02734

============================================================
time elapsed: 0:21:03
train iter: 334
num of updates: 33500
dynamics loss: 21301.45703

============================================================
time elapsed: 0:21:06
train iter: 335
num of updates: 33600
dynamics loss: 21290.36133

============================================================
time elapsed: 0:21:10
train iter: 336
num of updates: 33700
dynamics loss: 21272.58984

============================================================
time elapsed: 0:21:13
train iter: 337
num of updates: 33800
dynamics loss: 21235.46484

============================================================
time elapsed: 0:21:17
train iter: 338
num of updates: 33900
dynamics loss: 21235.13672

============================================================
time elapsed: 0:21:20
train iter: 339
num of updates: 34000
dynamics loss: 21212.14062

============================================================
time elapsed: 0:21:24
train iter: 340
num of updates: 34100
dynamics loss: 21165.45703

============================================================
time elapsed: 0:21:27
train iter: 341
num of updates: 34200
dynamics loss: 21152.88086

============================================================
time elapsed: 0:21:31
train iter: 342
num of updates: 34300
dynamics loss: 21148.94141

============================================================
time elapsed: 0:21:34
train iter: 343
num of updates: 34400
dynamics loss: 21114.03516

============================================================
time elapsed: 0:21:38
train iter: 344
num of updates: 34500
dynamics loss: 21114.77344

============================================================
time elapsed: 0:21:41
train iter: 345
num of updates: 34600
dynamics loss: 21068.44336

============================================================
time elapsed: 0:21:45
train iter: 346
num of updates: 34700
dynamics loss: 21054.62109

============================================================
time elapsed: 0:21:48
train iter: 347
num of updates: 34800
dynamics loss: 21043.71680

============================================================
time elapsed: 0:21:52
train iter: 348
num of updates: 34900
dynamics loss: 21018.31641

============================================================
time elapsed: 0:21:55
train iter: 349
num of updates: 35000
dynamics loss: 21007.62109

============================================================
time elapsed: 0:21:59
train iter: 350
num of updates: 35100
dynamics loss: 20958.97852

============================================================
time elapsed: 0:22:02
train iter: 351
num of updates: 35200
dynamics loss: 20957.72656

============================================================
time elapsed: 0:22:06
train iter: 352
num of updates: 35300
dynamics loss: 20929.34766

============================================================
time elapsed: 0:22:09
train iter: 353
num of updates: 35400
dynamics loss: 20923.24023

============================================================
time elapsed: 0:22:13
train iter: 354
num of updates: 35500
dynamics loss: 20905.30859

============================================================
time elapsed: 0:22:16
train iter: 355
num of updates: 35600
dynamics loss: 20890.02734

============================================================
time elapsed: 0:22:20
train iter: 356
num of updates: 35700
dynamics loss: 20852.05664

============================================================
time elapsed: 0:22:23
train iter: 357
num of updates: 35800
dynamics loss: 20856.55859

============================================================
time elapsed: 0:22:27
train iter: 358
num of updates: 35900
dynamics loss: 20794.73828

============================================================
time elapsed: 0:22:31
train iter: 359
num of updates: 36000
dynamics loss: 20802.09570

============================================================
time elapsed: 0:22:34
train iter: 360
num of updates: 36100
dynamics loss: 20790.01758

============================================================
time elapsed: 0:22:38
train iter: 361
num of updates: 36200
dynamics loss: 20746.55273

============================================================
time elapsed: 0:22:41
train iter: 362
num of updates: 36300
dynamics loss: 20726.48047

============================================================
time elapsed: 0:22:45
train iter: 363
num of updates: 36400
dynamics loss: 20721.18945

============================================================
time elapsed: 0:22:48
train iter: 364
num of updates: 36500
dynamics loss: 20689.54297

============================================================
time elapsed: 0:22:52
train iter: 365
num of updates: 36600
dynamics loss: 20695.51758

============================================================
time elapsed: 0:22:55
train iter: 366
num of updates: 36700
dynamics loss: 20675.01562

============================================================
time elapsed: 0:22:59
train iter: 367
num of updates: 36800
dynamics loss: 20634.10156

============================================================
time elapsed: 0:23:02
train iter: 368
num of updates: 36900
dynamics loss: 20635.87305

============================================================
time elapsed: 0:23:06
train iter: 369
num of updates: 37000
dynamics loss: 20611.62109

============================================================
time elapsed: 0:23:09
train iter: 370
num of updates: 37100
dynamics loss: 20568.68359

============================================================
time elapsed: 0:23:13
train iter: 371
num of updates: 37200
dynamics loss: 20580.32227

============================================================
time elapsed: 0:23:16
train iter: 372
num of updates: 37300
dynamics loss: 20558.17969

============================================================
time elapsed: 0:23:20
train iter: 373
num of updates: 37400
dynamics loss: 20543.71875

============================================================
time elapsed: 0:23:23
train iter: 374
num of updates: 37500
dynamics loss: 20508.55664

============================================================
time elapsed: 0:23:27
train iter: 375
num of updates: 37600
dynamics loss: 20490.20312

============================================================
time elapsed: 0:23:30
train iter: 376
num of updates: 37700
dynamics loss: 20479.54102

============================================================
time elapsed: 0:23:34
train iter: 377
num of updates: 37800
dynamics loss: 20479.50977

============================================================
time elapsed: 0:23:37
train iter: 378
num of updates: 37900
dynamics loss: 20452.18555

============================================================
time elapsed: 0:23:41
train iter: 379
num of updates: 38000
dynamics loss: 20427.32031

============================================================
time elapsed: 0:23:44
train iter: 380
num of updates: 38100
dynamics loss: 20407.97070

============================================================
time elapsed: 0:23:48
train iter: 381
num of updates: 38200
dynamics loss: 20406.66602

============================================================
time elapsed: 0:23:51
train iter: 382
num of updates: 38300
dynamics loss: 20401.86523

============================================================
time elapsed: 0:23:55
train iter: 383
num of updates: 38400
dynamics loss: 20348.41211

============================================================
time elapsed: 0:23:58
train iter: 384
num of updates: 38500
dynamics loss: 20336.09375

============================================================
time elapsed: 0:24:02
train iter: 385
num of updates: 38600
dynamics loss: 20298.08594

============================================================
time elapsed: 0:24:06
train iter: 386
num of updates: 38700
dynamics loss: 20286.35938

============================================================
time elapsed: 0:24:09
train iter: 387
num of updates: 38800
dynamics loss: 20277.75977

============================================================
time elapsed: 0:24:13
train iter: 388
num of updates: 38900
dynamics loss: 20252.21875

============================================================
time elapsed: 0:24:16
train iter: 389
num of updates: 39000
dynamics loss: 20247.45312

============================================================
time elapsed: 0:24:20
train iter: 390
num of updates: 39100
dynamics loss: 20226.62500

============================================================
time elapsed: 0:24:23
train iter: 391
num of updates: 39200
dynamics loss: 20215.18164

============================================================
time elapsed: 0:24:27
train iter: 392
num of updates: 39300
dynamics loss: 20190.98438

============================================================
time elapsed: 0:24:30
train iter: 393
num of updates: 39400
dynamics loss: 20169.79492

============================================================
time elapsed: 0:24:34
train iter: 394
num of updates: 39500
dynamics loss: 20163.57422

============================================================
time elapsed: 0:24:37
train iter: 395
num of updates: 39600
dynamics loss: 20150.86914

============================================================
time elapsed: 0:24:41
train iter: 396
num of updates: 39700
dynamics loss: 20119.08008

============================================================
time elapsed: 0:24:44
train iter: 397
num of updates: 39800
dynamics loss: 20110.89258

============================================================
time elapsed: 0:24:48
train iter: 398
num of updates: 39900
dynamics loss: 20080.67773

============================================================
time elapsed: 0:24:51
train iter: 399
num of updates: 40000
dynamics loss: 20069.90039

============================================================
time elapsed: 0:24:55
train iter: 400
num of updates: 40100
dynamics loss: 20060.95898

============================================================
time elapsed: 0:24:58
train iter: 401
num of updates: 40200
dynamics loss: 20048.82812

============================================================
time elapsed: 0:25:02
train iter: 402
num of updates: 40300
dynamics loss: 20028.94141

============================================================
time elapsed: 0:25:05
train iter: 403
num of updates: 40400
dynamics loss: 20021.85547

============================================================
time elapsed: 0:25:09
train iter: 404
num of updates: 40500
dynamics loss: 19990.91016

============================================================
time elapsed: 0:25:12
train iter: 405
num of updates: 40600
dynamics loss: 19969.38867

============================================================
time elapsed: 0:25:16
train iter: 406
num of updates: 40700
dynamics loss: 19955.50000

============================================================
time elapsed: 0:25:19
train iter: 407
num of updates: 40800
dynamics loss: 19943.54102

============================================================
time elapsed: 0:25:23
train iter: 408
num of updates: 40900
dynamics loss: 19917.54102

============================================================
time elapsed: 0:25:26
train iter: 409
num of updates: 41000
dynamics loss: 19911.76562

============================================================
time elapsed: 0:25:30
train iter: 410
num of updates: 41100
dynamics loss: 19901.63672

============================================================
time elapsed: 0:25:34
train iter: 411
num of updates: 41200
dynamics loss: 19883.05664

============================================================
time elapsed: 0:25:37
train iter: 412
num of updates: 41300
dynamics loss: 19832.51562

============================================================
time elapsed: 0:25:41
train iter: 413
num of updates: 41400
dynamics loss: 19846.70117

============================================================
time elapsed: 0:25:44
train iter: 414
num of updates: 41500
dynamics loss: 19821.74414

============================================================
time elapsed: 0:25:48
train iter: 415
num of updates: 41600
dynamics loss: 19792.49805

============================================================
time elapsed: 0:25:51
train iter: 416
num of updates: 41700
dynamics loss: 19779.82031

============================================================
time elapsed: 0:25:55
train iter: 417
num of updates: 41800
dynamics loss: 19770.50977

============================================================
time elapsed: 0:25:58
train iter: 418
num of updates: 41900
dynamics loss: 19761.91016

============================================================
time elapsed: 0:26:02
train iter: 419
num of updates: 42000
dynamics loss: 19742.80859

============================================================
time elapsed: 0:26:05
train iter: 420
num of updates: 42100
dynamics loss: 19720.20898

============================================================
time elapsed: 0:26:09
train iter: 421
num of updates: 42200
dynamics loss: 19722.43750

============================================================
time elapsed: 0:26:12
train iter: 422
num of updates: 42300
dynamics loss: 19680.32227

============================================================
time elapsed: 0:26:16
train iter: 423
num of updates: 42400
dynamics loss: 19680.75000

============================================================
time elapsed: 0:26:19
train iter: 424
num of updates: 42500
dynamics loss: 19645.21289

============================================================
time elapsed: 0:26:23
train iter: 425
num of updates: 42600
dynamics loss: 19650.34180

============================================================
time elapsed: 0:26:26
train iter: 426
num of updates: 42700
dynamics loss: 19627.35156

============================================================
time elapsed: 0:26:30
train iter: 427
num of updates: 42800
dynamics loss: 19611.12109

============================================================
time elapsed: 0:26:33
train iter: 428
num of updates: 42900
dynamics loss: 19613.99219

============================================================
time elapsed: 0:26:37
train iter: 429
num of updates: 43000
dynamics loss: 19592.20312

============================================================
time elapsed: 0:26:40
train iter: 430
num of updates: 43100
dynamics loss: 19574.50391

============================================================
time elapsed: 0:26:44
train iter: 431
num of updates: 43200
dynamics loss: 19543.85938

============================================================
time elapsed: 0:26:47
train iter: 432
num of updates: 43300
dynamics loss: 19531.99219

============================================================
time elapsed: 0:26:51
train iter: 433
num of updates: 43400
dynamics loss: 19522.22266

============================================================
time elapsed: 0:26:54
train iter: 434
num of updates: 43500
dynamics loss: 19510.59180

============================================================
time elapsed: 0:26:58
train iter: 435
num of updates: 43600
dynamics loss: 19480.43555

============================================================
time elapsed: 0:27:02
train iter: 436
num of updates: 43700
dynamics loss: 19483.25586

============================================================
time elapsed: 0:27:05
train iter: 437
num of updates: 43800
dynamics loss: 19451.43945

============================================================
time elapsed: 0:27:09
train iter: 438
num of updates: 43900
dynamics loss: 19464.33398

============================================================
time elapsed: 0:27:12
train iter: 439
num of updates: 44000
dynamics loss: 19416.63086

============================================================
time elapsed: 0:27:16
train iter: 440
num of updates: 44100
dynamics loss: 19417.91016

============================================================
time elapsed: 0:27:19
train iter: 441
num of updates: 44200
dynamics loss: 19383.37109

============================================================
time elapsed: 0:27:23
train iter: 442
num of updates: 44300
dynamics loss: 19378.64062

============================================================
time elapsed: 0:27:26
train iter: 443
num of updates: 44400
dynamics loss: 19360.29492

============================================================
time elapsed: 0:27:30
train iter: 444
num of updates: 44500
dynamics loss: 19342.58984

============================================================
time elapsed: 0:27:33
train iter: 445
num of updates: 44600
dynamics loss: 19319.57617

============================================================
time elapsed: 0:27:37
train iter: 446
num of updates: 44700
dynamics loss: 19329.82812

============================================================
time elapsed: 0:27:40
train iter: 447
num of updates: 44800
dynamics loss: 19305.08984

============================================================
time elapsed: 0:27:44
train iter: 448
num of updates: 44900
dynamics loss: 19284.47656

============================================================
time elapsed: 0:27:47
train iter: 449
num of updates: 45000
dynamics loss: 19266.65039

============================================================
time elapsed: 0:27:51
train iter: 450
num of updates: 45100
dynamics loss: 19241.83594

============================================================
time elapsed: 0:27:54
train iter: 451
num of updates: 45200
dynamics loss: 19243.20898

============================================================
time elapsed: 0:27:58
train iter: 452
num of updates: 45300
dynamics loss: 19246.54492

============================================================
time elapsed: 0:28:01
train iter: 453
num of updates: 45400
dynamics loss: 19214.87891

============================================================
time elapsed: 0:28:05
train iter: 454
num of updates: 45500
dynamics loss: 19199.86719

============================================================
time elapsed: 0:28:08
train iter: 455
num of updates: 45600
dynamics loss: 19179.69727

============================================================
time elapsed: 0:28:12
train iter: 456
num of updates: 45700
dynamics loss: 19171.17383

============================================================
time elapsed: 0:28:15
train iter: 457
num of updates: 45800
dynamics loss: 19151.32812

============================================================
time elapsed: 0:28:19
train iter: 458
num of updates: 45900
dynamics loss: 19141.06445

============================================================
time elapsed: 0:28:22
train iter: 459
num of updates: 46000
dynamics loss: 19115.41406

============================================================
time elapsed: 0:28:26
train iter: 460
num of updates: 46100
dynamics loss: 19087.97266

============================================================
time elapsed: 0:28:30
train iter: 461
num of updates: 46200
dynamics loss: 19088.16406

============================================================
time elapsed: 0:28:33
train iter: 462
num of updates: 46300
dynamics loss: 19077.90625

============================================================
time elapsed: 0:28:37
train iter: 463
num of updates: 46400
dynamics loss: 19073.72852

============================================================
time elapsed: 0:28:40
train iter: 464
num of updates: 46500
dynamics loss: 19034.43359

============================================================
time elapsed: 0:28:44
train iter: 465
num of updates: 46600
dynamics loss: 19038.74023

============================================================
time elapsed: 0:28:47
train iter: 466
num of updates: 46700
dynamics loss: 19029.47656

============================================================
time elapsed: 0:28:51
train iter: 467
num of updates: 46800
dynamics loss: 18990.33203

============================================================
time elapsed: 0:28:54
train iter: 468
num of updates: 46900
dynamics loss: 18975.75781

============================================================
time elapsed: 0:28:58
train iter: 469
num of updates: 47000
dynamics loss: 18973.53125

============================================================
time elapsed: 0:29:01
train iter: 470
num of updates: 47100
dynamics loss: 18966.87695

============================================================
time elapsed: 0:29:05
train iter: 471
num of updates: 47200
dynamics loss: 18951.60938

============================================================
time elapsed: 0:29:08
train iter: 472
num of updates: 47300
dynamics loss: 18922.25781

============================================================
time elapsed: 0:29:12
train iter: 473
num of updates: 47400
dynamics loss: 18937.61523

============================================================
time elapsed: 0:29:15
train iter: 474
num of updates: 47500
dynamics loss: 18904.02734

============================================================
time elapsed: 0:29:19
train iter: 475
num of updates: 47600
dynamics loss: 18877.55273

============================================================
time elapsed: 0:29:22
train iter: 476
num of updates: 47700
dynamics loss: 18867.87109

============================================================
time elapsed: 0:29:26
train iter: 477
num of updates: 47800
dynamics loss: 18867.69727

============================================================
time elapsed: 0:29:29
train iter: 478
num of updates: 47900
dynamics loss: 18818.41406

============================================================
time elapsed: 0:29:33
train iter: 479
num of updates: 48000
dynamics loss: 18825.76172

============================================================
time elapsed: 0:29:36
train iter: 480
num of updates: 48100
dynamics loss: 18801.48438

============================================================
time elapsed: 0:29:40
train iter: 481
num of updates: 48200
dynamics loss: 18797.60156

============================================================
time elapsed: 0:29:43
train iter: 482
num of updates: 48300
dynamics loss: 18774.51367

============================================================
time elapsed: 0:29:47
train iter: 483
num of updates: 48400
dynamics loss: 18766.78516

============================================================
time elapsed: 0:29:50
train iter: 484
num of updates: 48500
dynamics loss: 18754.29492

============================================================
time elapsed: 0:29:54
train iter: 485
num of updates: 48600
dynamics loss: 18747.13281

============================================================
time elapsed: 0:29:57
train iter: 486
num of updates: 48700
dynamics loss: 18731.71875

============================================================
time elapsed: 0:30:01
train iter: 487
num of updates: 48800
dynamics loss: 18725.58008

============================================================
time elapsed: 0:30:05
train iter: 488
num of updates: 48900
dynamics loss: 18682.46289

============================================================
time elapsed: 0:30:08
train iter: 489
num of updates: 49000
dynamics loss: 18684.71289

============================================================
time elapsed: 0:30:12
train iter: 490
num of updates: 49100
dynamics loss: 18657.12891

============================================================
time elapsed: 0:30:15
train iter: 491
num of updates: 49200
dynamics loss: 18639.19727

============================================================
time elapsed: 0:30:19
train iter: 492
num of updates: 49300
dynamics loss: 18638.88477

============================================================
time elapsed: 0:30:22
train iter: 493
num of updates: 49400
dynamics loss: 18628.55273

============================================================
time elapsed: 0:30:26
train iter: 494
num of updates: 49500
dynamics loss: 18601.86914

============================================================
time elapsed: 0:30:29
train iter: 495
num of updates: 49600
dynamics loss: 18603.82422

============================================================
time elapsed: 0:30:33
train iter: 496
num of updates: 49700
dynamics loss: 18582.56445

============================================================
time elapsed: 0:30:36
train iter: 497
num of updates: 49800
dynamics loss: 18566.90625

============================================================
time elapsed: 0:30:40
train iter: 498
num of updates: 49900
dynamics loss: 18553.20117

============================================================
time elapsed: 0:30:43
train iter: 499
num of updates: 50000
dynamics loss: 18524.82617

============================================================
time elapsed: 0:30:47
train iter: 500
num of updates: 50100
dynamics loss: 18507.24805

============================================================
time elapsed: 0:30:50
train iter: 501
num of updates: 50200
dynamics loss: 18507.52930

============================================================
time elapsed: 0:30:54
train iter: 502
num of updates: 50300
dynamics loss: 18480.34180

============================================================
time elapsed: 0:30:57
train iter: 503
num of updates: 50400
dynamics loss: 18492.14453

============================================================
time elapsed: 0:31:01
train iter: 504
num of updates: 50500
dynamics loss: 18467.01367

============================================================
time elapsed: 0:31:04
train iter: 505
num of updates: 50600
dynamics loss: 18463.68555

============================================================
time elapsed: 0:31:08
train iter: 506
num of updates: 50700
dynamics loss: 18433.50977

============================================================
time elapsed: 0:31:11
train iter: 507
num of updates: 50800
dynamics loss: 18416.35938

============================================================
time elapsed: 0:31:15
train iter: 508
num of updates: 50900
dynamics loss: 18407.34375

============================================================
time elapsed: 0:31:18
train iter: 509
num of updates: 51000
dynamics loss: 18391.65234

============================================================
time elapsed: 0:31:22
train iter: 510
num of updates: 51100
dynamics loss: 18397.72266

============================================================
time elapsed: 0:31:25
train iter: 511
num of updates: 51200
dynamics loss: 18371.20703

============================================================
time elapsed: 0:31:29
train iter: 512
num of updates: 51300
dynamics loss: 18358.18750

============================================================
time elapsed: 0:31:32
train iter: 513
num of updates: 51400
dynamics loss: 18348.48828

============================================================
time elapsed: 0:31:36
train iter: 514
num of updates: 51500
dynamics loss: 18323.78320

============================================================
time elapsed: 0:31:40
train iter: 515
num of updates: 51600
dynamics loss: 18322.11719

============================================================
time elapsed: 0:31:43
train iter: 516
num of updates: 51700
dynamics loss: 18284.57227

============================================================
time elapsed: 0:31:47
train iter: 517
num of updates: 51800
dynamics loss: 18291.71289

============================================================
time elapsed: 0:31:50
train iter: 518
num of updates: 51900
dynamics loss: 18270.06445

============================================================
time elapsed: 0:31:54
train iter: 519
num of updates: 52000
dynamics loss: 18250.73438

============================================================
time elapsed: 0:31:57
train iter: 520
num of updates: 52100
dynamics loss: 18244.02930

============================================================
time elapsed: 0:32:01
train iter: 521
num of updates: 52200
dynamics loss: 18233.17773

============================================================
time elapsed: 0:32:04
train iter: 522
num of updates: 52300
dynamics loss: 18210.48828

============================================================
time elapsed: 0:32:08
train iter: 523
num of updates: 52400
dynamics loss: 18195.91602

============================================================
time elapsed: 0:32:11
train iter: 524
num of updates: 52500
dynamics loss: 18181.83008

============================================================
time elapsed: 0:32:15
train iter: 525
num of updates: 52600
dynamics loss: 18184.02930

============================================================
time elapsed: 0:32:18
train iter: 526
num of updates: 52700
dynamics loss: 18162.40820

============================================================
time elapsed: 0:32:22
train iter: 527
num of updates: 52800
dynamics loss: 18144.82031

============================================================
time elapsed: 0:32:25
train iter: 528
num of updates: 52900
dynamics loss: 18125.61523

============================================================
time elapsed: 0:32:29
train iter: 529
num of updates: 53000
dynamics loss: 18132.01562

============================================================
time elapsed: 0:32:32
train iter: 530
num of updates: 53100
dynamics loss: 18118.14648

============================================================
time elapsed: 0:32:36
train iter: 531
num of updates: 53200
dynamics loss: 18089.56641

============================================================
time elapsed: 0:32:39
train iter: 532
num of updates: 53300
dynamics loss: 18065.74805

============================================================
time elapsed: 0:32:43
train iter: 533
num of updates: 53400
dynamics loss: 18071.68164

============================================================
time elapsed: 0:32:46
train iter: 534
num of updates: 53500
dynamics loss: 18054.04492

============================================================
time elapsed: 0:32:50
train iter: 535
num of updates: 53600
dynamics loss: 18039.99609

============================================================
time elapsed: 0:32:53
train iter: 536
num of updates: 53700
dynamics loss: 18031.79102

============================================================
time elapsed: 0:32:57
train iter: 537
num of updates: 53800
dynamics loss: 18015.58789

============================================================
time elapsed: 0:33:01
train iter: 538
num of updates: 53900
dynamics loss: 17996.36328

============================================================
time elapsed: 0:33:04
train iter: 539
num of updates: 54000
dynamics loss: 17988.78906

============================================================
time elapsed: 0:33:08
train iter: 540
num of updates: 54100
dynamics loss: 17954.62109

============================================================
time elapsed: 0:33:11
train iter: 541
num of updates: 54200
dynamics loss: 17961.40430

============================================================
time elapsed: 0:33:15
train iter: 542
num of updates: 54300
dynamics loss: 17940.22656

============================================================
time elapsed: 0:33:18
train iter: 543
num of updates: 54400
dynamics loss: 17910.36523

============================================================
time elapsed: 0:33:22
train iter: 544
num of updates: 54500
dynamics loss: 17908.99609

============================================================
time elapsed: 0:33:25
train iter: 545
num of updates: 54600
dynamics loss: 17894.03711

============================================================
time elapsed: 0:33:29
train iter: 546
num of updates: 54700
dynamics loss: 17875.60938

============================================================
time elapsed: 0:33:32
train iter: 547
num of updates: 54800
dynamics loss: 17871.70117

============================================================
time elapsed: 0:33:36
train iter: 548
num of updates: 54900
dynamics loss: 17883.03320

============================================================
time elapsed: 0:33:39
train iter: 549
num of updates: 55000
dynamics loss: 17832.58203

============================================================
time elapsed: 0:33:43
train iter: 550
num of updates: 55100
dynamics loss: 17822.93945

============================================================
time elapsed: 0:33:46
train iter: 551
num of updates: 55200
dynamics loss: 17839.12891

============================================================
time elapsed: 0:33:50
train iter: 552
num of updates: 55300
dynamics loss: 17806.98438

============================================================
time elapsed: 0:33:53
train iter: 553
num of updates: 55400
dynamics loss: 17785.04492

============================================================
time elapsed: 0:33:57
train iter: 554
num of updates: 55500
dynamics loss: 17771.74219

============================================================
time elapsed: 0:34:00
train iter: 555
num of updates: 55600
dynamics loss: 17766.76172

============================================================
time elapsed: 0:34:04
train iter: 556
num of updates: 55700
dynamics loss: 17751.90430

============================================================
time elapsed: 0:34:07
train iter: 557
num of updates: 55800
dynamics loss: 17732.03906

============================================================
time elapsed: 0:34:11
train iter: 558
num of updates: 55900
dynamics loss: 17719.43555

============================================================
time elapsed: 0:34:14
train iter: 559
num of updates: 56000
dynamics loss: 17714.71680

============================================================
time elapsed: 0:34:18
train iter: 560
num of updates: 56100
dynamics loss: 17701.55273

============================================================
time elapsed: 0:34:21
train iter: 561
num of updates: 56200
dynamics loss: 17685.72852

============================================================
time elapsed: 0:34:25
train iter: 562
num of updates: 56300
dynamics loss: 17663.39258

============================================================
time elapsed: 0:34:29
train iter: 563
num of updates: 56400
dynamics loss: 17655.93750

============================================================
time elapsed: 0:34:32
train iter: 564
num of updates: 56500
dynamics loss: 17633.30078

============================================================
time elapsed: 0:34:36
train iter: 565
num of updates: 56600
dynamics loss: 17628.03711

============================================================
time elapsed: 0:34:39
train iter: 566
num of updates: 56700
dynamics loss: 17618.34180

============================================================
time elapsed: 0:34:43
train iter: 567
num of updates: 56800
dynamics loss: 17611.11133

============================================================
time elapsed: 0:34:46
train iter: 568
num of updates: 56900
dynamics loss: 17585.40625

============================================================
time elapsed: 0:34:50
train iter: 569
num of updates: 57000
dynamics loss: 17573.86133

============================================================
time elapsed: 0:34:53
train iter: 570
num of updates: 57100
dynamics loss: 17561.65234

============================================================
time elapsed: 0:34:57
train iter: 571
num of updates: 57200
dynamics loss: 17565.40039

============================================================
time elapsed: 0:35:00
train iter: 572
num of updates: 57300
dynamics loss: 17546.89062

============================================================
time elapsed: 0:35:04
train iter: 573
num of updates: 57400
dynamics loss: 17519.93750

============================================================
time elapsed: 0:35:07
train iter: 574
num of updates: 57500
dynamics loss: 17520.79102

============================================================
time elapsed: 0:35:11
train iter: 575
num of updates: 57600
dynamics loss: 17493.41602

============================================================
time elapsed: 0:35:14
train iter: 576
num of updates: 57700
dynamics loss: 17496.82031

============================================================
time elapsed: 0:35:18
train iter: 577
num of updates: 57800
dynamics loss: 17465.92773

============================================================
time elapsed: 0:35:21
train iter: 578
num of updates: 57900
dynamics loss: 17440.44727

============================================================
time elapsed: 0:35:25
train iter: 579
num of updates: 58000
dynamics loss: 17440.27930

============================================================
time elapsed: 0:35:28
train iter: 580
num of updates: 58100
dynamics loss: 17418.40820

============================================================
time elapsed: 0:35:32
train iter: 581
num of updates: 58200
dynamics loss: 17421.75195

============================================================
time elapsed: 0:35:35
train iter: 582
num of updates: 58300
dynamics loss: 17406.67188

============================================================
time elapsed: 0:35:39
train iter: 583
num of updates: 58400
dynamics loss: 17388.49609

============================================================
time elapsed: 0:35:42
train iter: 584
num of updates: 58500
dynamics loss: 17363.15430

============================================================
time elapsed: 0:35:46
train iter: 585
num of updates: 58600
dynamics loss: 17379.10156

============================================================
time elapsed: 0:35:49
train iter: 586
num of updates: 58700
dynamics loss: 17346.06055

============================================================
time elapsed: 0:35:53
train iter: 587
num of updates: 58800
dynamics loss: 17338.78906

============================================================
time elapsed: 0:35:56
train iter: 588
num of updates: 58900
dynamics loss: 17309.07617

============================================================
time elapsed: 0:36:00
train iter: 589
num of updates: 59000
dynamics loss: 17317.29492

============================================================
time elapsed: 0:36:04
train iter: 590
num of updates: 59100
dynamics loss: 17294.63672

============================================================
time elapsed: 0:36:07
train iter: 591
num of updates: 59200
dynamics loss: 17283.62891

============================================================
time elapsed: 0:36:11
train iter: 592
num of updates: 59300
dynamics loss: 17250.56836

============================================================
time elapsed: 0:36:14
train iter: 593
num of updates: 59400
dynamics loss: 17240.73828

============================================================
time elapsed: 0:36:18
train iter: 594
num of updates: 59500
dynamics loss: 17239.67578

============================================================
time elapsed: 0:36:21
train iter: 595
num of updates: 59600
dynamics loss: 17234.62695

============================================================
time elapsed: 0:36:25
train iter: 596
num of updates: 59700
dynamics loss: 17206.77344

============================================================
time elapsed: 0:36:28
train iter: 597
num of updates: 59800
dynamics loss: 17212.49219

============================================================
time elapsed: 0:36:32
train iter: 598
num of updates: 59900
dynamics loss: 17174.34766

============================================================
time elapsed: 0:36:35
train iter: 599
num of updates: 60000
dynamics loss: 17172.57617

============================================================
time elapsed: 0:36:39
train iter: 600
num of updates: 60100
dynamics loss: 17153.49023

============================================================
time elapsed: 0:36:42
train iter: 601
num of updates: 60200
dynamics loss: 17139.46289

============================================================
time elapsed: 0:36:46
train iter: 602
num of updates: 60300
dynamics loss: 17125.66797

============================================================
time elapsed: 0:36:49
train iter: 603
num of updates: 60400
dynamics loss: 17132.79297

============================================================
time elapsed: 0:36:53
train iter: 604
num of updates: 60500
dynamics loss: 17104.05469

============================================================
time elapsed: 0:36:56
train iter: 605
num of updates: 60600
dynamics loss: 17082.86133

============================================================
time elapsed: 0:37:00
train iter: 606
num of updates: 60700
dynamics loss: 17076.61719

============================================================
time elapsed: 0:37:03
train iter: 607
num of updates: 60800
dynamics loss: 17069.63281

============================================================
time elapsed: 0:37:07
train iter: 608
num of updates: 60900
dynamics loss: 17075.51172

============================================================
time elapsed: 0:37:10
train iter: 609
num of updates: 61000
dynamics loss: 17042.95703

============================================================
time elapsed: 0:37:14
train iter: 610
num of updates: 61100
dynamics loss: 17021.59766

============================================================
time elapsed: 0:37:17
train iter: 611
num of updates: 61200
dynamics loss: 17015.34766

============================================================
time elapsed: 0:37:21
train iter: 612
num of updates: 61300
dynamics loss: 16996.52930

============================================================
time elapsed: 0:37:24
train iter: 613
num of updates: 61400
dynamics loss: 16983.83203

============================================================
time elapsed: 0:37:28
train iter: 614
num of updates: 61500
dynamics loss: 16970.94336

============================================================
time elapsed: 0:37:31
train iter: 615
num of updates: 61600
dynamics loss: 16963.77148

============================================================
time elapsed: 0:37:35
train iter: 616
num of updates: 61700
dynamics loss: 16963.86719

============================================================
time elapsed: 0:37:39
train iter: 617
num of updates: 61800
dynamics loss: 16943.98047

============================================================
time elapsed: 0:37:42
train iter: 618
num of updates: 61900
dynamics loss: 16911.06250

============================================================
time elapsed: 0:37:46
train iter: 619
num of updates: 62000
dynamics loss: 16896.61719

============================================================
time elapsed: 0:37:49
train iter: 620
num of updates: 62100
dynamics loss: 16911.81836

============================================================
time elapsed: 0:37:53
train iter: 621
num of updates: 62200
dynamics loss: 16859.10938

============================================================
time elapsed: 0:37:56
train iter: 622
num of updates: 62300
dynamics loss: 16858.65625

============================================================
time elapsed: 0:38:00
train iter: 623
num of updates: 62400
dynamics loss: 16859.47461

============================================================
time elapsed: 0:38:03
train iter: 624
num of updates: 62500
dynamics loss: 16833.28125

============================================================
time elapsed: 0:38:07
train iter: 625
num of updates: 62600
dynamics loss: 16835.45898

============================================================
time elapsed: 0:38:10
train iter: 626
num of updates: 62700
dynamics loss: 16817.55859

============================================================
time elapsed: 0:38:14
train iter: 627
num of updates: 62800
dynamics loss: 16786.32422

============================================================
time elapsed: 0:38:17
train iter: 628
num of updates: 62900
dynamics loss: 16797.48438

============================================================
time elapsed: 0:38:21
train iter: 629
num of updates: 63000
dynamics loss: 16769.24219

============================================================
time elapsed: 0:38:24
train iter: 630
num of updates: 63100
dynamics loss: 16771.65625

============================================================
time elapsed: 0:38:28
train iter: 631
num of updates: 63200
dynamics loss: 16745.79102

============================================================
time elapsed: 0:38:31
train iter: 632
num of updates: 63300
dynamics loss: 16733.36328

============================================================
time elapsed: 0:38:35
train iter: 633
num of updates: 63400
dynamics loss: 16717.10547

============================================================
time elapsed: 0:38:38
train iter: 634
num of updates: 63500
dynamics loss: 16705.39453

============================================================
time elapsed: 0:38:42
train iter: 635
num of updates: 63600
dynamics loss: 16694.40625

============================================================
time elapsed: 0:38:45
train iter: 636
num of updates: 63700
dynamics loss: 16677.87500

============================================================
time elapsed: 0:38:49
train iter: 637
num of updates: 63800
dynamics loss: 16666.48047

============================================================
time elapsed: 0:38:52
train iter: 638
num of updates: 63900
dynamics loss: 16659.51562

============================================================
time elapsed: 0:38:56
train iter: 639
num of updates: 64000
dynamics loss: 16636.22656

============================================================
time elapsed: 0:38:59
train iter: 640
num of updates: 64100
dynamics loss: 16631.50586

============================================================
time elapsed: 0:39:03
train iter: 641
num of updates: 64200
dynamics loss: 16615.51953

============================================================
time elapsed: 0:39:07
train iter: 642
num of updates: 64300
dynamics loss: 16619.76367

============================================================
time elapsed: 0:39:10
train iter: 643
num of updates: 64400
dynamics loss: 16592.85156

============================================================
time elapsed: 0:39:14
train iter: 644
num of updates: 64500
dynamics loss: 16584.47070

============================================================
time elapsed: 0:39:17
train iter: 645
num of updates: 64600
dynamics loss: 16579.79688

============================================================
time elapsed: 0:39:21
train iter: 646
num of updates: 64700
dynamics loss: 16549.49414

============================================================
time elapsed: 0:39:24
train iter: 647
num of updates: 64800
dynamics loss: 16549.83984

============================================================
time elapsed: 0:39:28
train iter: 648
num of updates: 64900
dynamics loss: 16542.65625

============================================================
time elapsed: 0:39:31
train iter: 649
num of updates: 65000
dynamics loss: 16522.24609

============================================================
time elapsed: 0:39:35
train iter: 650
num of updates: 65100
dynamics loss: 16479.52734

============================================================
time elapsed: 0:39:38
train iter: 651
num of updates: 65200
dynamics loss: 16502.26172

============================================================
time elapsed: 0:39:42
train iter: 652
num of updates: 65300
dynamics loss: 16478.03516

============================================================
time elapsed: 0:39:45
train iter: 653
num of updates: 65400
dynamics loss: 16466.33398

============================================================
time elapsed: 0:39:49
train iter: 654
num of updates: 65500
dynamics loss: 16448.92773

============================================================
time elapsed: 0:39:52
train iter: 655
num of updates: 65600
dynamics loss: 16417.42383

============================================================
time elapsed: 0:39:56
train iter: 656
num of updates: 65700
dynamics loss: 16413.37500

============================================================
time elapsed: 0:39:59
train iter: 657
num of updates: 65800
dynamics loss: 16418.59375

============================================================
time elapsed: 0:40:03
train iter: 658
num of updates: 65900
dynamics loss: 16391.15039

============================================================
time elapsed: 0:40:06
train iter: 659
num of updates: 66000
dynamics loss: 16382.10645

============================================================
time elapsed: 0:40:10
train iter: 660
num of updates: 66100
dynamics loss: 16374.34180

============================================================
time elapsed: 0:40:13
train iter: 661
num of updates: 66200
dynamics loss: 16367.21680

============================================================
time elapsed: 0:40:17
train iter: 662
num of updates: 66300
dynamics loss: 16353.55762

============================================================
time elapsed: 0:40:20
train iter: 663
num of updates: 66400
dynamics loss: 16330.28906

============================================================
time elapsed: 0:40:24
train iter: 664
num of updates: 66500
dynamics loss: 16314.06250

============================================================
time elapsed: 0:40:27
train iter: 665
num of updates: 66600
dynamics loss: 16311.24707

============================================================
time elapsed: 0:40:31
train iter: 666
num of updates: 66700
dynamics loss: 16284.94922

============================================================
time elapsed: 0:40:34
train iter: 667
num of updates: 66800
dynamics loss: 16271.17871

============================================================
time elapsed: 0:40:38
train iter: 668
num of updates: 66900
dynamics loss: 16265.94043

============================================================
time elapsed: 0:40:42
train iter: 669
num of updates: 67000
dynamics loss: 16244.95605

============================================================
time elapsed: 0:40:45
train iter: 670
num of updates: 67100
dynamics loss: 16238.84277

============================================================
time elapsed: 0:40:49
train iter: 671
num of updates: 67200
dynamics loss: 16216.41797

============================================================
time elapsed: 0:40:52
train iter: 672
num of updates: 67300
dynamics loss: 16221.51172

============================================================
time elapsed: 0:40:56
train iter: 673
num of updates: 67400
dynamics loss: 16203.03125

============================================================
time elapsed: 0:40:59
train iter: 674
num of updates: 67500
dynamics loss: 16184.30762

============================================================
time elapsed: 0:41:03
train iter: 675
num of updates: 67600
dynamics loss: 16165.18359

============================================================
time elapsed: 0:41:06
train iter: 676
num of updates: 67700
dynamics loss: 16157.82031

============================================================
time elapsed: 0:41:10
train iter: 677
num of updates: 67800
dynamics loss: 16146.13477

============================================================
time elapsed: 0:41:13
train iter: 678
num of updates: 67900
dynamics loss: 16120.84570

============================================================
time elapsed: 0:41:17
train iter: 679
num of updates: 68000
dynamics loss: 16117.74414

============================================================
time elapsed: 0:41:20
train iter: 680
num of updates: 68100
dynamics loss: 16102.91211

============================================================
time elapsed: 0:41:24
train iter: 681
num of updates: 68200
dynamics loss: 16089.09082

============================================================
time elapsed: 0:41:27
train iter: 682
num of updates: 68300
dynamics loss: 16087.84863

============================================================
time elapsed: 0:41:31
train iter: 683
num of updates: 68400
dynamics loss: 16062.79492

============================================================
time elapsed: 0:41:34
train iter: 684
num of updates: 68500
dynamics loss: 16060.08691

============================================================
time elapsed: 0:41:38
train iter: 685
num of updates: 68600
dynamics loss: 16030.59863

============================================================
time elapsed: 0:41:41
train iter: 686
num of updates: 68700
dynamics loss: 16022.15137

============================================================
time elapsed: 0:41:45
train iter: 687
num of updates: 68800
dynamics loss: 16012.16113

============================================================
time elapsed: 0:41:48
train iter: 688
num of updates: 68900
dynamics loss: 15990.82031

============================================================
time elapsed: 0:41:52
train iter: 689
num of updates: 69000
dynamics loss: 15994.40430

============================================================
time elapsed: 0:41:55
train iter: 690
num of updates: 69100
dynamics loss: 15958.95801

============================================================
time elapsed: 0:41:59
train iter: 691
num of updates: 69200
dynamics loss: 15956.77637

============================================================
time elapsed: 0:42:02
train iter: 692
num of updates: 69300
dynamics loss: 15966.17480

============================================================
time elapsed: 0:42:06
train iter: 693
num of updates: 69400
dynamics loss: 15938.32910

============================================================
time elapsed: 0:42:10
train iter: 694
num of updates: 69500
dynamics loss: 15907.19336

============================================================
time elapsed: 0:42:13
train iter: 695
num of updates: 69600
dynamics loss: 15900.84570

============================================================
time elapsed: 0:42:17
train iter: 696
num of updates: 69700
dynamics loss: 15894.51074

============================================================
time elapsed: 0:42:20
train iter: 697
num of updates: 69800
dynamics loss: 15880.35742

============================================================
time elapsed: 0:42:24
train iter: 698
num of updates: 69900
dynamics loss: 15863.86719

============================================================
time elapsed: 0:42:27
train iter: 699
num of updates: 70000
dynamics loss: 15862.12695

============================================================
time elapsed: 0:42:31
train iter: 700
num of updates: 70100
dynamics loss: 15826.07910

============================================================
time elapsed: 0:42:34
train iter: 701
num of updates: 70200
dynamics loss: 15824.39844

============================================================
time elapsed: 0:42:38
train iter: 702
num of updates: 70300
dynamics loss: 15822.29980

============================================================
time elapsed: 0:42:41
train iter: 703
num of updates: 70400
dynamics loss: 15796.63965

============================================================
time elapsed: 0:42:45
train iter: 704
num of updates: 70500
dynamics loss: 15789.08691

============================================================
time elapsed: 0:42:48
train iter: 705
num of updates: 70600
dynamics loss: 15771.87695

============================================================
time elapsed: 0:42:52
train iter: 706
num of updates: 70700
dynamics loss: 15749.87695

============================================================
time elapsed: 0:42:55
train iter: 707
num of updates: 70800
dynamics loss: 15744.68457

============================================================
time elapsed: 0:42:59
train iter: 708
num of updates: 70900
dynamics loss: 15743.20508

============================================================
time elapsed: 0:43:02
train iter: 709
num of updates: 71000
dynamics loss: 15738.81250

============================================================
time elapsed: 0:43:06
train iter: 710
num of updates: 71100
dynamics loss: 15707.26270

============================================================
time elapsed: 0:43:09
train iter: 711
num of updates: 71200
dynamics loss: 15702.07715

============================================================
time elapsed: 0:43:13
train iter: 712
num of updates: 71300
dynamics loss: 15687.48047

============================================================
time elapsed: 0:43:16
train iter: 713
num of updates: 71400
dynamics loss: 15679.08691

============================================================
time elapsed: 0:43:20
train iter: 714
num of updates: 71500
dynamics loss: 15668.54785

============================================================
time elapsed: 0:43:23
train iter: 715
num of updates: 71600
dynamics loss: 15652.70020

============================================================
time elapsed: 0:43:27
train iter: 716
num of updates: 71700
dynamics loss: 15649.89844

============================================================
time elapsed: 0:43:30
train iter: 717
num of updates: 71800
dynamics loss: 15618.55664

============================================================
time elapsed: 0:43:34
train iter: 718
num of updates: 71900
dynamics loss: 15604.47266

============================================================
time elapsed: 0:43:38
train iter: 719
num of updates: 72000
dynamics loss: 15579.08691

============================================================
time elapsed: 0:43:41
train iter: 720
num of updates: 72100
dynamics loss: 15582.28027

============================================================
time elapsed: 0:43:45
train iter: 721
num of updates: 72200
dynamics loss: 15577.14258

============================================================
time elapsed: 0:43:48
train iter: 722
num of updates: 72300
dynamics loss: 15566.15820

============================================================
time elapsed: 0:43:52
train iter: 723
num of updates: 72400
dynamics loss: 15545.38477

============================================================
time elapsed: 0:43:55
train iter: 724
num of updates: 72500
dynamics loss: 15533.90527

============================================================
time elapsed: 0:43:59
train iter: 725
num of updates: 72600
dynamics loss: 15517.53125

============================================================
time elapsed: 0:44:02
train iter: 726
num of updates: 72700
dynamics loss: 15516.06543

============================================================
time elapsed: 0:44:06
train iter: 727
num of updates: 72800
dynamics loss: 15497.68848

============================================================
time elapsed: 0:44:09
train iter: 728
num of updates: 72900
dynamics loss: 15484.35840

============================================================
time elapsed: 0:44:13
train iter: 729
num of updates: 73000
dynamics loss: 15447.12500

============================================================
time elapsed: 0:44:16
train iter: 730
num of updates: 73100
dynamics loss: 15456.52246

============================================================
time elapsed: 0:44:20
train iter: 731
num of updates: 73200
dynamics loss: 15437.02051

============================================================
time elapsed: 0:44:23
train iter: 732
num of updates: 73300
dynamics loss: 15434.73828

============================================================
time elapsed: 0:44:27
train iter: 733
num of updates: 73400
dynamics loss: 15421.33887

============================================================
time elapsed: 0:44:30
train iter: 734
num of updates: 73500
dynamics loss: 15400.79883

============================================================
time elapsed: 0:44:34
train iter: 735
num of updates: 73600
dynamics loss: 15401.46484

============================================================
time elapsed: 0:44:37
train iter: 736
num of updates: 73700
dynamics loss: 15390.46289

============================================================
time elapsed: 0:44:41
train iter: 737
num of updates: 73800
dynamics loss: 15359.37305

============================================================
time elapsed: 0:44:44
train iter: 738
num of updates: 73900
dynamics loss: 15343.20703

============================================================
time elapsed: 0:44:48
train iter: 739
num of updates: 74000
dynamics loss: 15340.84961

============================================================
time elapsed: 0:44:51
train iter: 740
num of updates: 74100
dynamics loss: 15324.64258

============================================================
time elapsed: 0:44:55
train iter: 741
num of updates: 74200
dynamics loss: 15305.54590

============================================================
time elapsed: 0:44:58
train iter: 742
num of updates: 74300
dynamics loss: 15303.67676

============================================================
time elapsed: 0:45:02
train iter: 743
num of updates: 74400
dynamics loss: 15276.56445

============================================================
time elapsed: 0:45:06
train iter: 744
num of updates: 74500
dynamics loss: 15285.13281

============================================================
time elapsed: 0:45:09
train iter: 745
num of updates: 74600
dynamics loss: 15276.70703

============================================================
time elapsed: 0:45:13
train iter: 746
num of updates: 74700
dynamics loss: 15244.83398

============================================================
time elapsed: 0:45:16
train iter: 747
num of updates: 74800
dynamics loss: 15222.11133

============================================================
time elapsed: 0:45:20
train iter: 748
num of updates: 74900
dynamics loss: 15217.82324

============================================================
time elapsed: 0:45:23
train iter: 749
num of updates: 75000
dynamics loss: 15199.71875

============================================================
time elapsed: 0:45:27
train iter: 750
num of updates: 75100
dynamics loss: 15194.61230

============================================================
time elapsed: 0:45:30
train iter: 751
num of updates: 75200
dynamics loss: 15190.41406

============================================================
time elapsed: 0:45:34
train iter: 752
num of updates: 75300
dynamics loss: 15153.93555

============================================================
time elapsed: 0:45:37
train iter: 753
num of updates: 75400
dynamics loss: 15164.35254

============================================================
time elapsed: 0:45:41
train iter: 754
num of updates: 75500
dynamics loss: 15152.49707

============================================================
time elapsed: 0:45:44
train iter: 755
num of updates: 75600
dynamics loss: 15140.43848

============================================================
time elapsed: 0:45:48
train iter: 756
num of updates: 75700
dynamics loss: 15124.15137

============================================================
time elapsed: 0:45:51
train iter: 757
num of updates: 75800
dynamics loss: 15103.25098

============================================================
time elapsed: 0:45:55
train iter: 758
num of updates: 75900
dynamics loss: 15101.10938

============================================================
time elapsed: 0:45:58
train iter: 759
num of updates: 76000
dynamics loss: 15076.57617

============================================================
time elapsed: 0:46:02
train iter: 760
num of updates: 76100
dynamics loss: 15067.44238

============================================================
time elapsed: 0:46:05
train iter: 761
num of updates: 76200
dynamics loss: 15060.17480

============================================================
time elapsed: 0:46:09
train iter: 762
num of updates: 76300
dynamics loss: 15044.12891

============================================================
time elapsed: 0:46:12
train iter: 763
num of updates: 76400
dynamics loss: 15033.82129

============================================================
time elapsed: 0:46:16
train iter: 764
num of updates: 76500
dynamics loss: 15019.25293

============================================================
time elapsed: 0:46:19
train iter: 765
num of updates: 76600
dynamics loss: 15005.34766

============================================================
time elapsed: 0:46:23
train iter: 766
num of updates: 76700
dynamics loss: 14988.89746

============================================================
time elapsed: 0:46:26
train iter: 767
num of updates: 76800
dynamics loss: 14977.49316

============================================================
time elapsed: 0:46:30
train iter: 768
num of updates: 76900
dynamics loss: 14971.71875

============================================================
time elapsed: 0:46:34
train iter: 769
num of updates: 77000
dynamics loss: 14952.17285

============================================================
time elapsed: 0:46:37
train iter: 770
num of updates: 77100
dynamics loss: 14926.98340

============================================================
time elapsed: 0:46:41
train iter: 771
num of updates: 77200
dynamics loss: 14920.85742

============================================================
time elapsed: 0:46:44
train iter: 772
num of updates: 77300
dynamics loss: 14915.28516

============================================================
time elapsed: 0:46:48
train iter: 773
num of updates: 77400
dynamics loss: 14910.77441

============================================================
time elapsed: 0:46:51
train iter: 774
num of updates: 77500
dynamics loss: 14881.54688

============================================================
time elapsed: 0:46:55
train iter: 775
num of updates: 77600
dynamics loss: 14868.42090

============================================================
time elapsed: 0:46:58
train iter: 776
num of updates: 77700
dynamics loss: 14877.22363

============================================================
time elapsed: 0:47:02
train iter: 777
num of updates: 77800
dynamics loss: 14853.59082

============================================================
time elapsed: 0:47:05
train iter: 778
num of updates: 77900
dynamics loss: 14848.17871

============================================================
time elapsed: 0:47:09
train iter: 779
num of updates: 78000
dynamics loss: 14815.25391

============================================================
time elapsed: 0:47:12
train iter: 780
num of updates: 78100
dynamics loss: 14811.34961

============================================================
time elapsed: 0:47:16
train iter: 781
num of updates: 78200
dynamics loss: 14814.58398

============================================================
time elapsed: 0:47:19
train iter: 782
num of updates: 78300
dynamics loss: 14788.57715

============================================================
time elapsed: 0:47:23
train iter: 783
num of updates: 78400
dynamics loss: 14777.42090

============================================================
time elapsed: 0:47:26
train iter: 784
num of updates: 78500
dynamics loss: 14767.24805

============================================================
time elapsed: 0:47:30
train iter: 785
num of updates: 78600
dynamics loss: 14743.04102

============================================================
time elapsed: 0:47:33
train iter: 786
num of updates: 78700
dynamics loss: 14734.92773

============================================================
time elapsed: 0:47:37
train iter: 787
num of updates: 78800
dynamics loss: 14734.78516

============================================================
time elapsed: 0:47:40
train iter: 788
num of updates: 78900
dynamics loss: 14715.40332

============================================================
time elapsed: 0:47:44
train iter: 789
num of updates: 79000
dynamics loss: 14726.01074

============================================================
time elapsed: 0:47:47
train iter: 790
num of updates: 79100
dynamics loss: 14698.48438

============================================================
time elapsed: 0:47:51
train iter: 791
num of updates: 79200
dynamics loss: 14668.11621

============================================================
time elapsed: 0:47:54
train iter: 792
num of updates: 79300
dynamics loss: 14658.17871

============================================================
time elapsed: 0:47:58
train iter: 793
num of updates: 79400
dynamics loss: 14654.50488

============================================================
time elapsed: 0:48:01
train iter: 794
num of updates: 79500
dynamics loss: 14633.92090

============================================================
time elapsed: 0:48:05
train iter: 795
num of updates: 79600
dynamics loss: 14627.64258

============================================================
time elapsed: 0:48:09
train iter: 796
num of updates: 79700
dynamics loss: 14618.32422

============================================================
time elapsed: 0:48:12
train iter: 797
num of updates: 79800
dynamics loss: 14603.79590

============================================================
time elapsed: 0:48:16
train iter: 798
num of updates: 79900
dynamics loss: 14590.17090

============================================================
time elapsed: 0:48:19
train iter: 799
num of updates: 80000
dynamics loss: 14574.69531

============================================================
time elapsed: 0:48:23
train iter: 800
num of updates: 80100
dynamics loss: 14565.20898

============================================================
time elapsed: 0:48:26
train iter: 801
num of updates: 80200
dynamics loss: 14533.62500

============================================================
time elapsed: 0:48:30
train iter: 802
num of updates: 80300
dynamics loss: 14527.76660

============================================================
time elapsed: 0:48:33
train iter: 803
num of updates: 80400
dynamics loss: 14529.62109

============================================================
time elapsed: 0:48:37
train iter: 804
num of updates: 80500
dynamics loss: 14525.56641

============================================================
time elapsed: 0:48:40
train iter: 805
num of updates: 80600
dynamics loss: 14496.48828

============================================================
time elapsed: 0:48:44
train iter: 806
num of updates: 80700
dynamics loss: 14471.65820

============================================================
time elapsed: 0:48:47
train iter: 807
num of updates: 80800
dynamics loss: 14476.50195

============================================================
time elapsed: 0:48:51
train iter: 808
num of updates: 80900
dynamics loss: 14465.71777

============================================================
time elapsed: 0:48:54
train iter: 809
num of updates: 81000
dynamics loss: 14459.30762

============================================================
time elapsed: 0:48:58
train iter: 810
num of updates: 81100
dynamics loss: 14443.59766

============================================================
time elapsed: 0:49:01
train iter: 811
num of updates: 81200
dynamics loss: 14428.00098

============================================================
time elapsed: 0:49:05
train iter: 812
num of updates: 81300
dynamics loss: 14422.88086

============================================================
time elapsed: 0:49:08
train iter: 813
num of updates: 81400
dynamics loss: 14403.81348

============================================================
time elapsed: 0:49:12
train iter: 814
num of updates: 81500
dynamics loss: 14385.72070

============================================================
time elapsed: 0:49:15
train iter: 815
num of updates: 81600
dynamics loss: 14378.56348

============================================================
time elapsed: 0:49:19
train iter: 816
num of updates: 81700
dynamics loss: 14352.12207

============================================================
time elapsed: 0:49:22
train iter: 817
num of updates: 81800
dynamics loss: 14348.99902

============================================================
time elapsed: 0:49:26
train iter: 818
num of updates: 81900
dynamics loss: 14347.70898

============================================================
time elapsed: 0:49:29
train iter: 819
num of updates: 82000
dynamics loss: 14333.40039

============================================================
time elapsed: 0:49:33
train iter: 820
num of updates: 82100
dynamics loss: 14323.28711

============================================================
time elapsed: 0:49:37
train iter: 821
num of updates: 82200
dynamics loss: 14311.98926

============================================================
time elapsed: 0:49:40
train iter: 822
num of updates: 82300
dynamics loss: 14296.91797

============================================================
time elapsed: 0:49:44
train iter: 823
num of updates: 82400
dynamics loss: 14279.23633

============================================================
time elapsed: 0:49:47
train iter: 824
num of updates: 82500
dynamics loss: 14278.45801

============================================================
time elapsed: 0:49:51
train iter: 825
num of updates: 82600
dynamics loss: 14261.80566

============================================================
time elapsed: 0:49:54
train iter: 826
num of updates: 82700
dynamics loss: 14249.23242

============================================================
time elapsed: 0:49:58
train iter: 827
num of updates: 82800
dynamics loss: 14245.14062

============================================================
time elapsed: 0:50:01
train iter: 828
num of updates: 82900
dynamics loss: 14230.33105

============================================================
time elapsed: 0:50:05
train iter: 829
num of updates: 83000
dynamics loss: 14218.23242

============================================================
time elapsed: 0:50:08
train iter: 830
num of updates: 83100
dynamics loss: 14212.30566

============================================================
time elapsed: 0:50:12
train iter: 831
num of updates: 83200
dynamics loss: 14184.47656

============================================================
time elapsed: 0:50:15
train iter: 832
num of updates: 83300
dynamics loss: 14175.37793

============================================================
time elapsed: 0:50:19
train iter: 833
num of updates: 83400
dynamics loss: 14175.25293

============================================================
time elapsed: 0:50:22
train iter: 834
num of updates: 83500
dynamics loss: 14145.34863

============================================================
time elapsed: 0:50:26
train iter: 835
num of updates: 83600
dynamics loss: 14145.27539

============================================================
time elapsed: 0:50:29
train iter: 836
num of updates: 83700
dynamics loss: 14138.21094

============================================================
time elapsed: 0:50:33
train iter: 837
num of updates: 83800
dynamics loss: 14109.83789

============================================================
time elapsed: 0:50:36
train iter: 838
num of updates: 83900
dynamics loss: 14127.14062

============================================================
time elapsed: 0:50:40
train iter: 839
num of updates: 84000
dynamics loss: 14093.46680

============================================================
time elapsed: 0:50:43
train iter: 840
num of updates: 84100
dynamics loss: 14093.43262

============================================================
time elapsed: 0:50:47
train iter: 841
num of updates: 84200
dynamics loss: 14070.80273

============================================================
time elapsed: 0:50:50
train iter: 842
num of updates: 84300
dynamics loss: 14059.28613

============================================================
time elapsed: 0:50:54
train iter: 843
num of updates: 84400
dynamics loss: 14034.24219

============================================================
time elapsed: 0:50:57
train iter: 844
num of updates: 84500
dynamics loss: 14024.12207

============================================================
time elapsed: 0:51:01
train iter: 845
num of updates: 84600
dynamics loss: 14017.32910

============================================================
time elapsed: 0:51:05
train iter: 846
num of updates: 84700
dynamics loss: 14021.64746

============================================================
time elapsed: 0:51:08
train iter: 847
num of updates: 84800
dynamics loss: 13992.36914

============================================================
time elapsed: 0:51:12
train iter: 848
num of updates: 84900
dynamics loss: 13990.00391

============================================================
time elapsed: 0:51:15
train iter: 849
num of updates: 85000
dynamics loss: 13993.09277

============================================================
time elapsed: 0:51:19
train iter: 850
num of updates: 85100
dynamics loss: 13977.38086

============================================================
time elapsed: 0:51:22
train iter: 851
num of updates: 85200
dynamics loss: 13957.66992

============================================================
time elapsed: 0:51:26
train iter: 852
num of updates: 85300
dynamics loss: 13953.03027

============================================================
time elapsed: 0:51:29
train iter: 853
num of updates: 85400
dynamics loss: 13933.71094

============================================================
time elapsed: 0:51:33
train iter: 854
num of updates: 85500
dynamics loss: 13920.77637

============================================================
time elapsed: 0:51:36
train iter: 855
num of updates: 85600
dynamics loss: 13916.74707

============================================================
time elapsed: 0:51:40
train iter: 856
num of updates: 85700
dynamics loss: 13904.79004

============================================================
time elapsed: 0:51:43
train iter: 857
num of updates: 85800
dynamics loss: 13881.27832

============================================================
time elapsed: 0:51:47
train iter: 858
num of updates: 85900
dynamics loss: 13876.11035

============================================================
time elapsed: 0:51:50
train iter: 859
num of updates: 86000
dynamics loss: 13866.37695

============================================================
time elapsed: 0:51:54
train iter: 860
num of updates: 86100
dynamics loss: 13867.61719

============================================================
time elapsed: 0:51:57
train iter: 861
num of updates: 86200
dynamics loss: 13851.43066

============================================================
time elapsed: 0:52:01
train iter: 862
num of updates: 86300
dynamics loss: 13828.92676

============================================================
time elapsed: 0:52:04
train iter: 863
num of updates: 86400
dynamics loss: 13808.25293

============================================================
time elapsed: 0:52:08
train iter: 864
num of updates: 86500
dynamics loss: 13795.63672

============================================================
time elapsed: 0:52:11
train iter: 865
num of updates: 86600
dynamics loss: 13790.37500

============================================================
time elapsed: 0:52:15
train iter: 866
num of updates: 86700
dynamics loss: 13780.70703

============================================================
time elapsed: 0:52:18
train iter: 867
num of updates: 86800
dynamics loss: 13775.90430

============================================================
time elapsed: 0:52:22
train iter: 868
num of updates: 86900
dynamics loss: 13767.75293

============================================================
time elapsed: 0:52:25
train iter: 869
num of updates: 87000
dynamics loss: 13771.35645

============================================================
time elapsed: 0:52:29
train iter: 870
num of updates: 87100
dynamics loss: 13745.12402

============================================================
time elapsed: 0:52:33
train iter: 871
num of updates: 87200
dynamics loss: 13737.19824

============================================================
time elapsed: 0:52:36
train iter: 872
num of updates: 87300
dynamics loss: 13732.37988

============================================================
time elapsed: 0:52:40
train iter: 873
num of updates: 87400
dynamics loss: 13712.64258

============================================================
time elapsed: 0:52:43
train iter: 874
num of updates: 87500
dynamics loss: 13696.98438

============================================================
time elapsed: 0:52:47
train iter: 875
num of updates: 87600
dynamics loss: 13688.13672

============================================================
time elapsed: 0:52:50
train iter: 876
num of updates: 87700
dynamics loss: 13683.57227

============================================================
time elapsed: 0:52:54
train iter: 877
num of updates: 87800
dynamics loss: 13668.31836

============================================================
time elapsed: 0:52:57
train iter: 878
num of updates: 87900
dynamics loss: 13666.05273

============================================================
time elapsed: 0:53:01
train iter: 879
num of updates: 88000
dynamics loss: 13644.18848

============================================================
time elapsed: 0:53:04
train iter: 880
num of updates: 88100
dynamics loss: 13637.28418

============================================================
time elapsed: 0:53:08
train iter: 881
num of updates: 88200
dynamics loss: 13634.31445

============================================================
time elapsed: 0:53:11
train iter: 882
num of updates: 88300
dynamics loss: 13613.98730

============================================================
time elapsed: 0:53:15
train iter: 883
num of updates: 88400
dynamics loss: 13621.93262

============================================================
time elapsed: 0:53:18
train iter: 884
num of updates: 88500
dynamics loss: 13589.52246

============================================================
time elapsed: 0:53:22
train iter: 885
num of updates: 88600
dynamics loss: 13579.51855

============================================================
time elapsed: 0:53:25
train iter: 886
num of updates: 88700
dynamics loss: 13565.23828

============================================================
time elapsed: 0:53:29
train iter: 887
num of updates: 88800
dynamics loss: 13559.33008

============================================================
time elapsed: 0:53:32
train iter: 888
num of updates: 88900
dynamics loss: 13548.96387

============================================================
time elapsed: 0:53:36
train iter: 889
num of updates: 89000
dynamics loss: 13538.97559

============================================================
time elapsed: 0:53:39
train iter: 890
num of updates: 89100
dynamics loss: 13519.32910

============================================================
time elapsed: 0:53:43
train iter: 891
num of updates: 89200
dynamics loss: 13519.00879

============================================================
time elapsed: 0:53:46
train iter: 892
num of updates: 89300
dynamics loss: 13495.41504

============================================================
time elapsed: 0:53:50
train iter: 893
num of updates: 89400
dynamics loss: 13491.62500

============================================================
time elapsed: 0:53:53
train iter: 894
num of updates: 89500
dynamics loss: 13476.01758

============================================================
time elapsed: 0:53:57
train iter: 895
num of updates: 89600
dynamics loss: 13477.47852

============================================================
time elapsed: 0:54:01
train iter: 896
num of updates: 89700
dynamics loss: 13450.31836

============================================================
time elapsed: 0:54:04
train iter: 897
num of updates: 89800
dynamics loss: 13450.51562

============================================================
time elapsed: 0:54:08
train iter: 898
num of updates: 89900
dynamics loss: 13433.15137

============================================================
time elapsed: 0:54:11
train iter: 899
num of updates: 90000
dynamics loss: 13410.31348

============================================================
time elapsed: 0:54:15
train iter: 900
num of updates: 90100
dynamics loss: 13416.43066

============================================================
time elapsed: 0:54:18
train iter: 901
num of updates: 90200
dynamics loss: 13404.39258

============================================================
time elapsed: 0:54:22
train iter: 902
num of updates: 90300
dynamics loss: 13400.52441

============================================================
time elapsed: 0:54:25
train iter: 903
num of updates: 90400
dynamics loss: 13373.37793

============================================================
time elapsed: 0:54:29
train iter: 904
num of updates: 90500
dynamics loss: 13372.54395

============================================================
time elapsed: 0:54:32
train iter: 905
num of updates: 90600
dynamics loss: 13364.24707

============================================================
time elapsed: 0:54:36
train iter: 906
num of updates: 90700
dynamics loss: 13353.45703

============================================================
time elapsed: 0:54:39
train iter: 907
num of updates: 90800
dynamics loss: 13338.17480

============================================================
time elapsed: 0:54:43
train iter: 908
num of updates: 90900
dynamics loss: 13346.84375

============================================================
time elapsed: 0:54:46
train iter: 909
num of updates: 91000
dynamics loss: 13327.49512

============================================================
time elapsed: 0:54:50
train iter: 910
num of updates: 91100
dynamics loss: 13315.07715

============================================================
time elapsed: 0:54:53
train iter: 911
num of updates: 91200
dynamics loss: 13295.16602

============================================================
time elapsed: 0:54:57
train iter: 912
num of updates: 91300
dynamics loss: 13288.38477

============================================================
time elapsed: 0:55:00
train iter: 913
num of updates: 91400
dynamics loss: 13296.02734

============================================================
time elapsed: 0:55:04
train iter: 914
num of updates: 91500
dynamics loss: 13268.53516

============================================================
time elapsed: 0:55:07
train iter: 915
num of updates: 91600
dynamics loss: 13265.10938

============================================================
time elapsed: 0:55:11
train iter: 916
num of updates: 91700
dynamics loss: 13245.73047

============================================================
time elapsed: 0:55:14
train iter: 917
num of updates: 91800
dynamics loss: 13237.05078

============================================================
time elapsed: 0:55:18
train iter: 918
num of updates: 91900
dynamics loss: 13221.33008

============================================================
time elapsed: 0:55:21
train iter: 919
num of updates: 92000
dynamics loss: 13220.32422

============================================================
time elapsed: 0:55:25
train iter: 920
num of updates: 92100
dynamics loss: 13209.48438

============================================================
time elapsed: 0:55:29
train iter: 921
num of updates: 92200
dynamics loss: 13198.85840

============================================================
time elapsed: 0:55:32
train iter: 922
num of updates: 92300
dynamics loss: 13178.42285

============================================================
time elapsed: 0:55:36
train iter: 923
num of updates: 92400
dynamics loss: 13187.41895

============================================================
time elapsed: 0:55:39
train iter: 924
num of updates: 92500
dynamics loss: 13161.88574

============================================================
time elapsed: 0:55:43
train iter: 925
num of updates: 92600
dynamics loss: 13144.06055

============================================================
time elapsed: 0:55:46
train iter: 926
num of updates: 92700
dynamics loss: 13147.17578

============================================================
time elapsed: 0:55:50
train iter: 927
num of updates: 92800
dynamics loss: 13144.13672

============================================================
time elapsed: 0:55:53
train iter: 928
num of updates: 92900
dynamics loss: 13122.89648

============================================================
time elapsed: 0:55:57
train iter: 929
num of updates: 93000
dynamics loss: 13118.13184

============================================================
time elapsed: 0:56:00
train iter: 930
num of updates: 93100
dynamics loss: 13096.64453

============================================================
time elapsed: 0:56:04
train iter: 931
num of updates: 93200
dynamics loss: 13087.99023

============================================================
time elapsed: 0:56:07
train iter: 932
num of updates: 93300
dynamics loss: 13097.93848

============================================================
time elapsed: 0:56:11
train iter: 933
num of updates: 93400
dynamics loss: 13081.88574

============================================================
time elapsed: 0:56:14
train iter: 934
num of updates: 93500
dynamics loss: 13074.53223

============================================================
time elapsed: 0:56:18
train iter: 935
num of updates: 93600
dynamics loss: 13045.47461

============================================================
time elapsed: 0:56:21
train iter: 936
num of updates: 93700
dynamics loss: 13051.61621

============================================================
time elapsed: 0:56:25
train iter: 937
num of updates: 93800
dynamics loss: 13029.70898

============================================================
time elapsed: 0:56:28
train iter: 938
num of updates: 93900
dynamics loss: 13033.85645

============================================================
time elapsed: 0:56:32
train iter: 939
num of updates: 94000
dynamics loss: 13020.92188

============================================================
time elapsed: 0:56:35
train iter: 940
num of updates: 94100
dynamics loss: 13017.38086

============================================================
time elapsed: 0:56:39
train iter: 941
num of updates: 94200
dynamics loss: 12994.85449

============================================================
time elapsed: 0:56:42
train iter: 942
num of updates: 94300
dynamics loss: 12988.81641

============================================================
time elapsed: 0:56:46
train iter: 943
num of updates: 94400
dynamics loss: 12975.79004

============================================================
time elapsed: 0:56:49
train iter: 944
num of updates: 94500
dynamics loss: 12975.08887

============================================================
time elapsed: 0:56:53
train iter: 945
num of updates: 94600
dynamics loss: 12962.85547

============================================================
time elapsed: 0:56:57
train iter: 946
num of updates: 94700
dynamics loss: 12948.89844

============================================================
time elapsed: 0:57:00
train iter: 947
num of updates: 94800
dynamics loss: 12937.38086

============================================================
time elapsed: 0:57:04
train iter: 948
num of updates: 94900
dynamics loss: 12931.06836

============================================================
time elapsed: 0:57:07
train iter: 949
num of updates: 95000
dynamics loss: 12935.30566

============================================================
time elapsed: 0:57:11
train iter: 950
num of updates: 95100
dynamics loss: 12902.31836

============================================================
time elapsed: 0:57:14
train iter: 951
num of updates: 95200
dynamics loss: 12906.39648

============================================================
time elapsed: 0:57:18
train iter: 952
num of updates: 95300
dynamics loss: 12895.34473

============================================================
time elapsed: 0:57:21
train iter: 953
num of updates: 95400
dynamics loss: 12875.78027

============================================================
time elapsed: 0:57:25
train iter: 954
num of updates: 95500
dynamics loss: 12863.69141

============================================================
time elapsed: 0:57:28
train iter: 955
num of updates: 95600
dynamics loss: 12868.07812

============================================================
time elapsed: 0:57:32
train iter: 956
num of updates: 95700
dynamics loss: 12856.33301

============================================================
time elapsed: 0:57:35
train iter: 957
num of updates: 95800
dynamics loss: 12850.02637

============================================================
time elapsed: 0:57:39
train iter: 958
num of updates: 95900
dynamics loss: 12833.36426

============================================================
time elapsed: 0:57:42
train iter: 959
num of updates: 96000
dynamics loss: 12824.52344

============================================================
time elapsed: 0:57:46
train iter: 960
num of updates: 96100
dynamics loss: 12815.77051

============================================================
time elapsed: 0:57:49
train iter: 961
num of updates: 96200
dynamics loss: 12818.80469

============================================================
time elapsed: 0:57:53
train iter: 962
num of updates: 96300
dynamics loss: 12810.03418

============================================================
time elapsed: 0:57:56
train iter: 963
num of updates: 96400
dynamics loss: 12783.10742

============================================================
time elapsed: 0:58:00
train iter: 964
num of updates: 96500
dynamics loss: 12757.85840

============================================================
time elapsed: 0:58:03
train iter: 965
num of updates: 96600
dynamics loss: 12756.52637

============================================================
time elapsed: 0:58:07
train iter: 966
num of updates: 96700
dynamics loss: 12759.82031

============================================================
time elapsed: 0:58:10
train iter: 967
num of updates: 96800
dynamics loss: 12746.52930

============================================================
time elapsed: 0:58:14
train iter: 968
num of updates: 96900
dynamics loss: 12759.71777

============================================================
time elapsed: 0:58:17
train iter: 969
num of updates: 97000
dynamics loss: 12722.94238

============================================================
time elapsed: 0:58:21
train iter: 970
num of updates: 97100
dynamics loss: 12723.32227

============================================================
time elapsed: 0:58:25
train iter: 971
num of updates: 97200
dynamics loss: 12708.97168

============================================================
time elapsed: 0:58:28
train iter: 972
num of updates: 97300
dynamics loss: 12702.41699

============================================================
time elapsed: 0:58:32
train iter: 973
num of updates: 97400
dynamics loss: 12695.04199

============================================================
time elapsed: 0:58:35
train iter: 974
num of updates: 97500
dynamics loss: 12672.25293

============================================================
time elapsed: 0:58:39
train iter: 975
num of updates: 97600
dynamics loss: 12675.54785

============================================================
time elapsed: 0:58:42
train iter: 976
num of updates: 97700
dynamics loss: 12660.47363

============================================================
time elapsed: 0:58:46
train iter: 977
num of updates: 97800
dynamics loss: 12657.17285

============================================================
time elapsed: 0:58:49
train iter: 978
num of updates: 97900
dynamics loss: 12628.14551

============================================================
time elapsed: 0:58:53
train iter: 979
num of updates: 98000
dynamics loss: 12636.77344

============================================================
time elapsed: 0:58:56
train iter: 980
num of updates: 98100
dynamics loss: 12617.23047

============================================================
time elapsed: 0:59:00
train iter: 981
num of updates: 98200
dynamics loss: 12626.31641

============================================================
time elapsed: 0:59:03
train iter: 982
num of updates: 98300
dynamics loss: 12604.57422

============================================================
time elapsed: 0:59:07
train iter: 983
num of updates: 98400
dynamics loss: 12595.57812

============================================================
time elapsed: 0:59:10
train iter: 984
num of updates: 98500
dynamics loss: 12590.83398

============================================================
time elapsed: 0:59:14
train iter: 985
num of updates: 98600
dynamics loss: 12587.98633

============================================================
time elapsed: 0:59:17
train iter: 986
num of updates: 98700
dynamics loss: 12579.53711

============================================================
time elapsed: 0:59:21
train iter: 987
num of updates: 98800
dynamics loss: 12554.86523

============================================================
time elapsed: 0:59:24
train iter: 988
num of updates: 98900
dynamics loss: 12536.14453

============================================================
time elapsed: 0:59:28
train iter: 989
num of updates: 99000
dynamics loss: 12539.23242

============================================================
time elapsed: 0:59:31
train iter: 990
num of updates: 99100
dynamics loss: 12553.45020

============================================================
time elapsed: 0:59:35
train iter: 991
num of updates: 99200
dynamics loss: 12523.87012

============================================================
time elapsed: 0:59:38
train iter: 992
num of updates: 99300
dynamics loss: 12502.22070

============================================================
time elapsed: 0:59:42
train iter: 993
num of updates: 99400
dynamics loss: 12508.53223

============================================================
time elapsed: 0:59:45
train iter: 994
num of updates: 99500
dynamics loss: 12507.03027

============================================================
time elapsed: 0:59:49
train iter: 995
num of updates: 99600
dynamics loss: 12487.22070

============================================================
time elapsed: 0:59:53
train iter: 996
num of updates: 99700
dynamics loss: 12480.70020

============================================================
time elapsed: 0:59:56
train iter: 997
num of updates: 99800
dynamics loss: 12469.65430

============================================================
time elapsed: 1:00:00
train iter: 998
num of updates: 99900
dynamics loss: 12471.72461

============================================================
time elapsed: 1:00:03
train iter: 999
num of updates: 100000
dynamics loss: 12457.68457

saving current model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/dynamics_model_100000.pt
============================================================
finished training dynamics!
============================================================
started training dynamics at: 25-09-28-13-10-46
finished training dynamics at: 25-09-28-14-10-54
total dynamics training time: 1:00:08
saved last updated model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/dynamics_model
============================================================
2025-09-28 14:11:06.034395: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:11:09.451237: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 14:11:10.389696: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 324 bytes spill stores, 324 bytes spill loads

num_vae_param: 547754
2025-09-28 14:11:16.910609: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:11:16.910791: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:11:16.910847: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:11:16.911066: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:11:16.911110: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:11:18.238868: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 320 bytes spill stores, 220 bytes spill loads

2025-09-28 14:11:21.245840: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 388 bytes spill stores, 384 bytes spill loads

2025-09-28 14:11:21.760899: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 820 bytes spill stores, 564 bytes spill loads

2025-09-28 14:11:23.336825: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 1736 bytes spill stores, 1312 bytes spill loads

2025-09-28 14:11:28.354220: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15', 4 bytes spill stores, 4 bytes spill loads

2025-09-28 14:11:30.928035: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 196 bytes spill stores, 200 bytes spill loads

2025-09-28 14:11:33.869875: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 108 bytes spill stores, 108 bytes spill loads

2025-09-28 14:11:34.793847: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 200 bytes spill stores, 200 bytes spill loads

2025-09-28 14:11:35.566854: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 540 bytes spill stores, 540 bytes spill loads

2025-09-28 14:11:36.616614: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 8 bytes spill stores, 8 bytes spill loads

2025-09-28 14:11:39.874931: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 292 bytes spill stores, 292 bytes spill loads

============================================================
time elapsed: 1:01:04
train iter: 0
num of updates: 100
vae loss: 2.19801
kl loss: 0.11153
a decoder loss: 2.08648
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/vae_model_100.pt
2025-09-28 14:11:51.582454: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:11:53.561102: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 14:11:54.867606: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 324 bytes spill stores, 324 bytes spill loads

============================================================
time elapsed: 1:01:23
train iter: 1
num of updates: 200
vae loss: 2.19992
kl loss: 0.11173
a decoder loss: 2.08819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:24
train iter: 2
num of updates: 300
vae loss: 2.19370
kl loss: 0.11030
a decoder loss: 2.08340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:25
train iter: 3
num of updates: 400
vae loss: 2.18861
kl loss: 0.10910
a decoder loss: 2.07951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:26
train iter: 4
num of updates: 500
vae loss: 2.18650
kl loss: 0.10777
a decoder loss: 2.07873
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:27
train iter: 5
num of updates: 600
vae loss: 2.18512
kl loss: 0.10643
a decoder loss: 2.07869
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:28
train iter: 6
num of updates: 700
vae loss: 2.17932
kl loss: 0.10403
a decoder loss: 2.07529
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:29
train iter: 7
num of updates: 800
vae loss: 2.17097
kl loss: 0.10197
a decoder loss: 2.06900
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:30
train iter: 8
num of updates: 900
vae loss: 2.16282
kl loss: 0.10006
a decoder loss: 2.06276
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:31
train iter: 9
num of updates: 1000
vae loss: 2.14816
kl loss: 0.09719
a decoder loss: 2.05097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:32
train iter: 10
num of updates: 1100
vae loss: 2.14312
kl loss: 0.09464
a decoder loss: 2.04848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:33
train iter: 11
num of updates: 1200
vae loss: 2.12345
kl loss: 0.09206
a decoder loss: 2.03138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:34
train iter: 12
num of updates: 1300
vae loss: 2.12326
kl loss: 0.08949
a decoder loss: 2.03377
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:35
train iter: 13
num of updates: 1400
vae loss: 2.11781
kl loss: 0.08695
a decoder loss: 2.03087
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:36
train iter: 14
num of updates: 1500
vae loss: 2.09527
kl loss: 0.08414
a decoder loss: 2.01112
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:37
train iter: 15
num of updates: 1600
vae loss: 2.08284
kl loss: 0.08144
a decoder loss: 2.00140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:38
train iter: 16
num of updates: 1700
vae loss: 2.05850
kl loss: 0.07908
a decoder loss: 1.97942
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:39
train iter: 17
num of updates: 1800
vae loss: 2.05007
kl loss: 0.07693
a decoder loss: 1.97314
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:40
train iter: 18
num of updates: 1900
vae loss: 2.03763
kl loss: 0.07429
a decoder loss: 1.96334
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:41
train iter: 19
num of updates: 2000
vae loss: 2.02521
kl loss: 0.07222
a decoder loss: 1.95300
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:42
train iter: 20
num of updates: 2100
vae loss: 2.01481
kl loss: 0.06992
a decoder loss: 1.94489
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:43
train iter: 21
num of updates: 2200
vae loss: 1.98787
kl loss: 0.06812
a decoder loss: 1.91974
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:44
train iter: 22
num of updates: 2300
vae loss: 1.97078
kl loss: 0.06629
a decoder loss: 1.90449
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:45
train iter: 23
num of updates: 2400
vae loss: 1.95776
kl loss: 0.06448
a decoder loss: 1.89328
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:46
train iter: 24
num of updates: 2500
vae loss: 1.94260
kl loss: 0.06266
a decoder loss: 1.87993
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:47
train iter: 25
num of updates: 2600
vae loss: 1.91862
kl loss: 0.06082
a decoder loss: 1.85780
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:48
train iter: 26
num of updates: 2700
vae loss: 1.89960
kl loss: 0.05917
a decoder loss: 1.84043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:49
train iter: 27
num of updates: 2800
vae loss: 1.87959
kl loss: 0.05786
a decoder loss: 1.82174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:50
train iter: 28
num of updates: 2900
vae loss: 1.86244
kl loss: 0.05651
a decoder loss: 1.80593
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:51
train iter: 29
num of updates: 3000
vae loss: 1.84529
kl loss: 0.05512
a decoder loss: 1.79017
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:52
train iter: 30
num of updates: 3100
vae loss: 1.82687
kl loss: 0.05384
a decoder loss: 1.77303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:53
train iter: 31
num of updates: 3200
vae loss: 1.80338
kl loss: 0.05263
a decoder loss: 1.75075
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:54
train iter: 32
num of updates: 3300
vae loss: 1.78824
kl loss: 0.05164
a decoder loss: 1.73660
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:55
train iter: 33
num of updates: 3400
vae loss: 1.76855
kl loss: 0.05066
a decoder loss: 1.71789
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:56
train iter: 34
num of updates: 3500
vae loss: 1.74472
kl loss: 0.04967
a decoder loss: 1.69505
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:57
train iter: 35
num of updates: 3600
vae loss: 1.72390
kl loss: 0.04867
a decoder loss: 1.67524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:58
train iter: 36
num of updates: 3700
vae loss: 1.70026
kl loss: 0.04787
a decoder loss: 1.65239
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:59
train iter: 37
num of updates: 3800
vae loss: 1.67274
kl loss: 0.04729
a decoder loss: 1.62544
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:00
train iter: 38
num of updates: 3900
vae loss: 1.66225
kl loss: 0.04644
a decoder loss: 1.61581
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:01
train iter: 39
num of updates: 4000
vae loss: 1.63895
kl loss: 0.04577
a decoder loss: 1.59318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:02
train iter: 40
num of updates: 4100
vae loss: 1.61246
kl loss: 0.04502
a decoder loss: 1.56744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:03
train iter: 41
num of updates: 4200
vae loss: 1.59950
kl loss: 0.04442
a decoder loss: 1.55508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:04
train iter: 42
num of updates: 4300
vae loss: 1.57900
kl loss: 0.04391
a decoder loss: 1.53508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:05
train iter: 43
num of updates: 4400
vae loss: 1.55526
kl loss: 0.04340
a decoder loss: 1.51185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:06
train iter: 44
num of updates: 4500
vae loss: 1.54121
kl loss: 0.04302
a decoder loss: 1.49819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:07
train iter: 45
num of updates: 4600
vae loss: 1.51916
kl loss: 0.04267
a decoder loss: 1.47650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:08
train iter: 46
num of updates: 4700
vae loss: 1.49501
kl loss: 0.04232
a decoder loss: 1.45269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:09
train iter: 47
num of updates: 4800
vae loss: 1.48020
kl loss: 0.04212
a decoder loss: 1.43808
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:10
train iter: 48
num of updates: 4900
vae loss: 1.45642
kl loss: 0.04174
a decoder loss: 1.41469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:11
train iter: 49
num of updates: 5000
vae loss: 1.43248
kl loss: 0.04150
a decoder loss: 1.39098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:12
train iter: 50
num of updates: 5100
vae loss: 1.41750
kl loss: 0.04144
a decoder loss: 1.37606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:13
train iter: 51
num of updates: 5200
vae loss: 1.39302
kl loss: 0.04113
a decoder loss: 1.35189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:14
train iter: 52
num of updates: 5300
vae loss: 1.36982
kl loss: 0.04105
a decoder loss: 1.32876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:15
train iter: 53
num of updates: 5400
vae loss: 1.34566
kl loss: 0.04099
a decoder loss: 1.30467
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:16
train iter: 54
num of updates: 5500
vae loss: 1.33262
kl loss: 0.04091
a decoder loss: 1.29171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:17
train iter: 55
num of updates: 5600
vae loss: 1.30999
kl loss: 0.04080
a decoder loss: 1.26919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:18
train iter: 56
num of updates: 5700
vae loss: 1.29537
kl loss: 0.04075
a decoder loss: 1.25461
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:19
train iter: 57
num of updates: 5800
vae loss: 1.26549
kl loss: 0.04053
a decoder loss: 1.22496
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:20
train iter: 58
num of updates: 5900
vae loss: 1.24797
kl loss: 0.04061
a decoder loss: 1.20736
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:21
train iter: 59
num of updates: 6000
vae loss: 1.23256
kl loss: 0.04055
a decoder loss: 1.19201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:22
train iter: 60
num of updates: 6100
vae loss: 1.21006
kl loss: 0.04057
a decoder loss: 1.16948
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:23
train iter: 61
num of updates: 6200
vae loss: 1.19245
kl loss: 0.04039
a decoder loss: 1.15206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:25
train iter: 62
num of updates: 6300
vae loss: 1.16996
kl loss: 0.04065
a decoder loss: 1.12931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:26
train iter: 63
num of updates: 6400
vae loss: 1.14787
kl loss: 0.04047
a decoder loss: 1.10740
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:27
train iter: 64
num of updates: 6500
vae loss: 1.13003
kl loss: 0.04064
a decoder loss: 1.08939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:28
train iter: 65
num of updates: 6600
vae loss: 1.11173
kl loss: 0.04053
a decoder loss: 1.07120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:29
train iter: 66
num of updates: 6700
vae loss: 1.09101
kl loss: 0.04035
a decoder loss: 1.05066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:30
train iter: 67
num of updates: 6800
vae loss: 1.07168
kl loss: 0.04037
a decoder loss: 1.03132
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:31
train iter: 68
num of updates: 6900
vae loss: 1.05043
kl loss: 0.04035
a decoder loss: 1.01008
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:32
train iter: 69
num of updates: 7000
vae loss: 1.03244
kl loss: 0.04029
a decoder loss: 0.99215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:33
train iter: 70
num of updates: 7100
vae loss: 1.01709
kl loss: 0.04016
a decoder loss: 0.97693
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:34
train iter: 71
num of updates: 7200
vae loss: 0.99867
kl loss: 0.04017
a decoder loss: 0.95850
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:35
train iter: 72
num of updates: 7300
vae loss: 0.97575
kl loss: 0.04000
a decoder loss: 0.93575
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:36
train iter: 73
num of updates: 7400
vae loss: 0.96248
kl loss: 0.03991
a decoder loss: 0.92258
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:37
train iter: 74
num of updates: 7500
vae loss: 0.94269
kl loss: 0.03980
a decoder loss: 0.90289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:38
train iter: 75
num of updates: 7600
vae loss: 0.93136
kl loss: 0.03974
a decoder loss: 0.89162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:39
train iter: 76
num of updates: 7700
vae loss: 0.91329
kl loss: 0.03946
a decoder loss: 0.87383
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:40
train iter: 77
num of updates: 7800
vae loss: 0.89243
kl loss: 0.03925
a decoder loss: 0.85318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:41
train iter: 78
num of updates: 7900
vae loss: 0.87160
kl loss: 0.03899
a decoder loss: 0.83261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:42
train iter: 79
num of updates: 8000
vae loss: 0.86327
kl loss: 0.03873
a decoder loss: 0.82454
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:43
train iter: 80
num of updates: 8100
vae loss: 0.84527
kl loss: 0.03859
a decoder loss: 0.80667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:44
train iter: 81
num of updates: 8200
vae loss: 0.83156
kl loss: 0.03837
a decoder loss: 0.79319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:45
train iter: 82
num of updates: 8300
vae loss: 0.81415
kl loss: 0.03814
a decoder loss: 0.77601
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:46
train iter: 83
num of updates: 8400
vae loss: 0.79989
kl loss: 0.03787
a decoder loss: 0.76201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:47
train iter: 84
num of updates: 8500
vae loss: 0.78491
kl loss: 0.03744
a decoder loss: 0.74746
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:48
train iter: 85
num of updates: 8600
vae loss: 0.77138
kl loss: 0.03723
a decoder loss: 0.73414
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:49
train iter: 86
num of updates: 8700
vae loss: 0.75880
kl loss: 0.03697
a decoder loss: 0.72183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:50
train iter: 87
num of updates: 8800
vae loss: 0.74204
kl loss: 0.03659
a decoder loss: 0.70544
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:51
train iter: 88
num of updates: 8900
vae loss: 0.73010
kl loss: 0.03642
a decoder loss: 0.69368
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:52
train iter: 89
num of updates: 9000
vae loss: 0.71549
kl loss: 0.03603
a decoder loss: 0.67946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:53
train iter: 90
num of updates: 9100
vae loss: 0.70177
kl loss: 0.03577
a decoder loss: 0.66600
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:54
train iter: 91
num of updates: 9200
vae loss: 0.68917
kl loss: 0.03529
a decoder loss: 0.65388
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:55
train iter: 92
num of updates: 9300
vae loss: 0.67641
kl loss: 0.03494
a decoder loss: 0.64147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:56
train iter: 93
num of updates: 9400
vae loss: 0.66181
kl loss: 0.03454
a decoder loss: 0.62726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:57
train iter: 94
num of updates: 9500
vae loss: 0.64875
kl loss: 0.03423
a decoder loss: 0.61452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:58
train iter: 95
num of updates: 9600
vae loss: 0.64054
kl loss: 0.03360
a decoder loss: 0.60694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:59
train iter: 96
num of updates: 9700
vae loss: 0.62829
kl loss: 0.03325
a decoder loss: 0.59504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:00
train iter: 97
num of updates: 9800
vae loss: 0.61553
kl loss: 0.03282
a decoder loss: 0.58272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:01
train iter: 98
num of updates: 9900
vae loss: 0.60983
kl loss: 0.03266
a decoder loss: 0.57717
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:02
train iter: 99
num of updates: 10000
vae loss: 0.59623
kl loss: 0.03218
a decoder loss: 0.56405
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:03
train iter: 100
num of updates: 10100
vae loss: 0.58593
kl loss: 0.03180
a decoder loss: 0.55413
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:04
train iter: 101
num of updates: 10200
vae loss: 0.57731
kl loss: 0.03148
a decoder loss: 0.54583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:05
train iter: 102
num of updates: 10300
vae loss: 0.56611
kl loss: 0.03093
a decoder loss: 0.53518
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:06
train iter: 103
num of updates: 10400
vae loss: 0.55896
kl loss: 0.03056
a decoder loss: 0.52840
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:07
train iter: 104
num of updates: 10500
vae loss: 0.54751
kl loss: 0.03002
a decoder loss: 0.51749
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:08
train iter: 105
num of updates: 10600
vae loss: 0.53932
kl loss: 0.02957
a decoder loss: 0.50975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:09
train iter: 106
num of updates: 10700
vae loss: 0.53040
kl loss: 0.02923
a decoder loss: 0.50117
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:10
train iter: 107
num of updates: 10800
vae loss: 0.52362
kl loss: 0.02884
a decoder loss: 0.49478
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:11
train iter: 108
num of updates: 10900
vae loss: 0.51454
kl loss: 0.02842
a decoder loss: 0.48613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:12
train iter: 109
num of updates: 11000
vae loss: 0.50866
kl loss: 0.02786
a decoder loss: 0.48080
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:13
train iter: 110
num of updates: 11100
vae loss: 0.50401
kl loss: 0.02751
a decoder loss: 0.47650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:14
train iter: 111
num of updates: 11200
vae loss: 0.49260
kl loss: 0.02706
a decoder loss: 0.46554
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:15
train iter: 112
num of updates: 11300
vae loss: 0.48848
kl loss: 0.02669
a decoder loss: 0.46179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:16
train iter: 113
num of updates: 11400
vae loss: 0.48200
kl loss: 0.02618
a decoder loss: 0.45582
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:17
train iter: 114
num of updates: 11500
vae loss: 0.47525
kl loss: 0.02574
a decoder loss: 0.44951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:18
train iter: 115
num of updates: 11600
vae loss: 0.46944
kl loss: 0.02525
a decoder loss: 0.44418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:19
train iter: 116
num of updates: 11700
vae loss: 0.46435
kl loss: 0.02472
a decoder loss: 0.43963
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:20
train iter: 117
num of updates: 11800
vae loss: 0.45603
kl loss: 0.02421
a decoder loss: 0.43182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:21
train iter: 118
num of updates: 11900
vae loss: 0.45368
kl loss: 0.02383
a decoder loss: 0.42984
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:22
train iter: 119
num of updates: 12000
vae loss: 0.45040
kl loss: 0.02332
a decoder loss: 0.42708
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:23
train iter: 120
num of updates: 12100
vae loss: 0.44291
kl loss: 0.02286
a decoder loss: 0.42005
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:25
train iter: 121
num of updates: 12200
vae loss: 0.43666
kl loss: 0.02231
a decoder loss: 0.41435
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:26
train iter: 122
num of updates: 12300
vae loss: 0.43424
kl loss: 0.02182
a decoder loss: 0.41241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:27
train iter: 123
num of updates: 12400
vae loss: 0.42735
kl loss: 0.02132
a decoder loss: 0.40603
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:28
train iter: 124
num of updates: 12500
vae loss: 0.42316
kl loss: 0.02079
a decoder loss: 0.40238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:29
train iter: 125
num of updates: 12600
vae loss: 0.41754
kl loss: 0.02036
a decoder loss: 0.39717
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:30
train iter: 126
num of updates: 12700
vae loss: 0.41352
kl loss: 0.01987
a decoder loss: 0.39365
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:31
train iter: 127
num of updates: 12800
vae loss: 0.40920
kl loss: 0.01924
a decoder loss: 0.38996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:32
train iter: 128
num of updates: 12900
vae loss: 0.40400
kl loss: 0.01879
a decoder loss: 0.38521
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:33
train iter: 129
num of updates: 13000
vae loss: 0.40309
kl loss: 0.01843
a decoder loss: 0.38465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:34
train iter: 130
num of updates: 13100
vae loss: 0.39858
kl loss: 0.01788
a decoder loss: 0.38070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:35
train iter: 131
num of updates: 13200
vae loss: 0.39377
kl loss: 0.01749
a decoder loss: 0.37628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:36
train iter: 132
num of updates: 13300
vae loss: 0.39085
kl loss: 0.01705
a decoder loss: 0.37379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:37
train iter: 133
num of updates: 13400
vae loss: 0.38819
kl loss: 0.01659
a decoder loss: 0.37161
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:38
train iter: 134
num of updates: 13500
vae loss: 0.38227
kl loss: 0.01605
a decoder loss: 0.36621
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:39
train iter: 135
num of updates: 13600
vae loss: 0.38004
kl loss: 0.01565
a decoder loss: 0.36439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:40
train iter: 136
num of updates: 13700
vae loss: 0.37500
kl loss: 0.01514
a decoder loss: 0.35986
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:41
train iter: 137
num of updates: 13800
vae loss: 0.37310
kl loss: 0.01472
a decoder loss: 0.35838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:42
train iter: 138
num of updates: 13900
vae loss: 0.36988
kl loss: 0.01433
a decoder loss: 0.35555
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:43
train iter: 139
num of updates: 14000
vae loss: 0.36811
kl loss: 0.01391
a decoder loss: 0.35420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:44
train iter: 140
num of updates: 14100
vae loss: 0.36542
kl loss: 0.01343
a decoder loss: 0.35199
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:45
train iter: 141
num of updates: 14200
vae loss: 0.35902
kl loss: 0.01300
a decoder loss: 0.34602
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:46
train iter: 142
num of updates: 14300
vae loss: 0.35718
kl loss: 0.01265
a decoder loss: 0.34453
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:47
train iter: 143
num of updates: 14400
vae loss: 0.35577
kl loss: 0.01230
a decoder loss: 0.34347
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:48
train iter: 144
num of updates: 14500
vae loss: 0.35411
kl loss: 0.01195
a decoder loss: 0.34216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:49
train iter: 145
num of updates: 14600
vae loss: 0.34877
kl loss: 0.01151
a decoder loss: 0.33726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:50
train iter: 146
num of updates: 14700
vae loss: 0.34760
kl loss: 0.01118
a decoder loss: 0.33642
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:51
train iter: 147
num of updates: 14800
vae loss: 0.34439
kl loss: 0.01080
a decoder loss: 0.33360
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:52
train iter: 148
num of updates: 14900
vae loss: 0.34325
kl loss: 0.01054
a decoder loss: 0.33271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:53
train iter: 149
num of updates: 15000
vae loss: 0.33994
kl loss: 0.01018
a decoder loss: 0.32976
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:54
train iter: 150
num of updates: 15100
vae loss: 0.33821
kl loss: 0.00981
a decoder loss: 0.32840
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:55
train iter: 151
num of updates: 15200
vae loss: 0.33475
kl loss: 0.00946
a decoder loss: 0.32529
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:56
train iter: 152
num of updates: 15300
vae loss: 0.33307
kl loss: 0.00918
a decoder loss: 0.32389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:57
train iter: 153
num of updates: 15400
vae loss: 0.33161
kl loss: 0.00890
a decoder loss: 0.32271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:58
train iter: 154
num of updates: 15500
vae loss: 0.32895
kl loss: 0.00859
a decoder loss: 0.32035
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:59
train iter: 155
num of updates: 15600
vae loss: 0.32666
kl loss: 0.00835
a decoder loss: 0.31832
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:00
train iter: 156
num of updates: 15700
vae loss: 0.32399
kl loss: 0.00803
a decoder loss: 0.31596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:01
train iter: 157
num of updates: 15800
vae loss: 0.32158
kl loss: 0.00778
a decoder loss: 0.31380
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:02
train iter: 158
num of updates: 15900
vae loss: 0.31925
kl loss: 0.00755
a decoder loss: 0.31170
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:03
train iter: 159
num of updates: 16000
vae loss: 0.31848
kl loss: 0.00730
a decoder loss: 0.31119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:04
train iter: 160
num of updates: 16100
vae loss: 0.31530
kl loss: 0.00707
a decoder loss: 0.30823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:05
train iter: 161
num of updates: 16200
vae loss: 0.31314
kl loss: 0.00681
a decoder loss: 0.30633
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:06
train iter: 162
num of updates: 16300
vae loss: 0.31125
kl loss: 0.00660
a decoder loss: 0.30465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:07
train iter: 163
num of updates: 16400
vae loss: 0.31031
kl loss: 0.00638
a decoder loss: 0.30393
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:08
train iter: 164
num of updates: 16500
vae loss: 0.30974
kl loss: 0.00622
a decoder loss: 0.30352
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:09
train iter: 165
num of updates: 16600
vae loss: 0.30691
kl loss: 0.00602
a decoder loss: 0.30089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:10
train iter: 166
num of updates: 16700
vae loss: 0.30431
kl loss: 0.00585
a decoder loss: 0.29845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:11
train iter: 167
num of updates: 16800
vae loss: 0.30518
kl loss: 0.00568
a decoder loss: 0.29950
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:12
train iter: 168
num of updates: 16900
vae loss: 0.30151
kl loss: 0.00551
a decoder loss: 0.29600
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:13
train iter: 169
num of updates: 17000
vae loss: 0.30104
kl loss: 0.00536
a decoder loss: 0.29568
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:14
train iter: 170
num of updates: 17100
vae loss: 0.29864
kl loss: 0.00520
a decoder loss: 0.29344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:15
train iter: 171
num of updates: 17200
vae loss: 0.29798
kl loss: 0.00508
a decoder loss: 0.29289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:16
train iter: 172
num of updates: 17300
vae loss: 0.29586
kl loss: 0.00491
a decoder loss: 0.29095
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:17
train iter: 173
num of updates: 17400
vae loss: 0.29586
kl loss: 0.00479
a decoder loss: 0.29107
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:18
train iter: 174
num of updates: 17500
vae loss: 0.29491
kl loss: 0.00469
a decoder loss: 0.29022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:19
train iter: 175
num of updates: 17600
vae loss: 0.29175
kl loss: 0.00457
a decoder loss: 0.28719
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:20
train iter: 176
num of updates: 17700
vae loss: 0.29156
kl loss: 0.00443
a decoder loss: 0.28712
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:21
train iter: 177
num of updates: 17800
vae loss: 0.29017
kl loss: 0.00434
a decoder loss: 0.28583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:22
train iter: 178
num of updates: 17900
vae loss: 0.28919
kl loss: 0.00426
a decoder loss: 0.28493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:23
train iter: 179
num of updates: 18000
vae loss: 0.28695
kl loss: 0.00417
a decoder loss: 0.28279
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:24
train iter: 180
num of updates: 18100
vae loss: 0.28689
kl loss: 0.00407
a decoder loss: 0.28283
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:25
train iter: 181
num of updates: 18200
vae loss: 0.28536
kl loss: 0.00398
a decoder loss: 0.28137
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:26
train iter: 182
num of updates: 18300
vae loss: 0.28247
kl loss: 0.00386
a decoder loss: 0.27860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:28
train iter: 183
num of updates: 18400
vae loss: 0.28325
kl loss: 0.00383
a decoder loss: 0.27941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:29
train iter: 184
num of updates: 18500
vae loss: 0.28201
kl loss: 0.00374
a decoder loss: 0.27827
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:30
train iter: 185
num of updates: 18600
vae loss: 0.28087
kl loss: 0.00367
a decoder loss: 0.27720
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:31
train iter: 186
num of updates: 18700
vae loss: 0.28024
kl loss: 0.00361
a decoder loss: 0.27662
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:32
train iter: 187
num of updates: 18800
vae loss: 0.27760
kl loss: 0.00353
a decoder loss: 0.27407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:33
train iter: 188
num of updates: 18900
vae loss: 0.27587
kl loss: 0.00347
a decoder loss: 0.27240
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:34
train iter: 189
num of updates: 19000
vae loss: 0.27627
kl loss: 0.00341
a decoder loss: 0.27286
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:35
train iter: 190
num of updates: 19100
vae loss: 0.27627
kl loss: 0.00334
a decoder loss: 0.27293
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:36
train iter: 191
num of updates: 19200
vae loss: 0.27446
kl loss: 0.00328
a decoder loss: 0.27118
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:37
train iter: 192
num of updates: 19300
vae loss: 0.27403
kl loss: 0.00323
a decoder loss: 0.27079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:38
train iter: 193
num of updates: 19400
vae loss: 0.27143
kl loss: 0.00317
a decoder loss: 0.26826
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:39
train iter: 194
num of updates: 19500
vae loss: 0.27173
kl loss: 0.00313
a decoder loss: 0.26860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:40
train iter: 195
num of updates: 19600
vae loss: 0.27076
kl loss: 0.00308
a decoder loss: 0.26768
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:41
train iter: 196
num of updates: 19700
vae loss: 0.26907
kl loss: 0.00301
a decoder loss: 0.26606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:42
train iter: 197
num of updates: 19800
vae loss: 0.26969
kl loss: 0.00297
a decoder loss: 0.26673
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:43
train iter: 198
num of updates: 19900
vae loss: 0.26875
kl loss: 0.00291
a decoder loss: 0.26584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:44
train iter: 199
num of updates: 20000
vae loss: 0.26645
kl loss: 0.00286
a decoder loss: 0.26359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:45
train iter: 200
num of updates: 20100
vae loss: 0.26657
kl loss: 0.00282
a decoder loss: 0.26376
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:46
train iter: 201
num of updates: 20200
vae loss: 0.26547
kl loss: 0.00277
a decoder loss: 0.26269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:47
train iter: 202
num of updates: 20300
vae loss: 0.26546
kl loss: 0.00273
a decoder loss: 0.26273
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:48
train iter: 203
num of updates: 20400
vae loss: 0.26354
kl loss: 0.00268
a decoder loss: 0.26086
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:49
train iter: 204
num of updates: 20500
vae loss: 0.26386
kl loss: 0.00265
a decoder loss: 0.26121
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:50
train iter: 205
num of updates: 20600
vae loss: 0.26253
kl loss: 0.00260
a decoder loss: 0.25992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:51
train iter: 206
num of updates: 20700
vae loss: 0.26318
kl loss: 0.00257
a decoder loss: 0.26061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:52
train iter: 207
num of updates: 20800
vae loss: 0.26017
kl loss: 0.00252
a decoder loss: 0.25765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:53
train iter: 208
num of updates: 20900
vae loss: 0.25936
kl loss: 0.00249
a decoder loss: 0.25687
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:54
train iter: 209
num of updates: 21000
vae loss: 0.25980
kl loss: 0.00245
a decoder loss: 0.25735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:55
train iter: 210
num of updates: 21100
vae loss: 0.25971
kl loss: 0.00241
a decoder loss: 0.25730
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:56
train iter: 211
num of updates: 21200
vae loss: 0.25889
kl loss: 0.00238
a decoder loss: 0.25651
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:57
train iter: 212
num of updates: 21300
vae loss: 0.25810
kl loss: 0.00233
a decoder loss: 0.25577
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:58
train iter: 213
num of updates: 21400
vae loss: 0.25799
kl loss: 0.00230
a decoder loss: 0.25569
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:59
train iter: 214
num of updates: 21500
vae loss: 0.25614
kl loss: 0.00226
a decoder loss: 0.25389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:00
train iter: 215
num of updates: 21600
vae loss: 0.25611
kl loss: 0.00223
a decoder loss: 0.25388
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:01
train iter: 216
num of updates: 21700
vae loss: 0.25627
kl loss: 0.00220
a decoder loss: 0.25407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:02
train iter: 217
num of updates: 21800
vae loss: 0.25588
kl loss: 0.00215
a decoder loss: 0.25372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:03
train iter: 218
num of updates: 21900
vae loss: 0.25374
kl loss: 0.00213
a decoder loss: 0.25162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:04
train iter: 219
num of updates: 22000
vae loss: 0.25370
kl loss: 0.00210
a decoder loss: 0.25160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:05
train iter: 220
num of updates: 22100
vae loss: 0.25390
kl loss: 0.00207
a decoder loss: 0.25183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:06
train iter: 221
num of updates: 22200
vae loss: 0.25293
kl loss: 0.00205
a decoder loss: 0.25088
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:07
train iter: 222
num of updates: 22300
vae loss: 0.25073
kl loss: 0.00201
a decoder loss: 0.24872
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:08
train iter: 223
num of updates: 22400
vae loss: 0.25212
kl loss: 0.00198
a decoder loss: 0.25014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:09
train iter: 224
num of updates: 22500
vae loss: 0.25201
kl loss: 0.00196
a decoder loss: 0.25005
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:10
train iter: 225
num of updates: 22600
vae loss: 0.25123
kl loss: 0.00193
a decoder loss: 0.24930
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:11
train iter: 226
num of updates: 22700
vae loss: 0.25051
kl loss: 0.00190
a decoder loss: 0.24861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:12
train iter: 227
num of updates: 22800
vae loss: 0.24963
kl loss: 0.00187
a decoder loss: 0.24776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:13
train iter: 228
num of updates: 22900
vae loss: 0.24888
kl loss: 0.00185
a decoder loss: 0.24703
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:14
train iter: 229
num of updates: 23000
vae loss: 0.24795
kl loss: 0.00182
a decoder loss: 0.24613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:15
train iter: 230
num of updates: 23100
vae loss: 0.24838
kl loss: 0.00181
a decoder loss: 0.24658
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:16
train iter: 231
num of updates: 23200
vae loss: 0.24793
kl loss: 0.00178
a decoder loss: 0.24615
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:17
train iter: 232
num of updates: 23300
vae loss: 0.24766
kl loss: 0.00175
a decoder loss: 0.24591
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:18
train iter: 233
num of updates: 23400
vae loss: 0.24655
kl loss: 0.00172
a decoder loss: 0.24483
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:19
train iter: 234
num of updates: 23500
vae loss: 0.24718
kl loss: 0.00170
a decoder loss: 0.24548
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:20
train iter: 235
num of updates: 23600
vae loss: 0.24539
kl loss: 0.00168
a decoder loss: 0.24371
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:21
train iter: 236
num of updates: 23700
vae loss: 0.24542
kl loss: 0.00165
a decoder loss: 0.24376
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:22
train iter: 237
num of updates: 23800
vae loss: 0.24532
kl loss: 0.00163
a decoder loss: 0.24368
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:23
train iter: 238
num of updates: 23900
vae loss: 0.24323
kl loss: 0.00160
a decoder loss: 0.24163
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:24
train iter: 239
num of updates: 24000
vae loss: 0.24368
kl loss: 0.00158
a decoder loss: 0.24210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:25
train iter: 240
num of updates: 24100
vae loss: 0.24378
kl loss: 0.00157
a decoder loss: 0.24221
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:26
train iter: 241
num of updates: 24200
vae loss: 0.24334
kl loss: 0.00155
a decoder loss: 0.24179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:27
train iter: 242
num of updates: 24300
vae loss: 0.24332
kl loss: 0.00153
a decoder loss: 0.24179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:28
train iter: 243
num of updates: 24400
vae loss: 0.24289
kl loss: 0.00151
a decoder loss: 0.24138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:29
train iter: 244
num of updates: 24500
vae loss: 0.24163
kl loss: 0.00149
a decoder loss: 0.24014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:30
train iter: 245
num of updates: 24600
vae loss: 0.24159
kl loss: 0.00147
a decoder loss: 0.24012
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:31
train iter: 246
num of updates: 24700
vae loss: 0.24159
kl loss: 0.00145
a decoder loss: 0.24014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:32
train iter: 247
num of updates: 24800
vae loss: 0.24167
kl loss: 0.00144
a decoder loss: 0.24023
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:33
train iter: 248
num of updates: 24900
vae loss: 0.24134
kl loss: 0.00141
a decoder loss: 0.23992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:34
train iter: 249
num of updates: 25000
vae loss: 0.24031
kl loss: 0.00140
a decoder loss: 0.23891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:36
train iter: 250
num of updates: 25100
vae loss: 0.23919
kl loss: 0.00137
a decoder loss: 0.23782
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:37
train iter: 251
num of updates: 25200
vae loss: 0.23876
kl loss: 0.00136
a decoder loss: 0.23739
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:38
train iter: 252
num of updates: 25300
vae loss: 0.24018
kl loss: 0.00135
a decoder loss: 0.23883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:39
train iter: 253
num of updates: 25400
vae loss: 0.23941
kl loss: 0.00133
a decoder loss: 0.23809
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:40
train iter: 254
num of updates: 25500
vae loss: 0.23848
kl loss: 0.00133
a decoder loss: 0.23715
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:41
train iter: 255
num of updates: 25600
vae loss: 0.23954
kl loss: 0.00129
a decoder loss: 0.23825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:42
train iter: 256
num of updates: 25700
vae loss: 0.23674
kl loss: 0.00129
a decoder loss: 0.23546
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:43
train iter: 257
num of updates: 25800
vae loss: 0.23783
kl loss: 0.00127
a decoder loss: 0.23656
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:44
train iter: 258
num of updates: 25900
vae loss: 0.23790
kl loss: 0.00125
a decoder loss: 0.23665
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:45
train iter: 259
num of updates: 26000
vae loss: 0.23683
kl loss: 0.00124
a decoder loss: 0.23560
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:46
train iter: 260
num of updates: 26100
vae loss: 0.23597
kl loss: 0.00123
a decoder loss: 0.23474
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:47
train iter: 261
num of updates: 26200
vae loss: 0.23589
kl loss: 0.00121
a decoder loss: 0.23468
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:48
train iter: 262
num of updates: 26300
vae loss: 0.23645
kl loss: 0.00120
a decoder loss: 0.23525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:49
train iter: 263
num of updates: 26400
vae loss: 0.23563
kl loss: 0.00119
a decoder loss: 0.23445
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:50
train iter: 264
num of updates: 26500
vae loss: 0.23589
kl loss: 0.00116
a decoder loss: 0.23473
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:51
train iter: 265
num of updates: 26600
vae loss: 0.23679
kl loss: 0.00115
a decoder loss: 0.23564
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:52
train iter: 266
num of updates: 26700
vae loss: 0.23523
kl loss: 0.00114
a decoder loss: 0.23408
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:53
train iter: 267
num of updates: 26800
vae loss: 0.23556
kl loss: 0.00113
a decoder loss: 0.23443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:54
train iter: 268
num of updates: 26900
vae loss: 0.23550
kl loss: 0.00112
a decoder loss: 0.23438
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:55
train iter: 269
num of updates: 27000
vae loss: 0.23521
kl loss: 0.00110
a decoder loss: 0.23411
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:56
train iter: 270
num of updates: 27100
vae loss: 0.23366
kl loss: 0.00109
a decoder loss: 0.23257
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:57
train iter: 271
num of updates: 27200
vae loss: 0.23405
kl loss: 0.00108
a decoder loss: 0.23297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:58
train iter: 272
num of updates: 27300
vae loss: 0.23402
kl loss: 0.00107
a decoder loss: 0.23296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:59
train iter: 273
num of updates: 27400
vae loss: 0.23354
kl loss: 0.00105
a decoder loss: 0.23249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:00
train iter: 274
num of updates: 27500
vae loss: 0.23309
kl loss: 0.00105
a decoder loss: 0.23204
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:01
train iter: 275
num of updates: 27600
vae loss: 0.23358
kl loss: 0.00103
a decoder loss: 0.23255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:02
train iter: 276
num of updates: 27700
vae loss: 0.23374
kl loss: 0.00102
a decoder loss: 0.23272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:03
train iter: 277
num of updates: 27800
vae loss: 0.23241
kl loss: 0.00100
a decoder loss: 0.23141
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:04
train iter: 278
num of updates: 27900
vae loss: 0.23221
kl loss: 0.00099
a decoder loss: 0.23122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:05
train iter: 279
num of updates: 28000
vae loss: 0.23219
kl loss: 0.00100
a decoder loss: 0.23119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:06
train iter: 280
num of updates: 28100
vae loss: 0.23192
kl loss: 0.00097
a decoder loss: 0.23094
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:07
train iter: 281
num of updates: 28200
vae loss: 0.23166
kl loss: 0.00096
a decoder loss: 0.23070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:08
train iter: 282
num of updates: 28300
vae loss: 0.23187
kl loss: 0.00097
a decoder loss: 0.23091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:09
train iter: 283
num of updates: 28400
vae loss: 0.23039
kl loss: 0.00094
a decoder loss: 0.22944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:10
train iter: 284
num of updates: 28500
vae loss: 0.23053
kl loss: 0.00094
a decoder loss: 0.22959
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:11
train iter: 285
num of updates: 28600
vae loss: 0.23080
kl loss: 0.00093
a decoder loss: 0.22987
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:12
train iter: 286
num of updates: 28700
vae loss: 0.23120
kl loss: 0.00092
a decoder loss: 0.23029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:13
train iter: 287
num of updates: 28800
vae loss: 0.22921
kl loss: 0.00091
a decoder loss: 0.22831
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:14
train iter: 288
num of updates: 28900
vae loss: 0.23013
kl loss: 0.00090
a decoder loss: 0.22923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:15
train iter: 289
num of updates: 29000
vae loss: 0.23088
kl loss: 0.00089
a decoder loss: 0.22998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:16
train iter: 290
num of updates: 29100
vae loss: 0.23003
kl loss: 0.00088
a decoder loss: 0.22915
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:17
train iter: 291
num of updates: 29200
vae loss: 0.22948
kl loss: 0.00088
a decoder loss: 0.22860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:18
train iter: 292
num of updates: 29300
vae loss: 0.22931
kl loss: 0.00086
a decoder loss: 0.22845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:19
train iter: 293
num of updates: 29400
vae loss: 0.22907
kl loss: 0.00086
a decoder loss: 0.22821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:20
train iter: 294
num of updates: 29500
vae loss: 0.22936
kl loss: 0.00085
a decoder loss: 0.22851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:21
train iter: 295
num of updates: 29600
vae loss: 0.22920
kl loss: 0.00084
a decoder loss: 0.22836
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:22
train iter: 296
num of updates: 29700
vae loss: 0.22864
kl loss: 0.00083
a decoder loss: 0.22782
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:23
train iter: 297
num of updates: 29800
vae loss: 0.22826
kl loss: 0.00082
a decoder loss: 0.22744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:24
train iter: 298
num of updates: 29900
vae loss: 0.22794
kl loss: 0.00081
a decoder loss: 0.22714
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:25
train iter: 299
num of updates: 30000
vae loss: 0.22701
kl loss: 0.00081
a decoder loss: 0.22620
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:26
train iter: 300
num of updates: 30100
vae loss: 0.22845
kl loss: 0.00080
a decoder loss: 0.22765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:27
train iter: 301
num of updates: 30200
vae loss: 0.22917
kl loss: 0.00079
a decoder loss: 0.22837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:28
train iter: 302
num of updates: 30300
vae loss: 0.22764
kl loss: 0.00078
a decoder loss: 0.22685
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:29
train iter: 303
num of updates: 30400
vae loss: 0.22779
kl loss: 0.00078
a decoder loss: 0.22701
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:30
train iter: 304
num of updates: 30500
vae loss: 0.22803
kl loss: 0.00077
a decoder loss: 0.22726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:31
train iter: 305
num of updates: 30600
vae loss: 0.22770
kl loss: 0.00076
a decoder loss: 0.22694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:33
train iter: 306
num of updates: 30700
vae loss: 0.22710
kl loss: 0.00075
a decoder loss: 0.22635
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:34
train iter: 307
num of updates: 30800
vae loss: 0.22651
kl loss: 0.00075
a decoder loss: 0.22576
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:35
train iter: 308
num of updates: 30900
vae loss: 0.22662
kl loss: 0.00074
a decoder loss: 0.22588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:36
train iter: 309
num of updates: 31000
vae loss: 0.22690
kl loss: 0.00073
a decoder loss: 0.22616
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:37
train iter: 310
num of updates: 31100
vae loss: 0.22704
kl loss: 0.00072
a decoder loss: 0.22631
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:38
train iter: 311
num of updates: 31200
vae loss: 0.22661
kl loss: 0.00072
a decoder loss: 0.22589
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:39
train iter: 312
num of updates: 31300
vae loss: 0.22671
kl loss: 0.00072
a decoder loss: 0.22599
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:40
train iter: 313
num of updates: 31400
vae loss: 0.22620
kl loss: 0.00071
a decoder loss: 0.22549
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:41
train iter: 314
num of updates: 31500
vae loss: 0.22594
kl loss: 0.00071
a decoder loss: 0.22524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:42
train iter: 315
num of updates: 31600
vae loss: 0.22622
kl loss: 0.00070
a decoder loss: 0.22552
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:43
train iter: 316
num of updates: 31700
vae loss: 0.22589
kl loss: 0.00069
a decoder loss: 0.22520
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:44
train iter: 317
num of updates: 31800
vae loss: 0.22634
kl loss: 0.00068
a decoder loss: 0.22566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:45
train iter: 318
num of updates: 31900
vae loss: 0.22490
kl loss: 0.00068
a decoder loss: 0.22422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:46
train iter: 319
num of updates: 32000
vae loss: 0.22576
kl loss: 0.00067
a decoder loss: 0.22509
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:47
train iter: 320
num of updates: 32100
vae loss: 0.22557
kl loss: 0.00067
a decoder loss: 0.22490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:48
train iter: 321
num of updates: 32200
vae loss: 0.22574
kl loss: 0.00067
a decoder loss: 0.22507
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:49
train iter: 322
num of updates: 32300
vae loss: 0.22519
kl loss: 0.00066
a decoder loss: 0.22454
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:50
train iter: 323
num of updates: 32400
vae loss: 0.22568
kl loss: 0.00065
a decoder loss: 0.22503
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:51
train iter: 324
num of updates: 32500
vae loss: 0.22466
kl loss: 0.00065
a decoder loss: 0.22401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:52
train iter: 325
num of updates: 32600
vae loss: 0.22467
kl loss: 0.00064
a decoder loss: 0.22403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:53
train iter: 326
num of updates: 32700
vae loss: 0.22526
kl loss: 0.00063
a decoder loss: 0.22462
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:54
train iter: 327
num of updates: 32800
vae loss: 0.22495
kl loss: 0.00063
a decoder loss: 0.22432
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:55
train iter: 328
num of updates: 32900
vae loss: 0.22464
kl loss: 0.00063
a decoder loss: 0.22401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:56
train iter: 329
num of updates: 33000
vae loss: 0.22460
kl loss: 0.00062
a decoder loss: 0.22398
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:57
train iter: 330
num of updates: 33100
vae loss: 0.22375
kl loss: 0.00062
a decoder loss: 0.22313
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:58
train iter: 331
num of updates: 33200
vae loss: 0.22430
kl loss: 0.00061
a decoder loss: 0.22369
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:59
train iter: 332
num of updates: 33300
vae loss: 0.22353
kl loss: 0.00060
a decoder loss: 0.22293
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:00
train iter: 333
num of updates: 33400
vae loss: 0.22346
kl loss: 0.00060
a decoder loss: 0.22286
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:01
train iter: 334
num of updates: 33500
vae loss: 0.22412
kl loss: 0.00059
a decoder loss: 0.22353
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:02
train iter: 335
num of updates: 33600
vae loss: 0.22276
kl loss: 0.00059
a decoder loss: 0.22217
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:03
train iter: 336
num of updates: 33700
vae loss: 0.22312
kl loss: 0.00058
a decoder loss: 0.22254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:04
train iter: 337
num of updates: 33800
vae loss: 0.22264
kl loss: 0.00058
a decoder loss: 0.22206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:05
train iter: 338
num of updates: 33900
vae loss: 0.22377
kl loss: 0.00057
a decoder loss: 0.22319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:06
train iter: 339
num of updates: 34000
vae loss: 0.22405
kl loss: 0.00057
a decoder loss: 0.22347
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:07
train iter: 340
num of updates: 34100
vae loss: 0.22300
kl loss: 0.00057
a decoder loss: 0.22244
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:08
train iter: 341
num of updates: 34200
vae loss: 0.22358
kl loss: 0.00056
a decoder loss: 0.22302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:09
train iter: 342
num of updates: 34300
vae loss: 0.22336
kl loss: 0.00056
a decoder loss: 0.22280
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:10
train iter: 343
num of updates: 34400
vae loss: 0.22318
kl loss: 0.00055
a decoder loss: 0.22263
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:11
train iter: 344
num of updates: 34500
vae loss: 0.22252
kl loss: 0.00055
a decoder loss: 0.22197
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:12
train iter: 345
num of updates: 34600
vae loss: 0.22338
kl loss: 0.00054
a decoder loss: 0.22284
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:13
train iter: 346
num of updates: 34700
vae loss: 0.22176
kl loss: 0.00054
a decoder loss: 0.22122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:14
train iter: 347
num of updates: 34800
vae loss: 0.22219
kl loss: 0.00054
a decoder loss: 0.22165
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:15
train iter: 348
num of updates: 34900
vae loss: 0.22269
kl loss: 0.00054
a decoder loss: 0.22215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:16
train iter: 349
num of updates: 35000
vae loss: 0.22219
kl loss: 0.00053
a decoder loss: 0.22166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:17
train iter: 350
num of updates: 35100
vae loss: 0.22272
kl loss: 0.00053
a decoder loss: 0.22219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:18
train iter: 351
num of updates: 35200
vae loss: 0.22153
kl loss: 0.00052
a decoder loss: 0.22101
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:19
train iter: 352
num of updates: 35300
vae loss: 0.22189
kl loss: 0.00052
a decoder loss: 0.22137
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:20
train iter: 353
num of updates: 35400
vae loss: 0.22200
kl loss: 0.00051
a decoder loss: 0.22149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:21
train iter: 354
num of updates: 35500
vae loss: 0.22234
kl loss: 0.00051
a decoder loss: 0.22183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:22
train iter: 355
num of updates: 35600
vae loss: 0.22072
kl loss: 0.00051
a decoder loss: 0.22021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:23
train iter: 356
num of updates: 35700
vae loss: 0.22202
kl loss: 0.00051
a decoder loss: 0.22152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:24
train iter: 357
num of updates: 35800
vae loss: 0.22052
kl loss: 0.00050
a decoder loss: 0.22002
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:25
train iter: 358
num of updates: 35900
vae loss: 0.22208
kl loss: 0.00050
a decoder loss: 0.22158
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:27
train iter: 359
num of updates: 36000
vae loss: 0.22179
kl loss: 0.00050
a decoder loss: 0.22130
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:28
train iter: 360
num of updates: 36100
vae loss: 0.21965
kl loss: 0.00049
a decoder loss: 0.21916
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:29
train iter: 361
num of updates: 36200
vae loss: 0.22120
kl loss: 0.00049
a decoder loss: 0.22072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:30
train iter: 362
num of updates: 36300
vae loss: 0.22137
kl loss: 0.00048
a decoder loss: 0.22089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:31
train iter: 363
num of updates: 36400
vae loss: 0.22029
kl loss: 0.00048
a decoder loss: 0.21981
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:32
train iter: 364
num of updates: 36500
vae loss: 0.22131
kl loss: 0.00047
a decoder loss: 0.22084
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:33
train iter: 365
num of updates: 36600
vae loss: 0.22116
kl loss: 0.00047
a decoder loss: 0.22069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:34
train iter: 366
num of updates: 36700
vae loss: 0.22092
kl loss: 0.00046
a decoder loss: 0.22045
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:35
train iter: 367
num of updates: 36800
vae loss: 0.22124
kl loss: 0.00047
a decoder loss: 0.22077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:36
train iter: 368
num of updates: 36900
vae loss: 0.22091
kl loss: 0.00047
a decoder loss: 0.22044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:37
train iter: 369
num of updates: 37000
vae loss: 0.22088
kl loss: 0.00046
a decoder loss: 0.22042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:38
train iter: 370
num of updates: 37100
vae loss: 0.22002
kl loss: 0.00046
a decoder loss: 0.21956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:39
train iter: 371
num of updates: 37200
vae loss: 0.22085
kl loss: 0.00045
a decoder loss: 0.22039
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:40
train iter: 372
num of updates: 37300
vae loss: 0.22106
kl loss: 0.00045
a decoder loss: 0.22061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:41
train iter: 373
num of updates: 37400
vae loss: 0.22107
kl loss: 0.00045
a decoder loss: 0.22062
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:42
train iter: 374
num of updates: 37500
vae loss: 0.21929
kl loss: 0.00045
a decoder loss: 0.21885
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:43
train iter: 375
num of updates: 37600
vae loss: 0.22051
kl loss: 0.00044
a decoder loss: 0.22007
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:44
train iter: 376
num of updates: 37700
vae loss: 0.22033
kl loss: 0.00044
a decoder loss: 0.21989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:45
train iter: 377
num of updates: 37800
vae loss: 0.21994
kl loss: 0.00043
a decoder loss: 0.21950
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:46
train iter: 378
num of updates: 37900
vae loss: 0.22009
kl loss: 0.00043
a decoder loss: 0.21965
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:47
train iter: 379
num of updates: 38000
vae loss: 0.21931
kl loss: 0.00043
a decoder loss: 0.21888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:48
train iter: 380
num of updates: 38100
vae loss: 0.22080
kl loss: 0.00043
a decoder loss: 0.22037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:49
train iter: 381
num of updates: 38200
vae loss: 0.22011
kl loss: 0.00043
a decoder loss: 0.21968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:50
train iter: 382
num of updates: 38300
vae loss: 0.21934
kl loss: 0.00042
a decoder loss: 0.21892
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:51
train iter: 383
num of updates: 38400
vae loss: 0.21893
kl loss: 0.00042
a decoder loss: 0.21851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:52
train iter: 384
num of updates: 38500
vae loss: 0.22027
kl loss: 0.00042
a decoder loss: 0.21985
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:53
train iter: 385
num of updates: 38600
vae loss: 0.21961
kl loss: 0.00041
a decoder loss: 0.21920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:54
train iter: 386
num of updates: 38700
vae loss: 0.21862
kl loss: 0.00041
a decoder loss: 0.21821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:55
train iter: 387
num of updates: 38800
vae loss: 0.21870
kl loss: 0.00041
a decoder loss: 0.21829
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:56
train iter: 388
num of updates: 38900
vae loss: 0.21932
kl loss: 0.00041
a decoder loss: 0.21891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:57
train iter: 389
num of updates: 39000
vae loss: 0.22007
kl loss: 0.00040
a decoder loss: 0.21967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:58
train iter: 390
num of updates: 39100
vae loss: 0.21870
kl loss: 0.00040
a decoder loss: 0.21830
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:59
train iter: 391
num of updates: 39200
vae loss: 0.21878
kl loss: 0.00040
a decoder loss: 0.21838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:00
train iter: 392
num of updates: 39300
vae loss: 0.21793
kl loss: 0.00040
a decoder loss: 0.21753
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:01
train iter: 393
num of updates: 39400
vae loss: 0.21886
kl loss: 0.00039
a decoder loss: 0.21847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:02
train iter: 394
num of updates: 39500
vae loss: 0.21815
kl loss: 0.00039
a decoder loss: 0.21776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:03
train iter: 395
num of updates: 39600
vae loss: 0.21867
kl loss: 0.00039
a decoder loss: 0.21828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:04
train iter: 396
num of updates: 39700
vae loss: 0.21835
kl loss: 0.00039
a decoder loss: 0.21796
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:05
train iter: 397
num of updates: 39800
vae loss: 0.21888
kl loss: 0.00039
a decoder loss: 0.21849
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:06
train iter: 398
num of updates: 39900
vae loss: 0.21761
kl loss: 0.00038
a decoder loss: 0.21723
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:07
train iter: 399
num of updates: 40000
vae loss: 0.21816
kl loss: 0.00038
a decoder loss: 0.21778
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:08
train iter: 400
num of updates: 40100
vae loss: 0.21852
kl loss: 0.00038
a decoder loss: 0.21814
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:09
train iter: 401
num of updates: 40200
vae loss: 0.21856
kl loss: 0.00037
a decoder loss: 0.21818
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:11
train iter: 402
num of updates: 40300
vae loss: 0.21809
kl loss: 0.00037
a decoder loss: 0.21772
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:12
train iter: 403
num of updates: 40400
vae loss: 0.21800
kl loss: 0.00037
a decoder loss: 0.21763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:13
train iter: 404
num of updates: 40500
vae loss: 0.21771
kl loss: 0.00037
a decoder loss: 0.21734
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:14
train iter: 405
num of updates: 40600
vae loss: 0.21829
kl loss: 0.00037
a decoder loss: 0.21792
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:15
train iter: 406
num of updates: 40700
vae loss: 0.21833
kl loss: 0.00037
a decoder loss: 0.21796
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:16
train iter: 407
num of updates: 40800
vae loss: 0.21857
kl loss: 0.00036
a decoder loss: 0.21820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:17
train iter: 408
num of updates: 40900
vae loss: 0.21773
kl loss: 0.00036
a decoder loss: 0.21737
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:18
train iter: 409
num of updates: 41000
vae loss: 0.21781
kl loss: 0.00036
a decoder loss: 0.21745
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:19
train iter: 410
num of updates: 41100
vae loss: 0.21763
kl loss: 0.00036
a decoder loss: 0.21728
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:20
train iter: 411
num of updates: 41200
vae loss: 0.21863
kl loss: 0.00036
a decoder loss: 0.21828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:21
train iter: 412
num of updates: 41300
vae loss: 0.21791
kl loss: 0.00035
a decoder loss: 0.21756
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:22
train iter: 413
num of updates: 41400
vae loss: 0.21622
kl loss: 0.00035
a decoder loss: 0.21587
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:23
train iter: 414
num of updates: 41500
vae loss: 0.21740
kl loss: 0.00035
a decoder loss: 0.21705
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:24
train iter: 415
num of updates: 41600
vae loss: 0.21823
kl loss: 0.00035
a decoder loss: 0.21788
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:25
train iter: 416
num of updates: 41700
vae loss: 0.21741
kl loss: 0.00034
a decoder loss: 0.21707
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:26
train iter: 417
num of updates: 41800
vae loss: 0.21707
kl loss: 0.00034
a decoder loss: 0.21673
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:27
train iter: 418
num of updates: 41900
vae loss: 0.21769
kl loss: 0.00034
a decoder loss: 0.21735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:28
train iter: 419
num of updates: 42000
vae loss: 0.21763
kl loss: 0.00034
a decoder loss: 0.21729
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:29
train iter: 420
num of updates: 42100
vae loss: 0.21750
kl loss: 0.00034
a decoder loss: 0.21716
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:30
train iter: 421
num of updates: 42200
vae loss: 0.21884
kl loss: 0.00034
a decoder loss: 0.21851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:31
train iter: 422
num of updates: 42300
vae loss: 0.21783
kl loss: 0.00033
a decoder loss: 0.21749
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:32
train iter: 423
num of updates: 42400
vae loss: 0.21635
kl loss: 0.00033
a decoder loss: 0.21602
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:33
train iter: 424
num of updates: 42500
vae loss: 0.21744
kl loss: 0.00033
a decoder loss: 0.21711
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:34
train iter: 425
num of updates: 42600
vae loss: 0.21754
kl loss: 0.00033
a decoder loss: 0.21721
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:35
train iter: 426
num of updates: 42700
vae loss: 0.21661
kl loss: 0.00033
a decoder loss: 0.21628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:36
train iter: 427
num of updates: 42800
vae loss: 0.21704
kl loss: 0.00032
a decoder loss: 0.21672
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:37
train iter: 428
num of updates: 42900
vae loss: 0.21767
kl loss: 0.00032
a decoder loss: 0.21735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:38
train iter: 429
num of updates: 43000
vae loss: 0.21713
kl loss: 0.00032
a decoder loss: 0.21681
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:39
train iter: 430
num of updates: 43100
vae loss: 0.21599
kl loss: 0.00032
a decoder loss: 0.21566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:40
train iter: 431
num of updates: 43200
vae loss: 0.21639
kl loss: 0.00032
a decoder loss: 0.21607
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:41
train iter: 432
num of updates: 43300
vae loss: 0.21658
kl loss: 0.00032
a decoder loss: 0.21626
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:42
train iter: 433
num of updates: 43400
vae loss: 0.21649
kl loss: 0.00032
a decoder loss: 0.21617
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:43
train iter: 434
num of updates: 43500
vae loss: 0.21694
kl loss: 0.00031
a decoder loss: 0.21663
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:44
train iter: 435
num of updates: 43600
vae loss: 0.21621
kl loss: 0.00031
a decoder loss: 0.21590
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:45
train iter: 436
num of updates: 43700
vae loss: 0.21675
kl loss: 0.00031
a decoder loss: 0.21644
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:46
train iter: 437
num of updates: 43800
vae loss: 0.21705
kl loss: 0.00031
a decoder loss: 0.21674
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:47
train iter: 438
num of updates: 43900
vae loss: 0.21728
kl loss: 0.00031
a decoder loss: 0.21697
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:48
train iter: 439
num of updates: 44000
vae loss: 0.21644
kl loss: 0.00031
a decoder loss: 0.21613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:49
train iter: 440
num of updates: 44100
vae loss: 0.21681
kl loss: 0.00031
a decoder loss: 0.21650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:50
train iter: 441
num of updates: 44200
vae loss: 0.21688
kl loss: 0.00030
a decoder loss: 0.21658
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:51
train iter: 442
num of updates: 44300
vae loss: 0.21579
kl loss: 0.00030
a decoder loss: 0.21549
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:52
train iter: 443
num of updates: 44400
vae loss: 0.21710
kl loss: 0.00030
a decoder loss: 0.21679
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:53
train iter: 444
num of updates: 44500
vae loss: 0.21601
kl loss: 0.00030
a decoder loss: 0.21571
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:54
train iter: 445
num of updates: 44600
vae loss: 0.21680
kl loss: 0.00030
a decoder loss: 0.21650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:56
train iter: 446
num of updates: 44700
vae loss: 0.21607
kl loss: 0.00030
a decoder loss: 0.21577
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:57
train iter: 447
num of updates: 44800
vae loss: 0.21717
kl loss: 0.00029
a decoder loss: 0.21688
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:58
train iter: 448
num of updates: 44900
vae loss: 0.21643
kl loss: 0.00029
a decoder loss: 0.21613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:08:59
train iter: 449
num of updates: 45000
vae loss: 0.21715
kl loss: 0.00029
a decoder loss: 0.21686
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:00
train iter: 450
num of updates: 45100
vae loss: 0.21619
kl loss: 0.00029
a decoder loss: 0.21590
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:01
train iter: 451
num of updates: 45200
vae loss: 0.21613
kl loss: 0.00029
a decoder loss: 0.21584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:02
train iter: 452
num of updates: 45300
vae loss: 0.21575
kl loss: 0.00029
a decoder loss: 0.21546
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:03
train iter: 453
num of updates: 45400
vae loss: 0.21581
kl loss: 0.00028
a decoder loss: 0.21553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:04
train iter: 454
num of updates: 45500
vae loss: 0.21578
kl loss: 0.00028
a decoder loss: 0.21550
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:05
train iter: 455
num of updates: 45600
vae loss: 0.21581
kl loss: 0.00028
a decoder loss: 0.21553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:06
train iter: 456
num of updates: 45700
vae loss: 0.21616
kl loss: 0.00028
a decoder loss: 0.21588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:07
train iter: 457
num of updates: 45800
vae loss: 0.21529
kl loss: 0.00028
a decoder loss: 0.21501
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:08
train iter: 458
num of updates: 45900
vae loss: 0.21650
kl loss: 0.00028
a decoder loss: 0.21622
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:09
train iter: 459
num of updates: 46000
vae loss: 0.21536
kl loss: 0.00028
a decoder loss: 0.21508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:10
train iter: 460
num of updates: 46100
vae loss: 0.21559
kl loss: 0.00028
a decoder loss: 0.21531
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:11
train iter: 461
num of updates: 46200
vae loss: 0.21538
kl loss: 0.00027
a decoder loss: 0.21510
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:12
train iter: 462
num of updates: 46300
vae loss: 0.21673
kl loss: 0.00027
a decoder loss: 0.21645
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:13
train iter: 463
num of updates: 46400
vae loss: 0.21479
kl loss: 0.00027
a decoder loss: 0.21452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:14
train iter: 464
num of updates: 46500
vae loss: 0.21623
kl loss: 0.00027
a decoder loss: 0.21596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:15
train iter: 465
num of updates: 46600
vae loss: 0.21540
kl loss: 0.00027
a decoder loss: 0.21513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:16
train iter: 466
num of updates: 46700
vae loss: 0.21554
kl loss: 0.00027
a decoder loss: 0.21527
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:17
train iter: 467
num of updates: 46800
vae loss: 0.21496
kl loss: 0.00027
a decoder loss: 0.21469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:18
train iter: 468
num of updates: 46900
vae loss: 0.21470
kl loss: 0.00027
a decoder loss: 0.21443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:19
train iter: 469
num of updates: 47000
vae loss: 0.21470
kl loss: 0.00027
a decoder loss: 0.21444
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:20
train iter: 470
num of updates: 47100
vae loss: 0.21551
kl loss: 0.00027
a decoder loss: 0.21524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:21
train iter: 471
num of updates: 47200
vae loss: 0.21590
kl loss: 0.00026
a decoder loss: 0.21563
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:22
train iter: 472
num of updates: 47300
vae loss: 0.21490
kl loss: 0.00026
a decoder loss: 0.21464
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:23
train iter: 473
num of updates: 47400
vae loss: 0.21581
kl loss: 0.00026
a decoder loss: 0.21555
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:24
train iter: 474
num of updates: 47500
vae loss: 0.21587
kl loss: 0.00026
a decoder loss: 0.21561
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:25
train iter: 475
num of updates: 47600
vae loss: 0.21540
kl loss: 0.00026
a decoder loss: 0.21514
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:26
train iter: 476
num of updates: 47700
vae loss: 0.21421
kl loss: 0.00026
a decoder loss: 0.21396
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:27
train iter: 477
num of updates: 47800
vae loss: 0.21466
kl loss: 0.00026
a decoder loss: 0.21440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:28
train iter: 478
num of updates: 47900
vae loss: 0.21544
kl loss: 0.00026
a decoder loss: 0.21518
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:29
train iter: 479
num of updates: 48000
vae loss: 0.21534
kl loss: 0.00026
a decoder loss: 0.21509
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:30
train iter: 480
num of updates: 48100
vae loss: 0.21485
kl loss: 0.00025
a decoder loss: 0.21460
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:31
train iter: 481
num of updates: 48200
vae loss: 0.21422
kl loss: 0.00025
a decoder loss: 0.21397
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:32
train iter: 482
num of updates: 48300
vae loss: 0.21538
kl loss: 0.00025
a decoder loss: 0.21513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:33
train iter: 483
num of updates: 48400
vae loss: 0.21507
kl loss: 0.00025
a decoder loss: 0.21482
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:34
train iter: 484
num of updates: 48500
vae loss: 0.21563
kl loss: 0.00025
a decoder loss: 0.21538
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:35
train iter: 485
num of updates: 48600
vae loss: 0.21352
kl loss: 0.00025
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:36
train iter: 486
num of updates: 48700
vae loss: 0.21529
kl loss: 0.00025
a decoder loss: 0.21504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:37
train iter: 487
num of updates: 48800
vae loss: 0.21497
kl loss: 0.00025
a decoder loss: 0.21472
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:39
train iter: 488
num of updates: 48900
vae loss: 0.21464
kl loss: 0.00024
a decoder loss: 0.21439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:40
train iter: 489
num of updates: 49000
vae loss: 0.21523
kl loss: 0.00024
a decoder loss: 0.21499
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:41
train iter: 490
num of updates: 49100
vae loss: 0.21437
kl loss: 0.00024
a decoder loss: 0.21413
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:42
train iter: 491
num of updates: 49200
vae loss: 0.21473
kl loss: 0.00024
a decoder loss: 0.21449
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:43
train iter: 492
num of updates: 49300
vae loss: 0.21399
kl loss: 0.00024
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:44
train iter: 493
num of updates: 49400
vae loss: 0.21427
kl loss: 0.00024
a decoder loss: 0.21403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:45
train iter: 494
num of updates: 49500
vae loss: 0.21450
kl loss: 0.00024
a decoder loss: 0.21426
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:46
train iter: 495
num of updates: 49600
vae loss: 0.21495
kl loss: 0.00024
a decoder loss: 0.21471
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:47
train iter: 496
num of updates: 49700
vae loss: 0.21445
kl loss: 0.00024
a decoder loss: 0.21422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:48
train iter: 497
num of updates: 49800
vae loss: 0.21442
kl loss: 0.00024
a decoder loss: 0.21418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:49
train iter: 498
num of updates: 49900
vae loss: 0.21521
kl loss: 0.00023
a decoder loss: 0.21497
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:50
train iter: 499
num of updates: 50000
vae loss: 0.21475
kl loss: 0.00023
a decoder loss: 0.21452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:51
train iter: 500
num of updates: 50100
vae loss: 0.21527
kl loss: 0.00023
a decoder loss: 0.21504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:52
train iter: 501
num of updates: 50200
vae loss: 0.21417
kl loss: 0.00023
a decoder loss: 0.21394
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:53
train iter: 502
num of updates: 50300
vae loss: 0.21399
kl loss: 0.00023
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:54
train iter: 503
num of updates: 50400
vae loss: 0.21382
kl loss: 0.00023
a decoder loss: 0.21359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:55
train iter: 504
num of updates: 50500
vae loss: 0.21359
kl loss: 0.00023
a decoder loss: 0.21337
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:56
train iter: 505
num of updates: 50600
vae loss: 0.21448
kl loss: 0.00023
a decoder loss: 0.21426
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:57
train iter: 506
num of updates: 50700
vae loss: 0.21294
kl loss: 0.00023
a decoder loss: 0.21271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:58
train iter: 507
num of updates: 50800
vae loss: 0.21398
kl loss: 0.00023
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:09:59
train iter: 508
num of updates: 50900
vae loss: 0.21469
kl loss: 0.00022
a decoder loss: 0.21446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:00
train iter: 509
num of updates: 51000
vae loss: 0.21426
kl loss: 0.00022
a decoder loss: 0.21403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:01
train iter: 510
num of updates: 51100
vae loss: 0.21442
kl loss: 0.00022
a decoder loss: 0.21420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:02
train iter: 511
num of updates: 51200
vae loss: 0.21354
kl loss: 0.00022
a decoder loss: 0.21332
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:03
train iter: 512
num of updates: 51300
vae loss: 0.21374
kl loss: 0.00022
a decoder loss: 0.21351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:04
train iter: 513
num of updates: 51400
vae loss: 0.21336
kl loss: 0.00022
a decoder loss: 0.21314
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:05
train iter: 514
num of updates: 51500
vae loss: 0.21428
kl loss: 0.00022
a decoder loss: 0.21406
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:06
train iter: 515
num of updates: 51600
vae loss: 0.21463
kl loss: 0.00022
a decoder loss: 0.21441
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:07
train iter: 516
num of updates: 51700
vae loss: 0.21417
kl loss: 0.00022
a decoder loss: 0.21395
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:08
train iter: 517
num of updates: 51800
vae loss: 0.21323
kl loss: 0.00022
a decoder loss: 0.21302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:09
train iter: 518
num of updates: 51900
vae loss: 0.21413
kl loss: 0.00022
a decoder loss: 0.21392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:10
train iter: 519
num of updates: 52000
vae loss: 0.21363
kl loss: 0.00022
a decoder loss: 0.21341
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:11
train iter: 520
num of updates: 52100
vae loss: 0.21370
kl loss: 0.00022
a decoder loss: 0.21349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:12
train iter: 521
num of updates: 52200
vae loss: 0.21396
kl loss: 0.00022
a decoder loss: 0.21374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:13
train iter: 522
num of updates: 52300
vae loss: 0.21359
kl loss: 0.00021
a decoder loss: 0.21338
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:14
train iter: 523
num of updates: 52400
vae loss: 0.21413
kl loss: 0.00022
a decoder loss: 0.21391
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:15
train iter: 524
num of updates: 52500
vae loss: 0.21365
kl loss: 0.00021
a decoder loss: 0.21344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:16
train iter: 525
num of updates: 52600
vae loss: 0.21332
kl loss: 0.00021
a decoder loss: 0.21310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:17
train iter: 526
num of updates: 52700
vae loss: 0.21364
kl loss: 0.00021
a decoder loss: 0.21343
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:18
train iter: 527
num of updates: 52800
vae loss: 0.21447
kl loss: 0.00021
a decoder loss: 0.21427
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:19
train iter: 528
num of updates: 52900
vae loss: 0.21363
kl loss: 0.00021
a decoder loss: 0.21342
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:20
train iter: 529
num of updates: 53000
vae loss: 0.21328
kl loss: 0.00021
a decoder loss: 0.21307
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:21
train iter: 530
num of updates: 53100
vae loss: 0.21317
kl loss: 0.00021
a decoder loss: 0.21296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:22
train iter: 531
num of updates: 53200
vae loss: 0.21251
kl loss: 0.00021
a decoder loss: 0.21231
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:24
train iter: 532
num of updates: 53300
vae loss: 0.21338
kl loss: 0.00021
a decoder loss: 0.21317
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:25
train iter: 533
num of updates: 53400
vae loss: 0.21355
kl loss: 0.00021
a decoder loss: 0.21335
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:26
train iter: 534
num of updates: 53500
vae loss: 0.21405
kl loss: 0.00021
a decoder loss: 0.21384
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:27
train iter: 535
num of updates: 53600
vae loss: 0.21345
kl loss: 0.00020
a decoder loss: 0.21325
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:28
train iter: 536
num of updates: 53700
vae loss: 0.21311
kl loss: 0.00021
a decoder loss: 0.21291
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:29
train iter: 537
num of updates: 53800
vae loss: 0.21359
kl loss: 0.00020
a decoder loss: 0.21339
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:30
train iter: 538
num of updates: 53900
vae loss: 0.21341
kl loss: 0.00020
a decoder loss: 0.21321
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:31
train iter: 539
num of updates: 54000
vae loss: 0.21360
kl loss: 0.00020
a decoder loss: 0.21340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:32
train iter: 540
num of updates: 54100
vae loss: 0.21399
kl loss: 0.00020
a decoder loss: 0.21379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:33
train iter: 541
num of updates: 54200
vae loss: 0.21409
kl loss: 0.00020
a decoder loss: 0.21389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:34
train iter: 542
num of updates: 54300
vae loss: 0.21281
kl loss: 0.00020
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:35
train iter: 543
num of updates: 54400
vae loss: 0.21329
kl loss: 0.00020
a decoder loss: 0.21309
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:36
train iter: 544
num of updates: 54500
vae loss: 0.21371
kl loss: 0.00020
a decoder loss: 0.21351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:37
train iter: 545
num of updates: 54600
vae loss: 0.21308
kl loss: 0.00020
a decoder loss: 0.21289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:38
train iter: 546
num of updates: 54700
vae loss: 0.21417
kl loss: 0.00020
a decoder loss: 0.21397
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:39
train iter: 547
num of updates: 54800
vae loss: 0.21346
kl loss: 0.00020
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:40
train iter: 548
num of updates: 54900
vae loss: 0.21247
kl loss: 0.00019
a decoder loss: 0.21227
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:41
train iter: 549
num of updates: 55000
vae loss: 0.21392
kl loss: 0.00020
a decoder loss: 0.21373
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:42
train iter: 550
num of updates: 55100
vae loss: 0.21326
kl loss: 0.00020
a decoder loss: 0.21306
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:43
train iter: 551
num of updates: 55200
vae loss: 0.21298
kl loss: 0.00019
a decoder loss: 0.21279
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:44
train iter: 552
num of updates: 55300
vae loss: 0.21239
kl loss: 0.00019
a decoder loss: 0.21220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:45
train iter: 553
num of updates: 55400
vae loss: 0.21386
kl loss: 0.00019
a decoder loss: 0.21367
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:46
train iter: 554
num of updates: 55500
vae loss: 0.21273
kl loss: 0.00019
a decoder loss: 0.21254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:47
train iter: 555
num of updates: 55600
vae loss: 0.21381
kl loss: 0.00019
a decoder loss: 0.21362
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:48
train iter: 556
num of updates: 55700
vae loss: 0.21264
kl loss: 0.00019
a decoder loss: 0.21245
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:49
train iter: 557
num of updates: 55800
vae loss: 0.21314
kl loss: 0.00019
a decoder loss: 0.21295
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:50
train iter: 558
num of updates: 55900
vae loss: 0.21251
kl loss: 0.00019
a decoder loss: 0.21232
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:51
train iter: 559
num of updates: 56000
vae loss: 0.21327
kl loss: 0.00019
a decoder loss: 0.21308
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:52
train iter: 560
num of updates: 56100
vae loss: 0.21188
kl loss: 0.00019
a decoder loss: 0.21169
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:53
train iter: 561
num of updates: 56200
vae loss: 0.21339
kl loss: 0.00019
a decoder loss: 0.21320
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:54
train iter: 562
num of updates: 56300
vae loss: 0.21252
kl loss: 0.00019
a decoder loss: 0.21233
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:55
train iter: 563
num of updates: 56400
vae loss: 0.21273
kl loss: 0.00019
a decoder loss: 0.21254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:56
train iter: 564
num of updates: 56500
vae loss: 0.21287
kl loss: 0.00019
a decoder loss: 0.21269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:57
train iter: 565
num of updates: 56600
vae loss: 0.21220
kl loss: 0.00019
a decoder loss: 0.21202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:58
train iter: 566
num of updates: 56700
vae loss: 0.21236
kl loss: 0.00018
a decoder loss: 0.21218
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:10:59
train iter: 567
num of updates: 56800
vae loss: 0.21230
kl loss: 0.00018
a decoder loss: 0.21211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:00
train iter: 568
num of updates: 56900
vae loss: 0.21309
kl loss: 0.00018
a decoder loss: 0.21290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:01
train iter: 569
num of updates: 57000
vae loss: 0.21367
kl loss: 0.00018
a decoder loss: 0.21349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:02
train iter: 570
num of updates: 57100
vae loss: 0.21273
kl loss: 0.00018
a decoder loss: 0.21255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:03
train iter: 571
num of updates: 57200
vae loss: 0.21346
kl loss: 0.00018
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:04
train iter: 572
num of updates: 57300
vae loss: 0.21232
kl loss: 0.00018
a decoder loss: 0.21214
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:05
train iter: 573
num of updates: 57400
vae loss: 0.21253
kl loss: 0.00018
a decoder loss: 0.21235
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:06
train iter: 574
num of updates: 57500
vae loss: 0.21303
kl loss: 0.00018
a decoder loss: 0.21285
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:08
train iter: 575
num of updates: 57600
vae loss: 0.21315
kl loss: 0.00018
a decoder loss: 0.21297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:09
train iter: 576
num of updates: 57700
vae loss: 0.21299
kl loss: 0.00018
a decoder loss: 0.21281
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:10
train iter: 577
num of updates: 57800
vae loss: 0.21226
kl loss: 0.00018
a decoder loss: 0.21208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:11
train iter: 578
num of updates: 57900
vae loss: 0.21224
kl loss: 0.00018
a decoder loss: 0.21206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:12
train iter: 579
num of updates: 58000
vae loss: 0.21220
kl loss: 0.00018
a decoder loss: 0.21202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:13
train iter: 580
num of updates: 58100
vae loss: 0.21323
kl loss: 0.00018
a decoder loss: 0.21305
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:14
train iter: 581
num of updates: 58200
vae loss: 0.21256
kl loss: 0.00018
a decoder loss: 0.21238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:15
train iter: 582
num of updates: 58300
vae loss: 0.21202
kl loss: 0.00018
a decoder loss: 0.21185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:16
train iter: 583
num of updates: 58400
vae loss: 0.21234
kl loss: 0.00018
a decoder loss: 0.21216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:17
train iter: 584
num of updates: 58500
vae loss: 0.21263
kl loss: 0.00017
a decoder loss: 0.21246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:18
train iter: 585
num of updates: 58600
vae loss: 0.21264
kl loss: 0.00017
a decoder loss: 0.21246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:19
train iter: 586
num of updates: 58700
vae loss: 0.21195
kl loss: 0.00017
a decoder loss: 0.21178
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:20
train iter: 587
num of updates: 58800
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:21
train iter: 588
num of updates: 58900
vae loss: 0.21146
kl loss: 0.00017
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:22
train iter: 589
num of updates: 59000
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:23
train iter: 590
num of updates: 59100
vae loss: 0.21179
kl loss: 0.00017
a decoder loss: 0.21162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:24
train iter: 591
num of updates: 59200
vae loss: 0.21184
kl loss: 0.00017
a decoder loss: 0.21167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:25
train iter: 592
num of updates: 59300
vae loss: 0.21233
kl loss: 0.00017
a decoder loss: 0.21215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:26
train iter: 593
num of updates: 59400
vae loss: 0.21183
kl loss: 0.00017
a decoder loss: 0.21166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:27
train iter: 594
num of updates: 59500
vae loss: 0.21186
kl loss: 0.00017
a decoder loss: 0.21169
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:28
train iter: 595
num of updates: 59600
vae loss: 0.21227
kl loss: 0.00017
a decoder loss: 0.21210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:29
train iter: 596
num of updates: 59700
vae loss: 0.21265
kl loss: 0.00017
a decoder loss: 0.21248
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:30
train iter: 597
num of updates: 59800
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21262
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:31
train iter: 598
num of updates: 59900
vae loss: 0.21212
kl loss: 0.00017
a decoder loss: 0.21195
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:32
train iter: 599
num of updates: 60000
vae loss: 0.21266
kl loss: 0.00017
a decoder loss: 0.21249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:33
train iter: 600
num of updates: 60100
vae loss: 0.21215
kl loss: 0.00017
a decoder loss: 0.21198
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:34
train iter: 601
num of updates: 60200
vae loss: 0.21191
kl loss: 0.00017
a decoder loss: 0.21174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:35
train iter: 602
num of updates: 60300
vae loss: 0.21222
kl loss: 0.00017
a decoder loss: 0.21205
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:36
train iter: 603
num of updates: 60400
vae loss: 0.21125
kl loss: 0.00016
a decoder loss: 0.21109
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:37
train iter: 604
num of updates: 60500
vae loss: 0.21234
kl loss: 0.00017
a decoder loss: 0.21217
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:38
train iter: 605
num of updates: 60600
vae loss: 0.21135
kl loss: 0.00016
a decoder loss: 0.21119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:39
train iter: 606
num of updates: 60700
vae loss: 0.21258
kl loss: 0.00016
a decoder loss: 0.21242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:40
train iter: 607
num of updates: 60800
vae loss: 0.21230
kl loss: 0.00016
a decoder loss: 0.21213
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:41
train iter: 608
num of updates: 60900
vae loss: 0.21141
kl loss: 0.00016
a decoder loss: 0.21125
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:42
train iter: 609
num of updates: 61000
vae loss: 0.21163
kl loss: 0.00016
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:43
train iter: 610
num of updates: 61100
vae loss: 0.21205
kl loss: 0.00016
a decoder loss: 0.21189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:44
train iter: 611
num of updates: 61200
vae loss: 0.21294
kl loss: 0.00016
a decoder loss: 0.21278
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:45
train iter: 612
num of updates: 61300
vae loss: 0.21187
kl loss: 0.00016
a decoder loss: 0.21171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:46
train iter: 613
num of updates: 61400
vae loss: 0.21241
kl loss: 0.00016
a decoder loss: 0.21225
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:47
train iter: 614
num of updates: 61500
vae loss: 0.21210
kl loss: 0.00016
a decoder loss: 0.21194
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:48
train iter: 615
num of updates: 61600
vae loss: 0.21232
kl loss: 0.00016
a decoder loss: 0.21216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:49
train iter: 616
num of updates: 61700
vae loss: 0.21177
kl loss: 0.00016
a decoder loss: 0.21161
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:50
train iter: 617
num of updates: 61800
vae loss: 0.21127
kl loss: 0.00016
a decoder loss: 0.21111
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:52
train iter: 618
num of updates: 61900
vae loss: 0.21257
kl loss: 0.00016
a decoder loss: 0.21241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:53
train iter: 619
num of updates: 62000
vae loss: 0.21163
kl loss: 0.00016
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:54
train iter: 620
num of updates: 62100
vae loss: 0.21083
kl loss: 0.00016
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:55
train iter: 621
num of updates: 62200
vae loss: 0.21235
kl loss: 0.00016
a decoder loss: 0.21219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:56
train iter: 622
num of updates: 62300
vae loss: 0.21112
kl loss: 0.00016
a decoder loss: 0.21096
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:57
train iter: 623
num of updates: 62400
vae loss: 0.21165
kl loss: 0.00016
a decoder loss: 0.21149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:58
train iter: 624
num of updates: 62500
vae loss: 0.21158
kl loss: 0.00016
a decoder loss: 0.21142
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:11:59
train iter: 625
num of updates: 62600
vae loss: 0.21168
kl loss: 0.00015
a decoder loss: 0.21152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:00
train iter: 626
num of updates: 62700
vae loss: 0.21218
kl loss: 0.00015
a decoder loss: 0.21203
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:01
train iter: 627
num of updates: 62800
vae loss: 0.21200
kl loss: 0.00016
a decoder loss: 0.21185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:02
train iter: 628
num of updates: 62900
vae loss: 0.21101
kl loss: 0.00015
a decoder loss: 0.21086
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:03
train iter: 629
num of updates: 63000
vae loss: 0.21094
kl loss: 0.00015
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:04
train iter: 630
num of updates: 63100
vae loss: 0.21168
kl loss: 0.00015
a decoder loss: 0.21152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:05
train iter: 631
num of updates: 63200
vae loss: 0.21093
kl loss: 0.00015
a decoder loss: 0.21077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:06
train iter: 632
num of updates: 63300
vae loss: 0.21148
kl loss: 0.00015
a decoder loss: 0.21133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:07
train iter: 633
num of updates: 63400
vae loss: 0.21190
kl loss: 0.00015
a decoder loss: 0.21175
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:08
train iter: 634
num of updates: 63500
vae loss: 0.21113
kl loss: 0.00015
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:09
train iter: 635
num of updates: 63600
vae loss: 0.21112
kl loss: 0.00015
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:10
train iter: 636
num of updates: 63700
vae loss: 0.21186
kl loss: 0.00015
a decoder loss: 0.21171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:11
train iter: 637
num of updates: 63800
vae loss: 0.21193
kl loss: 0.00015
a decoder loss: 0.21178
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:12
train iter: 638
num of updates: 63900
vae loss: 0.21197
kl loss: 0.00015
a decoder loss: 0.21182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:13
train iter: 639
num of updates: 64000
vae loss: 0.21219
kl loss: 0.00015
a decoder loss: 0.21204
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:14
train iter: 640
num of updates: 64100
vae loss: 0.21158
kl loss: 0.00015
a decoder loss: 0.21143
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:15
train iter: 641
num of updates: 64200
vae loss: 0.21081
kl loss: 0.00015
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:16
train iter: 642
num of updates: 64300
vae loss: 0.21129
kl loss: 0.00015
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:17
train iter: 643
num of updates: 64400
vae loss: 0.21155
kl loss: 0.00015
a decoder loss: 0.21140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:18
train iter: 644
num of updates: 64500
vae loss: 0.21107
kl loss: 0.00015
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:19
train iter: 645
num of updates: 64600
vae loss: 0.21170
kl loss: 0.00015
a decoder loss: 0.21155
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:20
train iter: 646
num of updates: 64700
vae loss: 0.21222
kl loss: 0.00015
a decoder loss: 0.21208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:21
train iter: 647
num of updates: 64800
vae loss: 0.21188
kl loss: 0.00015
a decoder loss: 0.21173
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:22
train iter: 648
num of updates: 64900
vae loss: 0.21106
kl loss: 0.00015
a decoder loss: 0.21091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:23
train iter: 649
num of updates: 65000
vae loss: 0.21068
kl loss: 0.00015
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:24
train iter: 650
num of updates: 65100
vae loss: 0.21119
kl loss: 0.00015
a decoder loss: 0.21104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:25
train iter: 651
num of updates: 65200
vae loss: 0.21204
kl loss: 0.00014
a decoder loss: 0.21190
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:26
train iter: 652
num of updates: 65300
vae loss: 0.21083
kl loss: 0.00015
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:27
train iter: 653
num of updates: 65400
vae loss: 0.21115
kl loss: 0.00014
a decoder loss: 0.21100
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:28
train iter: 654
num of updates: 65500
vae loss: 0.21096
kl loss: 0.00014
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:29
train iter: 655
num of updates: 65600
vae loss: 0.21101
kl loss: 0.00014
a decoder loss: 0.21087
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:30
train iter: 656
num of updates: 65700
vae loss: 0.21175
kl loss: 0.00014
a decoder loss: 0.21160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:31
train iter: 657
num of updates: 65800
vae loss: 0.21148
kl loss: 0.00014
a decoder loss: 0.21133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:32
train iter: 658
num of updates: 65900
vae loss: 0.21132
kl loss: 0.00014
a decoder loss: 0.21118
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:33
train iter: 659
num of updates: 66000
vae loss: 0.21095
kl loss: 0.00014
a decoder loss: 0.21081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:35
train iter: 660
num of updates: 66100
vae loss: 0.21143
kl loss: 0.00014
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:36
train iter: 661
num of updates: 66200
vae loss: 0.21153
kl loss: 0.00014
a decoder loss: 0.21139
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:37
train iter: 662
num of updates: 66300
vae loss: 0.21035
kl loss: 0.00014
a decoder loss: 0.21020
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:38
train iter: 663
num of updates: 66400
vae loss: 0.21052
kl loss: 0.00014
a decoder loss: 0.21038
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:39
train iter: 664
num of updates: 66500
vae loss: 0.21138
kl loss: 0.00014
a decoder loss: 0.21124
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:40
train iter: 665
num of updates: 66600
vae loss: 0.21176
kl loss: 0.00014
a decoder loss: 0.21162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:41
train iter: 666
num of updates: 66700
vae loss: 0.21130
kl loss: 0.00014
a decoder loss: 0.21116
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:42
train iter: 667
num of updates: 66800
vae loss: 0.21082
kl loss: 0.00014
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:43
train iter: 668
num of updates: 66900
vae loss: 0.21108
kl loss: 0.00014
a decoder loss: 0.21094
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:44
train iter: 669
num of updates: 67000
vae loss: 0.21075
kl loss: 0.00014
a decoder loss: 0.21061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:45
train iter: 670
num of updates: 67100
vae loss: 0.21112
kl loss: 0.00014
a decoder loss: 0.21098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:46
train iter: 671
num of updates: 67200
vae loss: 0.21111
kl loss: 0.00014
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:47
train iter: 672
num of updates: 67300
vae loss: 0.21143
kl loss: 0.00014
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:48
train iter: 673
num of updates: 67400
vae loss: 0.21098
kl loss: 0.00014
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:49
train iter: 674
num of updates: 67500
vae loss: 0.21054
kl loss: 0.00014
a decoder loss: 0.21040
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:50
train iter: 675
num of updates: 67600
vae loss: 0.21078
kl loss: 0.00014
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:51
train iter: 676
num of updates: 67700
vae loss: 0.21092
kl loss: 0.00014
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:52
train iter: 677
num of updates: 67800
vae loss: 0.21079
kl loss: 0.00014
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:53
train iter: 678
num of updates: 67900
vae loss: 0.21106
kl loss: 0.00014
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:54
train iter: 679
num of updates: 68000
vae loss: 0.21159
kl loss: 0.00014
a decoder loss: 0.21146
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:55
train iter: 680
num of updates: 68100
vae loss: 0.21065
kl loss: 0.00014
a decoder loss: 0.21052
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:56
train iter: 681
num of updates: 68200
vae loss: 0.21130
kl loss: 0.00013
a decoder loss: 0.21117
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:57
train iter: 682
num of updates: 68300
vae loss: 0.21127
kl loss: 0.00013
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:58
train iter: 683
num of updates: 68400
vae loss: 0.21106
kl loss: 0.00013
a decoder loss: 0.21093
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:12:59
train iter: 684
num of updates: 68500
vae loss: 0.21030
kl loss: 0.00013
a decoder loss: 0.21016
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:00
train iter: 685
num of updates: 68600
vae loss: 0.21115
kl loss: 0.00013
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:01
train iter: 686
num of updates: 68700
vae loss: 0.21158
kl loss: 0.00014
a decoder loss: 0.21145
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:02
train iter: 687
num of updates: 68800
vae loss: 0.21117
kl loss: 0.00013
a decoder loss: 0.21104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:03
train iter: 688
num of updates: 68900
vae loss: 0.21099
kl loss: 0.00013
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:04
train iter: 689
num of updates: 69000
vae loss: 0.21095
kl loss: 0.00013
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:05
train iter: 690
num of updates: 69100
vae loss: 0.21045
kl loss: 0.00013
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:06
train iter: 691
num of updates: 69200
vae loss: 0.21084
kl loss: 0.00013
a decoder loss: 0.21071
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:07
train iter: 692
num of updates: 69300
vae loss: 0.21068
kl loss: 0.00013
a decoder loss: 0.21055
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:08
train iter: 693
num of updates: 69400
vae loss: 0.21071
kl loss: 0.00013
a decoder loss: 0.21058
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:09
train iter: 694
num of updates: 69500
vae loss: 0.21062
kl loss: 0.00013
a decoder loss: 0.21049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:10
train iter: 695
num of updates: 69600
vae loss: 0.21039
kl loss: 0.00013
a decoder loss: 0.21026
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:11
train iter: 696
num of updates: 69700
vae loss: 0.21214
kl loss: 0.00013
a decoder loss: 0.21201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:12
train iter: 697
num of updates: 69800
vae loss: 0.21067
kl loss: 0.00013
a decoder loss: 0.21054
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:13
train iter: 698
num of updates: 69900
vae loss: 0.21087
kl loss: 0.00013
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:14
train iter: 699
num of updates: 70000
vae loss: 0.21102
kl loss: 0.00013
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:15
train iter: 700
num of updates: 70100
vae loss: 0.20980
kl loss: 0.00013
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:16
train iter: 701
num of updates: 70200
vae loss: 0.21077
kl loss: 0.00013
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:18
train iter: 702
num of updates: 70300
vae loss: 0.21125
kl loss: 0.00013
a decoder loss: 0.21112
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:19
train iter: 703
num of updates: 70400
vae loss: 0.21115
kl loss: 0.00013
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:20
train iter: 704
num of updates: 70500
vae loss: 0.21127
kl loss: 0.00013
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:21
train iter: 705
num of updates: 70600
vae loss: 0.21091
kl loss: 0.00013
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:22
train iter: 706
num of updates: 70700
vae loss: 0.21007
kl loss: 0.00013
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:23
train iter: 707
num of updates: 70800
vae loss: 0.21055
kl loss: 0.00013
a decoder loss: 0.21043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:24
train iter: 708
num of updates: 70900
vae loss: 0.20956
kl loss: 0.00013
a decoder loss: 0.20943
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:25
train iter: 709
num of updates: 71000
vae loss: 0.20981
kl loss: 0.00013
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:26
train iter: 710
num of updates: 71100
vae loss: 0.21028
kl loss: 0.00013
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:27
train iter: 711
num of updates: 71200
vae loss: 0.21043
kl loss: 0.00013
a decoder loss: 0.21031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:28
train iter: 712
num of updates: 71300
vae loss: 0.21094
kl loss: 0.00013
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:29
train iter: 713
num of updates: 71400
vae loss: 0.21017
kl loss: 0.00013
a decoder loss: 0.21004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:30
train iter: 714
num of updates: 71500
vae loss: 0.20995
kl loss: 0.00012
a decoder loss: 0.20983
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:31
train iter: 715
num of updates: 71600
vae loss: 0.21031
kl loss: 0.00013
a decoder loss: 0.21018
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:32
train iter: 716
num of updates: 71700
vae loss: 0.21033
kl loss: 0.00012
a decoder loss: 0.21021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:33
train iter: 717
num of updates: 71800
vae loss: 0.21015
kl loss: 0.00012
a decoder loss: 0.21003
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:34
train iter: 718
num of updates: 71900
vae loss: 0.21132
kl loss: 0.00012
a decoder loss: 0.21120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:35
train iter: 719
num of updates: 72000
vae loss: 0.21081
kl loss: 0.00012
a decoder loss: 0.21069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:36
train iter: 720
num of updates: 72100
vae loss: 0.21084
kl loss: 0.00012
a decoder loss: 0.21072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:37
train iter: 721
num of updates: 72200
vae loss: 0.21108
kl loss: 0.00012
a decoder loss: 0.21095
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:38
train iter: 722
num of updates: 72300
vae loss: 0.21041
kl loss: 0.00012
a decoder loss: 0.21029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:39
train iter: 723
num of updates: 72400
vae loss: 0.21049
kl loss: 0.00012
a decoder loss: 0.21037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:40
train iter: 724
num of updates: 72500
vae loss: 0.21054
kl loss: 0.00012
a decoder loss: 0.21042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:41
train iter: 725
num of updates: 72600
vae loss: 0.21086
kl loss: 0.00012
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:42
train iter: 726
num of updates: 72700
vae loss: 0.20980
kl loss: 0.00012
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:43
train iter: 727
num of updates: 72800
vae loss: 0.21061
kl loss: 0.00012
a decoder loss: 0.21049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:44
train iter: 728
num of updates: 72900
vae loss: 0.21056
kl loss: 0.00012
a decoder loss: 0.21044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:45
train iter: 729
num of updates: 73000
vae loss: 0.21101
kl loss: 0.00012
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:46
train iter: 730
num of updates: 73100
vae loss: 0.21091
kl loss: 0.00012
a decoder loss: 0.21079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:47
train iter: 731
num of updates: 73200
vae loss: 0.21016
kl loss: 0.00012
a decoder loss: 0.21004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:48
train iter: 732
num of updates: 73300
vae loss: 0.21141
kl loss: 0.00012
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:49
train iter: 733
num of updates: 73400
vae loss: 0.21048
kl loss: 0.00012
a decoder loss: 0.21036
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:50
train iter: 734
num of updates: 73500
vae loss: 0.21034
kl loss: 0.00012
a decoder loss: 0.21022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:51
train iter: 735
num of updates: 73600
vae loss: 0.21082
kl loss: 0.00012
a decoder loss: 0.21069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:52
train iter: 736
num of updates: 73700
vae loss: 0.21008
kl loss: 0.00012
a decoder loss: 0.20996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:53
train iter: 737
num of updates: 73800
vae loss: 0.21000
kl loss: 0.00012
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:54
train iter: 738
num of updates: 73900
vae loss: 0.20994
kl loss: 0.00012
a decoder loss: 0.20982
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:55
train iter: 739
num of updates: 74000
vae loss: 0.20998
kl loss: 0.00012
a decoder loss: 0.20986
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:56
train iter: 740
num of updates: 74100
vae loss: 0.20991
kl loss: 0.00012
a decoder loss: 0.20979
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:57
train iter: 741
num of updates: 74200
vae loss: 0.21031
kl loss: 0.00012
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:58
train iter: 742
num of updates: 74300
vae loss: 0.21074
kl loss: 0.00012
a decoder loss: 0.21062
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:13:59
train iter: 743
num of updates: 74400
vae loss: 0.21053
kl loss: 0.00012
a decoder loss: 0.21042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:00
train iter: 744
num of updates: 74500
vae loss: 0.21072
kl loss: 0.00012
a decoder loss: 0.21061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:02
train iter: 745
num of updates: 74600
vae loss: 0.21027
kl loss: 0.00012
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:03
train iter: 746
num of updates: 74700
vae loss: 0.21031
kl loss: 0.00012
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:04
train iter: 747
num of updates: 74800
vae loss: 0.20951
kl loss: 0.00012
a decoder loss: 0.20939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:05
train iter: 748
num of updates: 74900
vae loss: 0.20950
kl loss: 0.00012
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:06
train iter: 749
num of updates: 75000
vae loss: 0.20960
kl loss: 0.00012
a decoder loss: 0.20948
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:07
train iter: 750
num of updates: 75100
vae loss: 0.21092
kl loss: 0.00012
a decoder loss: 0.21080
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:08
train iter: 751
num of updates: 75200
vae loss: 0.21105
kl loss: 0.00012
a decoder loss: 0.21093
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:09
train iter: 752
num of updates: 75300
vae loss: 0.20931
kl loss: 0.00012
a decoder loss: 0.20920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:10
train iter: 753
num of updates: 75400
vae loss: 0.20972
kl loss: 0.00012
a decoder loss: 0.20961
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:11
train iter: 754
num of updates: 75500
vae loss: 0.20902
kl loss: 0.00012
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:12
train iter: 755
num of updates: 75600
vae loss: 0.20978
kl loss: 0.00011
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:13
train iter: 756
num of updates: 75700
vae loss: 0.21092
kl loss: 0.00011
a decoder loss: 0.21081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:14
train iter: 757
num of updates: 75800
vae loss: 0.21094
kl loss: 0.00011
a decoder loss: 0.21083
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:15
train iter: 758
num of updates: 75900
vae loss: 0.20981
kl loss: 0.00011
a decoder loss: 0.20970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:16
train iter: 759
num of updates: 76000
vae loss: 0.20988
kl loss: 0.00011
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:17
train iter: 760
num of updates: 76100
vae loss: 0.21111
kl loss: 0.00011
a decoder loss: 0.21100
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:18
train iter: 761
num of updates: 76200
vae loss: 0.21008
kl loss: 0.00011
a decoder loss: 0.20997
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:19
train iter: 762
num of updates: 76300
vae loss: 0.21046
kl loss: 0.00011
a decoder loss: 0.21035
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:20
train iter: 763
num of updates: 76400
vae loss: 0.20895
kl loss: 0.00011
a decoder loss: 0.20883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:21
train iter: 764
num of updates: 76500
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:22
train iter: 765
num of updates: 76600
vae loss: 0.20950
kl loss: 0.00011
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:23
train iter: 766
num of updates: 76700
vae loss: 0.20948
kl loss: 0.00011
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:24
train iter: 767
num of updates: 76800
vae loss: 0.21075
kl loss: 0.00011
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:25
train iter: 768
num of updates: 76900
vae loss: 0.21003
kl loss: 0.00011
a decoder loss: 0.20992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:26
train iter: 769
num of updates: 77000
vae loss: 0.21058
kl loss: 0.00011
a decoder loss: 0.21047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:27
train iter: 770
num of updates: 77100
vae loss: 0.20977
kl loss: 0.00011
a decoder loss: 0.20966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:28
train iter: 771
num of updates: 77200
vae loss: 0.21000
kl loss: 0.00011
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:29
train iter: 772
num of updates: 77300
vae loss: 0.21075
kl loss: 0.00011
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:30
train iter: 773
num of updates: 77400
vae loss: 0.21009
kl loss: 0.00011
a decoder loss: 0.20998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:31
train iter: 774
num of updates: 77500
vae loss: 0.20921
kl loss: 0.00011
a decoder loss: 0.20910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:32
train iter: 775
num of updates: 77600
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:33
train iter: 776
num of updates: 77700
vae loss: 0.20935
kl loss: 0.00011
a decoder loss: 0.20924
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:34
train iter: 777
num of updates: 77800
vae loss: 0.20977
kl loss: 0.00011
a decoder loss: 0.20966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:35
train iter: 778
num of updates: 77900
vae loss: 0.21005
kl loss: 0.00011
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:36
train iter: 779
num of updates: 78000
vae loss: 0.20916
kl loss: 0.00011
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:37
train iter: 780
num of updates: 78100
vae loss: 0.20949
kl loss: 0.00011
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:38
train iter: 781
num of updates: 78200
vae loss: 0.21064
kl loss: 0.00011
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:39
train iter: 782
num of updates: 78300
vae loss: 0.20962
kl loss: 0.00011
a decoder loss: 0.20951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:40
train iter: 783
num of updates: 78400
vae loss: 0.20933
kl loss: 0.00011
a decoder loss: 0.20922
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:41
train iter: 784
num of updates: 78500
vae loss: 0.20984
kl loss: 0.00011
a decoder loss: 0.20973
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:42
train iter: 785
num of updates: 78600
vae loss: 0.20957
kl loss: 0.00011
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:43
train iter: 786
num of updates: 78700
vae loss: 0.20948
kl loss: 0.00011
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:44
train iter: 787
num of updates: 78800
vae loss: 0.20982
kl loss: 0.00011
a decoder loss: 0.20972
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:45
train iter: 788
num of updates: 78900
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:46
train iter: 789
num of updates: 79000
vae loss: 0.20973
kl loss: 0.00011
a decoder loss: 0.20962
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:48
train iter: 790
num of updates: 79100
vae loss: 0.20991
kl loss: 0.00011
a decoder loss: 0.20980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:49
train iter: 791
num of updates: 79200
vae loss: 0.20955
kl loss: 0.00011
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:50
train iter: 792
num of updates: 79300
vae loss: 0.21007
kl loss: 0.00011
a decoder loss: 0.20996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:51
train iter: 793
num of updates: 79400
vae loss: 0.20995
kl loss: 0.00011
a decoder loss: 0.20984
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:52
train iter: 794
num of updates: 79500
vae loss: 0.21054
kl loss: 0.00010
a decoder loss: 0.21043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:53
train iter: 795
num of updates: 79600
vae loss: 0.20963
kl loss: 0.00011
a decoder loss: 0.20952
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:54
train iter: 796
num of updates: 79700
vae loss: 0.20908
kl loss: 0.00011
a decoder loss: 0.20898
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:55
train iter: 797
num of updates: 79800
vae loss: 0.21043
kl loss: 0.00011
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:56
train iter: 798
num of updates: 79900
vae loss: 0.20945
kl loss: 0.00011
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:57
train iter: 799
num of updates: 80000
vae loss: 0.20913
kl loss: 0.00010
a decoder loss: 0.20902
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:58
train iter: 800
num of updates: 80100
vae loss: 0.21027
kl loss: 0.00010
a decoder loss: 0.21016
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:14:59
train iter: 801
num of updates: 80200
vae loss: 0.20951
kl loss: 0.00010
a decoder loss: 0.20941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:00
train iter: 802
num of updates: 80300
vae loss: 0.21019
kl loss: 0.00010
a decoder loss: 0.21009
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:01
train iter: 803
num of updates: 80400
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20913
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:02
train iter: 804
num of updates: 80500
vae loss: 0.20965
kl loss: 0.00010
a decoder loss: 0.20955
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:03
train iter: 805
num of updates: 80600
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:04
train iter: 806
num of updates: 80700
vae loss: 0.21001
kl loss: 0.00010
a decoder loss: 0.20991
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:05
train iter: 807
num of updates: 80800
vae loss: 0.20943
kl loss: 0.00010
a decoder loss: 0.20933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:06
train iter: 808
num of updates: 80900
vae loss: 0.20937
kl loss: 0.00010
a decoder loss: 0.20927
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:07
train iter: 809
num of updates: 81000
vae loss: 0.20982
kl loss: 0.00010
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:08
train iter: 810
num of updates: 81100
vae loss: 0.21004
kl loss: 0.00010
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:09
train iter: 811
num of updates: 81200
vae loss: 0.20981
kl loss: 0.00010
a decoder loss: 0.20970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:10
train iter: 812
num of updates: 81300
vae loss: 0.21003
kl loss: 0.00010
a decoder loss: 0.20993
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:11
train iter: 813
num of updates: 81400
vae loss: 0.20938
kl loss: 0.00010
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:12
train iter: 814
num of updates: 81500
vae loss: 0.20991
kl loss: 0.00010
a decoder loss: 0.20980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:13
train iter: 815
num of updates: 81600
vae loss: 0.21002
kl loss: 0.00010
a decoder loss: 0.20992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:14
train iter: 816
num of updates: 81700
vae loss: 0.21010
kl loss: 0.00010
a decoder loss: 0.20999
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:15
train iter: 817
num of updates: 81800
vae loss: 0.21035
kl loss: 0.00010
a decoder loss: 0.21025
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:16
train iter: 818
num of updates: 81900
vae loss: 0.20965
kl loss: 0.00010
a decoder loss: 0.20954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:17
train iter: 819
num of updates: 82000
vae loss: 0.20964
kl loss: 0.00010
a decoder loss: 0.20954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:18
train iter: 820
num of updates: 82100
vae loss: 0.20981
kl loss: 0.00010
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:19
train iter: 821
num of updates: 82200
vae loss: 0.20835
kl loss: 0.00010
a decoder loss: 0.20825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:20
train iter: 822
num of updates: 82300
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:21
train iter: 823
num of updates: 82400
vae loss: 0.20956
kl loss: 0.00010
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:22
train iter: 824
num of updates: 82500
vae loss: 0.20918
kl loss: 0.00010
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:23
train iter: 825
num of updates: 82600
vae loss: 0.20938
kl loss: 0.00010
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:24
train iter: 826
num of updates: 82700
vae loss: 0.20945
kl loss: 0.00010
a decoder loss: 0.20935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:25
train iter: 827
num of updates: 82800
vae loss: 0.20903
kl loss: 0.00010
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:26
train iter: 828
num of updates: 82900
vae loss: 0.20922
kl loss: 0.00010
a decoder loss: 0.20912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:27
train iter: 829
num of updates: 83000
vae loss: 0.20944
kl loss: 0.00010
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:28
train iter: 830
num of updates: 83100
vae loss: 0.20919
kl loss: 0.00010
a decoder loss: 0.20909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:29
train iter: 831
num of updates: 83200
vae loss: 0.20970
kl loss: 0.00010
a decoder loss: 0.20960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:30
train iter: 832
num of updates: 83300
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:31
train iter: 833
num of updates: 83400
vae loss: 0.20943
kl loss: 0.00010
a decoder loss: 0.20933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:33
train iter: 834
num of updates: 83500
vae loss: 0.20901
kl loss: 0.00010
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:34
train iter: 835
num of updates: 83600
vae loss: 0.20999
kl loss: 0.00010
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:35
train iter: 836
num of updates: 83700
vae loss: 0.20896
kl loss: 0.00010
a decoder loss: 0.20887
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:36
train iter: 837
num of updates: 83800
vae loss: 0.20978
kl loss: 0.00010
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:37
train iter: 838
num of updates: 83900
vae loss: 0.20830
kl loss: 0.00010
a decoder loss: 0.20820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:38
train iter: 839
num of updates: 84000
vae loss: 0.20950
kl loss: 0.00010
a decoder loss: 0.20940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:39
train iter: 840
num of updates: 84100
vae loss: 0.20965
kl loss: 0.00010
a decoder loss: 0.20956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:40
train iter: 841
num of updates: 84200
vae loss: 0.20944
kl loss: 0.00010
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:41
train iter: 842
num of updates: 84300
vae loss: 0.20905
kl loss: 0.00010
a decoder loss: 0.20896
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:42
train iter: 843
num of updates: 84400
vae loss: 0.20863
kl loss: 0.00010
a decoder loss: 0.20854
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:43
train iter: 844
num of updates: 84500
vae loss: 0.20985
kl loss: 0.00010
a decoder loss: 0.20975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:44
train iter: 845
num of updates: 84600
vae loss: 0.20899
kl loss: 0.00010
a decoder loss: 0.20889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:45
train iter: 846
num of updates: 84700
vae loss: 0.20955
kl loss: 0.00010
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:46
train iter: 847
num of updates: 84800
vae loss: 0.20887
kl loss: 0.00010
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:47
train iter: 848
num of updates: 84900
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:48
train iter: 849
num of updates: 85000
vae loss: 0.20913
kl loss: 0.00010
a decoder loss: 0.20903
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:49
train iter: 850
num of updates: 85100
vae loss: 0.20895
kl loss: 0.00010
a decoder loss: 0.20885
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:50
train iter: 851
num of updates: 85200
vae loss: 0.20954
kl loss: 0.00010
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:51
train iter: 852
num of updates: 85300
vae loss: 0.20893
kl loss: 0.00009
a decoder loss: 0.20884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:52
train iter: 853
num of updates: 85400
vae loss: 0.20977
kl loss: 0.00009
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:53
train iter: 854
num of updates: 85500
vae loss: 0.20922
kl loss: 0.00010
a decoder loss: 0.20912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:54
train iter: 855
num of updates: 85600
vae loss: 0.20941
kl loss: 0.00009
a decoder loss: 0.20932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:55
train iter: 856
num of updates: 85700
vae loss: 0.20984
kl loss: 0.00009
a decoder loss: 0.20975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:56
train iter: 857
num of updates: 85800
vae loss: 0.20927
kl loss: 0.00010
a decoder loss: 0.20918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:57
train iter: 858
num of updates: 85900
vae loss: 0.20949
kl loss: 0.00009
a decoder loss: 0.20940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:58
train iter: 859
num of updates: 86000
vae loss: 0.20945
kl loss: 0.00009
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:15:59
train iter: 860
num of updates: 86100
vae loss: 0.20916
kl loss: 0.00009
a decoder loss: 0.20907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:00
train iter: 861
num of updates: 86200
vae loss: 0.20930
kl loss: 0.00009
a decoder loss: 0.20920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:01
train iter: 862
num of updates: 86300
vae loss: 0.20884
kl loss: 0.00009
a decoder loss: 0.20875
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:02
train iter: 863
num of updates: 86400
vae loss: 0.20997
kl loss: 0.00009
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:03
train iter: 864
num of updates: 86500
vae loss: 0.20866
kl loss: 0.00009
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:04
train iter: 865
num of updates: 86600
vae loss: 0.20986
kl loss: 0.00009
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:05
train iter: 866
num of updates: 86700
vae loss: 0.20932
kl loss: 0.00009
a decoder loss: 0.20923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:06
train iter: 867
num of updates: 86800
vae loss: 0.20918
kl loss: 0.00009
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:07
train iter: 868
num of updates: 86900
vae loss: 0.20920
kl loss: 0.00009
a decoder loss: 0.20911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:08
train iter: 869
num of updates: 87000
vae loss: 0.20906
kl loss: 0.00009
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:09
train iter: 870
num of updates: 87100
vae loss: 0.20899
kl loss: 0.00009
a decoder loss: 0.20889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:10
train iter: 871
num of updates: 87200
vae loss: 0.20940
kl loss: 0.00009
a decoder loss: 0.20931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:11
train iter: 872
num of updates: 87300
vae loss: 0.20832
kl loss: 0.00009
a decoder loss: 0.20823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:12
train iter: 873
num of updates: 87400
vae loss: 0.20897
kl loss: 0.00009
a decoder loss: 0.20888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:13
train iter: 874
num of updates: 87500
vae loss: 0.20915
kl loss: 0.00009
a decoder loss: 0.20906
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:14
train iter: 875
num of updates: 87600
vae loss: 0.20901
kl loss: 0.00009
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:15
train iter: 876
num of updates: 87700
vae loss: 0.20841
kl loss: 0.00009
a decoder loss: 0.20832
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:17
train iter: 877
num of updates: 87800
vae loss: 0.20997
kl loss: 0.00009
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:18
train iter: 878
num of updates: 87900
vae loss: 0.20915
kl loss: 0.00009
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:19
train iter: 879
num of updates: 88000
vae loss: 0.20873
kl loss: 0.00009
a decoder loss: 0.20864
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:20
train iter: 880
num of updates: 88100
vae loss: 0.20854
kl loss: 0.00009
a decoder loss: 0.20845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:21
train iter: 881
num of updates: 88200
vae loss: 0.20941
kl loss: 0.00009
a decoder loss: 0.20932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:22
train iter: 882
num of updates: 88300
vae loss: 0.20918
kl loss: 0.00009
a decoder loss: 0.20909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:23
train iter: 883
num of updates: 88400
vae loss: 0.20998
kl loss: 0.00009
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:24
train iter: 884
num of updates: 88500
vae loss: 0.20870
kl loss: 0.00009
a decoder loss: 0.20861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:25
train iter: 885
num of updates: 88600
vae loss: 0.20926
kl loss: 0.00009
a decoder loss: 0.20917
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:26
train iter: 886
num of updates: 88700
vae loss: 0.20919
kl loss: 0.00009
a decoder loss: 0.20910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:27
train iter: 887
num of updates: 88800
vae loss: 0.20914
kl loss: 0.00009
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:28
train iter: 888
num of updates: 88900
vae loss: 0.20845
kl loss: 0.00009
a decoder loss: 0.20837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:29
train iter: 889
num of updates: 89000
vae loss: 0.20860
kl loss: 0.00009
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:30
train iter: 890
num of updates: 89100
vae loss: 0.20825
kl loss: 0.00009
a decoder loss: 0.20816
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:31
train iter: 891
num of updates: 89200
vae loss: 0.20943
kl loss: 0.00009
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:32
train iter: 892
num of updates: 89300
vae loss: 0.20837
kl loss: 0.00009
a decoder loss: 0.20828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:33
train iter: 893
num of updates: 89400
vae loss: 0.20868
kl loss: 0.00009
a decoder loss: 0.20859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:34
train iter: 894
num of updates: 89500
vae loss: 0.20857
kl loss: 0.00009
a decoder loss: 0.20848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:35
train iter: 895
num of updates: 89600
vae loss: 0.20926
kl loss: 0.00009
a decoder loss: 0.20917
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:36
train iter: 896
num of updates: 89700
vae loss: 0.20811
kl loss: 0.00009
a decoder loss: 0.20802
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:37
train iter: 897
num of updates: 89800
vae loss: 0.20976
kl loss: 0.00009
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:38
train iter: 898
num of updates: 89900
vae loss: 0.20909
kl loss: 0.00009
a decoder loss: 0.20900
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:39
train iter: 899
num of updates: 90000
vae loss: 0.20920
kl loss: 0.00009
a decoder loss: 0.20911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:40
train iter: 900
num of updates: 90100
vae loss: 0.20822
kl loss: 0.00009
a decoder loss: 0.20813
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:41
train iter: 901
num of updates: 90200
vae loss: 0.20907
kl loss: 0.00009
a decoder loss: 0.20898
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:42
train iter: 902
num of updates: 90300
vae loss: 0.20869
kl loss: 0.00009
a decoder loss: 0.20860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:43
train iter: 903
num of updates: 90400
vae loss: 0.20878
kl loss: 0.00009
a decoder loss: 0.20869
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:44
train iter: 904
num of updates: 90500
vae loss: 0.20928
kl loss: 0.00009
a decoder loss: 0.20919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:45
train iter: 905
num of updates: 90600
vae loss: 0.20752
kl loss: 0.00009
a decoder loss: 0.20744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:46
train iter: 906
num of updates: 90700
vae loss: 0.20951
kl loss: 0.00009
a decoder loss: 0.20942
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:47
train iter: 907
num of updates: 90800
vae loss: 0.20860
kl loss: 0.00009
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:48
train iter: 908
num of updates: 90900
vae loss: 0.20832
kl loss: 0.00009
a decoder loss: 0.20823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:49
train iter: 909
num of updates: 91000
vae loss: 0.20829
kl loss: 0.00009
a decoder loss: 0.20820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:50
train iter: 910
num of updates: 91100
vae loss: 0.20929
kl loss: 0.00009
a decoder loss: 0.20920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:51
train iter: 911
num of updates: 91200
vae loss: 0.20862
kl loss: 0.00009
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:52
train iter: 912
num of updates: 91300
vae loss: 0.20977
kl loss: 0.00009
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:53
train iter: 913
num of updates: 91400
vae loss: 0.20837
kl loss: 0.00009
a decoder loss: 0.20828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:54
train iter: 914
num of updates: 91500
vae loss: 0.20899
kl loss: 0.00009
a decoder loss: 0.20890
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:55
train iter: 915
num of updates: 91600
vae loss: 0.20865
kl loss: 0.00009
a decoder loss: 0.20856
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:56
train iter: 916
num of updates: 91700
vae loss: 0.20855
kl loss: 0.00009
a decoder loss: 0.20847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:57
train iter: 917
num of updates: 91800
vae loss: 0.20901
kl loss: 0.00008
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:58
train iter: 918
num of updates: 91900
vae loss: 0.20945
kl loss: 0.00009
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:16:59
train iter: 919
num of updates: 92000
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:00
train iter: 920
num of updates: 92100
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:02
train iter: 921
num of updates: 92200
vae loss: 0.20876
kl loss: 0.00009
a decoder loss: 0.20868
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:03
train iter: 922
num of updates: 92300
vae loss: 0.20884
kl loss: 0.00008
a decoder loss: 0.20876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:04
train iter: 923
num of updates: 92400
vae loss: 0.20880
kl loss: 0.00009
a decoder loss: 0.20871
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:05
train iter: 924
num of updates: 92500
vae loss: 0.20834
kl loss: 0.00008
a decoder loss: 0.20825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:06
train iter: 925
num of updates: 92600
vae loss: 0.20916
kl loss: 0.00008
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:07
train iter: 926
num of updates: 92700
vae loss: 0.20915
kl loss: 0.00008
a decoder loss: 0.20907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:08
train iter: 927
num of updates: 92800
vae loss: 0.20846
kl loss: 0.00008
a decoder loss: 0.20838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:09
train iter: 928
num of updates: 92900
vae loss: 0.20846
kl loss: 0.00008
a decoder loss: 0.20838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:10
train iter: 929
num of updates: 93000
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20852
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:11
train iter: 930
num of updates: 93100
vae loss: 0.20863
kl loss: 0.00008
a decoder loss: 0.20854
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:12
train iter: 931
num of updates: 93200
vae loss: 0.20875
kl loss: 0.00008
a decoder loss: 0.20867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:13
train iter: 932
num of updates: 93300
vae loss: 0.20823
kl loss: 0.00008
a decoder loss: 0.20815
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:14
train iter: 933
num of updates: 93400
vae loss: 0.20927
kl loss: 0.00008
a decoder loss: 0.20918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:15
train iter: 934
num of updates: 93500
vae loss: 0.20827
kl loss: 0.00008
a decoder loss: 0.20819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:16
train iter: 935
num of updates: 93600
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:17
train iter: 936
num of updates: 93700
vae loss: 0.20898
kl loss: 0.00008
a decoder loss: 0.20890
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:18
train iter: 937
num of updates: 93800
vae loss: 0.20792
kl loss: 0.00008
a decoder loss: 0.20784
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:19
train iter: 938
num of updates: 93900
vae loss: 0.20976
kl loss: 0.00008
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:20
train iter: 939
num of updates: 94000
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20843
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:21
train iter: 940
num of updates: 94100
vae loss: 0.20882
kl loss: 0.00008
a decoder loss: 0.20874
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:22
train iter: 941
num of updates: 94200
vae loss: 0.20794
kl loss: 0.00008
a decoder loss: 0.20786
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:23
train iter: 942
num of updates: 94300
vae loss: 0.20865
kl loss: 0.00008
a decoder loss: 0.20856
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:24
train iter: 943
num of updates: 94400
vae loss: 0.20875
kl loss: 0.00008
a decoder loss: 0.20867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:25
train iter: 944
num of updates: 94500
vae loss: 0.20954
kl loss: 0.00008
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:26
train iter: 945
num of updates: 94600
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20842
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:27
train iter: 946
num of updates: 94700
vae loss: 0.20895
kl loss: 0.00008
a decoder loss: 0.20887
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:28
train iter: 947
num of updates: 94800
vae loss: 0.20814
kl loss: 0.00008
a decoder loss: 0.20806
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:29
train iter: 948
num of updates: 94900
vae loss: 0.20847
kl loss: 0.00008
a decoder loss: 0.20839
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:30
train iter: 949
num of updates: 95000
vae loss: 0.20835
kl loss: 0.00008
a decoder loss: 0.20827
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:31
train iter: 950
num of updates: 95100
vae loss: 0.20777
kl loss: 0.00008
a decoder loss: 0.20769
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:32
train iter: 951
num of updates: 95200
vae loss: 0.20923
kl loss: 0.00008
a decoder loss: 0.20915
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:33
train iter: 952
num of updates: 95300
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:34
train iter: 953
num of updates: 95400
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:35
train iter: 954
num of updates: 95500
vae loss: 0.20906
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:36
train iter: 955
num of updates: 95600
vae loss: 0.20812
kl loss: 0.00008
a decoder loss: 0.20804
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:37
train iter: 956
num of updates: 95700
vae loss: 0.20952
kl loss: 0.00008
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:38
train iter: 957
num of updates: 95800
vae loss: 0.20867
kl loss: 0.00008
a decoder loss: 0.20859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:39
train iter: 958
num of updates: 95900
vae loss: 0.20746
kl loss: 0.00008
a decoder loss: 0.20738
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:40
train iter: 959
num of updates: 96000
vae loss: 0.20838
kl loss: 0.00008
a decoder loss: 0.20830
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:41
train iter: 960
num of updates: 96100
vae loss: 0.20865
kl loss: 0.00008
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:42
train iter: 961
num of updates: 96200
vae loss: 0.20829
kl loss: 0.00008
a decoder loss: 0.20821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:43
train iter: 962
num of updates: 96300
vae loss: 0.20857
kl loss: 0.00008
a decoder loss: 0.20849
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:44
train iter: 963
num of updates: 96400
vae loss: 0.20852
kl loss: 0.00008
a decoder loss: 0.20844
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:46
train iter: 964
num of updates: 96500
vae loss: 0.20825
kl loss: 0.00008
a decoder loss: 0.20817
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:47
train iter: 965
num of updates: 96600
vae loss: 0.20905
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:48
train iter: 966
num of updates: 96700
vae loss: 0.20820
kl loss: 0.00008
a decoder loss: 0.20812
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:49
train iter: 967
num of updates: 96800
vae loss: 0.20889
kl loss: 0.00008
a decoder loss: 0.20881
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:50
train iter: 968
num of updates: 96900
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:51
train iter: 969
num of updates: 97000
vae loss: 0.20869
kl loss: 0.00008
a decoder loss: 0.20861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:52
train iter: 970
num of updates: 97100
vae loss: 0.20817
kl loss: 0.00008
a decoder loss: 0.20809
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:53
train iter: 971
num of updates: 97200
vae loss: 0.20944
kl loss: 0.00008
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:54
train iter: 972
num of updates: 97300
vae loss: 0.20902
kl loss: 0.00008
a decoder loss: 0.20894
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:55
train iter: 973
num of updates: 97400
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:56
train iter: 974
num of updates: 97500
vae loss: 0.20876
kl loss: 0.00008
a decoder loss: 0.20868
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:57
train iter: 975
num of updates: 97600
vae loss: 0.20901
kl loss: 0.00008
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:58
train iter: 976
num of updates: 97700
vae loss: 0.20796
kl loss: 0.00008
a decoder loss: 0.20788
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:17:59
train iter: 977
num of updates: 97800
vae loss: 0.20815
kl loss: 0.00008
a decoder loss: 0.20807
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:00
train iter: 978
num of updates: 97900
vae loss: 0.20850
kl loss: 0.00008
a decoder loss: 0.20842
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:01
train iter: 979
num of updates: 98000
vae loss: 0.20905
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:02
train iter: 980
num of updates: 98100
vae loss: 0.20783
kl loss: 0.00008
a decoder loss: 0.20775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:03
train iter: 981
num of updates: 98200
vae loss: 0.20880
kl loss: 0.00008
a decoder loss: 0.20872
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:04
train iter: 982
num of updates: 98300
vae loss: 0.20907
kl loss: 0.00008
a decoder loss: 0.20899
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:05
train iter: 983
num of updates: 98400
vae loss: 0.20890
kl loss: 0.00008
a decoder loss: 0.20882
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:06
train iter: 984
num of updates: 98500
vae loss: 0.20834
kl loss: 0.00008
a decoder loss: 0.20826
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:07
train iter: 985
num of updates: 98600
vae loss: 0.20821
kl loss: 0.00008
a decoder loss: 0.20813
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:08
train iter: 986
num of updates: 98700
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:09
train iter: 987
num of updates: 98800
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:10
train iter: 988
num of updates: 98900
vae loss: 0.20842
kl loss: 0.00008
a decoder loss: 0.20834
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:11
train iter: 989
num of updates: 99000
vae loss: 0.20867
kl loss: 0.00008
a decoder loss: 0.20860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:12
train iter: 990
num of updates: 99100
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20843
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:13
train iter: 991
num of updates: 99200
vae loss: 0.20858
kl loss: 0.00008
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:14
train iter: 992
num of updates: 99300
vae loss: 0.20884
kl loss: 0.00008
a decoder loss: 0.20877
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:15
train iter: 993
num of updates: 99400
vae loss: 0.20811
kl loss: 0.00008
a decoder loss: 0.20803
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:16
train iter: 994
num of updates: 99500
vae loss: 0.20864
kl loss: 0.00008
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:17
train iter: 995
num of updates: 99600
vae loss: 0.20830
kl loss: 0.00008
a decoder loss: 0.20822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:18
train iter: 996
num of updates: 99700
vae loss: 0.20773
kl loss: 0.00008
a decoder loss: 0.20765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:19
train iter: 997
num of updates: 99800
vae loss: 0.20844
kl loss: 0.00008
a decoder loss: 0.20837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:20
train iter: 998
num of updates: 99900
vae loss: 0.20813
kl loss: 0.00007
a decoder loss: 0.20806
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:18:21
train iter: 999
num of updates: 100000
vae loss: 0.20890
kl loss: 0.00008
a decoder loss: 0.20883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/vae_model_100000.pt
============================================================
finished training vae!
============================================================
started training vae at: 25-09-28-13-10-46
finished training vae at: 25-09-28-14-29-18
total vae training time: 1:18:32
saved last updated model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/vae_model
============================================================
2025-09-28 14:29:21.704231: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:29:22.858539: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 20 bytes spill stores, 20 bytes spill loads

2025-09-28 14:29:23.776392: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 40 bytes spill stores, 40 bytes spill loads

2025-09-28 14:29:25.394000: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 14:29:26.635558: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:29:29.149643: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 14:29:29.769495: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 14:29:30.108122: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 14:29:33.183358: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:29:35.801268: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 236 bytes spill stores, 236 bytes spill loads

2025-09-28 14:29:36.072076: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 404 bytes spill stores, 404 bytes spill loads

2025-09-28 14:29:37.675103: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 908 bytes spill stores, 668 bytes spill loads

2025-09-28 14:29:38.003965: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 1868 bytes spill stores, 1352 bytes spill loads

2025-09-28 14:29:38.919448: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 504 bytes spill stores, 460 bytes spill loads

2025-09-28 14:29:40.204929: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:29:41.539449: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 24 bytes spill stores, 24 bytes spill loads

num_emp_param: 547754
2025-09-28 14:29:51.593373: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:29:51.594534: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 14:29:52.708430: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_323', 232 bytes spill stores, 232 bytes spill loads

2025-09-28 14:29:54.023000: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_323', 628 bytes spill stores, 492 bytes spill loads

2025-09-28 14:29:56.815359: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_323', 388 bytes spill stores, 300 bytes spill loads

2025-09-28 14:29:59.704917: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_323', 2140 bytes spill stores, 1648 bytes spill loads

2025-09-28 14:29:59.927987: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_277', 4 bytes spill stores, 4 bytes spill loads

2025-09-28 14:30:00.363006: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_277', 4 bytes spill stores, 4 bytes spill loads

2025-09-28 14:30:00.731302: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_323', 80 bytes spill stores, 80 bytes spill loads

2025-09-28 14:30:01.330361: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_277', 200 bytes spill stores, 200 bytes spill loads

2025-09-28 14:30:03.420802: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_278', 268 bytes spill stores, 268 bytes spill loads

2025-09-28 14:30:04.053766: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_331', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 14:30:04.837852: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_331', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 14:30:05.134466: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_277', 12 bytes spill stores, 12 bytes spill loads

2025-09-28 14:30:06.482129: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_277', 116 bytes spill stores, 116 bytes spill loads

2025-09-28 14:30:08.362062: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_278', 76 bytes spill stores, 76 bytes spill loads

2025-09-28 14:30:08.551353: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_282', 84 bytes spill stores, 84 bytes spill loads

2025-09-28 14:30:12.446855: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_286', 28 bytes spill stores, 28 bytes spill loads

2025-09-28 14:30:16.165198: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_285', 8 bytes spill stores, 8 bytes spill loads

2025-09-28 14:30:27.943795: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion', 24 bytes spill stores, 24 bytes spill loads

============================================================
time elapsed: 1:19:44
train iter: 0
num of updates: 100
emp loss: 40.46308

saving current model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/emp_model_100.pt
============================================================
time elapsed: 1:19:51
train iter: 1
num of updates: 200
emp loss: 40.36184

============================================================
time elapsed: 1:19:53
train iter: 2
num of updates: 300
emp loss: 40.12481

============================================================
time elapsed: 1:19:55
train iter: 3
num of updates: 400
emp loss: 39.89246

============================================================
time elapsed: 1:19:57
train iter: 4
num of updates: 500
emp loss: 39.53239

============================================================
time elapsed: 1:20:00
train iter: 5
num of updates: 600
emp loss: 39.14986

============================================================
time elapsed: 1:20:02
train iter: 6
num of updates: 700
emp loss: 38.52318

============================================================
time elapsed: 1:20:04
train iter: 7
num of updates: 800
emp loss: 37.94902

============================================================
time elapsed: 1:20:06
train iter: 8
num of updates: 900
emp loss: 37.22723

============================================================
time elapsed: 1:20:08
train iter: 9
num of updates: 1000
emp loss: 36.44503

============================================================
time elapsed: 1:20:11
train iter: 10
num of updates: 1100
emp loss: 35.63821

============================================================
time elapsed: 1:20:13
train iter: 11
num of updates: 1200
emp loss: 34.74172

============================================================
time elapsed: 1:20:15
train iter: 12
num of updates: 1300
emp loss: 33.76648

============================================================
time elapsed: 1:20:17
train iter: 13
num of updates: 1400
emp loss: 32.79248

============================================================
time elapsed: 1:20:20
train iter: 14
num of updates: 1500
emp loss: 31.63160

============================================================
time elapsed: 1:20:22
train iter: 15
num of updates: 1600
emp loss: 30.53161

============================================================
time elapsed: 1:20:24
train iter: 16
num of updates: 1700
emp loss: 29.49644

============================================================
time elapsed: 1:20:26
train iter: 17
num of updates: 1800
emp loss: 28.30467

============================================================
time elapsed: 1:20:29
train iter: 18
num of updates: 1900
emp loss: 27.07133

============================================================
time elapsed: 1:20:31
train iter: 19
num of updates: 2000
emp loss: 25.85142

============================================================
time elapsed: 1:20:33
train iter: 20
num of updates: 2100
emp loss: 24.58060

============================================================
time elapsed: 1:20:35
train iter: 21
num of updates: 2200
emp loss: 23.44870

============================================================
time elapsed: 1:20:37
train iter: 22
num of updates: 2300
emp loss: 22.22241

============================================================
time elapsed: 1:20:40
train iter: 23
num of updates: 2400
emp loss: 21.00018

============================================================
time elapsed: 1:20:42
train iter: 24
num of updates: 2500
emp loss: 19.77592

============================================================
time elapsed: 1:20:44
train iter: 25
num of updates: 2600
emp loss: 18.54813

============================================================
time elapsed: 1:20:46
train iter: 26
num of updates: 2700
emp loss: 17.39050

============================================================
time elapsed: 1:20:49
train iter: 27
num of updates: 2800
emp loss: 16.23478

============================================================
time elapsed: 1:20:51
train iter: 28
num of updates: 2900
emp loss: 15.15709

============================================================
time elapsed: 1:20:53
train iter: 29
num of updates: 3000
emp loss: 14.12028

============================================================
time elapsed: 1:20:55
train iter: 30
num of updates: 3100
emp loss: 13.11728

============================================================
time elapsed: 1:20:57
train iter: 31
num of updates: 3200
emp loss: 12.17481

============================================================
time elapsed: 1:21:00
train iter: 32
num of updates: 3300
emp loss: 11.26307

============================================================
time elapsed: 1:21:02
train iter: 33
num of updates: 3400
emp loss: 10.36471

============================================================
time elapsed: 1:21:04
train iter: 34
num of updates: 3500
emp loss: 9.58168

============================================================
time elapsed: 1:21:06
train iter: 35
num of updates: 3600
emp loss: 8.86039

============================================================
time elapsed: 1:21:09
train iter: 36
num of updates: 3700
emp loss: 8.14127

============================================================
time elapsed: 1:21:11
train iter: 37
num of updates: 3800
emp loss: 7.53641

============================================================
time elapsed: 1:21:13
train iter: 38
num of updates: 3900
emp loss: 6.94782

============================================================
time elapsed: 1:21:15
train iter: 39
num of updates: 4000
emp loss: 6.40822

============================================================
time elapsed: 1:21:18
train iter: 40
num of updates: 4100
emp loss: 5.92603

============================================================
time elapsed: 1:21:20
train iter: 41
num of updates: 4200
emp loss: 5.49966

============================================================
time elapsed: 1:21:22
train iter: 42
num of updates: 4300
emp loss: 5.10154

============================================================
time elapsed: 1:21:24
train iter: 43
num of updates: 4400
emp loss: 4.74149

============================================================
time elapsed: 1:21:26
train iter: 44
num of updates: 4500
emp loss: 4.43916

============================================================
time elapsed: 1:21:29
train iter: 45
num of updates: 4600
emp loss: 4.16919

============================================================
time elapsed: 1:21:31
train iter: 46
num of updates: 4700
emp loss: 3.92048

============================================================
time elapsed: 1:21:33
train iter: 47
num of updates: 4800
emp loss: 3.70340

============================================================
time elapsed: 1:21:35
train iter: 48
num of updates: 4900
emp loss: 3.50583

============================================================
time elapsed: 1:21:38
train iter: 49
num of updates: 5000
emp loss: 3.35027

============================================================
time elapsed: 1:21:40
train iter: 50
num of updates: 5100
emp loss: 3.19752

============================================================
time elapsed: 1:21:42
train iter: 51
num of updates: 5200
emp loss: 3.06952

============================================================
time elapsed: 1:21:44
train iter: 52
num of updates: 5300
emp loss: 2.96029

============================================================
time elapsed: 1:21:46
train iter: 53
num of updates: 5400
emp loss: 2.85849

============================================================
time elapsed: 1:21:49
train iter: 54
num of updates: 5500
emp loss: 2.77209

============================================================
time elapsed: 1:21:51
train iter: 55
num of updates: 5600
emp loss: 2.69625

============================================================
time elapsed: 1:21:53
train iter: 56
num of updates: 5700
emp loss: 2.63066

============================================================
time elapsed: 1:21:55
train iter: 57
num of updates: 5800
emp loss: 2.57755

============================================================
time elapsed: 1:21:58
train iter: 58
num of updates: 5900
emp loss: 2.52530

============================================================
time elapsed: 1:22:00
train iter: 59
num of updates: 6000
emp loss: 2.48598

============================================================
time elapsed: 1:22:02
train iter: 60
num of updates: 6100
emp loss: 2.44688

============================================================
time elapsed: 1:22:04
train iter: 61
num of updates: 6200
emp loss: 2.40970

============================================================
time elapsed: 1:22:07
train iter: 62
num of updates: 6300
emp loss: 2.38696

============================================================
time elapsed: 1:22:09
train iter: 63
num of updates: 6400
emp loss: 2.35882

============================================================
time elapsed: 1:22:11
train iter: 64
num of updates: 6500
emp loss: 2.33737

============================================================
time elapsed: 1:22:13
train iter: 65
num of updates: 6600
emp loss: 2.31593

============================================================
time elapsed: 1:22:15
train iter: 66
num of updates: 6700
emp loss: 2.30110

============================================================
time elapsed: 1:22:18
train iter: 67
num of updates: 6800
emp loss: 2.28537

============================================================
time elapsed: 1:22:20
train iter: 68
num of updates: 6900
emp loss: 2.27326

============================================================
time elapsed: 1:22:22
train iter: 69
num of updates: 7000
emp loss: 2.26513

============================================================
time elapsed: 1:22:24
train iter: 70
num of updates: 7100
emp loss: 2.25697

============================================================
time elapsed: 1:22:27
train iter: 71
num of updates: 7200
emp loss: 2.24842

============================================================
time elapsed: 1:22:29
train iter: 72
num of updates: 7300
emp loss: 2.23626

============================================================
time elapsed: 1:22:31
train iter: 73
num of updates: 7400
emp loss: 2.23316

============================================================
time elapsed: 1:22:33
train iter: 74
num of updates: 7500
emp loss: 2.23050

============================================================
time elapsed: 1:22:35
train iter: 75
num of updates: 7600
emp loss: 2.22673

============================================================
time elapsed: 1:22:38
train iter: 76
num of updates: 7700
emp loss: 2.22186

============================================================
time elapsed: 1:22:40
train iter: 77
num of updates: 7800
emp loss: 2.21485

============================================================
time elapsed: 1:22:42
train iter: 78
num of updates: 7900
emp loss: 2.20978

============================================================
time elapsed: 1:22:44
train iter: 79
num of updates: 8000
emp loss: 2.21213

============================================================
time elapsed: 1:22:47
train iter: 80
num of updates: 8100
emp loss: 2.20739

============================================================
time elapsed: 1:22:49
train iter: 81
num of updates: 8200
emp loss: 2.20721

============================================================
time elapsed: 1:22:51
train iter: 82
num of updates: 8300
emp loss: 2.20539

============================================================
time elapsed: 1:22:53
train iter: 83
num of updates: 8400
emp loss: 2.20329

============================================================
time elapsed: 1:22:56
train iter: 84
num of updates: 8500
emp loss: 2.20056

============================================================
time elapsed: 1:22:58
train iter: 85
num of updates: 8600
emp loss: 2.20138

============================================================
time elapsed: 1:23:00
train iter: 86
num of updates: 8700
emp loss: 2.19777

============================================================
time elapsed: 1:23:02
train iter: 87
num of updates: 8800
emp loss: 2.19667

============================================================
time elapsed: 1:23:05
train iter: 88
num of updates: 8900
emp loss: 2.19844

============================================================
time elapsed: 1:23:07
train iter: 89
num of updates: 9000
emp loss: 2.19306

============================================================
time elapsed: 1:23:09
train iter: 90
num of updates: 9100
emp loss: 2.19132

============================================================
time elapsed: 1:23:11
train iter: 91
num of updates: 9200
emp loss: 2.18655

============================================================
time elapsed: 1:23:13
train iter: 92
num of updates: 9300
emp loss: 2.18875

============================================================
time elapsed: 1:23:16
train iter: 93
num of updates: 9400
emp loss: 2.18703

============================================================
time elapsed: 1:23:18
train iter: 94
num of updates: 9500
emp loss: 2.18517

============================================================
time elapsed: 1:23:20
train iter: 95
num of updates: 9600
emp loss: 2.18785

============================================================
time elapsed: 1:23:22
train iter: 96
num of updates: 9700
emp loss: 2.18306

============================================================
time elapsed: 1:23:25
train iter: 97
num of updates: 9800
emp loss: 2.18048

============================================================
time elapsed: 1:23:27
train iter: 98
num of updates: 9900
emp loss: 2.18114

============================================================
time elapsed: 1:23:29
train iter: 99
num of updates: 10000
emp loss: 2.18008

============================================================
time elapsed: 1:23:31
train iter: 100
num of updates: 10100
emp loss: 2.17640

============================================================
time elapsed: 1:23:33
train iter: 101
num of updates: 10200
emp loss: 2.18146

============================================================
time elapsed: 1:23:36
train iter: 102
num of updates: 10300
emp loss: 2.17679

============================================================
time elapsed: 1:23:38
train iter: 103
num of updates: 10400
emp loss: 2.17695

============================================================
time elapsed: 1:23:40
train iter: 104
num of updates: 10500
emp loss: 2.17341

============================================================
time elapsed: 1:23:42
train iter: 105
num of updates: 10600
emp loss: 2.17228

============================================================
time elapsed: 1:23:45
train iter: 106
num of updates: 10700
emp loss: 2.17302

============================================================
time elapsed: 1:23:47
train iter: 107
num of updates: 10800
emp loss: 2.17301

============================================================
time elapsed: 1:23:49
train iter: 108
num of updates: 10900
emp loss: 2.17136

============================================================
time elapsed: 1:23:51
train iter: 109
num of updates: 11000
emp loss: 2.16909

============================================================
time elapsed: 1:23:54
train iter: 110
num of updates: 11100
emp loss: 2.16732

============================================================
time elapsed: 1:23:56
train iter: 111
num of updates: 11200
emp loss: 2.16864

============================================================
time elapsed: 1:23:58
train iter: 112
num of updates: 11300
emp loss: 2.16890

============================================================
time elapsed: 1:24:00
train iter: 113
num of updates: 11400
emp loss: 2.16366

============================================================
time elapsed: 1:24:02
train iter: 114
num of updates: 11500
emp loss: 2.16510

============================================================
time elapsed: 1:24:05
train iter: 115
num of updates: 11600
emp loss: 2.16484

============================================================
time elapsed: 1:24:07
train iter: 116
num of updates: 11700
emp loss: 2.16663

============================================================
time elapsed: 1:24:09
train iter: 117
num of updates: 11800
emp loss: 2.16365

============================================================
time elapsed: 1:24:11
train iter: 118
num of updates: 11900
emp loss: 2.16238

============================================================
time elapsed: 1:24:14
train iter: 119
num of updates: 12000
emp loss: 2.16486

============================================================
time elapsed: 1:24:16
train iter: 120
num of updates: 12100
emp loss: 2.15961

============================================================
time elapsed: 1:24:18
train iter: 121
num of updates: 12200
emp loss: 2.16082

============================================================
time elapsed: 1:24:20
train iter: 122
num of updates: 12300
emp loss: 2.16434

============================================================
time elapsed: 1:24:23
train iter: 123
num of updates: 12400
emp loss: 2.16041

============================================================
time elapsed: 1:24:25
train iter: 124
num of updates: 12500
emp loss: 2.15919

============================================================
time elapsed: 1:24:27
train iter: 125
num of updates: 12600
emp loss: 2.15827

============================================================
time elapsed: 1:24:29
train iter: 126
num of updates: 12700
emp loss: 2.16010

============================================================
time elapsed: 1:24:31
train iter: 127
num of updates: 12800
emp loss: 2.15949

============================================================
time elapsed: 1:24:34
train iter: 128
num of updates: 12900
emp loss: 2.15487

============================================================
time elapsed: 1:24:36
train iter: 129
num of updates: 13000
emp loss: 2.15904

============================================================
time elapsed: 1:24:38
train iter: 130
num of updates: 13100
emp loss: 2.15988

============================================================
time elapsed: 1:24:40
train iter: 131
num of updates: 13200
emp loss: 2.15548

============================================================
time elapsed: 1:24:43
train iter: 132
num of updates: 13300
emp loss: 2.15800

============================================================
time elapsed: 1:24:45
train iter: 133
num of updates: 13400
emp loss: 2.15787

============================================================
time elapsed: 1:24:47
train iter: 134
num of updates: 13500
emp loss: 2.15420

============================================================
time elapsed: 1:24:49
train iter: 135
num of updates: 13600
emp loss: 2.15254

============================================================
time elapsed: 1:24:51
train iter: 136
num of updates: 13700
emp loss: 2.15260

============================================================
time elapsed: 1:24:54
train iter: 137
num of updates: 13800
emp loss: 2.15604

============================================================
time elapsed: 1:24:56
train iter: 138
num of updates: 13900
emp loss: 2.15548

============================================================
time elapsed: 1:24:58
train iter: 139
num of updates: 14000
emp loss: 2.15512

============================================================
time elapsed: 1:25:00
train iter: 140
num of updates: 14100
emp loss: 2.15631

============================================================
time elapsed: 1:25:03
train iter: 141
num of updates: 14200
emp loss: 2.15080

============================================================
time elapsed: 1:25:05
train iter: 142
num of updates: 14300
emp loss: 2.15545

============================================================
time elapsed: 1:25:07
train iter: 143
num of updates: 14400
emp loss: 2.15178

============================================================
time elapsed: 1:25:09
train iter: 144
num of updates: 14500
emp loss: 2.14888

============================================================
time elapsed: 1:25:12
train iter: 145
num of updates: 14600
emp loss: 2.15119

============================================================
time elapsed: 1:25:14
train iter: 146
num of updates: 14700
emp loss: 2.15004

============================================================
time elapsed: 1:25:16
train iter: 147
num of updates: 14800
emp loss: 2.15086

============================================================
time elapsed: 1:25:18
train iter: 148
num of updates: 14900
emp loss: 2.15295

============================================================
time elapsed: 1:25:21
train iter: 149
num of updates: 15000
emp loss: 2.15316

============================================================
time elapsed: 1:25:23
train iter: 150
num of updates: 15100
emp loss: 2.15074

============================================================
time elapsed: 1:25:25
train iter: 151
num of updates: 15200
emp loss: 2.14870

============================================================
time elapsed: 1:25:27
train iter: 152
num of updates: 15300
emp loss: 2.14901

============================================================
time elapsed: 1:25:29
train iter: 153
num of updates: 15400
emp loss: 2.14974

============================================================
time elapsed: 1:25:32
train iter: 154
num of updates: 15500
emp loss: 2.14718

============================================================
time elapsed: 1:25:34
train iter: 155
num of updates: 15600
emp loss: 2.15043

============================================================
time elapsed: 1:25:36
train iter: 156
num of updates: 15700
emp loss: 2.14971

============================================================
time elapsed: 1:25:38
train iter: 157
num of updates: 15800
emp loss: 2.15080

============================================================
time elapsed: 1:25:41
train iter: 158
num of updates: 15900
emp loss: 2.14878

============================================================
time elapsed: 1:25:43
train iter: 159
num of updates: 16000
emp loss: 2.14663

============================================================
time elapsed: 1:25:45
train iter: 160
num of updates: 16100
emp loss: 2.14589

============================================================
time elapsed: 1:25:47
train iter: 161
num of updates: 16200
emp loss: 2.14885

============================================================
time elapsed: 1:25:50
train iter: 162
num of updates: 16300
emp loss: 2.14591

============================================================
time elapsed: 1:25:52
train iter: 163
num of updates: 16400
emp loss: 2.14825

============================================================
time elapsed: 1:25:54
train iter: 164
num of updates: 16500
emp loss: 2.14564

============================================================
time elapsed: 1:25:56
train iter: 165
num of updates: 16600
emp loss: 2.14793

============================================================
time elapsed: 1:25:58
train iter: 166
num of updates: 16700
emp loss: 2.14374

============================================================
time elapsed: 1:26:01
train iter: 167
num of updates: 16800
emp loss: 2.14987

============================================================
time elapsed: 1:26:03
train iter: 168
num of updates: 16900
emp loss: 2.14684

============================================================
time elapsed: 1:26:05
train iter: 169
num of updates: 17000
emp loss: 2.14413

============================================================
time elapsed: 1:26:07
train iter: 170
num of updates: 17100
emp loss: 2.14634

============================================================
time elapsed: 1:26:10
train iter: 171
num of updates: 17200
emp loss: 2.14593

============================================================
time elapsed: 1:26:12
train iter: 172
num of updates: 17300
emp loss: 2.14499

============================================================
time elapsed: 1:26:14
train iter: 173
num of updates: 17400
emp loss: 2.14577

============================================================
time elapsed: 1:26:16
train iter: 174
num of updates: 17500
emp loss: 2.14299

============================================================
time elapsed: 1:26:19
train iter: 175
num of updates: 17600
emp loss: 2.14582

============================================================
time elapsed: 1:26:21
train iter: 176
num of updates: 17700
emp loss: 2.14477

============================================================
time elapsed: 1:26:23
train iter: 177
num of updates: 17800
emp loss: 2.14673

============================================================
time elapsed: 1:26:25
train iter: 178
num of updates: 17900
emp loss: 2.14481

============================================================
time elapsed: 1:26:28
train iter: 179
num of updates: 18000
emp loss: 2.14468

============================================================
time elapsed: 1:26:30
train iter: 180
num of updates: 18100
emp loss: 2.14378

============================================================
time elapsed: 1:26:32
train iter: 181
num of updates: 18200
emp loss: 2.14396

============================================================
time elapsed: 1:26:34
train iter: 182
num of updates: 18300
emp loss: 2.14605

============================================================
time elapsed: 1:26:37
train iter: 183
num of updates: 18400
emp loss: 2.14183

============================================================
time elapsed: 1:26:39
train iter: 184
num of updates: 18500
emp loss: 2.14473

============================================================
time elapsed: 1:26:41
train iter: 185
num of updates: 18600
emp loss: 2.14255

============================================================
time elapsed: 1:26:43
train iter: 186
num of updates: 18700
emp loss: 2.14143

============================================================
time elapsed: 1:26:45
train iter: 187
num of updates: 18800
emp loss: 2.14122

============================================================
time elapsed: 1:26:48
train iter: 188
num of updates: 18900
emp loss: 2.14375

============================================================
time elapsed: 1:26:50
train iter: 189
num of updates: 19000
emp loss: 2.14274

============================================================
time elapsed: 1:26:52
train iter: 190
num of updates: 19100
emp loss: 2.14740

============================================================
time elapsed: 1:26:54
train iter: 191
num of updates: 19200
emp loss: 2.14747

============================================================
time elapsed: 1:26:57
train iter: 192
num of updates: 19300
emp loss: 2.14478

============================================================
time elapsed: 1:26:59
train iter: 193
num of updates: 19400
emp loss: 2.14150

============================================================
time elapsed: 1:27:01
train iter: 194
num of updates: 19500
emp loss: 2.14448

============================================================
time elapsed: 1:27:03
train iter: 195
num of updates: 19600
emp loss: 2.14400

============================================================
time elapsed: 1:27:06
train iter: 196
num of updates: 19700
emp loss: 2.14492

============================================================
time elapsed: 1:27:08
train iter: 197
num of updates: 19800
emp loss: 2.14288

============================================================
time elapsed: 1:27:10
train iter: 198
num of updates: 19900
emp loss: 2.14329

============================================================
time elapsed: 1:27:12
train iter: 199
num of updates: 20000
emp loss: 2.14159

============================================================
time elapsed: 1:27:15
train iter: 200
num of updates: 20100
emp loss: 2.14485

============================================================
time elapsed: 1:27:17
train iter: 201
num of updates: 20200
emp loss: 2.14464

============================================================
time elapsed: 1:27:19
train iter: 202
num of updates: 20300
emp loss: 2.14391

============================================================
time elapsed: 1:27:21
train iter: 203
num of updates: 20400
emp loss: 2.13897

============================================================
time elapsed: 1:27:23
train iter: 204
num of updates: 20500
emp loss: 2.14424

============================================================
time elapsed: 1:27:26
train iter: 205
num of updates: 20600
emp loss: 2.14462

============================================================
time elapsed: 1:27:28
train iter: 206
num of updates: 20700
emp loss: 2.14331

============================================================
time elapsed: 1:27:30
train iter: 207
num of updates: 20800
emp loss: 2.13965

============================================================
time elapsed: 1:27:32
train iter: 208
num of updates: 20900
emp loss: 2.13842

============================================================
time elapsed: 1:27:35
train iter: 209
num of updates: 21000
emp loss: 2.14280

============================================================
time elapsed: 1:27:37
train iter: 210
num of updates: 21100
emp loss: 2.14142

============================================================
time elapsed: 1:27:39
train iter: 211
num of updates: 21200
emp loss: 2.14319

============================================================
time elapsed: 1:27:41
train iter: 212
num of updates: 21300
emp loss: 2.14129

============================================================
time elapsed: 1:27:44
train iter: 213
num of updates: 21400
emp loss: 2.14379

============================================================
time elapsed: 1:27:46
train iter: 214
num of updates: 21500
emp loss: 2.13951

============================================================
time elapsed: 1:27:48
train iter: 215
num of updates: 21600
emp loss: 2.14116

============================================================
time elapsed: 1:27:50
train iter: 216
num of updates: 21700
emp loss: 2.14120

============================================================
time elapsed: 1:27:53
train iter: 217
num of updates: 21800
emp loss: 2.14308

============================================================
time elapsed: 1:27:55
train iter: 218
num of updates: 21900
emp loss: 2.13817

============================================================
time elapsed: 1:27:57
train iter: 219
num of updates: 22000
emp loss: 2.13793

============================================================
time elapsed: 1:27:59
train iter: 220
num of updates: 22100
emp loss: 2.14165

============================================================
time elapsed: 1:28:02
train iter: 221
num of updates: 22200
emp loss: 2.14185

============================================================
time elapsed: 1:28:04
train iter: 222
num of updates: 22300
emp loss: 2.13762

============================================================
time elapsed: 1:28:06
train iter: 223
num of updates: 22400
emp loss: 2.14471

============================================================
time elapsed: 1:28:08
train iter: 224
num of updates: 22500
emp loss: 2.14205

============================================================
time elapsed: 1:28:10
train iter: 225
num of updates: 22600
emp loss: 2.14267

============================================================
time elapsed: 1:28:13
train iter: 226
num of updates: 22700
emp loss: 2.14411

============================================================
time elapsed: 1:28:15
train iter: 227
num of updates: 22800
emp loss: 2.14074

============================================================
time elapsed: 1:28:17
train iter: 228
num of updates: 22900
emp loss: 2.14025

============================================================
time elapsed: 1:28:19
train iter: 229
num of updates: 23000
emp loss: 2.13994

============================================================
time elapsed: 1:28:22
train iter: 230
num of updates: 23100
emp loss: 2.13982

============================================================
time elapsed: 1:28:24
train iter: 231
num of updates: 23200
emp loss: 2.14209

============================================================
time elapsed: 1:28:26
train iter: 232
num of updates: 23300
emp loss: 2.13890

============================================================
time elapsed: 1:28:28
train iter: 233
num of updates: 23400
emp loss: 2.13850

============================================================
time elapsed: 1:28:31
train iter: 234
num of updates: 23500
emp loss: 2.14039

============================================================
time elapsed: 1:28:33
train iter: 235
num of updates: 23600
emp loss: 2.13987

============================================================
time elapsed: 1:28:35
train iter: 236
num of updates: 23700
emp loss: 2.14077

============================================================
time elapsed: 1:28:37
train iter: 237
num of updates: 23800
emp loss: 2.14112

============================================================
time elapsed: 1:28:40
train iter: 238
num of updates: 23900
emp loss: 2.13866

============================================================
time elapsed: 1:28:42
train iter: 239
num of updates: 24000
emp loss: 2.13822

============================================================
time elapsed: 1:28:44
train iter: 240
num of updates: 24100
emp loss: 2.13954

============================================================
time elapsed: 1:28:46
train iter: 241
num of updates: 24200
emp loss: 2.13579

============================================================
time elapsed: 1:28:49
train iter: 242
num of updates: 24300
emp loss: 2.14234

============================================================
time elapsed: 1:28:51
train iter: 243
num of updates: 24400
emp loss: 2.14028

============================================================
time elapsed: 1:28:53
train iter: 244
num of updates: 24500
emp loss: 2.13909

============================================================
time elapsed: 1:28:55
train iter: 245
num of updates: 24600
emp loss: 2.13801

============================================================
time elapsed: 1:28:57
train iter: 246
num of updates: 24700
emp loss: 2.13981

============================================================
time elapsed: 1:29:00
train iter: 247
num of updates: 24800
emp loss: 2.13824

============================================================
time elapsed: 1:29:02
train iter: 248
num of updates: 24900
emp loss: 2.14059

============================================================
time elapsed: 1:29:04
train iter: 249
num of updates: 25000
emp loss: 2.13814

============================================================
time elapsed: 1:29:06
train iter: 250
num of updates: 25100
emp loss: 2.13791

============================================================
time elapsed: 1:29:09
train iter: 251
num of updates: 25200
emp loss: 2.13859

============================================================
time elapsed: 1:29:11
train iter: 252
num of updates: 25300
emp loss: 2.14168

============================================================
time elapsed: 1:29:13
train iter: 253
num of updates: 25400
emp loss: 2.13954

============================================================
time elapsed: 1:29:15
train iter: 254
num of updates: 25500
emp loss: 2.13981

============================================================
time elapsed: 1:29:18
train iter: 255
num of updates: 25600
emp loss: 2.13793

============================================================
time elapsed: 1:29:20
train iter: 256
num of updates: 25700
emp loss: 2.13814

============================================================
time elapsed: 1:29:22
train iter: 257
num of updates: 25800
emp loss: 2.14084

============================================================
time elapsed: 1:29:24
train iter: 258
num of updates: 25900
emp loss: 2.13943

============================================================
time elapsed: 1:29:27
train iter: 259
num of updates: 26000
emp loss: 2.13777

============================================================
time elapsed: 1:29:29
train iter: 260
num of updates: 26100
emp loss: 2.13515

============================================================
time elapsed: 1:29:31
train iter: 261
num of updates: 26200
emp loss: 2.13768

============================================================
time elapsed: 1:29:33
train iter: 262
num of updates: 26300
emp loss: 2.13659

============================================================
time elapsed: 1:29:35
train iter: 263
num of updates: 26400
emp loss: 2.13856

============================================================
time elapsed: 1:29:38
train iter: 264
num of updates: 26500
emp loss: 2.13816

============================================================
time elapsed: 1:29:40
train iter: 265
num of updates: 26600
emp loss: 2.13845

============================================================
time elapsed: 1:29:42
train iter: 266
num of updates: 26700
emp loss: 2.13618

============================================================
time elapsed: 1:29:44
train iter: 267
num of updates: 26800
emp loss: 2.13864

============================================================
time elapsed: 1:29:47
train iter: 268
num of updates: 26900
emp loss: 2.13862

============================================================
time elapsed: 1:29:49
train iter: 269
num of updates: 27000
emp loss: 2.13789

============================================================
time elapsed: 1:29:51
train iter: 270
num of updates: 27100
emp loss: 2.13684

============================================================
time elapsed: 1:29:53
train iter: 271
num of updates: 27200
emp loss: 2.13862

============================================================
time elapsed: 1:29:56
train iter: 272
num of updates: 27300
emp loss: 2.13991

============================================================
time elapsed: 1:29:58
train iter: 273
num of updates: 27400
emp loss: 2.13751

============================================================
time elapsed: 1:30:00
train iter: 274
num of updates: 27500
emp loss: 2.13513

============================================================
time elapsed: 1:30:02
train iter: 275
num of updates: 27600
emp loss: 2.14078

============================================================
time elapsed: 1:30:05
train iter: 276
num of updates: 27700
emp loss: 2.13766

============================================================
time elapsed: 1:30:07
train iter: 277
num of updates: 27800
emp loss: 2.13731

============================================================
time elapsed: 1:30:09
train iter: 278
num of updates: 27900
emp loss: 2.13368

============================================================
time elapsed: 1:30:11
train iter: 279
num of updates: 28000
emp loss: 2.13796

============================================================
time elapsed: 1:30:14
train iter: 280
num of updates: 28100
emp loss: 2.13797

============================================================
time elapsed: 1:30:16
train iter: 281
num of updates: 28200
emp loss: 2.13529

============================================================
time elapsed: 1:30:18
train iter: 282
num of updates: 28300
emp loss: 2.13889

============================================================
time elapsed: 1:30:20
train iter: 283
num of updates: 28400
emp loss: 2.13437

============================================================
time elapsed: 1:30:22
train iter: 284
num of updates: 28500
emp loss: 2.13612

============================================================
time elapsed: 1:30:25
train iter: 285
num of updates: 28600
emp loss: 2.13758

============================================================
time elapsed: 1:30:27
train iter: 286
num of updates: 28700
emp loss: 2.13805

============================================================
time elapsed: 1:30:29
train iter: 287
num of updates: 28800
emp loss: 2.13663

============================================================
time elapsed: 1:30:31
train iter: 288
num of updates: 28900
emp loss: 2.13668

============================================================
time elapsed: 1:30:34
train iter: 289
num of updates: 29000
emp loss: 2.13766

============================================================
time elapsed: 1:30:36
train iter: 290
num of updates: 29100
emp loss: 2.13820

============================================================
time elapsed: 1:30:38
train iter: 291
num of updates: 29200
emp loss: 2.13385

============================================================
time elapsed: 1:30:40
train iter: 292
num of updates: 29300
emp loss: 2.13782

============================================================
time elapsed: 1:30:43
train iter: 293
num of updates: 29400
emp loss: 2.13749

============================================================
time elapsed: 1:30:45
train iter: 294
num of updates: 29500
emp loss: 2.13937

============================================================
time elapsed: 1:30:47
train iter: 295
num of updates: 29600
emp loss: 2.13703

============================================================
time elapsed: 1:30:49
train iter: 296
num of updates: 29700
emp loss: 2.13520

============================================================
time elapsed: 1:30:52
train iter: 297
num of updates: 29800
emp loss: 2.13615

============================================================
time elapsed: 1:30:54
train iter: 298
num of updates: 29900
emp loss: 2.13426

============================================================
time elapsed: 1:30:56
train iter: 299
num of updates: 30000
emp loss: 2.13616

============================================================
time elapsed: 1:30:58
train iter: 300
num of updates: 30100
emp loss: 2.13596

============================================================
time elapsed: 1:31:01
train iter: 301
num of updates: 30200
emp loss: 2.13856

============================================================
time elapsed: 1:31:03
train iter: 302
num of updates: 30300
emp loss: 2.13637

============================================================
time elapsed: 1:31:05
train iter: 303
num of updates: 30400
emp loss: 2.13780

============================================================
time elapsed: 1:31:07
train iter: 304
num of updates: 30500
emp loss: 2.13738

============================================================
time elapsed: 1:31:09
train iter: 305
num of updates: 30600
emp loss: 2.13859

============================================================
time elapsed: 1:31:12
train iter: 306
num of updates: 30700
emp loss: 2.13491

============================================================
time elapsed: 1:31:14
train iter: 307
num of updates: 30800
emp loss: 2.13058

============================================================
time elapsed: 1:31:16
train iter: 308
num of updates: 30900
emp loss: 2.13822

============================================================
time elapsed: 1:31:18
train iter: 309
num of updates: 31000
emp loss: 2.13337

============================================================
time elapsed: 1:31:21
train iter: 310
num of updates: 31100
emp loss: 2.13749

============================================================
time elapsed: 1:31:23
train iter: 311
num of updates: 31200
emp loss: 2.13437

============================================================
time elapsed: 1:31:25
train iter: 312
num of updates: 31300
emp loss: 2.13673

============================================================
time elapsed: 1:31:27
train iter: 313
num of updates: 31400
emp loss: 2.13490

============================================================
time elapsed: 1:31:30
train iter: 314
num of updates: 31500
emp loss: 2.13845

============================================================
time elapsed: 1:31:32
train iter: 315
num of updates: 31600
emp loss: 2.13484

============================================================
time elapsed: 1:31:34
train iter: 316
num of updates: 31700
emp loss: 2.13390

============================================================
time elapsed: 1:31:36
train iter: 317
num of updates: 31800
emp loss: 2.13827

============================================================
time elapsed: 1:31:39
train iter: 318
num of updates: 31900
emp loss: 2.13527

============================================================
time elapsed: 1:31:41
train iter: 319
num of updates: 32000
emp loss: 2.13971

============================================================
time elapsed: 1:31:43
train iter: 320
num of updates: 32100
emp loss: 2.13757

============================================================
time elapsed: 1:31:45
train iter: 321
num of updates: 32200
emp loss: 2.13532

============================================================
time elapsed: 1:31:48
train iter: 322
num of updates: 32300
emp loss: 2.13820

============================================================
time elapsed: 1:31:50
train iter: 323
num of updates: 32400
emp loss: 2.13586

============================================================
time elapsed: 1:31:52
train iter: 324
num of updates: 32500
emp loss: 2.13581

============================================================
time elapsed: 1:31:54
train iter: 325
num of updates: 32600
emp loss: 2.13615

============================================================
time elapsed: 1:31:56
train iter: 326
num of updates: 32700
emp loss: 2.13483

============================================================
time elapsed: 1:31:59
train iter: 327
num of updates: 32800
emp loss: 2.13290

============================================================
time elapsed: 1:32:01
train iter: 328
num of updates: 32900
emp loss: 2.13870

============================================================
time elapsed: 1:32:03
train iter: 329
num of updates: 33000
emp loss: 2.13531

============================================================
time elapsed: 1:32:05
train iter: 330
num of updates: 33100
emp loss: 2.13448

============================================================
time elapsed: 1:32:08
train iter: 331
num of updates: 33200
emp loss: 2.13610

============================================================
time elapsed: 1:32:10
train iter: 332
num of updates: 33300
emp loss: 2.13489

============================================================
time elapsed: 1:32:12
train iter: 333
num of updates: 33400
emp loss: 2.13628

============================================================
time elapsed: 1:32:14
train iter: 334
num of updates: 33500
emp loss: 2.13394

============================================================
time elapsed: 1:32:17
train iter: 335
num of updates: 33600
emp loss: 2.13463

============================================================
time elapsed: 1:32:19
train iter: 336
num of updates: 33700
emp loss: 2.13817

============================================================
time elapsed: 1:32:21
train iter: 337
num of updates: 33800
emp loss: 2.13780

============================================================
time elapsed: 1:32:23
train iter: 338
num of updates: 33900
emp loss: 2.13247

============================================================
time elapsed: 1:32:26
train iter: 339
num of updates: 34000
emp loss: 2.13424

============================================================
time elapsed: 1:32:28
train iter: 340
num of updates: 34100
emp loss: 2.13419

============================================================
time elapsed: 1:32:30
train iter: 341
num of updates: 34200
emp loss: 2.13587

============================================================
time elapsed: 1:32:32
train iter: 342
num of updates: 34300
emp loss: 2.13972

============================================================
time elapsed: 1:32:35
train iter: 343
num of updates: 34400
emp loss: 2.13602

============================================================
time elapsed: 1:32:37
train iter: 344
num of updates: 34500
emp loss: 2.13302

============================================================
time elapsed: 1:32:39
train iter: 345
num of updates: 34600
emp loss: 2.13600

============================================================
time elapsed: 1:32:41
train iter: 346
num of updates: 34700
emp loss: 2.13513

============================================================
time elapsed: 1:32:43
train iter: 347
num of updates: 34800
emp loss: 2.13278

============================================================
time elapsed: 1:32:46
train iter: 348
num of updates: 34900
emp loss: 2.13583

============================================================
time elapsed: 1:32:48
train iter: 349
num of updates: 35000
emp loss: 2.13190

============================================================
time elapsed: 1:32:50
train iter: 350
num of updates: 35100
emp loss: 2.13514

============================================================
time elapsed: 1:32:52
train iter: 351
num of updates: 35200
emp loss: 2.13880

============================================================
time elapsed: 1:32:55
train iter: 352
num of updates: 35300
emp loss: 2.13058

============================================================
time elapsed: 1:32:57
train iter: 353
num of updates: 35400
emp loss: 2.13409

============================================================
time elapsed: 1:32:59
train iter: 354
num of updates: 35500
emp loss: 2.13329

============================================================
time elapsed: 1:33:01
train iter: 355
num of updates: 35600
emp loss: 2.13582

============================================================
time elapsed: 1:33:04
train iter: 356
num of updates: 35700
emp loss: 2.13581

============================================================
time elapsed: 1:33:06
train iter: 357
num of updates: 35800
emp loss: 2.13508

============================================================
time elapsed: 1:33:08
train iter: 358
num of updates: 35900
emp loss: 2.13447

============================================================
time elapsed: 1:33:10
train iter: 359
num of updates: 36000
emp loss: 2.13449

============================================================
time elapsed: 1:33:13
train iter: 360
num of updates: 36100
emp loss: 2.13080

============================================================
time elapsed: 1:33:15
train iter: 361
num of updates: 36200
emp loss: 2.13352

============================================================
time elapsed: 1:33:17
train iter: 362
num of updates: 36300
emp loss: 2.13420

============================================================
time elapsed: 1:33:19
train iter: 363
num of updates: 36400
emp loss: 2.13649

============================================================
time elapsed: 1:33:21
train iter: 364
num of updates: 36500
emp loss: 2.13250

============================================================
time elapsed: 1:33:24
train iter: 365
num of updates: 36600
emp loss: 2.13342

============================================================
time elapsed: 1:33:26
train iter: 366
num of updates: 36700
emp loss: 2.13082

============================================================
time elapsed: 1:33:28
train iter: 367
num of updates: 36800
emp loss: 2.13562

============================================================
time elapsed: 1:33:30
train iter: 368
num of updates: 36900
emp loss: 2.13854

============================================================
time elapsed: 1:33:33
train iter: 369
num of updates: 37000
emp loss: 2.13297

============================================================
time elapsed: 1:33:35
train iter: 370
num of updates: 37100
emp loss: 2.13406

============================================================
time elapsed: 1:33:37
train iter: 371
num of updates: 37200
emp loss: 2.13666

============================================================
time elapsed: 1:33:39
train iter: 372
num of updates: 37300
emp loss: 2.13350

============================================================
time elapsed: 1:33:42
train iter: 373
num of updates: 37400
emp loss: 2.13293

============================================================
time elapsed: 1:33:44
train iter: 374
num of updates: 37500
emp loss: 2.13338

============================================================
time elapsed: 1:33:46
train iter: 375
num of updates: 37600
emp loss: 2.13319

============================================================
time elapsed: 1:33:48
train iter: 376
num of updates: 37700
emp loss: 2.13475

============================================================
time elapsed: 1:33:51
train iter: 377
num of updates: 37800
emp loss: 2.13263

============================================================
time elapsed: 1:33:53
train iter: 378
num of updates: 37900
emp loss: 2.12944

============================================================
time elapsed: 1:33:55
train iter: 379
num of updates: 38000
emp loss: 2.13136

============================================================
time elapsed: 1:33:57
train iter: 380
num of updates: 38100
emp loss: 2.13732

============================================================
time elapsed: 1:34:00
train iter: 381
num of updates: 38200
emp loss: 2.13351

============================================================
time elapsed: 1:34:02
train iter: 382
num of updates: 38300
emp loss: 2.13632

============================================================
time elapsed: 1:34:04
train iter: 383
num of updates: 38400
emp loss: 2.13376

============================================================
time elapsed: 1:34:06
train iter: 384
num of updates: 38500
emp loss: 2.13397

============================================================
time elapsed: 1:34:08
train iter: 385
num of updates: 38600
emp loss: 2.13414

============================================================
time elapsed: 1:34:11
train iter: 386
num of updates: 38700
emp loss: 2.12849

============================================================
time elapsed: 1:34:13
train iter: 387
num of updates: 38800
emp loss: 2.13488

============================================================
time elapsed: 1:34:15
train iter: 388
num of updates: 38900
emp loss: 2.13262

============================================================
time elapsed: 1:34:17
train iter: 389
num of updates: 39000
emp loss: 2.13324

============================================================
time elapsed: 1:34:20
train iter: 390
num of updates: 39100
emp loss: 2.13210

============================================================
time elapsed: 1:34:22
train iter: 391
num of updates: 39200
emp loss: 2.13246

============================================================
time elapsed: 1:34:24
train iter: 392
num of updates: 39300
emp loss: 2.13303

============================================================
time elapsed: 1:34:26
train iter: 393
num of updates: 39400
emp loss: 2.13213

============================================================
time elapsed: 1:34:29
train iter: 394
num of updates: 39500
emp loss: 2.13772

============================================================
time elapsed: 1:34:31
train iter: 395
num of updates: 39600
emp loss: 2.13385

============================================================
time elapsed: 1:34:33
train iter: 396
num of updates: 39700
emp loss: 2.13181

============================================================
time elapsed: 1:34:35
train iter: 397
num of updates: 39800
emp loss: 2.13312

============================================================
time elapsed: 1:34:38
train iter: 398
num of updates: 39900
emp loss: 2.13493

============================================================
time elapsed: 1:34:40
train iter: 399
num of updates: 40000
emp loss: 2.13314

============================================================
time elapsed: 1:34:42
train iter: 400
num of updates: 40100
emp loss: 2.13228

============================================================
time elapsed: 1:34:44
train iter: 401
num of updates: 40200
emp loss: 2.13130

============================================================
time elapsed: 1:34:46
train iter: 402
num of updates: 40300
emp loss: 2.13638

============================================================
time elapsed: 1:34:49
train iter: 403
num of updates: 40400
emp loss: 2.13613

============================================================
time elapsed: 1:34:51
train iter: 404
num of updates: 40500
emp loss: 2.13039

============================================================
time elapsed: 1:34:53
train iter: 405
num of updates: 40600
emp loss: 2.13142

============================================================
time elapsed: 1:34:55
train iter: 406
num of updates: 40700
emp loss: 2.13149

============================================================
time elapsed: 1:34:58
train iter: 407
num of updates: 40800
emp loss: 2.13322

============================================================
time elapsed: 1:35:00
train iter: 408
num of updates: 40900
emp loss: 2.13344

============================================================
time elapsed: 1:35:02
train iter: 409
num of updates: 41000
emp loss: 2.13414

============================================================
time elapsed: 1:35:04
train iter: 410
num of updates: 41100
emp loss: 2.13357

============================================================
time elapsed: 1:35:07
train iter: 411
num of updates: 41200
emp loss: 2.13355

============================================================
time elapsed: 1:35:09
train iter: 412
num of updates: 41300
emp loss: 2.13290

============================================================
time elapsed: 1:35:11
train iter: 413
num of updates: 41400
emp loss: 2.13080

============================================================
time elapsed: 1:35:13
train iter: 414
num of updates: 41500
emp loss: 2.13332

============================================================
time elapsed: 1:35:16
train iter: 415
num of updates: 41600
emp loss: 2.13452

============================================================
time elapsed: 1:35:18
train iter: 416
num of updates: 41700
emp loss: 2.13185

============================================================
time elapsed: 1:35:20
train iter: 417
num of updates: 41800
emp loss: 2.13372

============================================================
time elapsed: 1:35:22
train iter: 418
num of updates: 41900
emp loss: 2.13494

============================================================
time elapsed: 1:35:25
train iter: 419
num of updates: 42000
emp loss: 2.13363

============================================================
time elapsed: 1:35:27
train iter: 420
num of updates: 42100
emp loss: 2.13013

============================================================
time elapsed: 1:35:29
train iter: 421
num of updates: 42200
emp loss: 2.13622

============================================================
time elapsed: 1:35:31
train iter: 422
num of updates: 42300
emp loss: 2.13248

============================================================
time elapsed: 1:35:33
train iter: 423
num of updates: 42400
emp loss: 2.13072

============================================================
time elapsed: 1:35:36
train iter: 424
num of updates: 42500
emp loss: 2.13223

============================================================
time elapsed: 1:35:38
train iter: 425
num of updates: 42600
emp loss: 2.13195

============================================================
time elapsed: 1:35:40
train iter: 426
num of updates: 42700
emp loss: 2.13190

============================================================
time elapsed: 1:35:42
train iter: 427
num of updates: 42800
emp loss: 2.13051

============================================================
time elapsed: 1:35:45
train iter: 428
num of updates: 42900
emp loss: 2.13122

============================================================
time elapsed: 1:35:47
train iter: 429
num of updates: 43000
emp loss: 2.13355

============================================================
time elapsed: 1:35:49
train iter: 430
num of updates: 43100
emp loss: 2.13082

============================================================
time elapsed: 1:35:51
train iter: 431
num of updates: 43200
emp loss: 2.12879

============================================================
time elapsed: 1:35:54
train iter: 432
num of updates: 43300
emp loss: 2.13103

============================================================
time elapsed: 1:35:56
train iter: 433
num of updates: 43400
emp loss: 2.13093

============================================================
time elapsed: 1:35:58
train iter: 434
num of updates: 43500
emp loss: 2.13163

============================================================
time elapsed: 1:36:00
train iter: 435
num of updates: 43600
emp loss: 2.12907

============================================================
time elapsed: 1:36:03
train iter: 436
num of updates: 43700
emp loss: 2.13155

============================================================
time elapsed: 1:36:05
train iter: 437
num of updates: 43800
emp loss: 2.13188

============================================================
time elapsed: 1:36:07
train iter: 438
num of updates: 43900
emp loss: 2.13372

============================================================
time elapsed: 1:36:09
train iter: 439
num of updates: 44000
emp loss: 2.13270

============================================================
time elapsed: 1:36:12
train iter: 440
num of updates: 44100
emp loss: 2.13386

============================================================
time elapsed: 1:36:14
train iter: 441
num of updates: 44200
emp loss: 2.13103

============================================================
time elapsed: 1:36:16
train iter: 442
num of updates: 44300
emp loss: 2.12709

============================================================
time elapsed: 1:36:18
train iter: 443
num of updates: 44400
emp loss: 2.13346

============================================================
time elapsed: 1:36:20
train iter: 444
num of updates: 44500
emp loss: 2.13167

============================================================
time elapsed: 1:36:23
train iter: 445
num of updates: 44600
emp loss: 2.13111

============================================================
time elapsed: 1:36:25
train iter: 446
num of updates: 44700
emp loss: 2.13170

============================================================
time elapsed: 1:36:27
train iter: 447
num of updates: 44800
emp loss: 2.13288

============================================================
time elapsed: 1:36:29
train iter: 448
num of updates: 44900
emp loss: 2.12985

============================================================
time elapsed: 1:36:32
train iter: 449
num of updates: 45000
emp loss: 2.13124

============================================================
time elapsed: 1:36:34
train iter: 450
num of updates: 45100
emp loss: 2.13218

============================================================
time elapsed: 1:36:36
train iter: 451
num of updates: 45200
emp loss: 2.13185

============================================================
time elapsed: 1:36:38
train iter: 452
num of updates: 45300
emp loss: 2.13194

============================================================
time elapsed: 1:36:41
train iter: 453
num of updates: 45400
emp loss: 2.13000

============================================================
time elapsed: 1:36:43
train iter: 454
num of updates: 45500
emp loss: 2.13167

============================================================
time elapsed: 1:36:45
train iter: 455
num of updates: 45600
emp loss: 2.13426

============================================================
time elapsed: 1:36:47
train iter: 456
num of updates: 45700
emp loss: 2.13451

============================================================
time elapsed: 1:36:50
train iter: 457
num of updates: 45800
emp loss: 2.13152

============================================================
time elapsed: 1:36:52
train iter: 458
num of updates: 45900
emp loss: 2.13289

============================================================
time elapsed: 1:36:54
train iter: 459
num of updates: 46000
emp loss: 2.13261

============================================================
time elapsed: 1:36:56
train iter: 460
num of updates: 46100
emp loss: 2.12978

============================================================
time elapsed: 1:36:59
train iter: 461
num of updates: 46200
emp loss: 2.13192

============================================================
time elapsed: 1:37:01
train iter: 462
num of updates: 46300
emp loss: 2.13068

============================================================
time elapsed: 1:37:03
train iter: 463
num of updates: 46400
emp loss: 2.12988

============================================================
time elapsed: 1:37:05
train iter: 464
num of updates: 46500
emp loss: 2.12903

============================================================
time elapsed: 1:37:07
train iter: 465
num of updates: 46600
emp loss: 2.13019

============================================================
time elapsed: 1:37:10
train iter: 466
num of updates: 46700
emp loss: 2.13073

============================================================
time elapsed: 1:37:12
train iter: 467
num of updates: 46800
emp loss: 2.12943

============================================================
time elapsed: 1:37:14
train iter: 468
num of updates: 46900
emp loss: 2.13201

============================================================
time elapsed: 1:37:16
train iter: 469
num of updates: 47000
emp loss: 2.13007

============================================================
time elapsed: 1:37:19
train iter: 470
num of updates: 47100
emp loss: 2.12801

============================================================
time elapsed: 1:37:21
train iter: 471
num of updates: 47200
emp loss: 2.13367

============================================================
time elapsed: 1:37:23
train iter: 472
num of updates: 47300
emp loss: 2.13327

============================================================
time elapsed: 1:37:25
train iter: 473
num of updates: 47400
emp loss: 2.13033

============================================================
time elapsed: 1:37:28
train iter: 474
num of updates: 47500
emp loss: 2.13280

============================================================
time elapsed: 1:37:30
train iter: 475
num of updates: 47600
emp loss: 2.13204

============================================================
time elapsed: 1:37:32
train iter: 476
num of updates: 47700
emp loss: 2.13063

============================================================
time elapsed: 1:37:34
train iter: 477
num of updates: 47800
emp loss: 2.13256

============================================================
time elapsed: 1:37:37
train iter: 478
num of updates: 47900
emp loss: 2.13164

============================================================
time elapsed: 1:37:39
train iter: 479
num of updates: 48000
emp loss: 2.13321

============================================================
time elapsed: 1:37:41
train iter: 480
num of updates: 48100
emp loss: 2.13001

============================================================
time elapsed: 1:37:43
train iter: 481
num of updates: 48200
emp loss: 2.13234

============================================================
time elapsed: 1:37:46
train iter: 482
num of updates: 48300
emp loss: 2.13060

============================================================
time elapsed: 1:37:48
train iter: 483
num of updates: 48400
emp loss: 2.12977

============================================================
time elapsed: 1:37:50
train iter: 484
num of updates: 48500
emp loss: 2.13258

============================================================
time elapsed: 1:37:52
train iter: 485
num of updates: 48600
emp loss: 2.13217

============================================================
time elapsed: 1:37:54
train iter: 486
num of updates: 48700
emp loss: 2.13185

============================================================
time elapsed: 1:37:57
train iter: 487
num of updates: 48800
emp loss: 2.12785

============================================================
time elapsed: 1:37:59
train iter: 488
num of updates: 48900
emp loss: 2.12924

============================================================
time elapsed: 1:38:01
train iter: 489
num of updates: 49000
emp loss: 2.13085

============================================================
time elapsed: 1:38:03
train iter: 490
num of updates: 49100
emp loss: 2.13434

============================================================
time elapsed: 1:38:06
train iter: 491
num of updates: 49200
emp loss: 2.12930

============================================================
time elapsed: 1:38:08
train iter: 492
num of updates: 49300
emp loss: 2.13103

============================================================
time elapsed: 1:38:10
train iter: 493
num of updates: 49400
emp loss: 2.12920

============================================================
time elapsed: 1:38:12
train iter: 494
num of updates: 49500
emp loss: 2.13168

============================================================
time elapsed: 1:38:15
train iter: 495
num of updates: 49600
emp loss: 2.13235

============================================================
time elapsed: 1:38:17
train iter: 496
num of updates: 49700
emp loss: 2.12962

============================================================
time elapsed: 1:38:19
train iter: 497
num of updates: 49800
emp loss: 2.13153

============================================================
time elapsed: 1:38:21
train iter: 498
num of updates: 49900
emp loss: 2.13139

============================================================
time elapsed: 1:38:24
train iter: 499
num of updates: 50000
emp loss: 2.13062

============================================================
time elapsed: 1:38:26
train iter: 500
num of updates: 50100
emp loss: 2.13329

============================================================
time elapsed: 1:38:28
train iter: 501
num of updates: 50200
emp loss: 2.12870

============================================================
time elapsed: 1:38:30
train iter: 502
num of updates: 50300
emp loss: 2.12913

============================================================
time elapsed: 1:38:32
train iter: 503
num of updates: 50400
emp loss: 2.13090

============================================================
time elapsed: 1:38:35
train iter: 504
num of updates: 50500
emp loss: 2.12800

============================================================
time elapsed: 1:38:37
train iter: 505
num of updates: 50600
emp loss: 2.13151

============================================================
time elapsed: 1:38:39
train iter: 506
num of updates: 50700
emp loss: 2.12535

============================================================
time elapsed: 1:38:41
train iter: 507
num of updates: 50800
emp loss: 2.12964

============================================================
time elapsed: 1:38:44
train iter: 508
num of updates: 50900
emp loss: 2.12913

============================================================
time elapsed: 1:38:46
train iter: 509
num of updates: 51000
emp loss: 2.12872

============================================================
time elapsed: 1:38:48
train iter: 510
num of updates: 51100
emp loss: 2.13076

============================================================
time elapsed: 1:38:50
train iter: 511
num of updates: 51200
emp loss: 2.13096

============================================================
time elapsed: 1:38:53
train iter: 512
num of updates: 51300
emp loss: 2.12729

============================================================
time elapsed: 1:38:55
train iter: 513
num of updates: 51400
emp loss: 2.12940

============================================================
time elapsed: 1:38:57
train iter: 514
num of updates: 51500
emp loss: 2.13193

============================================================
time elapsed: 1:38:59
train iter: 515
num of updates: 51600
emp loss: 2.13028

============================================================
time elapsed: 1:39:02
train iter: 516
num of updates: 51700
emp loss: 2.12999

============================================================
time elapsed: 1:39:04
train iter: 517
num of updates: 51800
emp loss: 2.12880

============================================================
time elapsed: 1:39:06
train iter: 518
num of updates: 51900
emp loss: 2.12999

============================================================
time elapsed: 1:39:08
train iter: 519
num of updates: 52000
emp loss: 2.13091

============================================================
time elapsed: 1:39:11
train iter: 520
num of updates: 52100
emp loss: 2.13052

============================================================
time elapsed: 1:39:13
train iter: 521
num of updates: 52200
emp loss: 2.12818

============================================================
time elapsed: 1:39:15
train iter: 522
num of updates: 52300
emp loss: 2.12764

============================================================
time elapsed: 1:39:17
train iter: 523
num of updates: 52400
emp loss: 2.12925

============================================================
time elapsed: 1:39:19
train iter: 524
num of updates: 52500
emp loss: 2.13210

============================================================
time elapsed: 1:39:22
train iter: 525
num of updates: 52600
emp loss: 2.12895

============================================================
time elapsed: 1:39:24
train iter: 526
num of updates: 52700
emp loss: 2.13029

============================================================
time elapsed: 1:39:26
train iter: 527
num of updates: 52800
emp loss: 2.12813

============================================================
time elapsed: 1:39:28
train iter: 528
num of updates: 52900
emp loss: 2.13083

============================================================
time elapsed: 1:39:31
train iter: 529
num of updates: 53000
emp loss: 2.12760

============================================================
time elapsed: 1:39:33
train iter: 530
num of updates: 53100
emp loss: 2.13053

============================================================
time elapsed: 1:39:35
train iter: 531
num of updates: 53200
emp loss: 2.13020

============================================================
time elapsed: 1:39:37
train iter: 532
num of updates: 53300
emp loss: 2.13007

============================================================
time elapsed: 1:39:40
train iter: 533
num of updates: 53400
emp loss: 2.12785

============================================================
time elapsed: 1:39:42
train iter: 534
num of updates: 53500
emp loss: 2.13061

============================================================
time elapsed: 1:39:44
train iter: 535
num of updates: 53600
emp loss: 2.13069

============================================================
time elapsed: 1:39:46
train iter: 536
num of updates: 53700
emp loss: 2.13084

============================================================
time elapsed: 1:39:49
train iter: 537
num of updates: 53800
emp loss: 2.13076

============================================================
time elapsed: 1:39:51
train iter: 538
num of updates: 53900
emp loss: 2.12700

============================================================
time elapsed: 1:39:53
train iter: 539
num of updates: 54000
emp loss: 2.13136

============================================================
time elapsed: 1:39:55
train iter: 540
num of updates: 54100
emp loss: 2.12851

============================================================
time elapsed: 1:39:58
train iter: 541
num of updates: 54200
emp loss: 2.13164

============================================================
time elapsed: 1:40:00
train iter: 542
num of updates: 54300
emp loss: 2.12912

============================================================
time elapsed: 1:40:02
train iter: 543
num of updates: 54400
emp loss: 2.12974

============================================================
time elapsed: 1:40:04
train iter: 544
num of updates: 54500
emp loss: 2.12861

============================================================
time elapsed: 1:40:06
train iter: 545
num of updates: 54600
emp loss: 2.12928

============================================================
time elapsed: 1:40:09
train iter: 546
num of updates: 54700
emp loss: 2.12944

============================================================
time elapsed: 1:40:11
train iter: 547
num of updates: 54800
emp loss: 2.12801

============================================================
time elapsed: 1:40:13
train iter: 548
num of updates: 54900
emp loss: 2.12554

============================================================
time elapsed: 1:40:15
train iter: 549
num of updates: 55000
emp loss: 2.13039

============================================================
time elapsed: 1:40:18
train iter: 550
num of updates: 55100
emp loss: 2.12936

============================================================
time elapsed: 1:40:20
train iter: 551
num of updates: 55200
emp loss: 2.12710

============================================================
time elapsed: 1:40:22
train iter: 552
num of updates: 55300
emp loss: 2.12680

============================================================
time elapsed: 1:40:24
train iter: 553
num of updates: 55400
emp loss: 2.12903

============================================================
time elapsed: 1:40:27
train iter: 554
num of updates: 55500
emp loss: 2.12860

============================================================
time elapsed: 1:40:29
train iter: 555
num of updates: 55600
emp loss: 2.13073

============================================================
time elapsed: 1:40:31
train iter: 556
num of updates: 55700
emp loss: 2.12629

============================================================
time elapsed: 1:40:33
train iter: 557
num of updates: 55800
emp loss: 2.12895

============================================================
time elapsed: 1:40:36
train iter: 558
num of updates: 55900
emp loss: 2.12825

============================================================
time elapsed: 1:40:38
train iter: 559
num of updates: 56000
emp loss: 2.12924

============================================================
time elapsed: 1:40:40
train iter: 560
num of updates: 56100
emp loss: 2.12948

============================================================
time elapsed: 1:40:42
train iter: 561
num of updates: 56200
emp loss: 2.12821

============================================================
time elapsed: 1:40:44
train iter: 562
num of updates: 56300
emp loss: 2.12869

============================================================
time elapsed: 1:40:47
train iter: 563
num of updates: 56400
emp loss: 2.12902

============================================================
time elapsed: 1:40:49
train iter: 564
num of updates: 56500
emp loss: 2.12895

============================================================
time elapsed: 1:40:51
train iter: 565
num of updates: 56600
emp loss: 2.12920

============================================================
time elapsed: 1:40:53
train iter: 566
num of updates: 56700
emp loss: 2.12533

============================================================
time elapsed: 1:40:56
train iter: 567
num of updates: 56800
emp loss: 2.12869

============================================================
time elapsed: 1:40:58
train iter: 568
num of updates: 56900
emp loss: 2.13101

============================================================
time elapsed: 1:41:00
train iter: 569
num of updates: 57000
emp loss: 2.13005

============================================================
time elapsed: 1:41:02
train iter: 570
num of updates: 57100
emp loss: 2.12875

============================================================
time elapsed: 1:41:05
train iter: 571
num of updates: 57200
emp loss: 2.13134

============================================================
time elapsed: 1:41:07
train iter: 572
num of updates: 57300
emp loss: 2.12695

============================================================
time elapsed: 1:41:09
train iter: 573
num of updates: 57400
emp loss: 2.12903

============================================================
time elapsed: 1:41:11
train iter: 574
num of updates: 57500
emp loss: 2.12961

============================================================
time elapsed: 1:41:14
train iter: 575
num of updates: 57600
emp loss: 2.12904

============================================================
time elapsed: 1:41:16
train iter: 576
num of updates: 57700
emp loss: 2.13051

============================================================
time elapsed: 1:41:18
train iter: 577
num of updates: 57800
emp loss: 2.12466

============================================================
time elapsed: 1:41:20
train iter: 578
num of updates: 57900
emp loss: 2.12665

============================================================
time elapsed: 1:41:23
train iter: 579
num of updates: 58000
emp loss: 2.12854

============================================================
time elapsed: 1:41:25
train iter: 580
num of updates: 58100
emp loss: 2.12850

============================================================
time elapsed: 1:41:27
train iter: 581
num of updates: 58200
emp loss: 2.13075

============================================================
time elapsed: 1:41:29
train iter: 582
num of updates: 58300
emp loss: 2.13048

============================================================
time elapsed: 1:41:31
train iter: 583
num of updates: 58400
emp loss: 2.13038

============================================================
time elapsed: 1:41:34
train iter: 584
num of updates: 58500
emp loss: 2.12996

============================================================
time elapsed: 1:41:36
train iter: 585
num of updates: 58600
emp loss: 2.12883

============================================================
time elapsed: 1:41:38
train iter: 586
num of updates: 58700
emp loss: 2.12733

============================================================
time elapsed: 1:41:40
train iter: 587
num of updates: 58800
emp loss: 2.12744

============================================================
time elapsed: 1:41:43
train iter: 588
num of updates: 58900
emp loss: 2.12761

============================================================
time elapsed: 1:41:45
train iter: 589
num of updates: 59000
emp loss: 2.12595

============================================================
time elapsed: 1:41:47
train iter: 590
num of updates: 59100
emp loss: 2.12977

============================================================
time elapsed: 1:41:49
train iter: 591
num of updates: 59200
emp loss: 2.12976

============================================================
time elapsed: 1:41:52
train iter: 592
num of updates: 59300
emp loss: 2.12527

============================================================
time elapsed: 1:41:54
train iter: 593
num of updates: 59400
emp loss: 2.12916

============================================================
time elapsed: 1:41:56
train iter: 594
num of updates: 59500
emp loss: 2.12950

============================================================
time elapsed: 1:41:58
train iter: 595
num of updates: 59600
emp loss: 2.12916

============================================================
time elapsed: 1:42:01
train iter: 596
num of updates: 59700
emp loss: 2.13067

============================================================
time elapsed: 1:42:03
train iter: 597
num of updates: 59800
emp loss: 2.12889

============================================================
time elapsed: 1:42:05
train iter: 598
num of updates: 59900
emp loss: 2.12959

============================================================
time elapsed: 1:42:07
train iter: 599
num of updates: 60000
emp loss: 2.12630

============================================================
time elapsed: 1:42:10
train iter: 600
num of updates: 60100
emp loss: 2.12620

============================================================
time elapsed: 1:42:12
train iter: 601
num of updates: 60200
emp loss: 2.12731

============================================================
time elapsed: 1:42:14
train iter: 602
num of updates: 60300
emp loss: 2.12845

============================================================
time elapsed: 1:42:16
train iter: 603
num of updates: 60400
emp loss: 2.12724

============================================================
time elapsed: 1:42:18
train iter: 604
num of updates: 60500
emp loss: 2.12781

============================================================
time elapsed: 1:42:21
train iter: 605
num of updates: 60600
emp loss: 2.12602

============================================================
time elapsed: 1:42:23
train iter: 606
num of updates: 60700
emp loss: 2.12994

============================================================
time elapsed: 1:42:25
train iter: 607
num of updates: 60800
emp loss: 2.12751

============================================================
time elapsed: 1:42:27
train iter: 608
num of updates: 60900
emp loss: 2.12763

============================================================
time elapsed: 1:42:30
train iter: 609
num of updates: 61000
emp loss: 2.12769

============================================================
time elapsed: 1:42:32
train iter: 610
num of updates: 61100
emp loss: 2.12739

============================================================
time elapsed: 1:42:34
train iter: 611
num of updates: 61200
emp loss: 2.13136

============================================================
time elapsed: 1:42:36
train iter: 612
num of updates: 61300
emp loss: 2.12877

============================================================
time elapsed: 1:42:39
train iter: 613
num of updates: 61400
emp loss: 2.12784

============================================================
time elapsed: 1:42:41
train iter: 614
num of updates: 61500
emp loss: 2.12896

============================================================
time elapsed: 1:42:43
train iter: 615
num of updates: 61600
emp loss: 2.12746

============================================================
time elapsed: 1:42:45
train iter: 616
num of updates: 61700
emp loss: 2.12549

============================================================
time elapsed: 1:42:48
train iter: 617
num of updates: 61800
emp loss: 2.13119

============================================================
time elapsed: 1:42:50
train iter: 618
num of updates: 61900
emp loss: 2.12719

============================================================
time elapsed: 1:42:52
train iter: 619
num of updates: 62000
emp loss: 2.12778

============================================================
time elapsed: 1:42:54
train iter: 620
num of updates: 62100
emp loss: 2.12708

============================================================
time elapsed: 1:42:57
train iter: 621
num of updates: 62200
emp loss: 2.12684

============================================================
time elapsed: 1:42:59
train iter: 622
num of updates: 62300
emp loss: 2.12500

============================================================
time elapsed: 1:43:01
train iter: 623
num of updates: 62400
emp loss: 2.12647

============================================================
time elapsed: 1:43:03
train iter: 624
num of updates: 62500
emp loss: 2.12445

============================================================
time elapsed: 1:43:06
train iter: 625
num of updates: 62600
emp loss: 2.12648

============================================================
time elapsed: 1:43:08
train iter: 626
num of updates: 62700
emp loss: 2.12967

============================================================
time elapsed: 1:43:10
train iter: 627
num of updates: 62800
emp loss: 2.13055

============================================================
time elapsed: 1:43:12
train iter: 628
num of updates: 62900
emp loss: 2.12608

============================================================
time elapsed: 1:43:14
train iter: 629
num of updates: 63000
emp loss: 2.12793

============================================================
time elapsed: 1:43:17
train iter: 630
num of updates: 63100
emp loss: 2.12840

============================================================
time elapsed: 1:43:19
train iter: 631
num of updates: 63200
emp loss: 2.12602

============================================================
time elapsed: 1:43:21
train iter: 632
num of updates: 63300
emp loss: 2.12821

============================================================
time elapsed: 1:43:23
train iter: 633
num of updates: 63400
emp loss: 2.12745

============================================================
time elapsed: 1:43:26
train iter: 634
num of updates: 63500
emp loss: 2.12848

============================================================
time elapsed: 1:43:28
train iter: 635
num of updates: 63600
emp loss: 2.12841

============================================================
time elapsed: 1:43:30
train iter: 636
num of updates: 63700
emp loss: 2.12808

============================================================
time elapsed: 1:43:32
train iter: 637
num of updates: 63800
emp loss: 2.12796

============================================================
time elapsed: 1:43:35
train iter: 638
num of updates: 63900
emp loss: 2.12762

============================================================
time elapsed: 1:43:37
train iter: 639
num of updates: 64000
emp loss: 2.12808

============================================================
time elapsed: 1:43:39
train iter: 640
num of updates: 64100
emp loss: 2.12824

============================================================
time elapsed: 1:43:41
train iter: 641
num of updates: 64200
emp loss: 2.12752

============================================================
time elapsed: 1:43:44
train iter: 642
num of updates: 64300
emp loss: 2.12912

============================================================
time elapsed: 1:43:46
train iter: 643
num of updates: 64400
emp loss: 2.12659

============================================================
time elapsed: 1:43:48
train iter: 644
num of updates: 64500
emp loss: 2.12552

============================================================
time elapsed: 1:43:50
train iter: 645
num of updates: 64600
emp loss: 2.12770

============================================================
time elapsed: 1:43:53
train iter: 646
num of updates: 64700
emp loss: 2.12809

============================================================
time elapsed: 1:43:55
train iter: 647
num of updates: 64800
emp loss: 2.12605

============================================================
time elapsed: 1:43:57
train iter: 648
num of updates: 64900
emp loss: 2.12903

============================================================
time elapsed: 1:43:59
train iter: 649
num of updates: 65000
emp loss: 2.12640

============================================================
time elapsed: 1:44:01
train iter: 650
num of updates: 65100
emp loss: 2.12487

============================================================
time elapsed: 1:44:04
train iter: 651
num of updates: 65200
emp loss: 2.12867

============================================================
time elapsed: 1:44:06
train iter: 652
num of updates: 65300
emp loss: 2.12699

============================================================
time elapsed: 1:44:08
train iter: 653
num of updates: 65400
emp loss: 2.12606

============================================================
time elapsed: 1:44:10
train iter: 654
num of updates: 65500
emp loss: 2.12486

============================================================
time elapsed: 1:44:13
train iter: 655
num of updates: 65600
emp loss: 2.12490

============================================================
time elapsed: 1:44:15
train iter: 656
num of updates: 65700
emp loss: 2.12970

============================================================
time elapsed: 1:44:17
train iter: 657
num of updates: 65800
emp loss: 2.12783

============================================================
time elapsed: 1:44:19
train iter: 658
num of updates: 65900
emp loss: 2.12757

============================================================
time elapsed: 1:44:22
train iter: 659
num of updates: 66000
emp loss: 2.12762

============================================================
time elapsed: 1:44:24
train iter: 660
num of updates: 66100
emp loss: 2.12765

============================================================
time elapsed: 1:44:26
train iter: 661
num of updates: 66200
emp loss: 2.12628

============================================================
time elapsed: 1:44:28
train iter: 662
num of updates: 66300
emp loss: 2.12652

============================================================
time elapsed: 1:44:31
train iter: 663
num of updates: 66400
emp loss: 2.12681

============================================================
time elapsed: 1:44:33
train iter: 664
num of updates: 66500
emp loss: 2.12541

============================================================
time elapsed: 1:44:35
train iter: 665
num of updates: 66600
emp loss: 2.12463

============================================================
time elapsed: 1:44:37
train iter: 666
num of updates: 66700
emp loss: 2.12586

============================================================
time elapsed: 1:44:40
train iter: 667
num of updates: 66800
emp loss: 2.12484

============================================================
time elapsed: 1:44:42
train iter: 668
num of updates: 66900
emp loss: 2.12524

============================================================
time elapsed: 1:44:44
train iter: 669
num of updates: 67000
emp loss: 2.12450

============================================================
time elapsed: 1:44:46
train iter: 670
num of updates: 67100
emp loss: 2.12855

============================================================
time elapsed: 1:44:48
train iter: 671
num of updates: 67200
emp loss: 2.12828

============================================================
time elapsed: 1:44:51
train iter: 672
num of updates: 67300
emp loss: 2.12526

============================================================
time elapsed: 1:44:53
train iter: 673
num of updates: 67400
emp loss: 2.12894

============================================================
time elapsed: 1:44:55
train iter: 674
num of updates: 67500
emp loss: 2.12306

============================================================
time elapsed: 1:44:57
train iter: 675
num of updates: 67600
emp loss: 2.12626

============================================================
time elapsed: 1:45:00
train iter: 676
num of updates: 67700
emp loss: 2.12639

============================================================
time elapsed: 1:45:02
train iter: 677
num of updates: 67800
emp loss: 2.12613

============================================================
time elapsed: 1:45:04
train iter: 678
num of updates: 67900
emp loss: 2.12457

============================================================
time elapsed: 1:45:06
train iter: 679
num of updates: 68000
emp loss: 2.12564

============================================================
time elapsed: 1:45:09
train iter: 680
num of updates: 68100
emp loss: 2.12732

============================================================
time elapsed: 1:45:11
train iter: 681
num of updates: 68200
emp loss: 2.12754

============================================================
time elapsed: 1:45:13
train iter: 682
num of updates: 68300
emp loss: 2.12750

============================================================
time elapsed: 1:45:15
train iter: 683
num of updates: 68400
emp loss: 2.12911

============================================================
time elapsed: 1:45:18
train iter: 684
num of updates: 68500
emp loss: 2.12370

============================================================
time elapsed: 1:45:20
train iter: 685
num of updates: 68600
emp loss: 2.12724

============================================================
time elapsed: 1:45:22
train iter: 686
num of updates: 68700
emp loss: 2.12959

============================================================
time elapsed: 1:45:24
train iter: 687
num of updates: 68800
emp loss: 2.12802

============================================================
time elapsed: 1:45:27
train iter: 688
num of updates: 68900
emp loss: 2.12545

============================================================
time elapsed: 1:45:29
train iter: 689
num of updates: 69000
emp loss: 2.12841

============================================================
time elapsed: 1:45:31
train iter: 690
num of updates: 69100
emp loss: 2.12256

============================================================
time elapsed: 1:45:33
train iter: 691
num of updates: 69200
emp loss: 2.12598

============================================================
time elapsed: 1:45:35
train iter: 692
num of updates: 69300
emp loss: 2.12647

============================================================
time elapsed: 1:45:38
train iter: 693
num of updates: 69400
emp loss: 2.12470

============================================================
time elapsed: 1:45:40
train iter: 694
num of updates: 69500
emp loss: 2.12895

============================================================
time elapsed: 1:45:42
train iter: 695
num of updates: 69600
emp loss: 2.12586

============================================================
time elapsed: 1:45:44
train iter: 696
num of updates: 69700
emp loss: 2.12782

============================================================
time elapsed: 1:45:47
train iter: 697
num of updates: 69800
emp loss: 2.12589

============================================================
time elapsed: 1:45:49
train iter: 698
num of updates: 69900
emp loss: 2.12771

============================================================
time elapsed: 1:45:51
train iter: 699
num of updates: 70000
emp loss: 2.12738

============================================================
time elapsed: 1:45:53
train iter: 700
num of updates: 70100
emp loss: 2.12599

============================================================
time elapsed: 1:45:56
train iter: 701
num of updates: 70200
emp loss: 2.12597

============================================================
time elapsed: 1:45:58
train iter: 702
num of updates: 70300
emp loss: 2.12498

============================================================
time elapsed: 1:46:00
train iter: 703
num of updates: 70400
emp loss: 2.12673

============================================================
time elapsed: 1:46:02
train iter: 704
num of updates: 70500
emp loss: 2.12610

============================================================
time elapsed: 1:46:05
train iter: 705
num of updates: 70600
emp loss: 2.12591

============================================================
time elapsed: 1:46:07
train iter: 706
num of updates: 70700
emp loss: 2.12430

============================================================
time elapsed: 1:46:09
train iter: 707
num of updates: 70800
emp loss: 2.12395

============================================================
time elapsed: 1:46:11
train iter: 708
num of updates: 70900
emp loss: 2.12437

============================================================
time elapsed: 1:46:14
train iter: 709
num of updates: 71000
emp loss: 2.12470

============================================================
time elapsed: 1:46:16
train iter: 710
num of updates: 71100
emp loss: 2.12587

============================================================
time elapsed: 1:46:18
train iter: 711
num of updates: 71200
emp loss: 2.12245

============================================================
time elapsed: 1:46:20
train iter: 712
num of updates: 71300
emp loss: 2.12625

============================================================
time elapsed: 1:46:22
train iter: 713
num of updates: 71400
emp loss: 2.12319

============================================================
time elapsed: 1:46:25
train iter: 714
num of updates: 71500
emp loss: 2.12645

============================================================
time elapsed: 1:46:27
train iter: 715
num of updates: 71600
emp loss: 2.12484

============================================================
time elapsed: 1:46:29
train iter: 716
num of updates: 71700
emp loss: 2.12779

============================================================
time elapsed: 1:46:31
train iter: 717
num of updates: 71800
emp loss: 2.12746

============================================================
time elapsed: 1:46:34
train iter: 718
num of updates: 71900
emp loss: 2.12970

============================================================
time elapsed: 1:46:36
train iter: 719
num of updates: 72000
emp loss: 2.12516

============================================================
time elapsed: 1:46:38
train iter: 720
num of updates: 72100
emp loss: 2.12883

============================================================
time elapsed: 1:46:40
train iter: 721
num of updates: 72200
emp loss: 2.12643

============================================================
time elapsed: 1:46:43
train iter: 722
num of updates: 72300
emp loss: 2.12287

============================================================
time elapsed: 1:46:45
train iter: 723
num of updates: 72400
emp loss: 2.12459

============================================================
time elapsed: 1:46:47
train iter: 724
num of updates: 72500
emp loss: 2.12736

============================================================
time elapsed: 1:46:49
train iter: 725
num of updates: 72600
emp loss: 2.12516

============================================================
time elapsed: 1:46:52
train iter: 726
num of updates: 72700
emp loss: 2.12329

============================================================
time elapsed: 1:46:54
train iter: 727
num of updates: 72800
emp loss: 2.12367

============================================================
time elapsed: 1:46:56
train iter: 728
num of updates: 72900
emp loss: 2.12737

============================================================
time elapsed: 1:46:58
train iter: 729
num of updates: 73000
emp loss: 2.12668

============================================================
time elapsed: 1:47:01
train iter: 730
num of updates: 73100
emp loss: 2.12911

============================================================
time elapsed: 1:47:03
train iter: 731
num of updates: 73200
emp loss: 2.12776

============================================================
time elapsed: 1:47:05
train iter: 732
num of updates: 73300
emp loss: 2.12609

============================================================
time elapsed: 1:47:07
train iter: 733
num of updates: 73400
emp loss: 2.12591

============================================================
time elapsed: 1:47:09
train iter: 734
num of updates: 73500
emp loss: 2.12502

============================================================
time elapsed: 1:47:12
train iter: 735
num of updates: 73600
emp loss: 2.12699

============================================================
time elapsed: 1:47:14
train iter: 736
num of updates: 73700
emp loss: 2.12459

============================================================
time elapsed: 1:47:16
train iter: 737
num of updates: 73800
emp loss: 2.12790

============================================================
time elapsed: 1:47:18
train iter: 738
num of updates: 73900
emp loss: 2.12596

============================================================
time elapsed: 1:47:21
train iter: 739
num of updates: 74000
emp loss: 2.12450

============================================================
time elapsed: 1:47:23
train iter: 740
num of updates: 74100
emp loss: 2.12569

============================================================
time elapsed: 1:47:25
train iter: 741
num of updates: 74200
emp loss: 2.12588

============================================================
time elapsed: 1:47:27
train iter: 742
num of updates: 74300
emp loss: 2.12673

============================================================
time elapsed: 1:47:30
train iter: 743
num of updates: 74400
emp loss: 2.12611

============================================================
time elapsed: 1:47:32
train iter: 744
num of updates: 74500
emp loss: 2.12622

============================================================
time elapsed: 1:47:34
train iter: 745
num of updates: 74600
emp loss: 2.12068

============================================================
time elapsed: 1:47:36
train iter: 746
num of updates: 74700
emp loss: 2.12618

============================================================
time elapsed: 1:47:39
train iter: 747
num of updates: 74800
emp loss: 2.12608

============================================================
time elapsed: 1:47:41
train iter: 748
num of updates: 74900
emp loss: 2.12375

============================================================
time elapsed: 1:47:43
train iter: 749
num of updates: 75000
emp loss: 2.12325

============================================================
time elapsed: 1:47:45
train iter: 750
num of updates: 75100
emp loss: 2.12351

============================================================
time elapsed: 1:47:48
train iter: 751
num of updates: 75200
emp loss: 2.12676

============================================================
time elapsed: 1:47:50
train iter: 752
num of updates: 75300
emp loss: 2.12405

============================================================
time elapsed: 1:47:52
train iter: 753
num of updates: 75400
emp loss: 2.12582

============================================================
time elapsed: 1:47:54
train iter: 754
num of updates: 75500
emp loss: 2.12470

============================================================
time elapsed: 1:47:56
train iter: 755
num of updates: 75600
emp loss: 2.12577

============================================================
time elapsed: 1:47:59
train iter: 756
num of updates: 75700
emp loss: 2.12571

============================================================
time elapsed: 1:48:01
train iter: 757
num of updates: 75800
emp loss: 2.12612

============================================================
time elapsed: 1:48:03
train iter: 758
num of updates: 75900
emp loss: 2.12583

============================================================
time elapsed: 1:48:05
train iter: 759
num of updates: 76000
emp loss: 2.12406

============================================================
time elapsed: 1:48:08
train iter: 760
num of updates: 76100
emp loss: 2.12430

============================================================
time elapsed: 1:48:10
train iter: 761
num of updates: 76200
emp loss: 2.12396

============================================================
time elapsed: 1:48:12
train iter: 762
num of updates: 76300
emp loss: 2.12638

============================================================
time elapsed: 1:48:14
train iter: 763
num of updates: 76400
emp loss: 2.12382

============================================================
time elapsed: 1:48:17
train iter: 764
num of updates: 76500
emp loss: 2.12492

============================================================
time elapsed: 1:48:19
train iter: 765
num of updates: 76600
emp loss: 2.12306

============================================================
time elapsed: 1:48:21
train iter: 766
num of updates: 76700
emp loss: 2.12372

============================================================
time elapsed: 1:48:23
train iter: 767
num of updates: 76800
emp loss: 2.12702

============================================================
time elapsed: 1:48:26
train iter: 768
num of updates: 76900
emp loss: 2.12433

============================================================
time elapsed: 1:48:28
train iter: 769
num of updates: 77000
emp loss: 2.12581

============================================================
time elapsed: 1:48:30
train iter: 770
num of updates: 77100
emp loss: 2.12384

============================================================
time elapsed: 1:48:32
train iter: 771
num of updates: 77200
emp loss: 2.12542

============================================================
time elapsed: 1:48:35
train iter: 772
num of updates: 77300
emp loss: 2.12703

============================================================
time elapsed: 1:48:37
train iter: 773
num of updates: 77400
emp loss: 2.12276

============================================================
time elapsed: 1:48:39
train iter: 774
num of updates: 77500
emp loss: 2.12663

============================================================
time elapsed: 1:48:41
train iter: 775
num of updates: 77600
emp loss: 2.12677

============================================================
time elapsed: 1:48:43
train iter: 776
num of updates: 77700
emp loss: 2.12454

============================================================
time elapsed: 1:48:46
train iter: 777
num of updates: 77800
emp loss: 2.12431

============================================================
time elapsed: 1:48:48
train iter: 778
num of updates: 77900
emp loss: 2.12276

============================================================
time elapsed: 1:48:50
train iter: 779
num of updates: 78000
emp loss: 2.12171

============================================================
time elapsed: 1:48:52
train iter: 780
num of updates: 78100
emp loss: 2.12609

============================================================
time elapsed: 1:48:55
train iter: 781
num of updates: 78200
emp loss: 2.12999

============================================================
time elapsed: 1:48:57
train iter: 782
num of updates: 78300
emp loss: 2.12596

============================================================
time elapsed: 1:48:59
train iter: 783
num of updates: 78400
emp loss: 2.12612

============================================================
time elapsed: 1:49:01
train iter: 784
num of updates: 78500
emp loss: 2.12697

============================================================
time elapsed: 1:49:04
train iter: 785
num of updates: 78600
emp loss: 2.12682

============================================================
time elapsed: 1:49:06
train iter: 786
num of updates: 78700
emp loss: 2.12676

============================================================
time elapsed: 1:49:08
train iter: 787
num of updates: 78800
emp loss: 2.12569

============================================================
time elapsed: 1:49:10
train iter: 788
num of updates: 78900
emp loss: 2.12499

============================================================
time elapsed: 1:49:13
train iter: 789
num of updates: 79000
emp loss: 2.12429

============================================================
time elapsed: 1:49:15
train iter: 790
num of updates: 79100
emp loss: 2.12662

============================================================
time elapsed: 1:49:17
train iter: 791
num of updates: 79200
emp loss: 2.12394

============================================================
time elapsed: 1:49:19
train iter: 792
num of updates: 79300
emp loss: 2.12372

============================================================
time elapsed: 1:49:22
train iter: 793
num of updates: 79400
emp loss: 2.12677

============================================================
time elapsed: 1:49:24
train iter: 794
num of updates: 79500
emp loss: 2.12410

============================================================
time elapsed: 1:49:26
train iter: 795
num of updates: 79600
emp loss: 2.12614

============================================================
time elapsed: 1:49:28
train iter: 796
num of updates: 79700
emp loss: 2.12373

============================================================
time elapsed: 1:49:31
train iter: 797
num of updates: 79800
emp loss: 2.12526

============================================================
time elapsed: 1:49:33
train iter: 798
num of updates: 79900
emp loss: 2.12369

============================================================
time elapsed: 1:49:35
train iter: 799
num of updates: 80000
emp loss: 2.12559

============================================================
time elapsed: 1:49:37
train iter: 800
num of updates: 80100
emp loss: 2.12556

============================================================
time elapsed: 1:49:39
train iter: 801
num of updates: 80200
emp loss: 2.12254

============================================================
time elapsed: 1:49:42
train iter: 802
num of updates: 80300
emp loss: 2.12713

============================================================
time elapsed: 1:49:44
train iter: 803
num of updates: 80400
emp loss: 2.12540

============================================================
time elapsed: 1:49:46
train iter: 804
num of updates: 80500
emp loss: 2.12512

============================================================
time elapsed: 1:49:48
train iter: 805
num of updates: 80600
emp loss: 2.12435

============================================================
time elapsed: 1:49:51
train iter: 806
num of updates: 80700
emp loss: 2.12510

============================================================
time elapsed: 1:49:53
train iter: 807
num of updates: 80800
emp loss: 2.12704

============================================================
time elapsed: 1:49:55
train iter: 808
num of updates: 80900
emp loss: 2.12283

============================================================
time elapsed: 1:49:57
train iter: 809
num of updates: 81000
emp loss: 2.12436

============================================================
time elapsed: 1:50:00
train iter: 810
num of updates: 81100
emp loss: 2.12556

============================================================
time elapsed: 1:50:02
train iter: 811
num of updates: 81200
emp loss: 2.12359

============================================================
time elapsed: 1:50:04
train iter: 812
num of updates: 81300
emp loss: 2.12584

============================================================
time elapsed: 1:50:06
train iter: 813
num of updates: 81400
emp loss: 2.12594

============================================================
time elapsed: 1:50:09
train iter: 814
num of updates: 81500
emp loss: 2.12479

============================================================
time elapsed: 1:50:11
train iter: 815
num of updates: 81600
emp loss: 2.12521

============================================================
time elapsed: 1:50:13
train iter: 816
num of updates: 81700
emp loss: 2.12426

============================================================
time elapsed: 1:50:15
train iter: 817
num of updates: 81800
emp loss: 2.12348

============================================================
time elapsed: 1:50:17
train iter: 818
num of updates: 81900
emp loss: 2.12685

============================================================
time elapsed: 1:50:20
train iter: 819
num of updates: 82000
emp loss: 2.12540

============================================================
time elapsed: 1:50:22
train iter: 820
num of updates: 82100
emp loss: 2.12383

============================================================
time elapsed: 1:50:24
train iter: 821
num of updates: 82200
emp loss: 2.12376

============================================================
time elapsed: 1:50:26
train iter: 822
num of updates: 82300
emp loss: 2.12273

============================================================
time elapsed: 1:50:29
train iter: 823
num of updates: 82400
emp loss: 2.12435

============================================================
time elapsed: 1:50:31
train iter: 824
num of updates: 82500
emp loss: 2.12144

============================================================
time elapsed: 1:50:33
train iter: 825
num of updates: 82600
emp loss: 2.12515

============================================================
time elapsed: 1:50:35
train iter: 826
num of updates: 82700
emp loss: 2.12690

============================================================
time elapsed: 1:50:38
train iter: 827
num of updates: 82800
emp loss: 2.12699

============================================================
time elapsed: 1:50:40
train iter: 828
num of updates: 82900
emp loss: 2.12490

============================================================
time elapsed: 1:50:42
train iter: 829
num of updates: 83000
emp loss: 2.12397

============================================================
time elapsed: 1:50:44
train iter: 830
num of updates: 83100
emp loss: 2.12285

============================================================
time elapsed: 1:50:47
train iter: 831
num of updates: 83200
emp loss: 2.12246

============================================================
time elapsed: 1:50:49
train iter: 832
num of updates: 83300
emp loss: 2.12334

============================================================
time elapsed: 1:50:51
train iter: 833
num of updates: 83400
emp loss: 2.12622

============================================================
time elapsed: 1:50:53
train iter: 834
num of updates: 83500
emp loss: 2.12151

============================================================
time elapsed: 1:50:56
train iter: 835
num of updates: 83600
emp loss: 2.12487

============================================================
time elapsed: 1:50:58
train iter: 836
num of updates: 83700
emp loss: 2.12464

============================================================
time elapsed: 1:51:00
train iter: 837
num of updates: 83800
emp loss: 2.12484

============================================================
time elapsed: 1:51:02
train iter: 838
num of updates: 83900
emp loss: 2.12221

============================================================
time elapsed: 1:51:04
train iter: 839
num of updates: 84000
emp loss: 2.12141

============================================================
time elapsed: 1:51:07
train iter: 840
num of updates: 84100
emp loss: 2.12035

============================================================
time elapsed: 1:51:09
train iter: 841
num of updates: 84200
emp loss: 2.12412

============================================================
time elapsed: 1:51:11
train iter: 842
num of updates: 84300
emp loss: 2.12563

============================================================
time elapsed: 1:51:13
train iter: 843
num of updates: 84400
emp loss: 2.12267

============================================================
time elapsed: 1:51:16
train iter: 844
num of updates: 84500
emp loss: 2.12337

============================================================
time elapsed: 1:51:18
train iter: 845
num of updates: 84600
emp loss: 2.12591

============================================================
time elapsed: 1:51:20
train iter: 846
num of updates: 84700
emp loss: 2.12543

============================================================
time elapsed: 1:51:22
train iter: 847
num of updates: 84800
emp loss: 2.12316

============================================================
time elapsed: 1:51:25
train iter: 848
num of updates: 84900
emp loss: 2.12627

============================================================
time elapsed: 1:51:27
train iter: 849
num of updates: 85000
emp loss: 2.12287

============================================================
time elapsed: 1:51:29
train iter: 850
num of updates: 85100
emp loss: 2.12131

============================================================
time elapsed: 1:51:31
train iter: 851
num of updates: 85200
emp loss: 2.12124

============================================================
time elapsed: 1:51:34
train iter: 852
num of updates: 85300
emp loss: 2.12229

============================================================
time elapsed: 1:51:36
train iter: 853
num of updates: 85400
emp loss: 2.12242

============================================================
time elapsed: 1:51:38
train iter: 854
num of updates: 85500
emp loss: 2.12436

============================================================
time elapsed: 1:51:40
train iter: 855
num of updates: 85600
emp loss: 2.12373

============================================================
time elapsed: 1:51:43
train iter: 856
num of updates: 85700
emp loss: 2.12179

============================================================
time elapsed: 1:51:45
train iter: 857
num of updates: 85800
emp loss: 2.12489

============================================================
time elapsed: 1:51:47
train iter: 858
num of updates: 85900
emp loss: 2.12166

============================================================
time elapsed: 1:51:49
train iter: 859
num of updates: 86000
emp loss: 2.12431

============================================================
time elapsed: 1:51:51
train iter: 860
num of updates: 86100
emp loss: 2.12360

============================================================
time elapsed: 1:51:54
train iter: 861
num of updates: 86200
emp loss: 2.12482

============================================================
time elapsed: 1:51:56
train iter: 862
num of updates: 86300
emp loss: 2.12297

============================================================
time elapsed: 1:51:58
train iter: 863
num of updates: 86400
emp loss: 2.12617

============================================================
time elapsed: 1:52:00
train iter: 864
num of updates: 86500
emp loss: 2.12430

============================================================
time elapsed: 1:52:03
train iter: 865
num of updates: 86600
emp loss: 2.12660

============================================================
time elapsed: 1:52:05
train iter: 866
num of updates: 86700
emp loss: 2.12284

============================================================
time elapsed: 1:52:07
train iter: 867
num of updates: 86800
emp loss: 2.12179

============================================================
time elapsed: 1:52:09
train iter: 868
num of updates: 86900
emp loss: 2.12335

============================================================
time elapsed: 1:52:12
train iter: 869
num of updates: 87000
emp loss: 2.12558

============================================================
time elapsed: 1:52:14
train iter: 870
num of updates: 87100
emp loss: 2.12553

============================================================
time elapsed: 1:52:16
train iter: 871
num of updates: 87200
emp loss: 2.12430

============================================================
time elapsed: 1:52:18
train iter: 872
num of updates: 87300
emp loss: 2.12298

============================================================
time elapsed: 1:52:21
train iter: 873
num of updates: 87400
emp loss: 2.12125

============================================================
time elapsed: 1:52:23
train iter: 874
num of updates: 87500
emp loss: 2.12290

============================================================
time elapsed: 1:52:25
train iter: 875
num of updates: 87600
emp loss: 2.12243

============================================================
time elapsed: 1:52:27
train iter: 876
num of updates: 87700
emp loss: 2.12208

============================================================
time elapsed: 1:52:30
train iter: 877
num of updates: 87800
emp loss: 2.12281

============================================================
time elapsed: 1:52:32
train iter: 878
num of updates: 87900
emp loss: 2.12490

============================================================
time elapsed: 1:52:34
train iter: 879
num of updates: 88000
emp loss: 2.12277

============================================================
time elapsed: 1:52:36
train iter: 880
num of updates: 88100
emp loss: 2.12240

============================================================
time elapsed: 1:52:38
train iter: 881
num of updates: 88200
emp loss: 2.12264

============================================================
time elapsed: 1:52:41
train iter: 882
num of updates: 88300
emp loss: 2.12573

============================================================
time elapsed: 1:52:43
train iter: 883
num of updates: 88400
emp loss: 2.12434

============================================================
time elapsed: 1:52:45
train iter: 884
num of updates: 88500
emp loss: 2.12697

============================================================
time elapsed: 1:52:47
train iter: 885
num of updates: 88600
emp loss: 2.12123

============================================================
time elapsed: 1:52:50
train iter: 886
num of updates: 88700
emp loss: 2.12553

============================================================
time elapsed: 1:52:52
train iter: 887
num of updates: 88800
emp loss: 2.12511

============================================================
time elapsed: 1:52:54
train iter: 888
num of updates: 88900
emp loss: 2.12244

============================================================
time elapsed: 1:52:56
train iter: 889
num of updates: 89000
emp loss: 2.12393

============================================================
time elapsed: 1:52:59
train iter: 890
num of updates: 89100
emp loss: 2.12310

============================================================
time elapsed: 1:53:01
train iter: 891
num of updates: 89200
emp loss: 2.12364

============================================================
time elapsed: 1:53:03
train iter: 892
num of updates: 89300
emp loss: 2.12111

============================================================
time elapsed: 1:53:05
train iter: 893
num of updates: 89400
emp loss: 2.12248

============================================================
time elapsed: 1:53:08
train iter: 894
num of updates: 89500
emp loss: 2.12393

============================================================
time elapsed: 1:53:10
train iter: 895
num of updates: 89600
emp loss: 2.12372

============================================================
time elapsed: 1:53:12
train iter: 896
num of updates: 89700
emp loss: 2.12243

============================================================
time elapsed: 1:53:14
train iter: 897
num of updates: 89800
emp loss: 2.12492

============================================================
time elapsed: 1:53:17
train iter: 898
num of updates: 89900
emp loss: 2.12399

============================================================
time elapsed: 1:53:19
train iter: 899
num of updates: 90000
emp loss: 2.12472

============================================================
time elapsed: 1:53:21
train iter: 900
num of updates: 90100
emp loss: 2.12115

============================================================
time elapsed: 1:53:23
train iter: 901
num of updates: 90200
emp loss: 2.12444

============================================================
time elapsed: 1:53:25
train iter: 902
num of updates: 90300
emp loss: 2.12511

============================================================
time elapsed: 1:53:28
train iter: 903
num of updates: 90400
emp loss: 2.12443

============================================================
time elapsed: 1:53:30
train iter: 904
num of updates: 90500
emp loss: 2.12360

============================================================
time elapsed: 1:53:32
train iter: 905
num of updates: 90600
emp loss: 2.12087

============================================================
time elapsed: 1:53:34
train iter: 906
num of updates: 90700
emp loss: 2.12390

============================================================
time elapsed: 1:53:37
train iter: 907
num of updates: 90800
emp loss: 2.12430

============================================================
time elapsed: 1:53:39
train iter: 908
num of updates: 90900
emp loss: 2.12386

============================================================
time elapsed: 1:53:41
train iter: 909
num of updates: 91000
emp loss: 2.12256

============================================================
time elapsed: 1:53:43
train iter: 910
num of updates: 91100
emp loss: 2.12240

============================================================
time elapsed: 1:53:46
train iter: 911
num of updates: 91200
emp loss: 2.11962

============================================================
time elapsed: 1:53:48
train iter: 912
num of updates: 91300
emp loss: 2.12168

============================================================
time elapsed: 1:53:50
train iter: 913
num of updates: 91400
emp loss: 2.12353

============================================================
time elapsed: 1:53:52
train iter: 914
num of updates: 91500
emp loss: 2.12271

============================================================
time elapsed: 1:53:55
train iter: 915
num of updates: 91600
emp loss: 2.11904

============================================================
time elapsed: 1:53:57
train iter: 916
num of updates: 91700
emp loss: 2.12378

============================================================
time elapsed: 1:53:59
train iter: 917
num of updates: 91800
emp loss: 2.12203

============================================================
time elapsed: 1:54:01
train iter: 918
num of updates: 91900
emp loss: 2.12399

============================================================
time elapsed: 1:54:04
train iter: 919
num of updates: 92000
emp loss: 2.12109

============================================================
time elapsed: 1:54:06
train iter: 920
num of updates: 92100
emp loss: 2.11935

============================================================
time elapsed: 1:54:08
train iter: 921
num of updates: 92200
emp loss: 2.12244

============================================================
time elapsed: 1:54:10
train iter: 922
num of updates: 92300
emp loss: 2.12197

============================================================
time elapsed: 1:54:12
train iter: 923
num of updates: 92400
emp loss: 2.12340

============================================================
time elapsed: 1:54:15
train iter: 924
num of updates: 92500
emp loss: 2.12569

============================================================
time elapsed: 1:54:17
train iter: 925
num of updates: 92600
emp loss: 2.12479

============================================================
time elapsed: 1:54:19
train iter: 926
num of updates: 92700
emp loss: 2.12081

============================================================
time elapsed: 1:54:21
train iter: 927
num of updates: 92800
emp loss: 2.12003

============================================================
time elapsed: 1:54:24
train iter: 928
num of updates: 92900
emp loss: 2.12147

============================================================
time elapsed: 1:54:26
train iter: 929
num of updates: 93000
emp loss: 2.12101

============================================================
time elapsed: 1:54:28
train iter: 930
num of updates: 93100
emp loss: 2.12210

============================================================
time elapsed: 1:54:30
train iter: 931
num of updates: 93200
emp loss: 2.12485

============================================================
time elapsed: 1:54:33
train iter: 932
num of updates: 93300
emp loss: 2.12363

============================================================
time elapsed: 1:54:35
train iter: 933
num of updates: 93400
emp loss: 2.12608

============================================================
time elapsed: 1:54:37
train iter: 934
num of updates: 93500
emp loss: 2.12186

============================================================
time elapsed: 1:54:39
train iter: 935
num of updates: 93600
emp loss: 2.12352

============================================================
time elapsed: 1:54:42
train iter: 936
num of updates: 93700
emp loss: 2.12444

============================================================
time elapsed: 1:54:44
train iter: 937
num of updates: 93800
emp loss: 2.12266

============================================================
time elapsed: 1:54:46
train iter: 938
num of updates: 93900
emp loss: 2.12351

============================================================
time elapsed: 1:54:48
train iter: 939
num of updates: 94000
emp loss: 2.11911

============================================================
time elapsed: 1:54:51
train iter: 940
num of updates: 94100
emp loss: 2.12360

============================================================
time elapsed: 1:54:53
train iter: 941
num of updates: 94200
emp loss: 2.12266

============================================================
time elapsed: 1:54:55
train iter: 942
num of updates: 94300
emp loss: 2.12058

============================================================
time elapsed: 1:54:57
train iter: 943
num of updates: 94400
emp loss: 2.12441

============================================================
time elapsed: 1:55:00
train iter: 944
num of updates: 94500
emp loss: 2.12401

============================================================
time elapsed: 1:55:02
train iter: 945
num of updates: 94600
emp loss: 2.12148

============================================================
time elapsed: 1:55:04
train iter: 946
num of updates: 94700
emp loss: 2.12289

============================================================
time elapsed: 1:55:06
train iter: 947
num of updates: 94800
emp loss: 2.12379

============================================================
time elapsed: 1:55:08
train iter: 948
num of updates: 94900
emp loss: 2.12453

============================================================
time elapsed: 1:55:11
train iter: 949
num of updates: 95000
emp loss: 2.12493

============================================================
time elapsed: 1:55:13
train iter: 950
num of updates: 95100
emp loss: 2.12195

============================================================
time elapsed: 1:55:15
train iter: 951
num of updates: 95200
emp loss: 2.12049

============================================================
time elapsed: 1:55:17
train iter: 952
num of updates: 95300
emp loss: 2.12036

============================================================
time elapsed: 1:55:20
train iter: 953
num of updates: 95400
emp loss: 2.12291

============================================================
time elapsed: 1:55:22
train iter: 954
num of updates: 95500
emp loss: 2.12178

============================================================
time elapsed: 1:55:24
train iter: 955
num of updates: 95600
emp loss: 2.12332

============================================================
time elapsed: 1:55:26
train iter: 956
num of updates: 95700
emp loss: 2.12064

============================================================
time elapsed: 1:55:29
train iter: 957
num of updates: 95800
emp loss: 2.12471

============================================================
time elapsed: 1:55:31
train iter: 958
num of updates: 95900
emp loss: 2.12005

============================================================
time elapsed: 1:55:33
train iter: 959
num of updates: 96000
emp loss: 2.12279

============================================================
time elapsed: 1:55:35
train iter: 960
num of updates: 96100
emp loss: 2.12314

============================================================
time elapsed: 1:55:38
train iter: 961
num of updates: 96200
emp loss: 2.12135

============================================================
time elapsed: 1:55:40
train iter: 962
num of updates: 96300
emp loss: 2.12238

============================================================
time elapsed: 1:55:42
train iter: 963
num of updates: 96400
emp loss: 2.12451

============================================================
time elapsed: 1:55:44
train iter: 964
num of updates: 96500
emp loss: 2.11973

============================================================
time elapsed: 1:55:47
train iter: 965
num of updates: 96600
emp loss: 2.12316

============================================================
time elapsed: 1:55:49
train iter: 966
num of updates: 96700
emp loss: 2.12323

============================================================
time elapsed: 1:55:51
train iter: 967
num of updates: 96800
emp loss: 2.12218

============================================================
time elapsed: 1:55:53
train iter: 968
num of updates: 96900
emp loss: 2.12318

============================================================
time elapsed: 1:55:55
train iter: 969
num of updates: 97000
emp loss: 2.11957

============================================================
time elapsed: 1:55:58
train iter: 970
num of updates: 97100
emp loss: 2.12148

============================================================
time elapsed: 1:56:00
train iter: 971
num of updates: 97200
emp loss: 2.12354

============================================================
time elapsed: 1:56:02
train iter: 972
num of updates: 97300
emp loss: 2.12042

============================================================
time elapsed: 1:56:04
train iter: 973
num of updates: 97400
emp loss: 2.12234

============================================================
time elapsed: 1:56:07
train iter: 974
num of updates: 97500
emp loss: 2.12267

============================================================
time elapsed: 1:56:09
train iter: 975
num of updates: 97600
emp loss: 2.12015

============================================================
time elapsed: 1:56:11
train iter: 976
num of updates: 97700
emp loss: 2.12571

============================================================
time elapsed: 1:56:13
train iter: 977
num of updates: 97800
emp loss: 2.12204

============================================================
time elapsed: 1:56:16
train iter: 978
num of updates: 97900
emp loss: 2.12285

============================================================
time elapsed: 1:56:18
train iter: 979
num of updates: 98000
emp loss: 2.12222

============================================================
time elapsed: 1:56:20
train iter: 980
num of updates: 98100
emp loss: 2.11864

============================================================
time elapsed: 1:56:22
train iter: 981
num of updates: 98200
emp loss: 2.12069

============================================================
time elapsed: 1:56:25
train iter: 982
num of updates: 98300
emp loss: 2.12167

============================================================
time elapsed: 1:56:27
train iter: 983
num of updates: 98400
emp loss: 2.11976

============================================================
time elapsed: 1:56:29
train iter: 984
num of updates: 98500
emp loss: 2.12537

============================================================
time elapsed: 1:56:31
train iter: 985
num of updates: 98600
emp loss: 2.12204

============================================================
time elapsed: 1:56:34
train iter: 986
num of updates: 98700
emp loss: 2.12406

============================================================
time elapsed: 1:56:36
train iter: 987
num of updates: 98800
emp loss: 2.12460

============================================================
time elapsed: 1:56:38
train iter: 988
num of updates: 98900
emp loss: 2.11975

============================================================
time elapsed: 1:56:40
train iter: 989
num of updates: 99000
emp loss: 2.12289

============================================================
time elapsed: 1:56:43
train iter: 990
num of updates: 99100
emp loss: 2.12377

============================================================
time elapsed: 1:56:45
train iter: 991
num of updates: 99200
emp loss: 2.12233

============================================================
time elapsed: 1:56:47
train iter: 992
num of updates: 99300
emp loss: 2.12233

============================================================
time elapsed: 1:56:49
train iter: 993
num of updates: 99400
emp loss: 2.12046

============================================================
time elapsed: 1:56:51
train iter: 994
num of updates: 99500
emp loss: 2.12126

============================================================
time elapsed: 1:56:54
train iter: 995
num of updates: 99600
emp loss: 2.12181

============================================================
time elapsed: 1:56:56
train iter: 996
num of updates: 99700
emp loss: 2.12107

============================================================
time elapsed: 1:56:58
train iter: 997
num of updates: 99800
emp loss: 2.11837

============================================================
time elapsed: 1:57:00
train iter: 998
num of updates: 99900
emp loss: 2.12160

============================================================
time elapsed: 1:57:03
train iter: 999
num of updates: 100000
emp loss: 2.12323

saving current model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/emp_model_100000.pt
============================================================
finished training emp!
============================================================
started training emp at: 25-09-28-13-10-46
finished training emp at: 25-09-28-15-07-54
total emp training time: 1:57:08
saved last updated model at: /nfs/nhome/live/jheald/jax_dt/model_outputs/2025-09-28/4ikd39ml/emp_model
============================================================
--- Logging error ---
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/logging/__init__.py", line 1164, in emit
    self.flush()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/logging/__init__.py", line 1144, in flush
    self.stream.flush()
OSError: [Errno 116] Stale file handle
Call stack:
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/threading.py", line 1032, in _bootstrap
    self._bootstrap_inner()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 71, in message_loop
    self._mailbox.close()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/wandb/sdk/mailbox/mailbox.py", line 129, in close
    _logger.info(
Message: 'Closing mailbox, abandoning 1 handles.'
Arguments: ()
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrelocate-expert-v1-985440[0m at: [34mhttps://wandb.ai/james-gatsby/jax_dt/runs/4ikd39ml[0m
