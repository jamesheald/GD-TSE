Launching a python run
Sun Sep 28 12:54:00 AM UTC 2025
Active conda env: /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/python3
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/bin/pip
2025-09-28 00:54:21.602245: I external/xla/xla/pjrt/pjrt_api.cc:115] GetPjrtApi was found for cuda at /nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/jax_plugins/xla_cuda12/xla_cuda_plugin.so
2025-09-28 00:54:21.603451: I external/xla/xla/pjrt/pjrt_api.cc:93] PJRT_Api is set for device type cuda
2025-09-28 00:54:21.663700: I external/xla/xla/pjrt/pjrt_api.cc:161] The PJRT plugin has PJRT API version 0.70. The framework PJRT API version is 0.70.
2025-09-28 00:54:22.099638: I external/xla/xla/service/service.cc:153] XLA service 0x56421f9660f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-09-28 00:54:22.099662: I external/xla/xla/service/service.cc:161]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2025-09-28 00:54:22.156318: I external/xla/xla/pjrt/pjrt_c_api_client.cc:130] PjRtCApiClient created.
[CudaDevice(id=0)]
/nfs/nhome/live/jheald/jax_dt/train_dt.py:50: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path=cfg_path, config_name="config.yaml")
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
============================================================
start time: 25-09-28-00-54-25
============================================================
dataset path: data//relocate-expert-v1-fullnextstate.pkl
log csv save path: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/log.csv
[2025-09-28 00:54:26,580][OpenGL.acceleratesupport][INFO] - No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'
wandb: Currently logged in as: james-heald (james-gatsby) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /nfs/nhome/live/jheald/jax_dt/outputs/2025-09-28/00-54-23/wandb/run-20250928_005517-vyerg8uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run relocate-expert-v1-985440
wandb: ‚≠êÔ∏è View project at https://wandb.ai/james-gatsby/jax_dt
wandb: üöÄ View run at https://wandb.ai/james-gatsby/jax_dt/runs/vyerg8uv
2025-09-28 00:55:21.050606: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 00:55:24.425853: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 232 bytes spill stores, 232 bytes spill loads

2025-09-28 00:55:25.752621: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 628 bytes spill stores, 492 bytes spill loads

2025-09-28 00:55:30.558913: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 2140 bytes spill stores, 1648 bytes spill loads

2025-09-28 00:55:30.756433: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 388 bytes spill stores, 296 bytes spill loads

2025-09-28 00:55:31.801802: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 80 bytes spill stores, 80 bytes spill loads

2025-09-28 00:55:34.322750: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 12 bytes spill stores, 12 bytes spill loads

2025-09-28 00:55:35.607047: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 16008 bytes spill stores, 16296 bytes spill loads

2025-09-28 00:55:36.270405: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 1016 bytes spill stores, 1016 bytes spill loads

2025-09-28 00:55:39.384271: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 5912 bytes spill stores, 5776 bytes spill loads

2025-09-28 00:55:40.211886: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 436 bytes spill stores, 436 bytes spill loads

============================================================
time elapsed: 0:01:21
train iter: 0
num of updates: 100
dynamics loss: 362632.12500

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/dynamics_model_100.pt
/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = _fork_exec(
============================================================
time elapsed: 0:01:33
train iter: 1
num of updates: 200
dynamics loss: 362374.12500

============================================================
time elapsed: 0:01:36
train iter: 2
num of updates: 300
dynamics loss: 361995.59375

============================================================
time elapsed: 0:01:39
train iter: 3
num of updates: 400
dynamics loss: 361465.56250

============================================================
time elapsed: 0:01:41
train iter: 4
num of updates: 500
dynamics loss: 360738.06250

============================================================
time elapsed: 0:01:44
train iter: 5
num of updates: 600
dynamics loss: 359797.65625

============================================================
time elapsed: 0:01:47
train iter: 6
num of updates: 700
dynamics loss: 358565.06250

============================================================
time elapsed: 0:01:50
train iter: 7
num of updates: 800
dynamics loss: 357281.87500

============================================================
time elapsed: 0:01:53
train iter: 8
num of updates: 900
dynamics loss: 355958.28125

============================================================
time elapsed: 0:01:56
train iter: 9
num of updates: 1000
dynamics loss: 354116.37500

============================================================
time elapsed: 0:01:59
train iter: 10
num of updates: 1100
dynamics loss: 352194.93750

============================================================
time elapsed: 0:02:02
train iter: 11
num of updates: 1200
dynamics loss: 350299.59375

============================================================
time elapsed: 0:02:05
train iter: 12
num of updates: 1300
dynamics loss: 347948.93750

============================================================
time elapsed: 0:02:08
train iter: 13
num of updates: 1400
dynamics loss: 345720.50000

============================================================
time elapsed: 0:02:10
train iter: 14
num of updates: 1500
dynamics loss: 343151.34375

============================================================
time elapsed: 0:02:13
train iter: 15
num of updates: 1600
dynamics loss: 340521.40625

============================================================
time elapsed: 0:02:16
train iter: 16
num of updates: 1700
dynamics loss: 337549.62500

============================================================
time elapsed: 0:02:19
train iter: 17
num of updates: 1800
dynamics loss: 334451.53125

============================================================
time elapsed: 0:02:22
train iter: 18
num of updates: 1900
dynamics loss: 331242.96875

============================================================
time elapsed: 0:02:25
train iter: 19
num of updates: 2000
dynamics loss: 328067.87500

============================================================
time elapsed: 0:02:28
train iter: 20
num of updates: 2100
dynamics loss: 324501.43750

============================================================
time elapsed: 0:02:31
train iter: 21
num of updates: 2200
dynamics loss: 320934.75000

============================================================
time elapsed: 0:02:34
train iter: 22
num of updates: 2300
dynamics loss: 317115.00000

============================================================
time elapsed: 0:02:37
train iter: 23
num of updates: 2400
dynamics loss: 313338.34375

============================================================
time elapsed: 0:02:39
train iter: 24
num of updates: 2500
dynamics loss: 309313.53125

============================================================
time elapsed: 0:02:42
train iter: 25
num of updates: 2600
dynamics loss: 305254.09375

============================================================
time elapsed: 0:02:45
train iter: 26
num of updates: 2700
dynamics loss: 300905.15625

============================================================
time elapsed: 0:02:48
train iter: 27
num of updates: 2800
dynamics loss: 296674.12500

============================================================
time elapsed: 0:02:51
train iter: 28
num of updates: 2900
dynamics loss: 292124.81250

============================================================
time elapsed: 0:02:54
train iter: 29
num of updates: 3000
dynamics loss: 287594.12500

============================================================
time elapsed: 0:02:57
train iter: 30
num of updates: 3100
dynamics loss: 283032.81250

============================================================
time elapsed: 0:03:00
train iter: 31
num of updates: 3200
dynamics loss: 278290.87500

============================================================
time elapsed: 0:03:03
train iter: 32
num of updates: 3300
dynamics loss: 273460.62500

============================================================
time elapsed: 0:03:06
train iter: 33
num of updates: 3400
dynamics loss: 268630.28125

============================================================
time elapsed: 0:03:08
train iter: 34
num of updates: 3500
dynamics loss: 263657.37500

============================================================
time elapsed: 0:03:11
train iter: 35
num of updates: 3600
dynamics loss: 258803.56250

============================================================
time elapsed: 0:03:14
train iter: 36
num of updates: 3700
dynamics loss: 253758.34375

============================================================
time elapsed: 0:03:17
train iter: 37
num of updates: 3800
dynamics loss: 248600.87500

============================================================
time elapsed: 0:03:20
train iter: 38
num of updates: 3900
dynamics loss: 243608.48438

============================================================
time elapsed: 0:03:23
train iter: 39
num of updates: 4000
dynamics loss: 238328.78125

============================================================
time elapsed: 0:03:26
train iter: 40
num of updates: 4100
dynamics loss: 233271.46875

============================================================
time elapsed: 0:03:29
train iter: 41
num of updates: 4200
dynamics loss: 228207.32812

============================================================
time elapsed: 0:03:32
train iter: 42
num of updates: 4300
dynamics loss: 222960.96875

============================================================
time elapsed: 0:03:35
train iter: 43
num of updates: 4400
dynamics loss: 217908.04688

============================================================
time elapsed: 0:03:37
train iter: 44
num of updates: 4500
dynamics loss: 212761.15625

============================================================
time elapsed: 0:03:40
train iter: 45
num of updates: 4600
dynamics loss: 207712.78125

============================================================
time elapsed: 0:03:43
train iter: 46
num of updates: 4700
dynamics loss: 202567.21875

============================================================
time elapsed: 0:03:46
train iter: 47
num of updates: 4800
dynamics loss: 197533.37500

============================================================
time elapsed: 0:03:49
train iter: 48
num of updates: 4900
dynamics loss: 192508.65625

============================================================
time elapsed: 0:03:52
train iter: 49
num of updates: 5000
dynamics loss: 187652.15625

============================================================
time elapsed: 0:03:55
train iter: 50
num of updates: 5100
dynamics loss: 182723.34375

============================================================
time elapsed: 0:03:58
train iter: 51
num of updates: 5200
dynamics loss: 177962.39062

============================================================
time elapsed: 0:04:01
train iter: 52
num of updates: 5300
dynamics loss: 173155.65625

============================================================
time elapsed: 0:04:03
train iter: 53
num of updates: 5400
dynamics loss: 168491.87500

============================================================
time elapsed: 0:04:06
train iter: 54
num of updates: 5500
dynamics loss: 163954.29688

============================================================
time elapsed: 0:04:09
train iter: 55
num of updates: 5600
dynamics loss: 159433.68750

============================================================
time elapsed: 0:04:12
train iter: 56
num of updates: 5700
dynamics loss: 155038.50000

============================================================
time elapsed: 0:04:15
train iter: 57
num of updates: 5800
dynamics loss: 150591.35938

============================================================
time elapsed: 0:04:18
train iter: 58
num of updates: 5900
dynamics loss: 146466.65625

============================================================
time elapsed: 0:04:21
train iter: 59
num of updates: 6000
dynamics loss: 142313.50000

============================================================
time elapsed: 0:04:24
train iter: 60
num of updates: 6100
dynamics loss: 138344.10938

============================================================
time elapsed: 0:04:27
train iter: 61
num of updates: 6200
dynamics loss: 134524.78125

============================================================
time elapsed: 0:04:30
train iter: 62
num of updates: 6300
dynamics loss: 130695.40625

============================================================
time elapsed: 0:04:32
train iter: 63
num of updates: 6400
dynamics loss: 127189.33594

============================================================
time elapsed: 0:04:35
train iter: 64
num of updates: 6500
dynamics loss: 123640.19531

============================================================
time elapsed: 0:04:38
train iter: 65
num of updates: 6600
dynamics loss: 120167.28906

============================================================
time elapsed: 0:04:41
train iter: 66
num of updates: 6700
dynamics loss: 116918.03906

============================================================
time elapsed: 0:04:44
train iter: 67
num of updates: 6800
dynamics loss: 113749.29688

============================================================
time elapsed: 0:04:47
train iter: 68
num of updates: 6900
dynamics loss: 110779.33594

============================================================
time elapsed: 0:04:50
train iter: 69
num of updates: 7000
dynamics loss: 107820.12500

============================================================
time elapsed: 0:04:53
train iter: 70
num of updates: 7100
dynamics loss: 105028.05469

============================================================
time elapsed: 0:04:56
train iter: 71
num of updates: 7200
dynamics loss: 102368.85156

============================================================
time elapsed: 0:04:59
train iter: 72
num of updates: 7300
dynamics loss: 99751.32031

============================================================
time elapsed: 0:05:01
train iter: 73
num of updates: 7400
dynamics loss: 97332.22656

============================================================
time elapsed: 0:05:04
train iter: 74
num of updates: 7500
dynamics loss: 94920.14062

============================================================
time elapsed: 0:05:07
train iter: 75
num of updates: 7600
dynamics loss: 92629.90625

============================================================
time elapsed: 0:05:10
train iter: 76
num of updates: 7700
dynamics loss: 90424.43750

============================================================
time elapsed: 0:05:13
train iter: 77
num of updates: 7800
dynamics loss: 88342.03906

============================================================
time elapsed: 0:05:16
train iter: 78
num of updates: 7900
dynamics loss: 86388.37500

============================================================
time elapsed: 0:05:19
train iter: 79
num of updates: 8000
dynamics loss: 84479.23438

============================================================
time elapsed: 0:05:22
train iter: 80
num of updates: 8100
dynamics loss: 82601.11719

============================================================
time elapsed: 0:05:25
train iter: 81
num of updates: 8200
dynamics loss: 80847.57031

============================================================
time elapsed: 0:05:28
train iter: 82
num of updates: 8300
dynamics loss: 79039.09375

============================================================
time elapsed: 0:05:30
train iter: 83
num of updates: 8400
dynamics loss: 77456.58594

============================================================
time elapsed: 0:05:33
train iter: 84
num of updates: 8500
dynamics loss: 75810.67188

============================================================
time elapsed: 0:05:36
train iter: 85
num of updates: 8600
dynamics loss: 74362.42969

============================================================
time elapsed: 0:05:39
train iter: 86
num of updates: 8700
dynamics loss: 72865.31250

============================================================
time elapsed: 0:05:42
train iter: 87
num of updates: 8800
dynamics loss: 71384.42188

============================================================
time elapsed: 0:05:45
train iter: 88
num of updates: 8900
dynamics loss: 69986.80469

============================================================
time elapsed: 0:05:48
train iter: 89
num of updates: 9000
dynamics loss: 68651.82812

============================================================
time elapsed: 0:05:51
train iter: 90
num of updates: 9100
dynamics loss: 67323.14062

============================================================
time elapsed: 0:05:54
train iter: 91
num of updates: 9200
dynamics loss: 66024.85938

============================================================
time elapsed: 0:05:56
train iter: 92
num of updates: 9300
dynamics loss: 64807.90625

============================================================
time elapsed: 0:05:59
train iter: 93
num of updates: 9400
dynamics loss: 63624.24219

============================================================
time elapsed: 0:06:02
train iter: 94
num of updates: 9500
dynamics loss: 62456.80859

============================================================
time elapsed: 0:06:05
train iter: 95
num of updates: 9600
dynamics loss: 61298.08203

============================================================
time elapsed: 0:06:08
train iter: 96
num of updates: 9700
dynamics loss: 60228.99219

============================================================
time elapsed: 0:06:11
train iter: 97
num of updates: 9800
dynamics loss: 59202.01953

============================================================
time elapsed: 0:06:14
train iter: 98
num of updates: 9900
dynamics loss: 58123.32031

============================================================
time elapsed: 0:06:17
train iter: 99
num of updates: 10000
dynamics loss: 57187.52344

============================================================
time elapsed: 0:06:20
train iter: 100
num of updates: 10100
dynamics loss: 56154.32812

============================================================
time elapsed: 0:06:23
train iter: 101
num of updates: 10200
dynamics loss: 55285.52344

============================================================
time elapsed: 0:06:25
train iter: 102
num of updates: 10300
dynamics loss: 54322.49219

============================================================
time elapsed: 0:06:28
train iter: 103
num of updates: 10400
dynamics loss: 53450.33203

============================================================
time elapsed: 0:06:31
train iter: 104
num of updates: 10500
dynamics loss: 52572.80078

============================================================
time elapsed: 0:06:34
train iter: 105
num of updates: 10600
dynamics loss: 51832.70312

============================================================
time elapsed: 0:06:37
train iter: 106
num of updates: 10700
dynamics loss: 51017.85938

============================================================
time elapsed: 0:06:40
train iter: 107
num of updates: 10800
dynamics loss: 50297.08594

============================================================
time elapsed: 0:06:43
train iter: 108
num of updates: 10900
dynamics loss: 49545.73828

============================================================
time elapsed: 0:06:46
train iter: 109
num of updates: 11000
dynamics loss: 48849.64844

============================================================
time elapsed: 0:06:49
train iter: 110
num of updates: 11100
dynamics loss: 48171.06641

============================================================
time elapsed: 0:06:52
train iter: 111
num of updates: 11200
dynamics loss: 47485.51562

============================================================
time elapsed: 0:06:54
train iter: 112
num of updates: 11300
dynamics loss: 46868.63672

============================================================
time elapsed: 0:06:57
train iter: 113
num of updates: 11400
dynamics loss: 46201.90625

============================================================
time elapsed: 0:07:00
train iter: 114
num of updates: 11500
dynamics loss: 45649.95703

============================================================
time elapsed: 0:07:03
train iter: 115
num of updates: 11600
dynamics loss: 45059.16406

============================================================
time elapsed: 0:07:06
train iter: 116
num of updates: 11700
dynamics loss: 44539.22656

============================================================
time elapsed: 0:07:09
train iter: 117
num of updates: 11800
dynamics loss: 43980.00000

============================================================
time elapsed: 0:07:12
train iter: 118
num of updates: 11900
dynamics loss: 43456.30078

============================================================
time elapsed: 0:07:15
train iter: 119
num of updates: 12000
dynamics loss: 42953.32031

============================================================
time elapsed: 0:07:18
train iter: 120
num of updates: 12100
dynamics loss: 42415.58203

============================================================
time elapsed: 0:07:20
train iter: 121
num of updates: 12200
dynamics loss: 41968.35547

============================================================
time elapsed: 0:07:23
train iter: 122
num of updates: 12300
dynamics loss: 41478.16406

============================================================
time elapsed: 0:07:26
train iter: 123
num of updates: 12400
dynamics loss: 41031.38281

============================================================
time elapsed: 0:07:29
train iter: 124
num of updates: 12500
dynamics loss: 40599.48047

============================================================
time elapsed: 0:07:32
train iter: 125
num of updates: 12600
dynamics loss: 40158.08203

============================================================
time elapsed: 0:07:35
train iter: 126
num of updates: 12700
dynamics loss: 39764.58203

============================================================
time elapsed: 0:07:38
train iter: 127
num of updates: 12800
dynamics loss: 39330.79297

============================================================
time elapsed: 0:07:41
train iter: 128
num of updates: 12900
dynamics loss: 38965.26562

============================================================
time elapsed: 0:07:44
train iter: 129
num of updates: 13000
dynamics loss: 38582.39453

============================================================
time elapsed: 0:07:47
train iter: 130
num of updates: 13100
dynamics loss: 38194.28125

============================================================
time elapsed: 0:07:49
train iter: 131
num of updates: 13200
dynamics loss: 37832.65625

============================================================
time elapsed: 0:07:52
train iter: 132
num of updates: 13300
dynamics loss: 37462.44922

============================================================
time elapsed: 0:07:55
train iter: 133
num of updates: 13400
dynamics loss: 37175.41016

============================================================
time elapsed: 0:07:58
train iter: 134
num of updates: 13500
dynamics loss: 36807.52734

============================================================
time elapsed: 0:08:01
train iter: 135
num of updates: 13600
dynamics loss: 36522.64062

============================================================
time elapsed: 0:08:04
train iter: 136
num of updates: 13700
dynamics loss: 36188.62500

============================================================
time elapsed: 0:08:07
train iter: 137
num of updates: 13800
dynamics loss: 35897.57812

============================================================
time elapsed: 0:08:10
train iter: 138
num of updates: 13900
dynamics loss: 35598.47266

============================================================
time elapsed: 0:08:13
train iter: 139
num of updates: 14000
dynamics loss: 35293.45703

============================================================
time elapsed: 0:08:16
train iter: 140
num of updates: 14100
dynamics loss: 35015.68359

============================================================
time elapsed: 0:08:18
train iter: 141
num of updates: 14200
dynamics loss: 34736.56641

============================================================
time elapsed: 0:08:21
train iter: 142
num of updates: 14300
dynamics loss: 34476.95312

============================================================
time elapsed: 0:08:24
train iter: 143
num of updates: 14400
dynamics loss: 34256.24609

============================================================
time elapsed: 0:08:27
train iter: 144
num of updates: 14500
dynamics loss: 33954.35156

============================================================
time elapsed: 0:08:30
train iter: 145
num of updates: 14600
dynamics loss: 33709.69141

============================================================
time elapsed: 0:08:33
train iter: 146
num of updates: 14700
dynamics loss: 33484.66406

============================================================
time elapsed: 0:08:36
train iter: 147
num of updates: 14800
dynamics loss: 33237.59375

============================================================
time elapsed: 0:08:39
train iter: 148
num of updates: 14900
dynamics loss: 33076.78906

============================================================
time elapsed: 0:08:42
train iter: 149
num of updates: 15000
dynamics loss: 32815.01562

============================================================
time elapsed: 0:08:44
train iter: 150
num of updates: 15100
dynamics loss: 32614.15430

============================================================
time elapsed: 0:08:47
train iter: 151
num of updates: 15200
dynamics loss: 32385.53125

============================================================
time elapsed: 0:08:50
train iter: 152
num of updates: 15300
dynamics loss: 32180.21484

============================================================
time elapsed: 0:08:53
train iter: 153
num of updates: 15400
dynamics loss: 31979.71289

============================================================
time elapsed: 0:08:56
train iter: 154
num of updates: 15500
dynamics loss: 31808.22070

============================================================
time elapsed: 0:08:59
train iter: 155
num of updates: 15600
dynamics loss: 31618.23047

============================================================
time elapsed: 0:09:02
train iter: 156
num of updates: 15700
dynamics loss: 31391.02930

============================================================
time elapsed: 0:09:05
train iter: 157
num of updates: 15800
dynamics loss: 31191.46484

============================================================
time elapsed: 0:09:08
train iter: 158
num of updates: 15900
dynamics loss: 31058.90234

============================================================
time elapsed: 0:09:11
train iter: 159
num of updates: 16000
dynamics loss: 30918.37695

============================================================
time elapsed: 0:09:13
train iter: 160
num of updates: 16100
dynamics loss: 30726.52539

============================================================
time elapsed: 0:09:16
train iter: 161
num of updates: 16200
dynamics loss: 30579.67969

============================================================
time elapsed: 0:09:19
train iter: 162
num of updates: 16300
dynamics loss: 30408.05469

============================================================
time elapsed: 0:09:22
train iter: 163
num of updates: 16400
dynamics loss: 30276.06641

============================================================
time elapsed: 0:09:25
train iter: 164
num of updates: 16500
dynamics loss: 30111.67383

============================================================
time elapsed: 0:09:28
train iter: 165
num of updates: 16600
dynamics loss: 29925.82227

============================================================
time elapsed: 0:09:31
train iter: 166
num of updates: 16700
dynamics loss: 29781.97266

============================================================
time elapsed: 0:09:34
train iter: 167
num of updates: 16800
dynamics loss: 29664.33008

============================================================
time elapsed: 0:09:37
train iter: 168
num of updates: 16900
dynamics loss: 29514.89062

============================================================
time elapsed: 0:09:40
train iter: 169
num of updates: 17000
dynamics loss: 29385.94727

============================================================
time elapsed: 0:09:42
train iter: 170
num of updates: 17100
dynamics loss: 29240.84375

============================================================
time elapsed: 0:09:45
train iter: 171
num of updates: 17200
dynamics loss: 29113.04492

============================================================
time elapsed: 0:09:48
train iter: 172
num of updates: 17300
dynamics loss: 29011.03906

============================================================
time elapsed: 0:09:51
train iter: 173
num of updates: 17400
dynamics loss: 28873.77148

============================================================
time elapsed: 0:09:54
train iter: 174
num of updates: 17500
dynamics loss: 28769.51953

============================================================
time elapsed: 0:09:57
train iter: 175
num of updates: 17600
dynamics loss: 28622.52539

============================================================
time elapsed: 0:10:00
train iter: 176
num of updates: 17700
dynamics loss: 28538.83398

============================================================
time elapsed: 0:10:03
train iter: 177
num of updates: 17800
dynamics loss: 28417.37109

============================================================
time elapsed: 0:10:06
train iter: 178
num of updates: 17900
dynamics loss: 28271.77148

============================================================
time elapsed: 0:10:08
train iter: 179
num of updates: 18000
dynamics loss: 28188.71484

============================================================
time elapsed: 0:10:11
train iter: 180
num of updates: 18100
dynamics loss: 28079.80859

============================================================
time elapsed: 0:10:14
train iter: 181
num of updates: 18200
dynamics loss: 27953.37500

============================================================
time elapsed: 0:10:17
train iter: 182
num of updates: 18300
dynamics loss: 27854.01367

============================================================
time elapsed: 0:10:20
train iter: 183
num of updates: 18400
dynamics loss: 27766.76562

============================================================
time elapsed: 0:10:23
train iter: 184
num of updates: 18500
dynamics loss: 27679.82617

============================================================
time elapsed: 0:10:26
train iter: 185
num of updates: 18600
dynamics loss: 27556.11719

============================================================
time elapsed: 0:10:29
train iter: 186
num of updates: 18700
dynamics loss: 27480.66211

============================================================
time elapsed: 0:10:32
train iter: 187
num of updates: 18800
dynamics loss: 27375.38086

============================================================
time elapsed: 0:10:35
train iter: 188
num of updates: 18900
dynamics loss: 27288.46875

============================================================
time elapsed: 0:10:37
train iter: 189
num of updates: 19000
dynamics loss: 27172.75391

============================================================
time elapsed: 0:10:40
train iter: 190
num of updates: 19100
dynamics loss: 27145.56445

============================================================
time elapsed: 0:10:43
train iter: 191
num of updates: 19200
dynamics loss: 27068.94727

============================================================
time elapsed: 0:10:46
train iter: 192
num of updates: 19300
dynamics loss: 26938.32812

============================================================
time elapsed: 0:10:49
train iter: 193
num of updates: 19400
dynamics loss: 26821.31445

============================================================
time elapsed: 0:10:52
train iter: 194
num of updates: 19500
dynamics loss: 26784.50195

============================================================
time elapsed: 0:10:55
train iter: 195
num of updates: 19600
dynamics loss: 26703.78125

============================================================
time elapsed: 0:10:58
train iter: 196
num of updates: 19700
dynamics loss: 26603.61719

============================================================
time elapsed: 0:11:01
train iter: 197
num of updates: 19800
dynamics loss: 26497.17383

============================================================
time elapsed: 0:11:04
train iter: 198
num of updates: 19900
dynamics loss: 26415.29297

============================================================
time elapsed: 0:11:06
train iter: 199
num of updates: 20000
dynamics loss: 26368.60352

============================================================
time elapsed: 0:11:09
train iter: 200
num of updates: 20100
dynamics loss: 26274.94141

============================================================
time elapsed: 0:11:12
train iter: 201
num of updates: 20200
dynamics loss: 26192.90234

============================================================
time elapsed: 0:11:15
train iter: 202
num of updates: 20300
dynamics loss: 26139.51953

============================================================
time elapsed: 0:11:18
train iter: 203
num of updates: 20400
dynamics loss: 26056.11719

============================================================
time elapsed: 0:11:21
train iter: 204
num of updates: 20500
dynamics loss: 26010.10938

============================================================
time elapsed: 0:11:24
train iter: 205
num of updates: 20600
dynamics loss: 25919.27344

============================================================
time elapsed: 0:11:27
train iter: 206
num of updates: 20700
dynamics loss: 25895.53711

============================================================
time elapsed: 0:11:30
train iter: 207
num of updates: 20800
dynamics loss: 25794.42188

============================================================
time elapsed: 0:11:33
train iter: 208
num of updates: 20900
dynamics loss: 25739.41016

============================================================
time elapsed: 0:11:35
train iter: 209
num of updates: 21000
dynamics loss: 25688.00000

============================================================
time elapsed: 0:11:38
train iter: 210
num of updates: 21100
dynamics loss: 25617.58203

============================================================
time elapsed: 0:11:41
train iter: 211
num of updates: 21200
dynamics loss: 25566.75977

============================================================
time elapsed: 0:11:44
train iter: 212
num of updates: 21300
dynamics loss: 25472.79688

============================================================
time elapsed: 0:11:47
train iter: 213
num of updates: 21400
dynamics loss: 25431.31641

============================================================
time elapsed: 0:11:50
train iter: 214
num of updates: 21500
dynamics loss: 25369.47656

============================================================
time elapsed: 0:11:53
train iter: 215
num of updates: 21600
dynamics loss: 25315.05859

============================================================
time elapsed: 0:11:56
train iter: 216
num of updates: 21700
dynamics loss: 25260.99414

============================================================
time elapsed: 0:11:59
train iter: 217
num of updates: 21800
dynamics loss: 25189.02148

============================================================
time elapsed: 0:12:01
train iter: 218
num of updates: 21900
dynamics loss: 25122.24023

============================================================
time elapsed: 0:12:04
train iter: 219
num of updates: 22000
dynamics loss: 25089.79102

============================================================
time elapsed: 0:12:07
train iter: 220
num of updates: 22100
dynamics loss: 24999.10547

============================================================
time elapsed: 0:12:10
train iter: 221
num of updates: 22200
dynamics loss: 25002.03320

============================================================
time elapsed: 0:12:13
train iter: 222
num of updates: 22300
dynamics loss: 24909.43359

============================================================
time elapsed: 0:12:16
train iter: 223
num of updates: 22400
dynamics loss: 24857.49805

============================================================
time elapsed: 0:12:19
train iter: 224
num of updates: 22500
dynamics loss: 24808.34570

============================================================
time elapsed: 0:12:22
train iter: 225
num of updates: 22600
dynamics loss: 24776.75000

============================================================
time elapsed: 0:12:25
train iter: 226
num of updates: 22700
dynamics loss: 24701.68164

============================================================
time elapsed: 0:12:28
train iter: 227
num of updates: 22800
dynamics loss: 24636.81445

============================================================
time elapsed: 0:12:30
train iter: 228
num of updates: 22900
dynamics loss: 24617.15430

============================================================
time elapsed: 0:12:33
train iter: 229
num of updates: 23000
dynamics loss: 24550.19922

============================================================
time elapsed: 0:12:36
train iter: 230
num of updates: 23100
dynamics loss: 24508.20898

============================================================
time elapsed: 0:12:39
train iter: 231
num of updates: 23200
dynamics loss: 24454.66602

============================================================
time elapsed: 0:12:42
train iter: 232
num of updates: 23300
dynamics loss: 24417.15625

============================================================
time elapsed: 0:12:45
train iter: 233
num of updates: 23400
dynamics loss: 24363.07812

============================================================
time elapsed: 0:12:48
train iter: 234
num of updates: 23500
dynamics loss: 24304.85352

============================================================
time elapsed: 0:12:51
train iter: 235
num of updates: 23600
dynamics loss: 24259.66992

============================================================
time elapsed: 0:12:54
train iter: 236
num of updates: 23700
dynamics loss: 24242.56641

============================================================
time elapsed: 0:12:57
train iter: 237
num of updates: 23800
dynamics loss: 24194.17383

============================================================
time elapsed: 0:12:59
train iter: 238
num of updates: 23900
dynamics loss: 24104.42969

============================================================
time elapsed: 0:13:02
train iter: 239
num of updates: 24000
dynamics loss: 24083.91797

============================================================
time elapsed: 0:13:05
train iter: 240
num of updates: 24100
dynamics loss: 24068.14453

============================================================
time elapsed: 0:13:08
train iter: 241
num of updates: 24200
dynamics loss: 24020.71289

============================================================
time elapsed: 0:13:11
train iter: 242
num of updates: 24300
dynamics loss: 23973.09961

============================================================
time elapsed: 0:13:14
train iter: 243
num of updates: 24400
dynamics loss: 23901.71875

============================================================
time elapsed: 0:13:17
train iter: 244
num of updates: 24500
dynamics loss: 23874.85547

============================================================
time elapsed: 0:13:20
train iter: 245
num of updates: 24600
dynamics loss: 23825.95312

============================================================
time elapsed: 0:13:23
train iter: 246
num of updates: 24700
dynamics loss: 23803.61719

============================================================
time elapsed: 0:13:26
train iter: 247
num of updates: 24800
dynamics loss: 23785.12891

============================================================
time elapsed: 0:13:28
train iter: 248
num of updates: 24900
dynamics loss: 23709.68945

============================================================
time elapsed: 0:13:31
train iter: 249
num of updates: 25000
dynamics loss: 23695.56836

============================================================
time elapsed: 0:13:34
train iter: 250
num of updates: 25100
dynamics loss: 23659.11719

============================================================
time elapsed: 0:13:37
train iter: 251
num of updates: 25200
dynamics loss: 23615.79297

============================================================
time elapsed: 0:13:40
train iter: 252
num of updates: 25300
dynamics loss: 23554.22070

============================================================
time elapsed: 0:13:43
train iter: 253
num of updates: 25400
dynamics loss: 23546.65234

============================================================
time elapsed: 0:13:46
train iter: 254
num of updates: 25500
dynamics loss: 23486.09375

============================================================
time elapsed: 0:13:49
train iter: 255
num of updates: 25600
dynamics loss: 23451.17188

============================================================
time elapsed: 0:13:52
train iter: 256
num of updates: 25700
dynamics loss: 23399.31641

============================================================
time elapsed: 0:13:54
train iter: 257
num of updates: 25800
dynamics loss: 23375.81445

============================================================
time elapsed: 0:13:57
train iter: 258
num of updates: 25900
dynamics loss: 23343.35938

============================================================
time elapsed: 0:14:00
train iter: 259
num of updates: 26000
dynamics loss: 23316.31641

============================================================
time elapsed: 0:14:03
train iter: 260
num of updates: 26100
dynamics loss: 23259.99219

============================================================
time elapsed: 0:14:06
train iter: 261
num of updates: 26200
dynamics loss: 23256.08008

============================================================
time elapsed: 0:14:09
train iter: 262
num of updates: 26300
dynamics loss: 23205.98047

============================================================
time elapsed: 0:14:12
train iter: 263
num of updates: 26400
dynamics loss: 23179.07227

============================================================
time elapsed: 0:14:15
train iter: 264
num of updates: 26500
dynamics loss: 23162.22070

============================================================
time elapsed: 0:14:18
train iter: 265
num of updates: 26600
dynamics loss: 23145.14453

============================================================
time elapsed: 0:14:21
train iter: 266
num of updates: 26700
dynamics loss: 23039.02930

============================================================
time elapsed: 0:14:23
train iter: 267
num of updates: 26800
dynamics loss: 23049.27344

============================================================
time elapsed: 0:14:26
train iter: 268
num of updates: 26900
dynamics loss: 23034.75781

============================================================
time elapsed: 0:14:29
train iter: 269
num of updates: 27000
dynamics loss: 22956.87891

============================================================
time elapsed: 0:14:32
train iter: 270
num of updates: 27100
dynamics loss: 22945.32812

============================================================
time elapsed: 0:14:35
train iter: 271
num of updates: 27200
dynamics loss: 22908.03711

============================================================
time elapsed: 0:14:38
train iter: 272
num of updates: 27300
dynamics loss: 22878.73828

============================================================
time elapsed: 0:14:41
train iter: 273
num of updates: 27400
dynamics loss: 22848.42578

============================================================
time elapsed: 0:14:44
train iter: 274
num of updates: 27500
dynamics loss: 22796.54102

============================================================
time elapsed: 0:14:47
train iter: 275
num of updates: 27600
dynamics loss: 22747.74023

============================================================
time elapsed: 0:14:50
train iter: 276
num of updates: 27700
dynamics loss: 22774.99219

============================================================
time elapsed: 0:14:52
train iter: 277
num of updates: 27800
dynamics loss: 22696.52148

============================================================
time elapsed: 0:14:55
train iter: 278
num of updates: 27900
dynamics loss: 22698.34766

============================================================
time elapsed: 0:14:58
train iter: 279
num of updates: 28000
dynamics loss: 22646.63281

============================================================
time elapsed: 0:15:01
train iter: 280
num of updates: 28100
dynamics loss: 22625.27734

============================================================
time elapsed: 0:15:04
train iter: 281
num of updates: 28200
dynamics loss: 22561.25586

============================================================
time elapsed: 0:15:07
train iter: 282
num of updates: 28300
dynamics loss: 22557.11328

============================================================
time elapsed: 0:15:10
train iter: 283
num of updates: 28400
dynamics loss: 22555.12305

============================================================
time elapsed: 0:15:13
train iter: 284
num of updates: 28500
dynamics loss: 22522.14453

============================================================
time elapsed: 0:15:16
train iter: 285
num of updates: 28600
dynamics loss: 22501.03711

============================================================
time elapsed: 0:15:19
train iter: 286
num of updates: 28700
dynamics loss: 22456.47656

============================================================
time elapsed: 0:15:21
train iter: 287
num of updates: 28800
dynamics loss: 22393.20312

============================================================
time elapsed: 0:15:24
train iter: 288
num of updates: 28900
dynamics loss: 22381.46875

============================================================
time elapsed: 0:15:27
train iter: 289
num of updates: 29000
dynamics loss: 22388.80859

============================================================
time elapsed: 0:15:30
train iter: 290
num of updates: 29100
dynamics loss: 22330.23047

============================================================
time elapsed: 0:15:33
train iter: 291
num of updates: 29200
dynamics loss: 22328.72461

============================================================
time elapsed: 0:15:36
train iter: 292
num of updates: 29300
dynamics loss: 22302.14062

============================================================
time elapsed: 0:15:39
train iter: 293
num of updates: 29400
dynamics loss: 22234.87305

============================================================
time elapsed: 0:15:42
train iter: 294
num of updates: 29500
dynamics loss: 22278.68555

============================================================
time elapsed: 0:15:45
train iter: 295
num of updates: 29600
dynamics loss: 22189.27930

============================================================
time elapsed: 0:15:47
train iter: 296
num of updates: 29700
dynamics loss: 22190.64844

============================================================
time elapsed: 0:15:50
train iter: 297
num of updates: 29800
dynamics loss: 22143.65625

============================================================
time elapsed: 0:15:53
train iter: 298
num of updates: 29900
dynamics loss: 22127.92578

============================================================
time elapsed: 0:15:56
train iter: 299
num of updates: 30000
dynamics loss: 22126.31250

============================================================
time elapsed: 0:15:59
train iter: 300
num of updates: 30100
dynamics loss: 22105.04492

============================================================
time elapsed: 0:16:02
train iter: 301
num of updates: 30200
dynamics loss: 22072.47852

============================================================
time elapsed: 0:16:05
train iter: 302
num of updates: 30300
dynamics loss: 22011.95898

============================================================
time elapsed: 0:16:08
train iter: 303
num of updates: 30400
dynamics loss: 21965.75391

============================================================
time elapsed: 0:16:11
train iter: 304
num of updates: 30500
dynamics loss: 21993.22070

============================================================
time elapsed: 0:16:14
train iter: 305
num of updates: 30600
dynamics loss: 21949.81250

============================================================
time elapsed: 0:16:16
train iter: 306
num of updates: 30700
dynamics loss: 21934.46289

============================================================
time elapsed: 0:16:19
train iter: 307
num of updates: 30800
dynamics loss: 21906.00977

============================================================
time elapsed: 0:16:22
train iter: 308
num of updates: 30900
dynamics loss: 21873.34180

============================================================
time elapsed: 0:16:25
train iter: 309
num of updates: 31000
dynamics loss: 21832.92969

============================================================
time elapsed: 0:16:28
train iter: 310
num of updates: 31100
dynamics loss: 21835.78125

============================================================
time elapsed: 0:16:31
train iter: 311
num of updates: 31200
dynamics loss: 21810.69531

============================================================
time elapsed: 0:16:34
train iter: 312
num of updates: 31300
dynamics loss: 21763.87695

============================================================
time elapsed: 0:16:37
train iter: 313
num of updates: 31400
dynamics loss: 21755.06836

============================================================
time elapsed: 0:16:40
train iter: 314
num of updates: 31500
dynamics loss: 21710.43555

============================================================
time elapsed: 0:16:43
train iter: 315
num of updates: 31600
dynamics loss: 21706.84375

============================================================
time elapsed: 0:16:45
train iter: 316
num of updates: 31700
dynamics loss: 21678.93359

============================================================
time elapsed: 0:16:48
train iter: 317
num of updates: 31800
dynamics loss: 21650.34961

============================================================
time elapsed: 0:16:51
train iter: 318
num of updates: 31900
dynamics loss: 21658.20508

============================================================
time elapsed: 0:16:54
train iter: 319
num of updates: 32000
dynamics loss: 21585.17578

============================================================
time elapsed: 0:16:57
train iter: 320
num of updates: 32100
dynamics loss: 21624.88086

============================================================
time elapsed: 0:17:00
train iter: 321
num of updates: 32200
dynamics loss: 21568.30078

============================================================
time elapsed: 0:17:03
train iter: 322
num of updates: 32300
dynamics loss: 21553.13672

============================================================
time elapsed: 0:17:06
train iter: 323
num of updates: 32400
dynamics loss: 21519.06445

============================================================
time elapsed: 0:17:09
train iter: 324
num of updates: 32500
dynamics loss: 21514.67383

============================================================
time elapsed: 0:17:12
train iter: 325
num of updates: 32600
dynamics loss: 21489.84180

============================================================
time elapsed: 0:17:14
train iter: 326
num of updates: 32700
dynamics loss: 21436.20898

============================================================
time elapsed: 0:17:17
train iter: 327
num of updates: 32800
dynamics loss: 21427.23242

============================================================
time elapsed: 0:17:20
train iter: 328
num of updates: 32900
dynamics loss: 21412.60938

============================================================
time elapsed: 0:17:23
train iter: 329
num of updates: 33000
dynamics loss: 21370.38867

============================================================
time elapsed: 0:17:26
train iter: 330
num of updates: 33100
dynamics loss: 21357.44727

============================================================
time elapsed: 0:17:29
train iter: 331
num of updates: 33200
dynamics loss: 21352.85742

============================================================
time elapsed: 0:17:32
train iter: 332
num of updates: 33300
dynamics loss: 21311.65820

============================================================
time elapsed: 0:17:35
train iter: 333
num of updates: 33400
dynamics loss: 21314.17773

============================================================
time elapsed: 0:17:38
train iter: 334
num of updates: 33500
dynamics loss: 21284.98633

============================================================
time elapsed: 0:17:40
train iter: 335
num of updates: 33600
dynamics loss: 21249.65820

============================================================
time elapsed: 0:17:43
train iter: 336
num of updates: 33700
dynamics loss: 21226.71680

============================================================
time elapsed: 0:17:46
train iter: 337
num of updates: 33800
dynamics loss: 21223.45312

============================================================
time elapsed: 0:17:49
train iter: 338
num of updates: 33900
dynamics loss: 21202.51367

============================================================
time elapsed: 0:17:52
train iter: 339
num of updates: 34000
dynamics loss: 21203.81836

============================================================
time elapsed: 0:17:55
train iter: 340
num of updates: 34100
dynamics loss: 21135.90039

============================================================
time elapsed: 0:17:58
train iter: 341
num of updates: 34200
dynamics loss: 21132.67383

============================================================
time elapsed: 0:18:01
train iter: 342
num of updates: 34300
dynamics loss: 21138.65234

============================================================
time elapsed: 0:18:04
train iter: 343
num of updates: 34400
dynamics loss: 21087.81445

============================================================
time elapsed: 0:18:07
train iter: 344
num of updates: 34500
dynamics loss: 21082.61523

============================================================
time elapsed: 0:18:09
train iter: 345
num of updates: 34600
dynamics loss: 21043.59570

============================================================
time elapsed: 0:18:12
train iter: 346
num of updates: 34700
dynamics loss: 21023.80078

============================================================
time elapsed: 0:18:15
train iter: 347
num of updates: 34800
dynamics loss: 21027.04883

============================================================
time elapsed: 0:18:18
train iter: 348
num of updates: 34900
dynamics loss: 20991.32422

============================================================
time elapsed: 0:18:21
train iter: 349
num of updates: 35000
dynamics loss: 20983.32227

============================================================
time elapsed: 0:18:24
train iter: 350
num of updates: 35100
dynamics loss: 20932.83984

============================================================
time elapsed: 0:18:27
train iter: 351
num of updates: 35200
dynamics loss: 20929.24414

============================================================
time elapsed: 0:18:30
train iter: 352
num of updates: 35300
dynamics loss: 20920.65625

============================================================
time elapsed: 0:18:33
train iter: 353
num of updates: 35400
dynamics loss: 20905.52734

============================================================
time elapsed: 0:18:36
train iter: 354
num of updates: 35500
dynamics loss: 20862.33789

============================================================
time elapsed: 0:18:38
train iter: 355
num of updates: 35600
dynamics loss: 20874.27344

============================================================
time elapsed: 0:18:41
train iter: 356
num of updates: 35700
dynamics loss: 20830.85352

============================================================
time elapsed: 0:18:44
train iter: 357
num of updates: 35800
dynamics loss: 20837.50977

============================================================
time elapsed: 0:18:47
train iter: 358
num of updates: 35900
dynamics loss: 20752.03906

============================================================
time elapsed: 0:18:50
train iter: 359
num of updates: 36000
dynamics loss: 20777.86523

============================================================
time elapsed: 0:18:53
train iter: 360
num of updates: 36100
dynamics loss: 20760.60156

============================================================
time elapsed: 0:18:56
train iter: 361
num of updates: 36200
dynamics loss: 20713.19531

============================================================
time elapsed: 0:18:59
train iter: 362
num of updates: 36300
dynamics loss: 20695.95508

============================================================
time elapsed: 0:19:02
train iter: 363
num of updates: 36400
dynamics loss: 20703.93359

============================================================
time elapsed: 0:19:05
train iter: 364
num of updates: 36500
dynamics loss: 20665.60742

============================================================
time elapsed: 0:19:07
train iter: 365
num of updates: 36600
dynamics loss: 20654.80469

============================================================
time elapsed: 0:19:10
train iter: 366
num of updates: 36700
dynamics loss: 20650.96094

============================================================
time elapsed: 0:19:13
train iter: 367
num of updates: 36800
dynamics loss: 20627.29492

============================================================
time elapsed: 0:19:16
train iter: 368
num of updates: 36900
dynamics loss: 20570.44727

============================================================
time elapsed: 0:19:19
train iter: 369
num of updates: 37000
dynamics loss: 20577.93359

============================================================
time elapsed: 0:19:22
train iter: 370
num of updates: 37100
dynamics loss: 20530.61328

============================================================
time elapsed: 0:19:25
train iter: 371
num of updates: 37200
dynamics loss: 20537.25781

============================================================
time elapsed: 0:19:28
train iter: 372
num of updates: 37300
dynamics loss: 20529.91406

============================================================
time elapsed: 0:19:31
train iter: 373
num of updates: 37400
dynamics loss: 20505.14844

============================================================
time elapsed: 0:19:34
train iter: 374
num of updates: 37500
dynamics loss: 20491.42578

============================================================
time elapsed: 0:19:36
train iter: 375
num of updates: 37600
dynamics loss: 20460.69922

============================================================
time elapsed: 0:19:39
train iter: 376
num of updates: 37700
dynamics loss: 20461.07031

============================================================
time elapsed: 0:19:42
train iter: 377
num of updates: 37800
dynamics loss: 20465.53125

============================================================
time elapsed: 0:19:45
train iter: 378
num of updates: 37900
dynamics loss: 20413.47070

============================================================
time elapsed: 0:19:48
train iter: 379
num of updates: 38000
dynamics loss: 20408.31836

============================================================
time elapsed: 0:19:51
train iter: 380
num of updates: 38100
dynamics loss: 20361.66016

============================================================
time elapsed: 0:19:54
train iter: 381
num of updates: 38200
dynamics loss: 20358.09961

============================================================
time elapsed: 0:19:57
train iter: 382
num of updates: 38300
dynamics loss: 20379.27148

============================================================
time elapsed: 0:20:00
train iter: 383
num of updates: 38400
dynamics loss: 20305.32422

============================================================
time elapsed: 0:20:02
train iter: 384
num of updates: 38500
dynamics loss: 20319.66016

============================================================
time elapsed: 0:20:05
train iter: 385
num of updates: 38600
dynamics loss: 20281.43945

============================================================
time elapsed: 0:20:08
train iter: 386
num of updates: 38700
dynamics loss: 20260.92188

============================================================
time elapsed: 0:20:11
train iter: 387
num of updates: 38800
dynamics loss: 20244.15430

============================================================
time elapsed: 0:20:14
train iter: 388
num of updates: 38900
dynamics loss: 20231.42969

============================================================
time elapsed: 0:20:17
train iter: 389
num of updates: 39000
dynamics loss: 20216.45117

============================================================
time elapsed: 0:20:20
train iter: 390
num of updates: 39100
dynamics loss: 20192.79688

============================================================
time elapsed: 0:20:23
train iter: 391
num of updates: 39200
dynamics loss: 20184.64453

============================================================
time elapsed: 0:20:26
train iter: 392
num of updates: 39300
dynamics loss: 20160.21680

============================================================
time elapsed: 0:20:29
train iter: 393
num of updates: 39400
dynamics loss: 20141.29492

============================================================
time elapsed: 0:20:31
train iter: 394
num of updates: 39500
dynamics loss: 20143.34375

============================================================
time elapsed: 0:20:34
train iter: 395
num of updates: 39600
dynamics loss: 20123.06250

============================================================
time elapsed: 0:20:37
train iter: 396
num of updates: 39700
dynamics loss: 20083.43750

============================================================
time elapsed: 0:20:40
train iter: 397
num of updates: 39800
dynamics loss: 20076.27734

============================================================
time elapsed: 0:20:43
train iter: 398
num of updates: 39900
dynamics loss: 20034.91211

============================================================
time elapsed: 0:20:46
train iter: 399
num of updates: 40000
dynamics loss: 20040.58984

============================================================
time elapsed: 0:20:49
train iter: 400
num of updates: 40100
dynamics loss: 20017.47266

============================================================
time elapsed: 0:20:52
train iter: 401
num of updates: 40200
dynamics loss: 20007.74609

============================================================
time elapsed: 0:20:55
train iter: 402
num of updates: 40300
dynamics loss: 20002.33203

============================================================
time elapsed: 0:20:58
train iter: 403
num of updates: 40400
dynamics loss: 20003.82422

============================================================
time elapsed: 0:21:00
train iter: 404
num of updates: 40500
dynamics loss: 19963.82617

============================================================
time elapsed: 0:21:03
train iter: 405
num of updates: 40600
dynamics loss: 19955.19336

============================================================
time elapsed: 0:21:06
train iter: 406
num of updates: 40700
dynamics loss: 19925.06445

============================================================
time elapsed: 0:21:09
train iter: 407
num of updates: 40800
dynamics loss: 19918.66406

============================================================
time elapsed: 0:21:12
train iter: 408
num of updates: 40900
dynamics loss: 19905.13281

============================================================
time elapsed: 0:21:15
train iter: 409
num of updates: 41000
dynamics loss: 19883.25000

============================================================
time elapsed: 0:21:18
train iter: 410
num of updates: 41100
dynamics loss: 19869.99023

============================================================
time elapsed: 0:21:21
train iter: 411
num of updates: 41200
dynamics loss: 19864.14258

============================================================
time elapsed: 0:21:24
train iter: 412
num of updates: 41300
dynamics loss: 19800.03711

============================================================
time elapsed: 0:21:26
train iter: 413
num of updates: 41400
dynamics loss: 19809.83398

============================================================
time elapsed: 0:21:29
train iter: 414
num of updates: 41500
dynamics loss: 19790.78906

============================================================
time elapsed: 0:21:32
train iter: 415
num of updates: 41600
dynamics loss: 19762.63281

============================================================
time elapsed: 0:21:35
train iter: 416
num of updates: 41700
dynamics loss: 19729.67383

============================================================
time elapsed: 0:21:38
train iter: 417
num of updates: 41800
dynamics loss: 19740.84961

============================================================
time elapsed: 0:21:41
train iter: 418
num of updates: 41900
dynamics loss: 19711.50977

============================================================
time elapsed: 0:21:44
train iter: 419
num of updates: 42000
dynamics loss: 19721.54688

============================================================
time elapsed: 0:21:47
train iter: 420
num of updates: 42100
dynamics loss: 19687.34180

============================================================
time elapsed: 0:21:50
train iter: 421
num of updates: 42200
dynamics loss: 19692.82031

============================================================
time elapsed: 0:21:53
train iter: 422
num of updates: 42300
dynamics loss: 19626.79297

============================================================
time elapsed: 0:21:55
train iter: 423
num of updates: 42400
dynamics loss: 19645.75391

============================================================
time elapsed: 0:21:58
train iter: 424
num of updates: 42500
dynamics loss: 19611.64453

============================================================
time elapsed: 0:22:01
train iter: 425
num of updates: 42600
dynamics loss: 19631.16016

============================================================
time elapsed: 0:22:04
train iter: 426
num of updates: 42700
dynamics loss: 19591.60352

============================================================
time elapsed: 0:22:07
train iter: 427
num of updates: 42800
dynamics loss: 19581.19922

============================================================
time elapsed: 0:22:10
train iter: 428
num of updates: 42900
dynamics loss: 19575.38086

============================================================
time elapsed: 0:22:13
train iter: 429
num of updates: 43000
dynamics loss: 19566.42383

============================================================
time elapsed: 0:22:16
train iter: 430
num of updates: 43100
dynamics loss: 19551.06836

============================================================
time elapsed: 0:22:19
train iter: 431
num of updates: 43200
dynamics loss: 19507.53906

============================================================
time elapsed: 0:22:22
train iter: 432
num of updates: 43300
dynamics loss: 19493.71289

============================================================
time elapsed: 0:22:24
train iter: 433
num of updates: 43400
dynamics loss: 19476.36719

============================================================
time elapsed: 0:22:27
train iter: 434
num of updates: 43500
dynamics loss: 19492.48633

============================================================
time elapsed: 0:22:30
train iter: 435
num of updates: 43600
dynamics loss: 19437.90820

============================================================
time elapsed: 0:22:33
train iter: 436
num of updates: 43700
dynamics loss: 19443.96094

============================================================
time elapsed: 0:22:36
train iter: 437
num of updates: 43800
dynamics loss: 19417.30859

============================================================
time elapsed: 0:22:39
train iter: 438
num of updates: 43900
dynamics loss: 19432.84375

============================================================
time elapsed: 0:22:42
train iter: 439
num of updates: 44000
dynamics loss: 19377.58398

============================================================
time elapsed: 0:22:45
train iter: 440
num of updates: 44100
dynamics loss: 19392.38281

============================================================
time elapsed: 0:22:48
train iter: 441
num of updates: 44200
dynamics loss: 19343.40430

============================================================
time elapsed: 0:22:51
train iter: 442
num of updates: 44300
dynamics loss: 19350.96875

============================================================
time elapsed: 0:22:53
train iter: 443
num of updates: 44400
dynamics loss: 19311.37695

============================================================
time elapsed: 0:22:56
train iter: 444
num of updates: 44500
dynamics loss: 19293.88086

============================================================
time elapsed: 0:22:59
train iter: 445
num of updates: 44600
dynamics loss: 19280.29492

============================================================
time elapsed: 0:23:02
train iter: 446
num of updates: 44700
dynamics loss: 19295.55664

============================================================
time elapsed: 0:23:05
train iter: 447
num of updates: 44800
dynamics loss: 19258.81445

============================================================
time elapsed: 0:23:08
train iter: 448
num of updates: 44900
dynamics loss: 19260.54883

============================================================
time elapsed: 0:23:11
train iter: 449
num of updates: 45000
dynamics loss: 19243.53711

============================================================
time elapsed: 0:23:14
train iter: 450
num of updates: 45100
dynamics loss: 19204.33398

============================================================
time elapsed: 0:23:17
train iter: 451
num of updates: 45200
dynamics loss: 19216.50000

============================================================
time elapsed: 0:23:19
train iter: 452
num of updates: 45300
dynamics loss: 19216.37109

============================================================
time elapsed: 0:23:22
train iter: 453
num of updates: 45400
dynamics loss: 19193.18164

============================================================
time elapsed: 0:23:25
train iter: 454
num of updates: 45500
dynamics loss: 19168.62695

============================================================
time elapsed: 0:23:28
train iter: 455
num of updates: 45600
dynamics loss: 19142.13477

============================================================
time elapsed: 0:23:31
train iter: 456
num of updates: 45700
dynamics loss: 19139.39648

============================================================
time elapsed: 0:23:34
train iter: 457
num of updates: 45800
dynamics loss: 19119.57031

============================================================
time elapsed: 0:23:37
train iter: 458
num of updates: 45900
dynamics loss: 19096.41602

============================================================
time elapsed: 0:23:40
train iter: 459
num of updates: 46000
dynamics loss: 19066.45898

============================================================
time elapsed: 0:23:43
train iter: 460
num of updates: 46100
dynamics loss: 19050.80859

============================================================
time elapsed: 0:23:46
train iter: 461
num of updates: 46200
dynamics loss: 19065.68359

============================================================
time elapsed: 0:23:48
train iter: 462
num of updates: 46300
dynamics loss: 19045.15625

============================================================
time elapsed: 0:23:51
train iter: 463
num of updates: 46400
dynamics loss: 19045.54102

============================================================
time elapsed: 0:23:54
train iter: 464
num of updates: 46500
dynamics loss: 18992.48633

============================================================
time elapsed: 0:23:57
train iter: 465
num of updates: 46600
dynamics loss: 18984.33203

============================================================
time elapsed: 0:24:00
train iter: 466
num of updates: 46700
dynamics loss: 19001.91211

============================================================
time elapsed: 0:24:03
train iter: 467
num of updates: 46800
dynamics loss: 18944.32812

============================================================
time elapsed: 0:24:06
train iter: 468
num of updates: 46900
dynamics loss: 18933.62500

============================================================
time elapsed: 0:24:09
train iter: 469
num of updates: 47000
dynamics loss: 18939.70312

============================================================
time elapsed: 0:24:12
train iter: 470
num of updates: 47100
dynamics loss: 18938.95703

============================================================
time elapsed: 0:24:15
train iter: 471
num of updates: 47200
dynamics loss: 18919.20898

============================================================
time elapsed: 0:24:17
train iter: 472
num of updates: 47300
dynamics loss: 18891.15234

============================================================
time elapsed: 0:24:20
train iter: 473
num of updates: 47400
dynamics loss: 18900.46094

============================================================
time elapsed: 0:24:23
train iter: 474
num of updates: 47500
dynamics loss: 18868.46094

============================================================
time elapsed: 0:24:26
train iter: 475
num of updates: 47600
dynamics loss: 18825.69141

============================================================
time elapsed: 0:24:29
train iter: 476
num of updates: 47700
dynamics loss: 18836.74414

============================================================
time elapsed: 0:24:32
train iter: 477
num of updates: 47800
dynamics loss: 18845.08008

============================================================
time elapsed: 0:24:35
train iter: 478
num of updates: 47900
dynamics loss: 18793.84961

============================================================
time elapsed: 0:24:38
train iter: 479
num of updates: 48000
dynamics loss: 18772.54492

============================================================
time elapsed: 0:24:41
train iter: 480
num of updates: 48100
dynamics loss: 18756.19336

============================================================
time elapsed: 0:24:44
train iter: 481
num of updates: 48200
dynamics loss: 18760.50586

============================================================
time elapsed: 0:24:46
train iter: 482
num of updates: 48300
dynamics loss: 18755.46875

============================================================
time elapsed: 0:24:49
train iter: 483
num of updates: 48400
dynamics loss: 18736.26172

============================================================
time elapsed: 0:24:52
train iter: 484
num of updates: 48500
dynamics loss: 18711.72461

============================================================
time elapsed: 0:24:55
train iter: 485
num of updates: 48600
dynamics loss: 18704.79883

============================================================
time elapsed: 0:24:58
train iter: 486
num of updates: 48700
dynamics loss: 18688.90234

============================================================
time elapsed: 0:25:01
train iter: 487
num of updates: 48800
dynamics loss: 18683.12695

============================================================
time elapsed: 0:25:04
train iter: 488
num of updates: 48900
dynamics loss: 18642.33594

============================================================
time elapsed: 0:25:07
train iter: 489
num of updates: 49000
dynamics loss: 18643.98438

============================================================
time elapsed: 0:25:10
train iter: 490
num of updates: 49100
dynamics loss: 18631.15234

============================================================
time elapsed: 0:25:13
train iter: 491
num of updates: 49200
dynamics loss: 18621.89844

============================================================
time elapsed: 0:25:15
train iter: 492
num of updates: 49300
dynamics loss: 18603.58398

============================================================
time elapsed: 0:25:18
train iter: 493
num of updates: 49400
dynamics loss: 18591.59375

============================================================
time elapsed: 0:25:21
train iter: 494
num of updates: 49500
dynamics loss: 18552.79102

============================================================
time elapsed: 0:25:24
train iter: 495
num of updates: 49600
dynamics loss: 18577.30859

============================================================
time elapsed: 0:25:27
train iter: 496
num of updates: 49700
dynamics loss: 18542.84180

============================================================
time elapsed: 0:25:30
train iter: 497
num of updates: 49800
dynamics loss: 18539.28906

============================================================
time elapsed: 0:25:33
train iter: 498
num of updates: 49900
dynamics loss: 18513.82812

============================================================
time elapsed: 0:25:36
train iter: 499
num of updates: 50000
dynamics loss: 18503.75391

============================================================
time elapsed: 0:25:39
train iter: 500
num of updates: 50100
dynamics loss: 18468.26758

============================================================
time elapsed: 0:25:41
train iter: 501
num of updates: 50200
dynamics loss: 18484.68555

============================================================
time elapsed: 0:25:44
train iter: 502
num of updates: 50300
dynamics loss: 18443.66602

============================================================
time elapsed: 0:25:47
train iter: 503
num of updates: 50400
dynamics loss: 18431.66406

============================================================
time elapsed: 0:25:50
train iter: 504
num of updates: 50500
dynamics loss: 18418.91992

============================================================
time elapsed: 0:25:53
train iter: 505
num of updates: 50600
dynamics loss: 18433.73242

============================================================
time elapsed: 0:25:56
train iter: 506
num of updates: 50700
dynamics loss: 18398.28125

============================================================
time elapsed: 0:25:59
train iter: 507
num of updates: 50800
dynamics loss: 18387.16211

============================================================
time elapsed: 0:26:02
train iter: 508
num of updates: 50900
dynamics loss: 18375.51758

============================================================
time elapsed: 0:26:05
train iter: 509
num of updates: 51000
dynamics loss: 18355.68164

============================================================
time elapsed: 0:26:08
train iter: 510
num of updates: 51100
dynamics loss: 18366.34570

============================================================
time elapsed: 0:26:10
train iter: 511
num of updates: 51200
dynamics loss: 18331.28516

============================================================
time elapsed: 0:26:13
train iter: 512
num of updates: 51300
dynamics loss: 18314.13672

============================================================
time elapsed: 0:26:16
train iter: 513
num of updates: 51400
dynamics loss: 18314.35547

============================================================
time elapsed: 0:26:19
train iter: 514
num of updates: 51500
dynamics loss: 18289.26172

============================================================
time elapsed: 0:26:22
train iter: 515
num of updates: 51600
dynamics loss: 18278.32812

============================================================
time elapsed: 0:26:25
train iter: 516
num of updates: 51700
dynamics loss: 18252.10547

============================================================
time elapsed: 0:26:28
train iter: 517
num of updates: 51800
dynamics loss: 18262.11719

============================================================
time elapsed: 0:26:31
train iter: 518
num of updates: 51900
dynamics loss: 18234.12500

============================================================
time elapsed: 0:26:34
train iter: 519
num of updates: 52000
dynamics loss: 18206.10547

============================================================
time elapsed: 0:26:37
train iter: 520
num of updates: 52100
dynamics loss: 18211.21680

============================================================
time elapsed: 0:26:39
train iter: 521
num of updates: 52200
dynamics loss: 18190.84570

============================================================
time elapsed: 0:26:42
train iter: 522
num of updates: 52300
dynamics loss: 18170.03711

============================================================
time elapsed: 0:26:45
train iter: 523
num of updates: 52400
dynamics loss: 18156.55664

============================================================
time elapsed: 0:26:48
train iter: 524
num of updates: 52500
dynamics loss: 18125.71289

============================================================
time elapsed: 0:26:51
train iter: 525
num of updates: 52600
dynamics loss: 18155.15234

============================================================
time elapsed: 0:26:54
train iter: 526
num of updates: 52700
dynamics loss: 18134.16992

============================================================
time elapsed: 0:26:57
train iter: 527
num of updates: 52800
dynamics loss: 18088.96094

============================================================
time elapsed: 0:27:00
train iter: 528
num of updates: 52900
dynamics loss: 18088.37305

============================================================
time elapsed: 0:27:03
train iter: 529
num of updates: 53000
dynamics loss: 18095.10352

============================================================
time elapsed: 0:27:06
train iter: 530
num of updates: 53100
dynamics loss: 18083.87305

============================================================
time elapsed: 0:27:08
train iter: 531
num of updates: 53200
dynamics loss: 18055.58203

============================================================
time elapsed: 0:27:11
train iter: 532
num of updates: 53300
dynamics loss: 18015.48047

============================================================
time elapsed: 0:27:14
train iter: 533
num of updates: 53400
dynamics loss: 18033.39258

============================================================
time elapsed: 0:27:17
train iter: 534
num of updates: 53500
dynamics loss: 18005.39648

============================================================
time elapsed: 0:27:20
train iter: 535
num of updates: 53600
dynamics loss: 18001.81055

============================================================
time elapsed: 0:27:23
train iter: 536
num of updates: 53700
dynamics loss: 18005.22852

============================================================
time elapsed: 0:27:26
train iter: 537
num of updates: 53800
dynamics loss: 17971.14844

============================================================
time elapsed: 0:27:29
train iter: 538
num of updates: 53900
dynamics loss: 17971.17969

============================================================
time elapsed: 0:27:32
train iter: 539
num of updates: 54000
dynamics loss: 17946.78516

============================================================
time elapsed: 0:27:35
train iter: 540
num of updates: 54100
dynamics loss: 17915.13281

============================================================
time elapsed: 0:27:37
train iter: 541
num of updates: 54200
dynamics loss: 17921.73828

============================================================
time elapsed: 0:27:40
train iter: 542
num of updates: 54300
dynamics loss: 17885.29297

============================================================
time elapsed: 0:27:43
train iter: 543
num of updates: 54400
dynamics loss: 17865.21289

============================================================
time elapsed: 0:27:46
train iter: 544
num of updates: 54500
dynamics loss: 17863.54102

============================================================
time elapsed: 0:27:49
train iter: 545
num of updates: 54600
dynamics loss: 17856.23242

============================================================
time elapsed: 0:27:52
train iter: 546
num of updates: 54700
dynamics loss: 17821.69727

============================================================
time elapsed: 0:27:55
train iter: 547
num of updates: 54800
dynamics loss: 17834.12109

============================================================
time elapsed: 0:27:58
train iter: 548
num of updates: 54900
dynamics loss: 17848.05078

============================================================
time elapsed: 0:28:01
train iter: 549
num of updates: 55000
dynamics loss: 17785.69141

============================================================
time elapsed: 0:28:03
train iter: 550
num of updates: 55100
dynamics loss: 17781.90430

============================================================
time elapsed: 0:28:06
train iter: 551
num of updates: 55200
dynamics loss: 17811.80078

============================================================
time elapsed: 0:28:09
train iter: 552
num of updates: 55300
dynamics loss: 17766.23633

============================================================
time elapsed: 0:28:12
train iter: 553
num of updates: 55400
dynamics loss: 17744.44922

============================================================
time elapsed: 0:28:15
train iter: 554
num of updates: 55500
dynamics loss: 17728.66797

============================================================
time elapsed: 0:28:18
train iter: 555
num of updates: 55600
dynamics loss: 17721.81641

============================================================
time elapsed: 0:28:21
train iter: 556
num of updates: 55700
dynamics loss: 17699.51367

============================================================
time elapsed: 0:28:24
train iter: 557
num of updates: 55800
dynamics loss: 17695.74414

============================================================
time elapsed: 0:28:27
train iter: 558
num of updates: 55900
dynamics loss: 17660.46484

============================================================
time elapsed: 0:28:30
train iter: 559
num of updates: 56000
dynamics loss: 17660.50391

============================================================
time elapsed: 0:28:32
train iter: 560
num of updates: 56100
dynamics loss: 17672.27930

============================================================
time elapsed: 0:28:35
train iter: 561
num of updates: 56200
dynamics loss: 17627.00391

============================================================
time elapsed: 0:28:38
train iter: 562
num of updates: 56300
dynamics loss: 17615.20898

============================================================
time elapsed: 0:28:41
train iter: 563
num of updates: 56400
dynamics loss: 17615.49609

============================================================
time elapsed: 0:28:44
train iter: 564
num of updates: 56500
dynamics loss: 17581.75000

============================================================
time elapsed: 0:28:47
train iter: 565
num of updates: 56600
dynamics loss: 17576.95703

============================================================
time elapsed: 0:28:50
train iter: 566
num of updates: 56700
dynamics loss: 17583.00391

============================================================
time elapsed: 0:28:53
train iter: 567
num of updates: 56800
dynamics loss: 17559.11523

============================================================
time elapsed: 0:28:56
train iter: 568
num of updates: 56900
dynamics loss: 17550.34961

============================================================
time elapsed: 0:28:59
train iter: 569
num of updates: 57000
dynamics loss: 17525.13281

============================================================
time elapsed: 0:29:01
train iter: 570
num of updates: 57100
dynamics loss: 17522.92188

============================================================
time elapsed: 0:29:04
train iter: 571
num of updates: 57200
dynamics loss: 17523.37109

============================================================
time elapsed: 0:29:07
train iter: 572
num of updates: 57300
dynamics loss: 17500.53320

============================================================
time elapsed: 0:29:10
train iter: 573
num of updates: 57400
dynamics loss: 17495.28516

============================================================
time elapsed: 0:29:13
train iter: 574
num of updates: 57500
dynamics loss: 17488.00391

============================================================
time elapsed: 0:29:16
train iter: 575
num of updates: 57600
dynamics loss: 17466.60156

============================================================
time elapsed: 0:29:19
train iter: 576
num of updates: 57700
dynamics loss: 17460.02734

============================================================
time elapsed: 0:29:22
train iter: 577
num of updates: 57800
dynamics loss: 17412.68164

============================================================
time elapsed: 0:29:25
train iter: 578
num of updates: 57900
dynamics loss: 17406.15625

============================================================
time elapsed: 0:29:28
train iter: 579
num of updates: 58000
dynamics loss: 17393.06055

============================================================
time elapsed: 0:29:30
train iter: 580
num of updates: 58100
dynamics loss: 17379.21289

============================================================
time elapsed: 0:29:33
train iter: 581
num of updates: 58200
dynamics loss: 17373.79297

============================================================
time elapsed: 0:29:36
train iter: 582
num of updates: 58300
dynamics loss: 17359.72461

============================================================
time elapsed: 0:29:39
train iter: 583
num of updates: 58400
dynamics loss: 17341.32812

============================================================
time elapsed: 0:29:42
train iter: 584
num of updates: 58500
dynamics loss: 17324.93359

============================================================
time elapsed: 0:29:45
train iter: 585
num of updates: 58600
dynamics loss: 17344.66016

============================================================
time elapsed: 0:29:48
train iter: 586
num of updates: 58700
dynamics loss: 17283.78516

============================================================
time elapsed: 0:29:51
train iter: 587
num of updates: 58800
dynamics loss: 17287.82617

============================================================
time elapsed: 0:29:54
train iter: 588
num of updates: 58900
dynamics loss: 17271.02344

============================================================
time elapsed: 0:29:56
train iter: 589
num of updates: 59000
dynamics loss: 17261.96875

============================================================
time elapsed: 0:29:59
train iter: 590
num of updates: 59100
dynamics loss: 17243.18750

============================================================
time elapsed: 0:30:02
train iter: 591
num of updates: 59200
dynamics loss: 17238.56055

============================================================
time elapsed: 0:30:05
train iter: 592
num of updates: 59300
dynamics loss: 17225.20508

============================================================
time elapsed: 0:30:08
train iter: 593
num of updates: 59400
dynamics loss: 17191.63867

============================================================
time elapsed: 0:30:11
train iter: 594
num of updates: 59500
dynamics loss: 17198.42773

============================================================
time elapsed: 0:30:14
train iter: 595
num of updates: 59600
dynamics loss: 17195.72070

============================================================
time elapsed: 0:30:17
train iter: 596
num of updates: 59700
dynamics loss: 17156.33984

============================================================
time elapsed: 0:30:20
train iter: 597
num of updates: 59800
dynamics loss: 17171.83789

============================================================
time elapsed: 0:30:23
train iter: 598
num of updates: 59900
dynamics loss: 17146.16602

============================================================
time elapsed: 0:30:25
train iter: 599
num of updates: 60000
dynamics loss: 17113.67188

============================================================
time elapsed: 0:30:28
train iter: 600
num of updates: 60100
dynamics loss: 17104.24219

============================================================
time elapsed: 0:30:31
train iter: 601
num of updates: 60200
dynamics loss: 17099.04688

============================================================
time elapsed: 0:30:34
train iter: 602
num of updates: 60300
dynamics loss: 17079.37305

============================================================
time elapsed: 0:30:37
train iter: 603
num of updates: 60400
dynamics loss: 17096.52734

============================================================
time elapsed: 0:30:40
train iter: 604
num of updates: 60500
dynamics loss: 17060.31445

============================================================
time elapsed: 0:30:43
train iter: 605
num of updates: 60600
dynamics loss: 17048.31250

============================================================
time elapsed: 0:30:46
train iter: 606
num of updates: 60700
dynamics loss: 17034.92969

============================================================
time elapsed: 0:30:49
train iter: 607
num of updates: 60800
dynamics loss: 17021.89844

============================================================
time elapsed: 0:30:52
train iter: 608
num of updates: 60900
dynamics loss: 17024.00391

============================================================
time elapsed: 0:30:54
train iter: 609
num of updates: 61000
dynamics loss: 17003.90430

============================================================
time elapsed: 0:30:57
train iter: 610
num of updates: 61100
dynamics loss: 16985.58203

============================================================
time elapsed: 0:31:00
train iter: 611
num of updates: 61200
dynamics loss: 16966.50977

============================================================
time elapsed: 0:31:03
train iter: 612
num of updates: 61300
dynamics loss: 16954.98438

============================================================
time elapsed: 0:31:06
train iter: 613
num of updates: 61400
dynamics loss: 16941.10156

============================================================
time elapsed: 0:31:09
train iter: 614
num of updates: 61500
dynamics loss: 16940.95703

============================================================
time elapsed: 0:31:12
train iter: 615
num of updates: 61600
dynamics loss: 16922.54102

============================================================
time elapsed: 0:31:15
train iter: 616
num of updates: 61700
dynamics loss: 16910.85547

============================================================
time elapsed: 0:31:18
train iter: 617
num of updates: 61800
dynamics loss: 16906.61328

============================================================
time elapsed: 0:31:20
train iter: 618
num of updates: 61900
dynamics loss: 16864.79492

============================================================
time elapsed: 0:31:23
train iter: 619
num of updates: 62000
dynamics loss: 16857.81055

============================================================
time elapsed: 0:31:26
train iter: 620
num of updates: 62100
dynamics loss: 16852.30859

============================================================
time elapsed: 0:31:29
train iter: 621
num of updates: 62200
dynamics loss: 16822.46094

============================================================
time elapsed: 0:31:32
train iter: 622
num of updates: 62300
dynamics loss: 16798.06641

============================================================
time elapsed: 0:31:35
train iter: 623
num of updates: 62400
dynamics loss: 16820.89648

============================================================
time elapsed: 0:31:38
train iter: 624
num of updates: 62500
dynamics loss: 16802.58398

============================================================
time elapsed: 0:31:41
train iter: 625
num of updates: 62600
dynamics loss: 16781.60352

============================================================
time elapsed: 0:31:44
train iter: 626
num of updates: 62700
dynamics loss: 16769.85742

============================================================
time elapsed: 0:31:47
train iter: 627
num of updates: 62800
dynamics loss: 16757.00391

============================================================
time elapsed: 0:31:49
train iter: 628
num of updates: 62900
dynamics loss: 16752.99219

============================================================
time elapsed: 0:31:52
train iter: 629
num of updates: 63000
dynamics loss: 16731.29297

============================================================
time elapsed: 0:31:55
train iter: 630
num of updates: 63100
dynamics loss: 16725.93945

============================================================
time elapsed: 0:31:58
train iter: 631
num of updates: 63200
dynamics loss: 16702.04102

============================================================
time elapsed: 0:32:01
train iter: 632
num of updates: 63300
dynamics loss: 16704.17969

============================================================
time elapsed: 0:32:04
train iter: 633
num of updates: 63400
dynamics loss: 16675.48047

============================================================
time elapsed: 0:32:07
train iter: 634
num of updates: 63500
dynamics loss: 16648.74414

============================================================
time elapsed: 0:32:10
train iter: 635
num of updates: 63600
dynamics loss: 16642.23242

============================================================
time elapsed: 0:32:13
train iter: 636
num of updates: 63700
dynamics loss: 16612.76953

============================================================
time elapsed: 0:32:16
train iter: 637
num of updates: 63800
dynamics loss: 16618.66602

============================================================
time elapsed: 0:32:18
train iter: 638
num of updates: 63900
dynamics loss: 16604.87500

============================================================
time elapsed: 0:32:21
train iter: 639
num of updates: 64000
dynamics loss: 16596.26758

============================================================
time elapsed: 0:32:24
train iter: 640
num of updates: 64100
dynamics loss: 16582.12305

============================================================
time elapsed: 0:32:27
train iter: 641
num of updates: 64200
dynamics loss: 16561.20312

============================================================
time elapsed: 0:32:30
train iter: 642
num of updates: 64300
dynamics loss: 16572.75586

============================================================
time elapsed: 0:32:33
train iter: 643
num of updates: 64400
dynamics loss: 16539.46289

============================================================
time elapsed: 0:32:36
train iter: 644
num of updates: 64500
dynamics loss: 16545.37695

============================================================
time elapsed: 0:32:39
train iter: 645
num of updates: 64600
dynamics loss: 16536.33984

============================================================
time elapsed: 0:32:42
train iter: 646
num of updates: 64700
dynamics loss: 16514.70117

============================================================
time elapsed: 0:32:44
train iter: 647
num of updates: 64800
dynamics loss: 16515.53125

============================================================
time elapsed: 0:32:47
train iter: 648
num of updates: 64900
dynamics loss: 16485.73242

============================================================
time elapsed: 0:32:50
train iter: 649
num of updates: 65000
dynamics loss: 16480.59961

============================================================
time elapsed: 0:32:53
train iter: 650
num of updates: 65100
dynamics loss: 16427.55664

============================================================
time elapsed: 0:32:56
train iter: 651
num of updates: 65200
dynamics loss: 16464.02539

============================================================
time elapsed: 0:32:59
train iter: 652
num of updates: 65300
dynamics loss: 16427.65039

============================================================
time elapsed: 0:33:02
train iter: 653
num of updates: 65400
dynamics loss: 16431.34961

============================================================
time elapsed: 0:33:05
train iter: 654
num of updates: 65500
dynamics loss: 16412.60547

============================================================
time elapsed: 0:33:08
train iter: 655
num of updates: 65600
dynamics loss: 16366.65039

============================================================
time elapsed: 0:33:11
train iter: 656
num of updates: 65700
dynamics loss: 16379.60352

============================================================
time elapsed: 0:33:13
train iter: 657
num of updates: 65800
dynamics loss: 16373.20215

============================================================
time elapsed: 0:33:16
train iter: 658
num of updates: 65900
dynamics loss: 16350.06055

============================================================
time elapsed: 0:33:19
train iter: 659
num of updates: 66000
dynamics loss: 16327.79004

============================================================
time elapsed: 0:33:22
train iter: 660
num of updates: 66100
dynamics loss: 16334.90820

============================================================
time elapsed: 0:33:25
train iter: 661
num of updates: 66200
dynamics loss: 16316.65332

============================================================
time elapsed: 0:33:28
train iter: 662
num of updates: 66300
dynamics loss: 16312.15430

============================================================
time elapsed: 0:33:31
train iter: 663
num of updates: 66400
dynamics loss: 16283.03320

============================================================
time elapsed: 0:33:34
train iter: 664
num of updates: 66500
dynamics loss: 16259.91406

============================================================
time elapsed: 0:33:37
train iter: 665
num of updates: 66600
dynamics loss: 16254.24316

============================================================
time elapsed: 0:33:40
train iter: 666
num of updates: 66700
dynamics loss: 16239.40918

============================================================
time elapsed: 0:33:42
train iter: 667
num of updates: 66800
dynamics loss: 16240.59473

============================================================
time elapsed: 0:33:45
train iter: 668
num of updates: 66900
dynamics loss: 16224.67871

============================================================
time elapsed: 0:33:48
train iter: 669
num of updates: 67000
dynamics loss: 16210.21289

============================================================
time elapsed: 0:33:51
train iter: 670
num of updates: 67100
dynamics loss: 16203.80078

============================================================
time elapsed: 0:33:54
train iter: 671
num of updates: 67200
dynamics loss: 16168.65039

============================================================
time elapsed: 0:33:57
train iter: 672
num of updates: 67300
dynamics loss: 16181.75879

============================================================
time elapsed: 0:34:00
train iter: 673
num of updates: 67400
dynamics loss: 16151.63477

============================================================
time elapsed: 0:34:03
train iter: 674
num of updates: 67500
dynamics loss: 16130.68945

============================================================
time elapsed: 0:34:06
train iter: 675
num of updates: 67600
dynamics loss: 16105.53320

============================================================
time elapsed: 0:34:09
train iter: 676
num of updates: 67700
dynamics loss: 16113.88477

============================================================
time elapsed: 0:34:11
train iter: 677
num of updates: 67800
dynamics loss: 16111.65234

============================================================
time elapsed: 0:34:14
train iter: 678
num of updates: 67900
dynamics loss: 16065.56250

============================================================
time elapsed: 0:34:17
train iter: 679
num of updates: 68000
dynamics loss: 16077.81055

============================================================
time elapsed: 0:34:20
train iter: 680
num of updates: 68100
dynamics loss: 16061.44434

============================================================
time elapsed: 0:34:23
train iter: 681
num of updates: 68200
dynamics loss: 16037.63965

============================================================
time elapsed: 0:34:26
train iter: 682
num of updates: 68300
dynamics loss: 16037.49121

============================================================
time elapsed: 0:34:29
train iter: 683
num of updates: 68400
dynamics loss: 16015.97168

============================================================
time elapsed: 0:34:32
train iter: 684
num of updates: 68500
dynamics loss: 16020.82715

============================================================
time elapsed: 0:34:35
train iter: 685
num of updates: 68600
dynamics loss: 15986.30469

============================================================
time elapsed: 0:34:37
train iter: 686
num of updates: 68700
dynamics loss: 15986.13672

============================================================
time elapsed: 0:34:40
train iter: 687
num of updates: 68800
dynamics loss: 15970.61523

============================================================
time elapsed: 0:34:43
train iter: 688
num of updates: 68900
dynamics loss: 15934.95898

============================================================
time elapsed: 0:34:46
train iter: 689
num of updates: 69000
dynamics loss: 15940.91309

============================================================
time elapsed: 0:34:49
train iter: 690
num of updates: 69100
dynamics loss: 15904.57324

============================================================
time elapsed: 0:34:52
train iter: 691
num of updates: 69200
dynamics loss: 15910.08105

============================================================
time elapsed: 0:34:55
train iter: 692
num of updates: 69300
dynamics loss: 15916.02930

============================================================
time elapsed: 0:34:58
train iter: 693
num of updates: 69400
dynamics loss: 15891.93652

============================================================
time elapsed: 0:35:01
train iter: 694
num of updates: 69500
dynamics loss: 15874.61523

============================================================
time elapsed: 0:35:04
train iter: 695
num of updates: 69600
dynamics loss: 15849.26562

============================================================
time elapsed: 0:35:06
train iter: 696
num of updates: 69700
dynamics loss: 15848.17871

============================================================
time elapsed: 0:35:09
train iter: 697
num of updates: 69800
dynamics loss: 15850.43848

============================================================
time elapsed: 0:35:12
train iter: 698
num of updates: 69900
dynamics loss: 15829.56836

============================================================
time elapsed: 0:35:15
train iter: 699
num of updates: 70000
dynamics loss: 15815.77051

============================================================
time elapsed: 0:35:18
train iter: 700
num of updates: 70100
dynamics loss: 15783.48438

============================================================
time elapsed: 0:35:21
train iter: 701
num of updates: 70200
dynamics loss: 15764.14844

============================================================
time elapsed: 0:35:24
train iter: 702
num of updates: 70300
dynamics loss: 15769.04980

============================================================
time elapsed: 0:35:27
train iter: 703
num of updates: 70400
dynamics loss: 15747.32129

============================================================
time elapsed: 0:35:30
train iter: 704
num of updates: 70500
dynamics loss: 15737.49609

============================================================
time elapsed: 0:35:33
train iter: 705
num of updates: 70600
dynamics loss: 15728.98438

============================================================
time elapsed: 0:35:35
train iter: 706
num of updates: 70700
dynamics loss: 15701.70605

============================================================
time elapsed: 0:35:38
train iter: 707
num of updates: 70800
dynamics loss: 15711.04297

============================================================
time elapsed: 0:35:41
train iter: 708
num of updates: 70900
dynamics loss: 15700.27441

============================================================
time elapsed: 0:35:44
train iter: 709
num of updates: 71000
dynamics loss: 15679.68262

============================================================
time elapsed: 0:35:47
train iter: 710
num of updates: 71100
dynamics loss: 15671.28320

============================================================
time elapsed: 0:35:50
train iter: 711
num of updates: 71200
dynamics loss: 15668.50293

============================================================
time elapsed: 0:35:53
train iter: 712
num of updates: 71300
dynamics loss: 15657.63086

============================================================
time elapsed: 0:35:56
train iter: 713
num of updates: 71400
dynamics loss: 15606.29492

============================================================
time elapsed: 0:35:59
train iter: 714
num of updates: 71500
dynamics loss: 15625.85352

============================================================
time elapsed: 0:36:02
train iter: 715
num of updates: 71600
dynamics loss: 15609.19629

============================================================
time elapsed: 0:36:04
train iter: 716
num of updates: 71700
dynamics loss: 15623.40234

============================================================
time elapsed: 0:36:07
train iter: 717
num of updates: 71800
dynamics loss: 15576.96680

============================================================
time elapsed: 0:36:10
train iter: 718
num of updates: 71900
dynamics loss: 15549.69434

============================================================
time elapsed: 0:36:13
train iter: 719
num of updates: 72000
dynamics loss: 15520.93066

============================================================
time elapsed: 0:36:16
train iter: 720
num of updates: 72100
dynamics loss: 15539.37891

============================================================
time elapsed: 0:36:19
train iter: 721
num of updates: 72200
dynamics loss: 15526.01172

============================================================
time elapsed: 0:36:22
train iter: 722
num of updates: 72300
dynamics loss: 15521.04492

============================================================
time elapsed: 0:36:25
train iter: 723
num of updates: 72400
dynamics loss: 15494.35547

============================================================
time elapsed: 0:36:28
train iter: 724
num of updates: 72500
dynamics loss: 15494.97852

============================================================
time elapsed: 0:36:31
train iter: 725
num of updates: 72600
dynamics loss: 15451.01465

============================================================
time elapsed: 0:36:33
train iter: 726
num of updates: 72700
dynamics loss: 15470.49609

============================================================
time elapsed: 0:36:36
train iter: 727
num of updates: 72800
dynamics loss: 15445.77539

============================================================
time elapsed: 0:36:39
train iter: 728
num of updates: 72900
dynamics loss: 15448.91211

============================================================
time elapsed: 0:36:42
train iter: 729
num of updates: 73000
dynamics loss: 15399.04980

============================================================
time elapsed: 0:36:45
train iter: 730
num of updates: 73100
dynamics loss: 15416.33887

============================================================
time elapsed: 0:36:48
train iter: 731
num of updates: 73200
dynamics loss: 15395.89453

============================================================
time elapsed: 0:36:51
train iter: 732
num of updates: 73300
dynamics loss: 15380.27344

============================================================
time elapsed: 0:36:54
train iter: 733
num of updates: 73400
dynamics loss: 15377.41113

============================================================
time elapsed: 0:36:57
train iter: 734
num of updates: 73500
dynamics loss: 15353.97656

============================================================
time elapsed: 0:37:00
train iter: 735
num of updates: 73600
dynamics loss: 15360.99902

============================================================
time elapsed: 0:37:02
train iter: 736
num of updates: 73700
dynamics loss: 15346.05371

============================================================
time elapsed: 0:37:05
train iter: 737
num of updates: 73800
dynamics loss: 15308.83887

============================================================
time elapsed: 0:37:08
train iter: 738
num of updates: 73900
dynamics loss: 15302.60547

============================================================
time elapsed: 0:37:11
train iter: 739
num of updates: 74000
dynamics loss: 15282.77051

============================================================
time elapsed: 0:37:14
train iter: 740
num of updates: 74100
dynamics loss: 15272.05469

============================================================
time elapsed: 0:37:17
train iter: 741
num of updates: 74200
dynamics loss: 15247.84473

============================================================
time elapsed: 0:37:20
train iter: 742
num of updates: 74300
dynamics loss: 15253.86816

============================================================
time elapsed: 0:37:23
train iter: 743
num of updates: 74400
dynamics loss: 15223.72754

============================================================
time elapsed: 0:37:26
train iter: 744
num of updates: 74500
dynamics loss: 15243.54199

============================================================
time elapsed: 0:37:29
train iter: 745
num of updates: 74600
dynamics loss: 15227.70508

============================================================
time elapsed: 0:37:31
train iter: 746
num of updates: 74700
dynamics loss: 15206.36133

============================================================
time elapsed: 0:37:34
train iter: 747
num of updates: 74800
dynamics loss: 15175.77832

============================================================
time elapsed: 0:37:37
train iter: 748
num of updates: 74900
dynamics loss: 15181.56934

============================================================
time elapsed: 0:37:40
train iter: 749
num of updates: 75000
dynamics loss: 15139.38184

============================================================
time elapsed: 0:37:43
train iter: 750
num of updates: 75100
dynamics loss: 15158.03320

============================================================
time elapsed: 0:37:46
train iter: 751
num of updates: 75200
dynamics loss: 15141.65625

============================================================
time elapsed: 0:37:49
train iter: 752
num of updates: 75300
dynamics loss: 15086.86914

============================================================
time elapsed: 0:37:52
train iter: 753
num of updates: 75400
dynamics loss: 15121.66309

============================================================
time elapsed: 0:37:55
train iter: 754
num of updates: 75500
dynamics loss: 15099.72754

============================================================
time elapsed: 0:37:57
train iter: 755
num of updates: 75600
dynamics loss: 15098.72363

============================================================
time elapsed: 0:38:00
train iter: 756
num of updates: 75700
dynamics loss: 15083.31445

============================================================
time elapsed: 0:38:03
train iter: 757
num of updates: 75800
dynamics loss: 15041.75879

============================================================
time elapsed: 0:38:06
train iter: 758
num of updates: 75900
dynamics loss: 15039.53223

============================================================
time elapsed: 0:38:09
train iter: 759
num of updates: 76000
dynamics loss: 15016.40234

============================================================
time elapsed: 0:38:12
train iter: 760
num of updates: 76100
dynamics loss: 15010.07910

============================================================
time elapsed: 0:38:15
train iter: 761
num of updates: 76200
dynamics loss: 15016.18652

============================================================
time elapsed: 0:38:18
train iter: 762
num of updates: 76300
dynamics loss: 14998.95508

============================================================
time elapsed: 0:38:21
train iter: 763
num of updates: 76400
dynamics loss: 14989.26367

============================================================
time elapsed: 0:38:24
train iter: 764
num of updates: 76500
dynamics loss: 14972.73438

============================================================
time elapsed: 0:38:26
train iter: 765
num of updates: 76600
dynamics loss: 14958.66699

============================================================
time elapsed: 0:38:29
train iter: 766
num of updates: 76700
dynamics loss: 14932.51465

============================================================
time elapsed: 0:38:32
train iter: 767
num of updates: 76800
dynamics loss: 14930.72559

============================================================
time elapsed: 0:38:35
train iter: 768
num of updates: 76900
dynamics loss: 14938.70410

============================================================
time elapsed: 0:38:38
train iter: 769
num of updates: 77000
dynamics loss: 14913.95898

============================================================
time elapsed: 0:38:41
train iter: 770
num of updates: 77100
dynamics loss: 14895.61230

============================================================
time elapsed: 0:38:44
train iter: 771
num of updates: 77200
dynamics loss: 14865.34473

============================================================
time elapsed: 0:38:47
train iter: 772
num of updates: 77300
dynamics loss: 14871.25977

============================================================
time elapsed: 0:38:50
train iter: 773
num of updates: 77400
dynamics loss: 14878.99707

============================================================
time elapsed: 0:38:53
train iter: 774
num of updates: 77500
dynamics loss: 14829.60938

============================================================
time elapsed: 0:38:55
train iter: 775
num of updates: 77600
dynamics loss: 14821.32910

============================================================
time elapsed: 0:38:58
train iter: 776
num of updates: 77700
dynamics loss: 14839.16406

============================================================
time elapsed: 0:39:01
train iter: 777
num of updates: 77800
dynamics loss: 14799.16309

============================================================
time elapsed: 0:39:04
train iter: 778
num of updates: 77900
dynamics loss: 14804.01660

============================================================
time elapsed: 0:39:07
train iter: 779
num of updates: 78000
dynamics loss: 14778.81250

============================================================
time elapsed: 0:39:10
train iter: 780
num of updates: 78100
dynamics loss: 14762.55469

============================================================
time elapsed: 0:39:13
train iter: 781
num of updates: 78200
dynamics loss: 14760.09473

============================================================
time elapsed: 0:39:16
train iter: 782
num of updates: 78300
dynamics loss: 14737.56055

============================================================
time elapsed: 0:39:19
train iter: 783
num of updates: 78400
dynamics loss: 14724.50000

============================================================
time elapsed: 0:39:22
train iter: 784
num of updates: 78500
dynamics loss: 14730.20312

============================================================
time elapsed: 0:39:24
train iter: 785
num of updates: 78600
dynamics loss: 14710.17676

============================================================
time elapsed: 0:39:27
train iter: 786
num of updates: 78700
dynamics loss: 14685.96680

============================================================
time elapsed: 0:39:30
train iter: 787
num of updates: 78800
dynamics loss: 14685.12695

============================================================
time elapsed: 0:39:33
train iter: 788
num of updates: 78900
dynamics loss: 14657.47656

============================================================
time elapsed: 0:39:36
train iter: 789
num of updates: 79000
dynamics loss: 14671.27832

============================================================
time elapsed: 0:39:39
train iter: 790
num of updates: 79100
dynamics loss: 14644.86035

============================================================
time elapsed: 0:39:42
train iter: 791
num of updates: 79200
dynamics loss: 14631.86621

============================================================
time elapsed: 0:39:45
train iter: 792
num of updates: 79300
dynamics loss: 14609.96484

============================================================
time elapsed: 0:39:48
train iter: 793
num of updates: 79400
dynamics loss: 14607.22070

============================================================
time elapsed: 0:39:51
train iter: 794
num of updates: 79500
dynamics loss: 14594.17676

============================================================
time elapsed: 0:39:53
train iter: 795
num of updates: 79600
dynamics loss: 14591.98438

============================================================
time elapsed: 0:39:56
train iter: 796
num of updates: 79700
dynamics loss: 14576.48828

============================================================
time elapsed: 0:39:59
train iter: 797
num of updates: 79800
dynamics loss: 14557.32422

============================================================
time elapsed: 0:40:02
train iter: 798
num of updates: 79900
dynamics loss: 14528.62988

============================================================
time elapsed: 0:40:05
train iter: 799
num of updates: 80000
dynamics loss: 14530.28809

============================================================
time elapsed: 0:40:08
train iter: 800
num of updates: 80100
dynamics loss: 14519.61426

============================================================
time elapsed: 0:40:11
train iter: 801
num of updates: 80200
dynamics loss: 14482.40430

============================================================
time elapsed: 0:40:14
train iter: 802
num of updates: 80300
dynamics loss: 14500.03809

============================================================
time elapsed: 0:40:17
train iter: 803
num of updates: 80400
dynamics loss: 14491.97461

============================================================
time elapsed: 0:40:20
train iter: 804
num of updates: 80500
dynamics loss: 14459.75781

============================================================
time elapsed: 0:40:22
train iter: 805
num of updates: 80600
dynamics loss: 14437.50586

============================================================
time elapsed: 0:40:25
train iter: 806
num of updates: 80700
dynamics loss: 14430.11035

============================================================
time elapsed: 0:40:28
train iter: 807
num of updates: 80800
dynamics loss: 14432.69434

============================================================
time elapsed: 0:40:31
train iter: 808
num of updates: 80900
dynamics loss: 14416.47461

============================================================
time elapsed: 0:40:34
train iter: 809
num of updates: 81000
dynamics loss: 14422.17578

============================================================
time elapsed: 0:40:37
train iter: 810
num of updates: 81100
dynamics loss: 14404.57031

============================================================
time elapsed: 0:40:40
train iter: 811
num of updates: 81200
dynamics loss: 14396.99512

============================================================
time elapsed: 0:40:43
train iter: 812
num of updates: 81300
dynamics loss: 14384.87695

============================================================
time elapsed: 0:40:46
train iter: 813
num of updates: 81400
dynamics loss: 14358.54297

============================================================
time elapsed: 0:40:48
train iter: 814
num of updates: 81500
dynamics loss: 14344.05859

============================================================
time elapsed: 0:40:51
train iter: 815
num of updates: 81600
dynamics loss: 14330.17578

============================================================
time elapsed: 0:40:54
train iter: 816
num of updates: 81700
dynamics loss: 14308.46484

============================================================
time elapsed: 0:40:57
train iter: 817
num of updates: 81800
dynamics loss: 14297.54980

============================================================
time elapsed: 0:41:00
train iter: 818
num of updates: 81900
dynamics loss: 14309.81641

============================================================
time elapsed: 0:41:03
train iter: 819
num of updates: 82000
dynamics loss: 14284.75195

============================================================
time elapsed: 0:41:06
train iter: 820
num of updates: 82100
dynamics loss: 14289.96191

============================================================
time elapsed: 0:41:09
train iter: 821
num of updates: 82200
dynamics loss: 14269.76855

============================================================
time elapsed: 0:41:12
train iter: 822
num of updates: 82300
dynamics loss: 14243.70215

============================================================
time elapsed: 0:41:15
train iter: 823
num of updates: 82400
dynamics loss: 14225.60254

============================================================
time elapsed: 0:41:17
train iter: 824
num of updates: 82500
dynamics loss: 14241.87695

============================================================
time elapsed: 0:41:20
train iter: 825
num of updates: 82600
dynamics loss: 14231.74707

============================================================
time elapsed: 0:41:23
train iter: 826
num of updates: 82700
dynamics loss: 14207.19922

============================================================
time elapsed: 0:41:26
train iter: 827
num of updates: 82800
dynamics loss: 14196.86621

============================================================
time elapsed: 0:41:29
train iter: 828
num of updates: 82900
dynamics loss: 14183.40430

============================================================
time elapsed: 0:41:32
train iter: 829
num of updates: 83000
dynamics loss: 14181.58008

============================================================
time elapsed: 0:41:35
train iter: 830
num of updates: 83100
dynamics loss: 14157.30078

============================================================
time elapsed: 0:41:38
train iter: 831
num of updates: 83200
dynamics loss: 14145.51074

============================================================
time elapsed: 0:41:41
train iter: 832
num of updates: 83300
dynamics loss: 14125.78320

============================================================
time elapsed: 0:41:44
train iter: 833
num of updates: 83400
dynamics loss: 14138.33594

============================================================
time elapsed: 0:41:46
train iter: 834
num of updates: 83500
dynamics loss: 14102.55469

============================================================
time elapsed: 0:41:49
train iter: 835
num of updates: 83600
dynamics loss: 14092.28223

============================================================
time elapsed: 0:41:52
train iter: 836
num of updates: 83700
dynamics loss: 14092.09277

============================================================
time elapsed: 0:41:55
train iter: 837
num of updates: 83800
dynamics loss: 14069.04492

============================================================
time elapsed: 0:41:58
train iter: 838
num of updates: 83900
dynamics loss: 14073.93262

============================================================
time elapsed: 0:42:01
train iter: 839
num of updates: 84000
dynamics loss: 14049.73438

============================================================
time elapsed: 0:42:04
train iter: 840
num of updates: 84100
dynamics loss: 14054.38477

============================================================
time elapsed: 0:42:07
train iter: 841
num of updates: 84200
dynamics loss: 14022.70801

============================================================
time elapsed: 0:42:10
train iter: 842
num of updates: 84300
dynamics loss: 14025.33887

============================================================
time elapsed: 0:42:12
train iter: 843
num of updates: 84400
dynamics loss: 13986.60254

============================================================
time elapsed: 0:42:15
train iter: 844
num of updates: 84500
dynamics loss: 13996.74805

============================================================
time elapsed: 0:42:18
train iter: 845
num of updates: 84600
dynamics loss: 13992.49414

============================================================
time elapsed: 0:42:21
train iter: 846
num of updates: 84700
dynamics loss: 13989.69434

============================================================
time elapsed: 0:42:24
train iter: 847
num of updates: 84800
dynamics loss: 13958.03027

============================================================
time elapsed: 0:42:27
train iter: 848
num of updates: 84900
dynamics loss: 13943.11133

============================================================
time elapsed: 0:42:30
train iter: 849
num of updates: 85000
dynamics loss: 13938.43848

============================================================
time elapsed: 0:42:33
train iter: 850
num of updates: 85100
dynamics loss: 13941.16309

============================================================
time elapsed: 0:42:36
train iter: 851
num of updates: 85200
dynamics loss: 13909.27930

============================================================
time elapsed: 0:42:39
train iter: 852
num of updates: 85300
dynamics loss: 13915.50098

============================================================
time elapsed: 0:42:41
train iter: 853
num of updates: 85400
dynamics loss: 13872.87598

============================================================
time elapsed: 0:42:44
train iter: 854
num of updates: 85500
dynamics loss: 13887.35352

============================================================
time elapsed: 0:42:47
train iter: 855
num of updates: 85600
dynamics loss: 13885.09570

============================================================
time elapsed: 0:42:50
train iter: 856
num of updates: 85700
dynamics loss: 13864.48242

============================================================
time elapsed: 0:42:53
train iter: 857
num of updates: 85800
dynamics loss: 13839.90039

============================================================
time elapsed: 0:42:56
train iter: 858
num of updates: 85900
dynamics loss: 13818.62598

============================================================
time elapsed: 0:42:59
train iter: 859
num of updates: 86000
dynamics loss: 13812.78223

============================================================
time elapsed: 0:43:02
train iter: 860
num of updates: 86100
dynamics loss: 13825.83105

============================================================
time elapsed: 0:43:05
train iter: 861
num of updates: 86200
dynamics loss: 13811.30762

============================================================
time elapsed: 0:43:08
train iter: 862
num of updates: 86300
dynamics loss: 13782.92090

============================================================
time elapsed: 0:43:10
train iter: 863
num of updates: 86400
dynamics loss: 13760.19043

============================================================
time elapsed: 0:43:13
train iter: 864
num of updates: 86500
dynamics loss: 13749.86719

============================================================
time elapsed: 0:43:16
train iter: 865
num of updates: 86600
dynamics loss: 13735.69043

============================================================
time elapsed: 0:43:19
train iter: 866
num of updates: 86700
dynamics loss: 13723.64551

============================================================
time elapsed: 0:43:22
train iter: 867
num of updates: 86800
dynamics loss: 13739.86230

============================================================
time elapsed: 0:43:25
train iter: 868
num of updates: 86900
dynamics loss: 13722.66797

============================================================
time elapsed: 0:43:28
train iter: 869
num of updates: 87000
dynamics loss: 13755.92090

============================================================
time elapsed: 0:43:31
train iter: 870
num of updates: 87100
dynamics loss: 13687.31152

============================================================
time elapsed: 0:43:34
train iter: 871
num of updates: 87200
dynamics loss: 13690.06836

============================================================
time elapsed: 0:43:37
train iter: 872
num of updates: 87300
dynamics loss: 13674.61035

============================================================
time elapsed: 0:43:39
train iter: 873
num of updates: 87400
dynamics loss: 13686.98047

============================================================
time elapsed: 0:43:42
train iter: 874
num of updates: 87500
dynamics loss: 13661.03613

============================================================
time elapsed: 0:43:45
train iter: 875
num of updates: 87600
dynamics loss: 13651.78711

============================================================
time elapsed: 0:43:48
train iter: 876
num of updates: 87700
dynamics loss: 13649.40332

============================================================
time elapsed: 0:43:51
train iter: 877
num of updates: 87800
dynamics loss: 13612.68848

============================================================
time elapsed: 0:43:54
train iter: 878
num of updates: 87900
dynamics loss: 13633.73242

============================================================
time elapsed: 0:43:57
train iter: 879
num of updates: 88000
dynamics loss: 13602.37988

============================================================
time elapsed: 0:44:00
train iter: 880
num of updates: 88100
dynamics loss: 13599.18066

============================================================
time elapsed: 0:44:03
train iter: 881
num of updates: 88200
dynamics loss: 13581.50293

============================================================
time elapsed: 0:44:06
train iter: 882
num of updates: 88300
dynamics loss: 13586.06641

============================================================
time elapsed: 0:44:08
train iter: 883
num of updates: 88400
dynamics loss: 13575.04297

============================================================
time elapsed: 0:44:11
train iter: 884
num of updates: 88500
dynamics loss: 13542.30469

============================================================
time elapsed: 0:44:14
train iter: 885
num of updates: 88600
dynamics loss: 13529.05078

============================================================
time elapsed: 0:44:17
train iter: 886
num of updates: 88700
dynamics loss: 13528.51660

============================================================
time elapsed: 0:44:20
train iter: 887
num of updates: 88800
dynamics loss: 13510.65820

============================================================
time elapsed: 0:44:23
train iter: 888
num of updates: 88900
dynamics loss: 13504.23438

============================================================
time elapsed: 0:44:26
train iter: 889
num of updates: 89000
dynamics loss: 13500.38184

============================================================
time elapsed: 0:44:29
train iter: 890
num of updates: 89100
dynamics loss: 13463.08691

============================================================
time elapsed: 0:44:32
train iter: 891
num of updates: 89200
dynamics loss: 13486.55469

============================================================
time elapsed: 0:44:35
train iter: 892
num of updates: 89300
dynamics loss: 13457.47852

============================================================
time elapsed: 0:44:37
train iter: 893
num of updates: 89400
dynamics loss: 13460.16406

============================================================
time elapsed: 0:44:40
train iter: 894
num of updates: 89500
dynamics loss: 13440.88477

============================================================
time elapsed: 0:44:43
train iter: 895
num of updates: 89600
dynamics loss: 13435.76074

============================================================
time elapsed: 0:44:46
train iter: 896
num of updates: 89700
dynamics loss: 13410.49707

============================================================
time elapsed: 0:44:49
train iter: 897
num of updates: 89800
dynamics loss: 13406.82422

============================================================
time elapsed: 0:44:52
train iter: 898
num of updates: 89900
dynamics loss: 13393.67871

============================================================
time elapsed: 0:44:55
train iter: 899
num of updates: 90000
dynamics loss: 13386.26270

============================================================
time elapsed: 0:44:58
train iter: 900
num of updates: 90100
dynamics loss: 13394.54492

============================================================
time elapsed: 0:45:01
train iter: 901
num of updates: 90200
dynamics loss: 13367.91797

============================================================
time elapsed: 0:45:03
train iter: 902
num of updates: 90300
dynamics loss: 13366.85449

============================================================
time elapsed: 0:45:06
train iter: 903
num of updates: 90400
dynamics loss: 13320.18066

============================================================
time elapsed: 0:45:09
train iter: 904
num of updates: 90500
dynamics loss: 13330.27148

============================================================
time elapsed: 0:45:12
train iter: 905
num of updates: 90600
dynamics loss: 13344.53906

============================================================
time elapsed: 0:45:15
train iter: 906
num of updates: 90700
dynamics loss: 13301.85059

============================================================
time elapsed: 0:45:18
train iter: 907
num of updates: 90800
dynamics loss: 13295.94824

============================================================
time elapsed: 0:45:21
train iter: 908
num of updates: 90900
dynamics loss: 13315.19434

============================================================
time elapsed: 0:45:24
train iter: 909
num of updates: 91000
dynamics loss: 13293.20703

============================================================
time elapsed: 0:45:27
train iter: 910
num of updates: 91100
dynamics loss: 13270.15625

============================================================
time elapsed: 0:45:30
train iter: 911
num of updates: 91200
dynamics loss: 13257.71777

============================================================
time elapsed: 0:45:32
train iter: 912
num of updates: 91300
dynamics loss: 13262.87891

============================================================
time elapsed: 0:45:35
train iter: 913
num of updates: 91400
dynamics loss: 13254.23438

============================================================
time elapsed: 0:45:38
train iter: 914
num of updates: 91500
dynamics loss: 13238.29102

============================================================
time elapsed: 0:45:41
train iter: 915
num of updates: 91600
dynamics loss: 13227.57910

============================================================
time elapsed: 0:45:44
train iter: 916
num of updates: 91700
dynamics loss: 13203.04492

============================================================
time elapsed: 0:45:47
train iter: 917
num of updates: 91800
dynamics loss: 13186.45508

============================================================
time elapsed: 0:45:50
train iter: 918
num of updates: 91900
dynamics loss: 13189.68555

============================================================
time elapsed: 0:45:53
train iter: 919
num of updates: 92000
dynamics loss: 13181.54395

============================================================
time elapsed: 0:45:56
train iter: 920
num of updates: 92100
dynamics loss: 13184.22852

============================================================
time elapsed: 0:45:59
train iter: 921
num of updates: 92200
dynamics loss: 13132.69043

============================================================
time elapsed: 0:46:01
train iter: 922
num of updates: 92300
dynamics loss: 13146.40039

============================================================
time elapsed: 0:46:04
train iter: 923
num of updates: 92400
dynamics loss: 13156.62988

============================================================
time elapsed: 0:46:07
train iter: 924
num of updates: 92500
dynamics loss: 13126.62695

============================================================
time elapsed: 0:46:10
train iter: 925
num of updates: 92600
dynamics loss: 13106.71289

============================================================
time elapsed: 0:46:13
train iter: 926
num of updates: 92700
dynamics loss: 13100.10254

============================================================
time elapsed: 0:46:16
train iter: 927
num of updates: 92800
dynamics loss: 13104.76270

============================================================
time elapsed: 0:46:19
train iter: 928
num of updates: 92900
dynamics loss: 13083.25586

============================================================
time elapsed: 0:46:22
train iter: 929
num of updates: 93000
dynamics loss: 13079.14062

============================================================
time elapsed: 0:46:25
train iter: 930
num of updates: 93100
dynamics loss: 13066.31445

============================================================
time elapsed: 0:46:28
train iter: 931
num of updates: 93200
dynamics loss: 13055.32129

============================================================
time elapsed: 0:46:30
train iter: 932
num of updates: 93300
dynamics loss: 13067.45410

============================================================
time elapsed: 0:46:33
train iter: 933
num of updates: 93400
dynamics loss: 13046.85938

============================================================
time elapsed: 0:46:36
train iter: 934
num of updates: 93500
dynamics loss: 13036.56836

============================================================
time elapsed: 0:46:39
train iter: 935
num of updates: 93600
dynamics loss: 13012.64355

============================================================
time elapsed: 0:46:42
train iter: 936
num of updates: 93700
dynamics loss: 13023.79297

============================================================
time elapsed: 0:46:45
train iter: 937
num of updates: 93800
dynamics loss: 12991.60059

============================================================
time elapsed: 0:46:48
train iter: 938
num of updates: 93900
dynamics loss: 12993.68359

============================================================
time elapsed: 0:46:51
train iter: 939
num of updates: 94000
dynamics loss: 12978.54980

============================================================
time elapsed: 0:46:54
train iter: 940
num of updates: 94100
dynamics loss: 12969.35449

============================================================
time elapsed: 0:46:57
train iter: 941
num of updates: 94200
dynamics loss: 12959.35840

============================================================
time elapsed: 0:46:59
train iter: 942
num of updates: 94300
dynamics loss: 12954.67871

============================================================
time elapsed: 0:47:02
train iter: 943
num of updates: 94400
dynamics loss: 12939.45703

============================================================
time elapsed: 0:47:05
train iter: 944
num of updates: 94500
dynamics loss: 12933.30469

============================================================
time elapsed: 0:47:08
train iter: 945
num of updates: 94600
dynamics loss: 12917.78613

============================================================
time elapsed: 0:47:11
train iter: 946
num of updates: 94700
dynamics loss: 12908.31250

============================================================
time elapsed: 0:47:14
train iter: 947
num of updates: 94800
dynamics loss: 12902.92969

============================================================
time elapsed: 0:47:17
train iter: 948
num of updates: 94900
dynamics loss: 12900.36621

============================================================
time elapsed: 0:47:20
train iter: 949
num of updates: 95000
dynamics loss: 12911.31055

============================================================
time elapsed: 0:47:23
train iter: 950
num of updates: 95100
dynamics loss: 12872.63086

============================================================
time elapsed: 0:47:25
train iter: 951
num of updates: 95200
dynamics loss: 12880.63184

============================================================
time elapsed: 0:47:28
train iter: 952
num of updates: 95300
dynamics loss: 12857.02637

============================================================
time elapsed: 0:47:31
train iter: 953
num of updates: 95400
dynamics loss: 12837.85547

============================================================
time elapsed: 0:47:34
train iter: 954
num of updates: 95500
dynamics loss: 12835.24707

============================================================
time elapsed: 0:47:37
train iter: 955
num of updates: 95600
dynamics loss: 12825.95508

============================================================
time elapsed: 0:47:40
train iter: 956
num of updates: 95700
dynamics loss: 12830.02246

============================================================
time elapsed: 0:47:43
train iter: 957
num of updates: 95800
dynamics loss: 12821.00488

============================================================
time elapsed: 0:47:46
train iter: 958
num of updates: 95900
dynamics loss: 12786.63867

============================================================
time elapsed: 0:47:49
train iter: 959
num of updates: 96000
dynamics loss: 12801.77441

============================================================
time elapsed: 0:47:52
train iter: 960
num of updates: 96100
dynamics loss: 12782.26562

============================================================
time elapsed: 0:47:54
train iter: 961
num of updates: 96200
dynamics loss: 12777.51465

============================================================
time elapsed: 0:47:57
train iter: 962
num of updates: 96300
dynamics loss: 12760.39258

============================================================
time elapsed: 0:48:00
train iter: 963
num of updates: 96400
dynamics loss: 12755.02246

============================================================
time elapsed: 0:48:03
train iter: 964
num of updates: 96500
dynamics loss: 12703.91895

============================================================
time elapsed: 0:48:06
train iter: 965
num of updates: 96600
dynamics loss: 12714.15332

============================================================
time elapsed: 0:48:09
train iter: 966
num of updates: 96700
dynamics loss: 12737.88086

============================================================
time elapsed: 0:48:12
train iter: 967
num of updates: 96800
dynamics loss: 12727.26855

============================================================
time elapsed: 0:48:15
train iter: 968
num of updates: 96900
dynamics loss: 12730.99707

============================================================
time elapsed: 0:48:18
train iter: 969
num of updates: 97000
dynamics loss: 12680.44043

============================================================
time elapsed: 0:48:21
train iter: 970
num of updates: 97100
dynamics loss: 12691.23828

============================================================
time elapsed: 0:48:23
train iter: 971
num of updates: 97200
dynamics loss: 12675.11426

============================================================
time elapsed: 0:48:26
train iter: 972
num of updates: 97300
dynamics loss: 12663.39453

============================================================
time elapsed: 0:48:29
train iter: 973
num of updates: 97400
dynamics loss: 12656.96680

============================================================
time elapsed: 0:48:32
train iter: 974
num of updates: 97500
dynamics loss: 12648.91992

============================================================
time elapsed: 0:48:35
train iter: 975
num of updates: 97600
dynamics loss: 12651.36426

============================================================
time elapsed: 0:48:38
train iter: 976
num of updates: 97700
dynamics loss: 12638.35059

============================================================
time elapsed: 0:48:41
train iter: 977
num of updates: 97800
dynamics loss: 12625.63086

============================================================
time elapsed: 0:48:44
train iter: 978
num of updates: 97900
dynamics loss: 12599.22070

============================================================
time elapsed: 0:48:47
train iter: 979
num of updates: 98000
dynamics loss: 12597.25488

============================================================
time elapsed: 0:48:50
train iter: 980
num of updates: 98100
dynamics loss: 12570.86230

============================================================
time elapsed: 0:48:52
train iter: 981
num of updates: 98200
dynamics loss: 12584.11426

============================================================
time elapsed: 0:48:55
train iter: 982
num of updates: 98300
dynamics loss: 12578.13770

============================================================
time elapsed: 0:48:58
train iter: 983
num of updates: 98400
dynamics loss: 12568.57031

============================================================
time elapsed: 0:49:01
train iter: 984
num of updates: 98500
dynamics loss: 12572.70898

============================================================
time elapsed: 0:49:04
train iter: 985
num of updates: 98600
dynamics loss: 12566.82129

============================================================
time elapsed: 0:49:07
train iter: 986
num of updates: 98700
dynamics loss: 12547.45703

============================================================
time elapsed: 0:49:10
train iter: 987
num of updates: 98800
dynamics loss: 12520.09277

============================================================
time elapsed: 0:49:13
train iter: 988
num of updates: 98900
dynamics loss: 12518.41016

============================================================
time elapsed: 0:49:16
train iter: 989
num of updates: 99000
dynamics loss: 12513.04004

============================================================
time elapsed: 0:49:18
train iter: 990
num of updates: 99100
dynamics loss: 12532.12695

============================================================
time elapsed: 0:49:21
train iter: 991
num of updates: 99200
dynamics loss: 12493.73633

============================================================
time elapsed: 0:49:24
train iter: 992
num of updates: 99300
dynamics loss: 12483.50488

============================================================
time elapsed: 0:49:27
train iter: 993
num of updates: 99400
dynamics loss: 12480.77539

============================================================
time elapsed: 0:49:30
train iter: 994
num of updates: 99500
dynamics loss: 12479.52637

============================================================
time elapsed: 0:49:33
train iter: 995
num of updates: 99600
dynamics loss: 12455.19824

============================================================
time elapsed: 0:49:36
train iter: 996
num of updates: 99700
dynamics loss: 12449.99414

============================================================
time elapsed: 0:49:39
train iter: 997
num of updates: 99800
dynamics loss: 12440.31641

============================================================
time elapsed: 0:49:42
train iter: 998
num of updates: 99900
dynamics loss: 12447.08203

============================================================
time elapsed: 0:49:45
train iter: 999
num of updates: 100000
dynamics loss: 12431.74219

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/dynamics_model_100000.pt
============================================================
finished training dynamics!
============================================================
started training dynamics at: 25-09-28-00-54-25
finished training dynamics at: 25-09-28-01-44-14
total dynamics training time: 0:49:49
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/dynamics_model.pt
============================================================
2025-09-28 01:44:24.424996: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:26.545830: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:44:28.003446: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 324 bytes spill stores, 324 bytes spill loads

num_vae_param: 547754
2025-09-28 01:44:34.418811: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:34.418990: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:34.419046: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:34.419266: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:34.419312: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:44:36.226357: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 320 bytes spill stores, 220 bytes spill loads

2025-09-28 01:44:36.808751: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 388 bytes spill stores, 384 bytes spill loads

2025-09-28 01:44:38.394127: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 820 bytes spill stores, 564 bytes spill loads

2025-09-28 01:44:40.711893: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_144', 1736 bytes spill stores, 1312 bytes spill loads

2025-09-28 01:44:46.642298: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15', 4 bytes spill stores, 4 bytes spill loads

2025-09-28 01:44:48.340992: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 540 bytes spill stores, 540 bytes spill loads

2025-09-28 01:44:49.242140: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_197', 196 bytes spill stores, 200 bytes spill loads

2025-09-28 01:44:50.811184: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 8 bytes spill stores, 8 bytes spill loads

2025-09-28 01:44:53.039527: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 108 bytes spill stores, 108 bytes spill loads

2025-09-28 01:44:54.025516: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 292 bytes spill stores, 292 bytes spill loads

2025-09-28 01:44:54.792367: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_191', 200 bytes spill stores, 200 bytes spill loads

============================================================
time elapsed: 0:50:43
train iter: 0
num of updates: 100
vae loss: 2.19801
kl loss: 0.11153
a decoder loss: 2.08648
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/vae_model_100.pt
2025-09-28 01:45:09.085374: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 01:45:10.844932: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 01:45:12.719435: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 324 bytes spill stores, 324 bytes spill loads

============================================================
time elapsed: 0:50:59
train iter: 1
num of updates: 200
vae loss: 2.19992
kl loss: 0.11173
a decoder loss: 2.08819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:01
train iter: 2
num of updates: 300
vae loss: 2.19370
kl loss: 0.11030
a decoder loss: 2.08340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:02
train iter: 3
num of updates: 400
vae loss: 2.18861
kl loss: 0.10910
a decoder loss: 2.07951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:03
train iter: 4
num of updates: 500
vae loss: 2.18650
kl loss: 0.10777
a decoder loss: 2.07873
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:04
train iter: 5
num of updates: 600
vae loss: 2.18512
kl loss: 0.10643
a decoder loss: 2.07869
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:05
train iter: 6
num of updates: 700
vae loss: 2.17932
kl loss: 0.10403
a decoder loss: 2.07529
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:06
train iter: 7
num of updates: 800
vae loss: 2.17097
kl loss: 0.10197
a decoder loss: 2.06900
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:07
train iter: 8
num of updates: 900
vae loss: 2.16282
kl loss: 0.10006
a decoder loss: 2.06276
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:08
train iter: 9
num of updates: 1000
vae loss: 2.14816
kl loss: 0.09719
a decoder loss: 2.05097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:09
train iter: 10
num of updates: 1100
vae loss: 2.14312
kl loss: 0.09464
a decoder loss: 2.04848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:10
train iter: 11
num of updates: 1200
vae loss: 2.12345
kl loss: 0.09206
a decoder loss: 2.03138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:11
train iter: 12
num of updates: 1300
vae loss: 2.12326
kl loss: 0.08949
a decoder loss: 2.03377
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:12
train iter: 13
num of updates: 1400
vae loss: 2.11781
kl loss: 0.08694
a decoder loss: 2.03087
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:13
train iter: 14
num of updates: 1500
vae loss: 2.09527
kl loss: 0.08414
a decoder loss: 2.01113
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:14
train iter: 15
num of updates: 1600
vae loss: 2.08284
kl loss: 0.08144
a decoder loss: 2.00140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:15
train iter: 16
num of updates: 1700
vae loss: 2.05850
kl loss: 0.07908
a decoder loss: 1.97942
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:16
train iter: 17
num of updates: 1800
vae loss: 2.05007
kl loss: 0.07693
a decoder loss: 1.97314
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:17
train iter: 18
num of updates: 1900
vae loss: 2.03763
kl loss: 0.07429
a decoder loss: 1.96334
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:18
train iter: 19
num of updates: 2000
vae loss: 2.02521
kl loss: 0.07222
a decoder loss: 1.95300
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:19
train iter: 20
num of updates: 2100
vae loss: 2.01481
kl loss: 0.06992
a decoder loss: 1.94490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:20
train iter: 21
num of updates: 2200
vae loss: 1.98787
kl loss: 0.06812
a decoder loss: 1.91974
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:21
train iter: 22
num of updates: 2300
vae loss: 1.97078
kl loss: 0.06629
a decoder loss: 1.90449
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:22
train iter: 23
num of updates: 2400
vae loss: 1.95776
kl loss: 0.06448
a decoder loss: 1.89328
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:23
train iter: 24
num of updates: 2500
vae loss: 1.94260
kl loss: 0.06266
a decoder loss: 1.87994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:24
train iter: 25
num of updates: 2600
vae loss: 1.91862
kl loss: 0.06082
a decoder loss: 1.85780
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:25
train iter: 26
num of updates: 2700
vae loss: 1.89960
kl loss: 0.05917
a decoder loss: 1.84043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:26
train iter: 27
num of updates: 2800
vae loss: 1.87959
kl loss: 0.05786
a decoder loss: 1.82174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:27
train iter: 28
num of updates: 2900
vae loss: 1.86244
kl loss: 0.05651
a decoder loss: 1.80593
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:28
train iter: 29
num of updates: 3000
vae loss: 1.84528
kl loss: 0.05512
a decoder loss: 1.79017
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:29
train iter: 30
num of updates: 3100
vae loss: 1.82687
kl loss: 0.05384
a decoder loss: 1.77303
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:30
train iter: 31
num of updates: 3200
vae loss: 1.80338
kl loss: 0.05264
a decoder loss: 1.75075
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:31
train iter: 32
num of updates: 3300
vae loss: 1.78824
kl loss: 0.05164
a decoder loss: 1.73659
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:32
train iter: 33
num of updates: 3400
vae loss: 1.76855
kl loss: 0.05066
a decoder loss: 1.71789
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:33
train iter: 34
num of updates: 3500
vae loss: 1.74472
kl loss: 0.04967
a decoder loss: 1.69505
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:34
train iter: 35
num of updates: 3600
vae loss: 1.72390
kl loss: 0.04867
a decoder loss: 1.67524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:35
train iter: 36
num of updates: 3700
vae loss: 1.70026
kl loss: 0.04787
a decoder loss: 1.65239
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:36
train iter: 37
num of updates: 3800
vae loss: 1.67274
kl loss: 0.04729
a decoder loss: 1.62544
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:37
train iter: 38
num of updates: 3900
vae loss: 1.66225
kl loss: 0.04644
a decoder loss: 1.61581
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:38
train iter: 39
num of updates: 4000
vae loss: 1.63895
kl loss: 0.04577
a decoder loss: 1.59318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:39
train iter: 40
num of updates: 4100
vae loss: 1.61246
kl loss: 0.04502
a decoder loss: 1.56744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:40
train iter: 41
num of updates: 4200
vae loss: 1.59950
kl loss: 0.04442
a decoder loss: 1.55508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:41
train iter: 42
num of updates: 4300
vae loss: 1.57900
kl loss: 0.04391
a decoder loss: 1.53508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:42
train iter: 43
num of updates: 4400
vae loss: 1.55526
kl loss: 0.04340
a decoder loss: 1.51185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:43
train iter: 44
num of updates: 4500
vae loss: 1.54121
kl loss: 0.04302
a decoder loss: 1.49819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:44
train iter: 45
num of updates: 4600
vae loss: 1.51916
kl loss: 0.04267
a decoder loss: 1.47650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:45
train iter: 46
num of updates: 4700
vae loss: 1.49501
kl loss: 0.04232
a decoder loss: 1.45269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:46
train iter: 47
num of updates: 4800
vae loss: 1.48020
kl loss: 0.04212
a decoder loss: 1.43808
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:47
train iter: 48
num of updates: 4900
vae loss: 1.45642
kl loss: 0.04174
a decoder loss: 1.41469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:48
train iter: 49
num of updates: 5000
vae loss: 1.43248
kl loss: 0.04150
a decoder loss: 1.39098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:49
train iter: 50
num of updates: 5100
vae loss: 1.41750
kl loss: 0.04144
a decoder loss: 1.37606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:50
train iter: 51
num of updates: 5200
vae loss: 1.39302
kl loss: 0.04113
a decoder loss: 1.35189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:51
train iter: 52
num of updates: 5300
vae loss: 1.36982
kl loss: 0.04105
a decoder loss: 1.32876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:52
train iter: 53
num of updates: 5400
vae loss: 1.34565
kl loss: 0.04099
a decoder loss: 1.30467
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:53
train iter: 54
num of updates: 5500
vae loss: 1.33262
kl loss: 0.04091
a decoder loss: 1.29171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:54
train iter: 55
num of updates: 5600
vae loss: 1.30999
kl loss: 0.04080
a decoder loss: 1.26919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:55
train iter: 56
num of updates: 5700
vae loss: 1.29537
kl loss: 0.04075
a decoder loss: 1.25461
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:56
train iter: 57
num of updates: 5800
vae loss: 1.26549
kl loss: 0.04053
a decoder loss: 1.22496
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:57
train iter: 58
num of updates: 5900
vae loss: 1.24797
kl loss: 0.04061
a decoder loss: 1.20736
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:58
train iter: 59
num of updates: 6000
vae loss: 1.23256
kl loss: 0.04055
a decoder loss: 1.19201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:51:59
train iter: 60
num of updates: 6100
vae loss: 1.21006
kl loss: 0.04057
a decoder loss: 1.16948
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:00
train iter: 61
num of updates: 6200
vae loss: 1.19245
kl loss: 0.04039
a decoder loss: 1.15206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:01
train iter: 62
num of updates: 6300
vae loss: 1.16996
kl loss: 0.04065
a decoder loss: 1.12931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:02
train iter: 63
num of updates: 6400
vae loss: 1.14787
kl loss: 0.04047
a decoder loss: 1.10740
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:03
train iter: 64
num of updates: 6500
vae loss: 1.13003
kl loss: 0.04064
a decoder loss: 1.08939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:04
train iter: 65
num of updates: 6600
vae loss: 1.11173
kl loss: 0.04053
a decoder loss: 1.07120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:05
train iter: 66
num of updates: 6700
vae loss: 1.09101
kl loss: 0.04035
a decoder loss: 1.05066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:06
train iter: 67
num of updates: 6800
vae loss: 1.07168
kl loss: 0.04037
a decoder loss: 1.03132
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:08
train iter: 68
num of updates: 6900
vae loss: 1.05043
kl loss: 0.04035
a decoder loss: 1.01007
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:09
train iter: 69
num of updates: 7000
vae loss: 1.03244
kl loss: 0.04029
a decoder loss: 0.99215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:10
train iter: 70
num of updates: 7100
vae loss: 1.01709
kl loss: 0.04016
a decoder loss: 0.97693
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:11
train iter: 71
num of updates: 7200
vae loss: 0.99867
kl loss: 0.04017
a decoder loss: 0.95850
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:12
train iter: 72
num of updates: 7300
vae loss: 0.97575
kl loss: 0.04001
a decoder loss: 0.93575
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:13
train iter: 73
num of updates: 7400
vae loss: 0.96248
kl loss: 0.03991
a decoder loss: 0.92258
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:14
train iter: 74
num of updates: 7500
vae loss: 0.94269
kl loss: 0.03980
a decoder loss: 0.90289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:15
train iter: 75
num of updates: 7600
vae loss: 0.93136
kl loss: 0.03974
a decoder loss: 0.89162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:16
train iter: 76
num of updates: 7700
vae loss: 0.91329
kl loss: 0.03946
a decoder loss: 0.87383
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:17
train iter: 77
num of updates: 7800
vae loss: 0.89243
kl loss: 0.03925
a decoder loss: 0.85318
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:18
train iter: 78
num of updates: 7900
vae loss: 0.87160
kl loss: 0.03898
a decoder loss: 0.83261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:19
train iter: 79
num of updates: 8000
vae loss: 0.86327
kl loss: 0.03873
a decoder loss: 0.82454
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:20
train iter: 80
num of updates: 8100
vae loss: 0.84527
kl loss: 0.03859
a decoder loss: 0.80667
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:21
train iter: 81
num of updates: 8200
vae loss: 0.83156
kl loss: 0.03837
a decoder loss: 0.79319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:22
train iter: 82
num of updates: 8300
vae loss: 0.81415
kl loss: 0.03814
a decoder loss: 0.77601
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:23
train iter: 83
num of updates: 8400
vae loss: 0.79989
kl loss: 0.03787
a decoder loss: 0.76201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:24
train iter: 84
num of updates: 8500
vae loss: 0.78490
kl loss: 0.03744
a decoder loss: 0.74746
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:25
train iter: 85
num of updates: 8600
vae loss: 0.77138
kl loss: 0.03723
a decoder loss: 0.73414
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:26
train iter: 86
num of updates: 8700
vae loss: 0.75880
kl loss: 0.03697
a decoder loss: 0.72183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:27
train iter: 87
num of updates: 8800
vae loss: 0.74204
kl loss: 0.03659
a decoder loss: 0.70544
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:28
train iter: 88
num of updates: 8900
vae loss: 0.73010
kl loss: 0.03642
a decoder loss: 0.69368
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:29
train iter: 89
num of updates: 9000
vae loss: 0.71549
kl loss: 0.03603
a decoder loss: 0.67946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:30
train iter: 90
num of updates: 9100
vae loss: 0.70177
kl loss: 0.03577
a decoder loss: 0.66600
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:31
train iter: 91
num of updates: 9200
vae loss: 0.68917
kl loss: 0.03529
a decoder loss: 0.65388
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:32
train iter: 92
num of updates: 9300
vae loss: 0.67641
kl loss: 0.03494
a decoder loss: 0.64147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:33
train iter: 93
num of updates: 9400
vae loss: 0.66181
kl loss: 0.03454
a decoder loss: 0.62726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:34
train iter: 94
num of updates: 9500
vae loss: 0.64875
kl loss: 0.03423
a decoder loss: 0.61452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:35
train iter: 95
num of updates: 9600
vae loss: 0.64054
kl loss: 0.03360
a decoder loss: 0.60694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:36
train iter: 96
num of updates: 9700
vae loss: 0.62829
kl loss: 0.03325
a decoder loss: 0.59504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:37
train iter: 97
num of updates: 9800
vae loss: 0.61553
kl loss: 0.03282
a decoder loss: 0.58272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:38
train iter: 98
num of updates: 9900
vae loss: 0.60983
kl loss: 0.03266
a decoder loss: 0.57717
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:39
train iter: 99
num of updates: 10000
vae loss: 0.59623
kl loss: 0.03218
a decoder loss: 0.56405
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:40
train iter: 100
num of updates: 10100
vae loss: 0.58593
kl loss: 0.03180
a decoder loss: 0.55413
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:41
train iter: 101
num of updates: 10200
vae loss: 0.57731
kl loss: 0.03149
a decoder loss: 0.54583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:42
train iter: 102
num of updates: 10300
vae loss: 0.56611
kl loss: 0.03093
a decoder loss: 0.53518
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:43
train iter: 103
num of updates: 10400
vae loss: 0.55896
kl loss: 0.03056
a decoder loss: 0.52840
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:44
train iter: 104
num of updates: 10500
vae loss: 0.54751
kl loss: 0.03002
a decoder loss: 0.51749
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:45
train iter: 105
num of updates: 10600
vae loss: 0.53932
kl loss: 0.02957
a decoder loss: 0.50975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:46
train iter: 106
num of updates: 10700
vae loss: 0.53040
kl loss: 0.02923
a decoder loss: 0.50117
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:47
train iter: 107
num of updates: 10800
vae loss: 0.52362
kl loss: 0.02884
a decoder loss: 0.49478
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:48
train iter: 108
num of updates: 10900
vae loss: 0.51454
kl loss: 0.02842
a decoder loss: 0.48613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:49
train iter: 109
num of updates: 11000
vae loss: 0.50866
kl loss: 0.02786
a decoder loss: 0.48080
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:50
train iter: 110
num of updates: 11100
vae loss: 0.50401
kl loss: 0.02751
a decoder loss: 0.47650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:51
train iter: 111
num of updates: 11200
vae loss: 0.49260
kl loss: 0.02706
a decoder loss: 0.46554
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:52
train iter: 112
num of updates: 11300
vae loss: 0.48848
kl loss: 0.02669
a decoder loss: 0.46179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:53
train iter: 113
num of updates: 11400
vae loss: 0.48200
kl loss: 0.02618
a decoder loss: 0.45582
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:54
train iter: 114
num of updates: 11500
vae loss: 0.47525
kl loss: 0.02574
a decoder loss: 0.44951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:55
train iter: 115
num of updates: 11600
vae loss: 0.46944
kl loss: 0.02525
a decoder loss: 0.44418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:56
train iter: 116
num of updates: 11700
vae loss: 0.46435
kl loss: 0.02472
a decoder loss: 0.43963
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:57
train iter: 117
num of updates: 11800
vae loss: 0.45603
kl loss: 0.02421
a decoder loss: 0.43182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:58
train iter: 118
num of updates: 11900
vae loss: 0.45368
kl loss: 0.02383
a decoder loss: 0.42984
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:52:59
train iter: 119
num of updates: 12000
vae loss: 0.45040
kl loss: 0.02332
a decoder loss: 0.42708
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:00
train iter: 120
num of updates: 12100
vae loss: 0.44291
kl loss: 0.02286
a decoder loss: 0.42005
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:01
train iter: 121
num of updates: 12200
vae loss: 0.43666
kl loss: 0.02231
a decoder loss: 0.41435
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:02
train iter: 122
num of updates: 12300
vae loss: 0.43424
kl loss: 0.02182
a decoder loss: 0.41241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:03
train iter: 123
num of updates: 12400
vae loss: 0.42735
kl loss: 0.02132
a decoder loss: 0.40603
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:04
train iter: 124
num of updates: 12500
vae loss: 0.42316
kl loss: 0.02079
a decoder loss: 0.40238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:05
train iter: 125
num of updates: 12600
vae loss: 0.41754
kl loss: 0.02036
a decoder loss: 0.39717
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:06
train iter: 126
num of updates: 12700
vae loss: 0.41352
kl loss: 0.01987
a decoder loss: 0.39365
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:07
train iter: 127
num of updates: 12800
vae loss: 0.40920
kl loss: 0.01924
a decoder loss: 0.38996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:09
train iter: 128
num of updates: 12900
vae loss: 0.40400
kl loss: 0.01879
a decoder loss: 0.38521
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:10
train iter: 129
num of updates: 13000
vae loss: 0.40309
kl loss: 0.01843
a decoder loss: 0.38465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:11
train iter: 130
num of updates: 13100
vae loss: 0.39858
kl loss: 0.01788
a decoder loss: 0.38070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:12
train iter: 131
num of updates: 13200
vae loss: 0.39377
kl loss: 0.01749
a decoder loss: 0.37628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:13
train iter: 132
num of updates: 13300
vae loss: 0.39085
kl loss: 0.01706
a decoder loss: 0.37379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:14
train iter: 133
num of updates: 13400
vae loss: 0.38819
kl loss: 0.01659
a decoder loss: 0.37160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:15
train iter: 134
num of updates: 13500
vae loss: 0.38227
kl loss: 0.01605
a decoder loss: 0.36621
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:16
train iter: 135
num of updates: 13600
vae loss: 0.38004
kl loss: 0.01565
a decoder loss: 0.36439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:17
train iter: 136
num of updates: 13700
vae loss: 0.37500
kl loss: 0.01514
a decoder loss: 0.35986
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:18
train iter: 137
num of updates: 13800
vae loss: 0.37310
kl loss: 0.01472
a decoder loss: 0.35838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:19
train iter: 138
num of updates: 13900
vae loss: 0.36988
kl loss: 0.01433
a decoder loss: 0.35555
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:20
train iter: 139
num of updates: 14000
vae loss: 0.36811
kl loss: 0.01391
a decoder loss: 0.35420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:21
train iter: 140
num of updates: 14100
vae loss: 0.36542
kl loss: 0.01343
a decoder loss: 0.35199
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:22
train iter: 141
num of updates: 14200
vae loss: 0.35902
kl loss: 0.01300
a decoder loss: 0.34602
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:23
train iter: 142
num of updates: 14300
vae loss: 0.35718
kl loss: 0.01265
a decoder loss: 0.34453
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:24
train iter: 143
num of updates: 14400
vae loss: 0.35577
kl loss: 0.01230
a decoder loss: 0.34347
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:25
train iter: 144
num of updates: 14500
vae loss: 0.35411
kl loss: 0.01195
a decoder loss: 0.34216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:26
train iter: 145
num of updates: 14600
vae loss: 0.34877
kl loss: 0.01151
a decoder loss: 0.33726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:27
train iter: 146
num of updates: 14700
vae loss: 0.34760
kl loss: 0.01118
a decoder loss: 0.33642
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:28
train iter: 147
num of updates: 14800
vae loss: 0.34439
kl loss: 0.01080
a decoder loss: 0.33360
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:29
train iter: 148
num of updates: 14900
vae loss: 0.34325
kl loss: 0.01054
a decoder loss: 0.33271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:30
train iter: 149
num of updates: 15000
vae loss: 0.33994
kl loss: 0.01018
a decoder loss: 0.32976
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:31
train iter: 150
num of updates: 15100
vae loss: 0.33821
kl loss: 0.00981
a decoder loss: 0.32840
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:32
train iter: 151
num of updates: 15200
vae loss: 0.33475
kl loss: 0.00946
a decoder loss: 0.32529
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:33
train iter: 152
num of updates: 15300
vae loss: 0.33307
kl loss: 0.00918
a decoder loss: 0.32389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:34
train iter: 153
num of updates: 15400
vae loss: 0.33161
kl loss: 0.00890
a decoder loss: 0.32271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:35
train iter: 154
num of updates: 15500
vae loss: 0.32895
kl loss: 0.00859
a decoder loss: 0.32035
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:36
train iter: 155
num of updates: 15600
vae loss: 0.32666
kl loss: 0.00835
a decoder loss: 0.31832
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:37
train iter: 156
num of updates: 15700
vae loss: 0.32399
kl loss: 0.00803
a decoder loss: 0.31596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:38
train iter: 157
num of updates: 15800
vae loss: 0.32158
kl loss: 0.00778
a decoder loss: 0.31380
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:39
train iter: 158
num of updates: 15900
vae loss: 0.31925
kl loss: 0.00755
a decoder loss: 0.31170
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:40
train iter: 159
num of updates: 16000
vae loss: 0.31848
kl loss: 0.00730
a decoder loss: 0.31119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:41
train iter: 160
num of updates: 16100
vae loss: 0.31530
kl loss: 0.00707
a decoder loss: 0.30823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:42
train iter: 161
num of updates: 16200
vae loss: 0.31314
kl loss: 0.00681
a decoder loss: 0.30633
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:43
train iter: 162
num of updates: 16300
vae loss: 0.31125
kl loss: 0.00660
a decoder loss: 0.30465
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:44
train iter: 163
num of updates: 16400
vae loss: 0.31031
kl loss: 0.00638
a decoder loss: 0.30393
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:45
train iter: 164
num of updates: 16500
vae loss: 0.30974
kl loss: 0.00622
a decoder loss: 0.30352
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:46
train iter: 165
num of updates: 16600
vae loss: 0.30691
kl loss: 0.00602
a decoder loss: 0.30089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:47
train iter: 166
num of updates: 16700
vae loss: 0.30431
kl loss: 0.00585
a decoder loss: 0.29845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:48
train iter: 167
num of updates: 16800
vae loss: 0.30518
kl loss: 0.00568
a decoder loss: 0.29950
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:49
train iter: 168
num of updates: 16900
vae loss: 0.30151
kl loss: 0.00551
a decoder loss: 0.29600
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:50
train iter: 169
num of updates: 17000
vae loss: 0.30104
kl loss: 0.00536
a decoder loss: 0.29568
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:51
train iter: 170
num of updates: 17100
vae loss: 0.29864
kl loss: 0.00521
a decoder loss: 0.29344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:52
train iter: 171
num of updates: 17200
vae loss: 0.29798
kl loss: 0.00508
a decoder loss: 0.29289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:53
train iter: 172
num of updates: 17300
vae loss: 0.29586
kl loss: 0.00491
a decoder loss: 0.29095
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:54
train iter: 173
num of updates: 17400
vae loss: 0.29586
kl loss: 0.00479
a decoder loss: 0.29107
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:55
train iter: 174
num of updates: 17500
vae loss: 0.29491
kl loss: 0.00469
a decoder loss: 0.29022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:56
train iter: 175
num of updates: 17600
vae loss: 0.29175
kl loss: 0.00457
a decoder loss: 0.28719
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:57
train iter: 176
num of updates: 17700
vae loss: 0.29156
kl loss: 0.00443
a decoder loss: 0.28712
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:58
train iter: 177
num of updates: 17800
vae loss: 0.29017
kl loss: 0.00434
a decoder loss: 0.28583
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:53:59
train iter: 178
num of updates: 17900
vae loss: 0.28919
kl loss: 0.00426
a decoder loss: 0.28493
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:00
train iter: 179
num of updates: 18000
vae loss: 0.28695
kl loss: 0.00417
a decoder loss: 0.28279
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:01
train iter: 180
num of updates: 18100
vae loss: 0.28689
kl loss: 0.00407
a decoder loss: 0.28283
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:02
train iter: 181
num of updates: 18200
vae loss: 0.28536
kl loss: 0.00398
a decoder loss: 0.28137
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:03
train iter: 182
num of updates: 18300
vae loss: 0.28247
kl loss: 0.00386
a decoder loss: 0.27860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:04
train iter: 183
num of updates: 18400
vae loss: 0.28325
kl loss: 0.00383
a decoder loss: 0.27941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:05
train iter: 184
num of updates: 18500
vae loss: 0.28201
kl loss: 0.00374
a decoder loss: 0.27827
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:06
train iter: 185
num of updates: 18600
vae loss: 0.28087
kl loss: 0.00367
a decoder loss: 0.27720
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:07
train iter: 186
num of updates: 18700
vae loss: 0.28024
kl loss: 0.00361
a decoder loss: 0.27662
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:08
train iter: 187
num of updates: 18800
vae loss: 0.27760
kl loss: 0.00353
a decoder loss: 0.27407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:09
train iter: 188
num of updates: 18900
vae loss: 0.27587
kl loss: 0.00347
a decoder loss: 0.27240
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:10
train iter: 189
num of updates: 19000
vae loss: 0.27627
kl loss: 0.00341
a decoder loss: 0.27286
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:11
train iter: 190
num of updates: 19100
vae loss: 0.27627
kl loss: 0.00334
a decoder loss: 0.27293
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:13
train iter: 191
num of updates: 19200
vae loss: 0.27446
kl loss: 0.00328
a decoder loss: 0.27118
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:14
train iter: 192
num of updates: 19300
vae loss: 0.27403
kl loss: 0.00323
a decoder loss: 0.27079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:15
train iter: 193
num of updates: 19400
vae loss: 0.27143
kl loss: 0.00317
a decoder loss: 0.26826
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:16
train iter: 194
num of updates: 19500
vae loss: 0.27173
kl loss: 0.00313
a decoder loss: 0.26860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:17
train iter: 195
num of updates: 19600
vae loss: 0.27076
kl loss: 0.00308
a decoder loss: 0.26768
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:18
train iter: 196
num of updates: 19700
vae loss: 0.26907
kl loss: 0.00301
a decoder loss: 0.26606
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:19
train iter: 197
num of updates: 19800
vae loss: 0.26969
kl loss: 0.00297
a decoder loss: 0.26673
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:20
train iter: 198
num of updates: 19900
vae loss: 0.26875
kl loss: 0.00291
a decoder loss: 0.26584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:21
train iter: 199
num of updates: 20000
vae loss: 0.26645
kl loss: 0.00286
a decoder loss: 0.26359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:22
train iter: 200
num of updates: 20100
vae loss: 0.26657
kl loss: 0.00282
a decoder loss: 0.26375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:23
train iter: 201
num of updates: 20200
vae loss: 0.26547
kl loss: 0.00277
a decoder loss: 0.26269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:24
train iter: 202
num of updates: 20300
vae loss: 0.26546
kl loss: 0.00273
a decoder loss: 0.26273
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:25
train iter: 203
num of updates: 20400
vae loss: 0.26354
kl loss: 0.00268
a decoder loss: 0.26086
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:26
train iter: 204
num of updates: 20500
vae loss: 0.26386
kl loss: 0.00265
a decoder loss: 0.26121
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:27
train iter: 205
num of updates: 20600
vae loss: 0.26253
kl loss: 0.00260
a decoder loss: 0.25992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:28
train iter: 206
num of updates: 20700
vae loss: 0.26318
kl loss: 0.00257
a decoder loss: 0.26061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:29
train iter: 207
num of updates: 20800
vae loss: 0.26017
kl loss: 0.00252
a decoder loss: 0.25765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:30
train iter: 208
num of updates: 20900
vae loss: 0.25936
kl loss: 0.00249
a decoder loss: 0.25687
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:31
train iter: 209
num of updates: 21000
vae loss: 0.25980
kl loss: 0.00245
a decoder loss: 0.25735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:32
train iter: 210
num of updates: 21100
vae loss: 0.25971
kl loss: 0.00241
a decoder loss: 0.25730
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:33
train iter: 211
num of updates: 21200
vae loss: 0.25889
kl loss: 0.00238
a decoder loss: 0.25651
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:34
train iter: 212
num of updates: 21300
vae loss: 0.25810
kl loss: 0.00233
a decoder loss: 0.25577
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:35
train iter: 213
num of updates: 21400
vae loss: 0.25799
kl loss: 0.00230
a decoder loss: 0.25569
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:36
train iter: 214
num of updates: 21500
vae loss: 0.25614
kl loss: 0.00226
a decoder loss: 0.25389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:37
train iter: 215
num of updates: 21600
vae loss: 0.25611
kl loss: 0.00223
a decoder loss: 0.25388
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:38
train iter: 216
num of updates: 21700
vae loss: 0.25627
kl loss: 0.00220
a decoder loss: 0.25407
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:39
train iter: 217
num of updates: 21800
vae loss: 0.25588
kl loss: 0.00215
a decoder loss: 0.25372
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:40
train iter: 218
num of updates: 21900
vae loss: 0.25374
kl loss: 0.00213
a decoder loss: 0.25162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:41
train iter: 219
num of updates: 22000
vae loss: 0.25370
kl loss: 0.00210
a decoder loss: 0.25160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:42
train iter: 220
num of updates: 22100
vae loss: 0.25390
kl loss: 0.00207
a decoder loss: 0.25183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:43
train iter: 221
num of updates: 22200
vae loss: 0.25293
kl loss: 0.00205
a decoder loss: 0.25088
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:44
train iter: 222
num of updates: 22300
vae loss: 0.25072
kl loss: 0.00201
a decoder loss: 0.24872
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:45
train iter: 223
num of updates: 22400
vae loss: 0.25212
kl loss: 0.00198
a decoder loss: 0.25014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:46
train iter: 224
num of updates: 22500
vae loss: 0.25201
kl loss: 0.00196
a decoder loss: 0.25005
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:47
train iter: 225
num of updates: 22600
vae loss: 0.25123
kl loss: 0.00193
a decoder loss: 0.24930
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:48
train iter: 226
num of updates: 22700
vae loss: 0.25051
kl loss: 0.00190
a decoder loss: 0.24861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:49
train iter: 227
num of updates: 22800
vae loss: 0.24963
kl loss: 0.00187
a decoder loss: 0.24776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:50
train iter: 228
num of updates: 22900
vae loss: 0.24888
kl loss: 0.00185
a decoder loss: 0.24703
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:51
train iter: 229
num of updates: 23000
vae loss: 0.24795
kl loss: 0.00182
a decoder loss: 0.24613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:52
train iter: 230
num of updates: 23100
vae loss: 0.24838
kl loss: 0.00181
a decoder loss: 0.24658
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:53
train iter: 231
num of updates: 23200
vae loss: 0.24793
kl loss: 0.00178
a decoder loss: 0.24615
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:54
train iter: 232
num of updates: 23300
vae loss: 0.24766
kl loss: 0.00175
a decoder loss: 0.24591
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:55
train iter: 233
num of updates: 23400
vae loss: 0.24655
kl loss: 0.00172
a decoder loss: 0.24482
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:56
train iter: 234
num of updates: 23500
vae loss: 0.24718
kl loss: 0.00170
a decoder loss: 0.24548
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:57
train iter: 235
num of updates: 23600
vae loss: 0.24539
kl loss: 0.00168
a decoder loss: 0.24371
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:58
train iter: 236
num of updates: 23700
vae loss: 0.24542
kl loss: 0.00165
a decoder loss: 0.24376
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:54:59
train iter: 237
num of updates: 23800
vae loss: 0.24532
kl loss: 0.00163
a decoder loss: 0.24368
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:00
train iter: 238
num of updates: 23900
vae loss: 0.24323
kl loss: 0.00160
a decoder loss: 0.24163
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:01
train iter: 239
num of updates: 24000
vae loss: 0.24368
kl loss: 0.00158
a decoder loss: 0.24210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:02
train iter: 240
num of updates: 24100
vae loss: 0.24378
kl loss: 0.00157
a decoder loss: 0.24221
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:03
train iter: 241
num of updates: 24200
vae loss: 0.24334
kl loss: 0.00155
a decoder loss: 0.24179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:04
train iter: 242
num of updates: 24300
vae loss: 0.24332
kl loss: 0.00153
a decoder loss: 0.24179
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:05
train iter: 243
num of updates: 24400
vae loss: 0.24289
kl loss: 0.00151
a decoder loss: 0.24138
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:06
train iter: 244
num of updates: 24500
vae loss: 0.24163
kl loss: 0.00149
a decoder loss: 0.24014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:07
train iter: 245
num of updates: 24600
vae loss: 0.24159
kl loss: 0.00147
a decoder loss: 0.24012
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:08
train iter: 246
num of updates: 24700
vae loss: 0.24159
kl loss: 0.00145
a decoder loss: 0.24014
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:09
train iter: 247
num of updates: 24800
vae loss: 0.24167
kl loss: 0.00144
a decoder loss: 0.24023
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:10
train iter: 248
num of updates: 24900
vae loss: 0.24134
kl loss: 0.00141
a decoder loss: 0.23992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:11
train iter: 249
num of updates: 25000
vae loss: 0.24031
kl loss: 0.00140
a decoder loss: 0.23891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:12
train iter: 250
num of updates: 25100
vae loss: 0.23919
kl loss: 0.00137
a decoder loss: 0.23782
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:13
train iter: 251
num of updates: 25200
vae loss: 0.23875
kl loss: 0.00136
a decoder loss: 0.23739
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:14
train iter: 252
num of updates: 25300
vae loss: 0.24018
kl loss: 0.00135
a decoder loss: 0.23883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:15
train iter: 253
num of updates: 25400
vae loss: 0.23941
kl loss: 0.00133
a decoder loss: 0.23809
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:16
train iter: 254
num of updates: 25500
vae loss: 0.23848
kl loss: 0.00133
a decoder loss: 0.23715
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:17
train iter: 255
num of updates: 25600
vae loss: 0.23954
kl loss: 0.00129
a decoder loss: 0.23825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:18
train iter: 256
num of updates: 25700
vae loss: 0.23674
kl loss: 0.00129
a decoder loss: 0.23546
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:19
train iter: 257
num of updates: 25800
vae loss: 0.23783
kl loss: 0.00127
a decoder loss: 0.23656
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:21
train iter: 258
num of updates: 25900
vae loss: 0.23790
kl loss: 0.00125
a decoder loss: 0.23665
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:22
train iter: 259
num of updates: 26000
vae loss: 0.23683
kl loss: 0.00124
a decoder loss: 0.23560
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:23
train iter: 260
num of updates: 26100
vae loss: 0.23597
kl loss: 0.00123
a decoder loss: 0.23474
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:24
train iter: 261
num of updates: 26200
vae loss: 0.23589
kl loss: 0.00121
a decoder loss: 0.23468
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:25
train iter: 262
num of updates: 26300
vae loss: 0.23645
kl loss: 0.00120
a decoder loss: 0.23525
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:26
train iter: 263
num of updates: 26400
vae loss: 0.23563
kl loss: 0.00119
a decoder loss: 0.23445
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:27
train iter: 264
num of updates: 26500
vae loss: 0.23589
kl loss: 0.00116
a decoder loss: 0.23473
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:28
train iter: 265
num of updates: 26600
vae loss: 0.23679
kl loss: 0.00115
a decoder loss: 0.23564
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:29
train iter: 266
num of updates: 26700
vae loss: 0.23523
kl loss: 0.00114
a decoder loss: 0.23408
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:30
train iter: 267
num of updates: 26800
vae loss: 0.23556
kl loss: 0.00113
a decoder loss: 0.23443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:31
train iter: 268
num of updates: 26900
vae loss: 0.23550
kl loss: 0.00112
a decoder loss: 0.23438
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:32
train iter: 269
num of updates: 27000
vae loss: 0.23521
kl loss: 0.00110
a decoder loss: 0.23410
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:33
train iter: 270
num of updates: 27100
vae loss: 0.23366
kl loss: 0.00109
a decoder loss: 0.23257
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:34
train iter: 271
num of updates: 27200
vae loss: 0.23405
kl loss: 0.00108
a decoder loss: 0.23297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:35
train iter: 272
num of updates: 27300
vae loss: 0.23402
kl loss: 0.00107
a decoder loss: 0.23296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:36
train iter: 273
num of updates: 27400
vae loss: 0.23354
kl loss: 0.00105
a decoder loss: 0.23249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:37
train iter: 274
num of updates: 27500
vae loss: 0.23309
kl loss: 0.00105
a decoder loss: 0.23204
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:38
train iter: 275
num of updates: 27600
vae loss: 0.23358
kl loss: 0.00103
a decoder loss: 0.23255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:39
train iter: 276
num of updates: 27700
vae loss: 0.23374
kl loss: 0.00102
a decoder loss: 0.23272
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:40
train iter: 277
num of updates: 27800
vae loss: 0.23241
kl loss: 0.00100
a decoder loss: 0.23141
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:41
train iter: 278
num of updates: 27900
vae loss: 0.23221
kl loss: 0.00099
a decoder loss: 0.23122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:42
train iter: 279
num of updates: 28000
vae loss: 0.23219
kl loss: 0.00100
a decoder loss: 0.23119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:43
train iter: 280
num of updates: 28100
vae loss: 0.23192
kl loss: 0.00097
a decoder loss: 0.23094
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:44
train iter: 281
num of updates: 28200
vae loss: 0.23166
kl loss: 0.00096
a decoder loss: 0.23070
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:45
train iter: 282
num of updates: 28300
vae loss: 0.23187
kl loss: 0.00097
a decoder loss: 0.23091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:46
train iter: 283
num of updates: 28400
vae loss: 0.23039
kl loss: 0.00094
a decoder loss: 0.22944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:47
train iter: 284
num of updates: 28500
vae loss: 0.23053
kl loss: 0.00094
a decoder loss: 0.22959
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:48
train iter: 285
num of updates: 28600
vae loss: 0.23080
kl loss: 0.00093
a decoder loss: 0.22987
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:49
train iter: 286
num of updates: 28700
vae loss: 0.23120
kl loss: 0.00092
a decoder loss: 0.23029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:50
train iter: 287
num of updates: 28800
vae loss: 0.22921
kl loss: 0.00091
a decoder loss: 0.22831
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:51
train iter: 288
num of updates: 28900
vae loss: 0.23013
kl loss: 0.00090
a decoder loss: 0.22923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:52
train iter: 289
num of updates: 29000
vae loss: 0.23088
kl loss: 0.00089
a decoder loss: 0.22998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:53
train iter: 290
num of updates: 29100
vae loss: 0.23003
kl loss: 0.00088
a decoder loss: 0.22915
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:54
train iter: 291
num of updates: 29200
vae loss: 0.22948
kl loss: 0.00088
a decoder loss: 0.22860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:55
train iter: 292
num of updates: 29300
vae loss: 0.22931
kl loss: 0.00086
a decoder loss: 0.22845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:56
train iter: 293
num of updates: 29400
vae loss: 0.22907
kl loss: 0.00086
a decoder loss: 0.22821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:57
train iter: 294
num of updates: 29500
vae loss: 0.22936
kl loss: 0.00085
a decoder loss: 0.22851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:58
train iter: 295
num of updates: 29600
vae loss: 0.22920
kl loss: 0.00084
a decoder loss: 0.22836
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:55:59
train iter: 296
num of updates: 29700
vae loss: 0.22864
kl loss: 0.00083
a decoder loss: 0.22782
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:00
train iter: 297
num of updates: 29800
vae loss: 0.22826
kl loss: 0.00082
a decoder loss: 0.22744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:01
train iter: 298
num of updates: 29900
vae loss: 0.22794
kl loss: 0.00081
a decoder loss: 0.22713
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:02
train iter: 299
num of updates: 30000
vae loss: 0.22701
kl loss: 0.00081
a decoder loss: 0.22620
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:03
train iter: 300
num of updates: 30100
vae loss: 0.22845
kl loss: 0.00080
a decoder loss: 0.22765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:04
train iter: 301
num of updates: 30200
vae loss: 0.22917
kl loss: 0.00079
a decoder loss: 0.22837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:05
train iter: 302
num of updates: 30300
vae loss: 0.22764
kl loss: 0.00078
a decoder loss: 0.22685
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:06
train iter: 303
num of updates: 30400
vae loss: 0.22779
kl loss: 0.00078
a decoder loss: 0.22701
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:07
train iter: 304
num of updates: 30500
vae loss: 0.22803
kl loss: 0.00077
a decoder loss: 0.22726
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:08
train iter: 305
num of updates: 30600
vae loss: 0.22770
kl loss: 0.00076
a decoder loss: 0.22694
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:09
train iter: 306
num of updates: 30700
vae loss: 0.22710
kl loss: 0.00075
a decoder loss: 0.22635
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:10
train iter: 307
num of updates: 30800
vae loss: 0.22651
kl loss: 0.00075
a decoder loss: 0.22576
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:11
train iter: 308
num of updates: 30900
vae loss: 0.22662
kl loss: 0.00074
a decoder loss: 0.22588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:12
train iter: 309
num of updates: 31000
vae loss: 0.22690
kl loss: 0.00073
a decoder loss: 0.22616
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:13
train iter: 310
num of updates: 31100
vae loss: 0.22704
kl loss: 0.00072
a decoder loss: 0.22631
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:14
train iter: 311
num of updates: 31200
vae loss: 0.22661
kl loss: 0.00072
a decoder loss: 0.22589
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:15
train iter: 312
num of updates: 31300
vae loss: 0.22671
kl loss: 0.00072
a decoder loss: 0.22599
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:16
train iter: 313
num of updates: 31400
vae loss: 0.22620
kl loss: 0.00071
a decoder loss: 0.22549
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:17
train iter: 314
num of updates: 31500
vae loss: 0.22594
kl loss: 0.00071
a decoder loss: 0.22524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:18
train iter: 315
num of updates: 31600
vae loss: 0.22622
kl loss: 0.00070
a decoder loss: 0.22552
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:19
train iter: 316
num of updates: 31700
vae loss: 0.22589
kl loss: 0.00069
a decoder loss: 0.22520
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:21
train iter: 317
num of updates: 31800
vae loss: 0.22634
kl loss: 0.00068
a decoder loss: 0.22566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:22
train iter: 318
num of updates: 31900
vae loss: 0.22490
kl loss: 0.00068
a decoder loss: 0.22422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:23
train iter: 319
num of updates: 32000
vae loss: 0.22576
kl loss: 0.00067
a decoder loss: 0.22509
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:24
train iter: 320
num of updates: 32100
vae loss: 0.22557
kl loss: 0.00067
a decoder loss: 0.22490
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:25
train iter: 321
num of updates: 32200
vae loss: 0.22574
kl loss: 0.00067
a decoder loss: 0.22507
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:26
train iter: 322
num of updates: 32300
vae loss: 0.22519
kl loss: 0.00066
a decoder loss: 0.22454
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:27
train iter: 323
num of updates: 32400
vae loss: 0.22568
kl loss: 0.00065
a decoder loss: 0.22503
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:28
train iter: 324
num of updates: 32500
vae loss: 0.22466
kl loss: 0.00065
a decoder loss: 0.22401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:29
train iter: 325
num of updates: 32600
vae loss: 0.22467
kl loss: 0.00064
a decoder loss: 0.22403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:30
train iter: 326
num of updates: 32700
vae loss: 0.22526
kl loss: 0.00063
a decoder loss: 0.22462
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:31
train iter: 327
num of updates: 32800
vae loss: 0.22495
kl loss: 0.00063
a decoder loss: 0.22432
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:32
train iter: 328
num of updates: 32900
vae loss: 0.22464
kl loss: 0.00063
a decoder loss: 0.22401
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:33
train iter: 329
num of updates: 33000
vae loss: 0.22460
kl loss: 0.00062
a decoder loss: 0.22398
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:34
train iter: 330
num of updates: 33100
vae loss: 0.22375
kl loss: 0.00062
a decoder loss: 0.22313
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:35
train iter: 331
num of updates: 33200
vae loss: 0.22430
kl loss: 0.00061
a decoder loss: 0.22369
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:36
train iter: 332
num of updates: 33300
vae loss: 0.22353
kl loss: 0.00060
a decoder loss: 0.22293
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:37
train iter: 333
num of updates: 33400
vae loss: 0.22346
kl loss: 0.00060
a decoder loss: 0.22286
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:38
train iter: 334
num of updates: 33500
vae loss: 0.22412
kl loss: 0.00059
a decoder loss: 0.22353
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:39
train iter: 335
num of updates: 33600
vae loss: 0.22276
kl loss: 0.00059
a decoder loss: 0.22217
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:40
train iter: 336
num of updates: 33700
vae loss: 0.22312
kl loss: 0.00058
a decoder loss: 0.22254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:41
train iter: 337
num of updates: 33800
vae loss: 0.22264
kl loss: 0.00058
a decoder loss: 0.22206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:42
train iter: 338
num of updates: 33900
vae loss: 0.22377
kl loss: 0.00057
a decoder loss: 0.22319
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:43
train iter: 339
num of updates: 34000
vae loss: 0.22405
kl loss: 0.00057
a decoder loss: 0.22347
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:44
train iter: 340
num of updates: 34100
vae loss: 0.22300
kl loss: 0.00057
a decoder loss: 0.22244
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:45
train iter: 341
num of updates: 34200
vae loss: 0.22358
kl loss: 0.00056
a decoder loss: 0.22302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:46
train iter: 342
num of updates: 34300
vae loss: 0.22336
kl loss: 0.00056
a decoder loss: 0.22280
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:47
train iter: 343
num of updates: 34400
vae loss: 0.22318
kl loss: 0.00055
a decoder loss: 0.22263
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:48
train iter: 344
num of updates: 34500
vae loss: 0.22252
kl loss: 0.00055
a decoder loss: 0.22197
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:49
train iter: 345
num of updates: 34600
vae loss: 0.22338
kl loss: 0.00054
a decoder loss: 0.22284
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:50
train iter: 346
num of updates: 34700
vae loss: 0.22176
kl loss: 0.00054
a decoder loss: 0.22122
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:51
train iter: 347
num of updates: 34800
vae loss: 0.22219
kl loss: 0.00054
a decoder loss: 0.22165
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:52
train iter: 348
num of updates: 34900
vae loss: 0.22269
kl loss: 0.00054
a decoder loss: 0.22215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:53
train iter: 349
num of updates: 35000
vae loss: 0.22219
kl loss: 0.00053
a decoder loss: 0.22166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:54
train iter: 350
num of updates: 35100
vae loss: 0.22272
kl loss: 0.00053
a decoder loss: 0.22219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:55
train iter: 351
num of updates: 35200
vae loss: 0.22153
kl loss: 0.00052
a decoder loss: 0.22101
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:56
train iter: 352
num of updates: 35300
vae loss: 0.22189
kl loss: 0.00052
a decoder loss: 0.22137
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:57
train iter: 353
num of updates: 35400
vae loss: 0.22200
kl loss: 0.00051
a decoder loss: 0.22149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:58
train iter: 354
num of updates: 35500
vae loss: 0.22234
kl loss: 0.00051
a decoder loss: 0.22183
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:56:59
train iter: 355
num of updates: 35600
vae loss: 0.22072
kl loss: 0.00051
a decoder loss: 0.22021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:00
train iter: 356
num of updates: 35700
vae loss: 0.22202
kl loss: 0.00051
a decoder loss: 0.22152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:01
train iter: 357
num of updates: 35800
vae loss: 0.22052
kl loss: 0.00050
a decoder loss: 0.22002
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:02
train iter: 358
num of updates: 35900
vae loss: 0.22208
kl loss: 0.00050
a decoder loss: 0.22158
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:03
train iter: 359
num of updates: 36000
vae loss: 0.22179
kl loss: 0.00050
a decoder loss: 0.22130
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:04
train iter: 360
num of updates: 36100
vae loss: 0.21965
kl loss: 0.00049
a decoder loss: 0.21916
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:05
train iter: 361
num of updates: 36200
vae loss: 0.22120
kl loss: 0.00049
a decoder loss: 0.22072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:06
train iter: 362
num of updates: 36300
vae loss: 0.22137
kl loss: 0.00048
a decoder loss: 0.22089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:07
train iter: 363
num of updates: 36400
vae loss: 0.22029
kl loss: 0.00048
a decoder loss: 0.21981
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:08
train iter: 364
num of updates: 36500
vae loss: 0.22131
kl loss: 0.00047
a decoder loss: 0.22084
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:09
train iter: 365
num of updates: 36600
vae loss: 0.22116
kl loss: 0.00047
a decoder loss: 0.22069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:10
train iter: 366
num of updates: 36700
vae loss: 0.22092
kl loss: 0.00046
a decoder loss: 0.22045
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:11
train iter: 367
num of updates: 36800
vae loss: 0.22124
kl loss: 0.00047
a decoder loss: 0.22077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:12
train iter: 368
num of updates: 36900
vae loss: 0.22091
kl loss: 0.00047
a decoder loss: 0.22044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:13
train iter: 369
num of updates: 37000
vae loss: 0.22088
kl loss: 0.00046
a decoder loss: 0.22042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:14
train iter: 370
num of updates: 37100
vae loss: 0.22002
kl loss: 0.00046
a decoder loss: 0.21956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:15
train iter: 371
num of updates: 37200
vae loss: 0.22085
kl loss: 0.00045
a decoder loss: 0.22039
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:16
train iter: 372
num of updates: 37300
vae loss: 0.22106
kl loss: 0.00045
a decoder loss: 0.22061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:17
train iter: 373
num of updates: 37400
vae loss: 0.22107
kl loss: 0.00045
a decoder loss: 0.22062
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:18
train iter: 374
num of updates: 37500
vae loss: 0.21929
kl loss: 0.00045
a decoder loss: 0.21885
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:19
train iter: 375
num of updates: 37600
vae loss: 0.22051
kl loss: 0.00044
a decoder loss: 0.22007
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:20
train iter: 376
num of updates: 37700
vae loss: 0.22033
kl loss: 0.00044
a decoder loss: 0.21989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:21
train iter: 377
num of updates: 37800
vae loss: 0.21994
kl loss: 0.00043
a decoder loss: 0.21950
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:22
train iter: 378
num of updates: 37900
vae loss: 0.22009
kl loss: 0.00043
a decoder loss: 0.21965
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:23
train iter: 379
num of updates: 38000
vae loss: 0.21931
kl loss: 0.00043
a decoder loss: 0.21888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:24
train iter: 380
num of updates: 38100
vae loss: 0.22080
kl loss: 0.00043
a decoder loss: 0.22037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:25
train iter: 381
num of updates: 38200
vae loss: 0.22011
kl loss: 0.00043
a decoder loss: 0.21968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:26
train iter: 382
num of updates: 38300
vae loss: 0.21934
kl loss: 0.00042
a decoder loss: 0.21892
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:27
train iter: 383
num of updates: 38400
vae loss: 0.21893
kl loss: 0.00042
a decoder loss: 0.21851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:28
train iter: 384
num of updates: 38500
vae loss: 0.22027
kl loss: 0.00042
a decoder loss: 0.21985
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:30
train iter: 385
num of updates: 38600
vae loss: 0.21961
kl loss: 0.00041
a decoder loss: 0.21920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:31
train iter: 386
num of updates: 38700
vae loss: 0.21862
kl loss: 0.00041
a decoder loss: 0.21821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:32
train iter: 387
num of updates: 38800
vae loss: 0.21870
kl loss: 0.00041
a decoder loss: 0.21829
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:33
train iter: 388
num of updates: 38900
vae loss: 0.21932
kl loss: 0.00041
a decoder loss: 0.21891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:34
train iter: 389
num of updates: 39000
vae loss: 0.22007
kl loss: 0.00040
a decoder loss: 0.21967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:35
train iter: 390
num of updates: 39100
vae loss: 0.21870
kl loss: 0.00040
a decoder loss: 0.21830
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:36
train iter: 391
num of updates: 39200
vae loss: 0.21878
kl loss: 0.00040
a decoder loss: 0.21838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:37
train iter: 392
num of updates: 39300
vae loss: 0.21793
kl loss: 0.00040
a decoder loss: 0.21753
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:38
train iter: 393
num of updates: 39400
vae loss: 0.21886
kl loss: 0.00039
a decoder loss: 0.21847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:39
train iter: 394
num of updates: 39500
vae loss: 0.21815
kl loss: 0.00039
a decoder loss: 0.21776
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:40
train iter: 395
num of updates: 39600
vae loss: 0.21867
kl loss: 0.00039
a decoder loss: 0.21828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:41
train iter: 396
num of updates: 39700
vae loss: 0.21835
kl loss: 0.00039
a decoder loss: 0.21796
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:42
train iter: 397
num of updates: 39800
vae loss: 0.21888
kl loss: 0.00039
a decoder loss: 0.21849
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:43
train iter: 398
num of updates: 39900
vae loss: 0.21761
kl loss: 0.00038
a decoder loss: 0.21723
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:44
train iter: 399
num of updates: 40000
vae loss: 0.21816
kl loss: 0.00038
a decoder loss: 0.21778
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:45
train iter: 400
num of updates: 40100
vae loss: 0.21852
kl loss: 0.00038
a decoder loss: 0.21814
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:46
train iter: 401
num of updates: 40200
vae loss: 0.21856
kl loss: 0.00037
a decoder loss: 0.21818
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:47
train iter: 402
num of updates: 40300
vae loss: 0.21809
kl loss: 0.00037
a decoder loss: 0.21772
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:48
train iter: 403
num of updates: 40400
vae loss: 0.21800
kl loss: 0.00037
a decoder loss: 0.21763
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:49
train iter: 404
num of updates: 40500
vae loss: 0.21771
kl loss: 0.00037
a decoder loss: 0.21734
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:50
train iter: 405
num of updates: 40600
vae loss: 0.21829
kl loss: 0.00037
a decoder loss: 0.21792
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:51
train iter: 406
num of updates: 40700
vae loss: 0.21833
kl loss: 0.00037
a decoder loss: 0.21796
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:52
train iter: 407
num of updates: 40800
vae loss: 0.21857
kl loss: 0.00036
a decoder loss: 0.21820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:53
train iter: 408
num of updates: 40900
vae loss: 0.21773
kl loss: 0.00036
a decoder loss: 0.21737
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:54
train iter: 409
num of updates: 41000
vae loss: 0.21781
kl loss: 0.00036
a decoder loss: 0.21745
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:55
train iter: 410
num of updates: 41100
vae loss: 0.21763
kl loss: 0.00036
a decoder loss: 0.21728
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:56
train iter: 411
num of updates: 41200
vae loss: 0.21863
kl loss: 0.00036
a decoder loss: 0.21828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:57
train iter: 412
num of updates: 41300
vae loss: 0.21791
kl loss: 0.00035
a decoder loss: 0.21756
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:58
train iter: 413
num of updates: 41400
vae loss: 0.21622
kl loss: 0.00035
a decoder loss: 0.21587
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:57:59
train iter: 414
num of updates: 41500
vae loss: 0.21740
kl loss: 0.00035
a decoder loss: 0.21705
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:00
train iter: 415
num of updates: 41600
vae loss: 0.21823
kl loss: 0.00035
a decoder loss: 0.21788
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:01
train iter: 416
num of updates: 41700
vae loss: 0.21741
kl loss: 0.00034
a decoder loss: 0.21707
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:02
train iter: 417
num of updates: 41800
vae loss: 0.21707
kl loss: 0.00034
a decoder loss: 0.21673
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:03
train iter: 418
num of updates: 41900
vae loss: 0.21769
kl loss: 0.00034
a decoder loss: 0.21735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:04
train iter: 419
num of updates: 42000
vae loss: 0.21763
kl loss: 0.00034
a decoder loss: 0.21729
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:05
train iter: 420
num of updates: 42100
vae loss: 0.21750
kl loss: 0.00034
a decoder loss: 0.21716
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:06
train iter: 421
num of updates: 42200
vae loss: 0.21884
kl loss: 0.00034
a decoder loss: 0.21851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:07
train iter: 422
num of updates: 42300
vae loss: 0.21782
kl loss: 0.00033
a decoder loss: 0.21749
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:08
train iter: 423
num of updates: 42400
vae loss: 0.21635
kl loss: 0.00033
a decoder loss: 0.21602
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:09
train iter: 424
num of updates: 42500
vae loss: 0.21744
kl loss: 0.00033
a decoder loss: 0.21711
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:10
train iter: 425
num of updates: 42600
vae loss: 0.21754
kl loss: 0.00033
a decoder loss: 0.21721
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:11
train iter: 426
num of updates: 42700
vae loss: 0.21661
kl loss: 0.00033
a decoder loss: 0.21628
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:12
train iter: 427
num of updates: 42800
vae loss: 0.21705
kl loss: 0.00032
a decoder loss: 0.21672
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:13
train iter: 428
num of updates: 42900
vae loss: 0.21767
kl loss: 0.00032
a decoder loss: 0.21735
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:14
train iter: 429
num of updates: 43000
vae loss: 0.21713
kl loss: 0.00032
a decoder loss: 0.21681
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:15
train iter: 430
num of updates: 43100
vae loss: 0.21599
kl loss: 0.00032
a decoder loss: 0.21566
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:16
train iter: 431
num of updates: 43200
vae loss: 0.21639
kl loss: 0.00032
a decoder loss: 0.21607
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:17
train iter: 432
num of updates: 43300
vae loss: 0.21658
kl loss: 0.00032
a decoder loss: 0.21626
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:18
train iter: 433
num of updates: 43400
vae loss: 0.21649
kl loss: 0.00032
a decoder loss: 0.21617
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:19
train iter: 434
num of updates: 43500
vae loss: 0.21694
kl loss: 0.00031
a decoder loss: 0.21663
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:20
train iter: 435
num of updates: 43600
vae loss: 0.21621
kl loss: 0.00031
a decoder loss: 0.21590
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:21
train iter: 436
num of updates: 43700
vae loss: 0.21675
kl loss: 0.00031
a decoder loss: 0.21644
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:22
train iter: 437
num of updates: 43800
vae loss: 0.21705
kl loss: 0.00031
a decoder loss: 0.21674
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:23
train iter: 438
num of updates: 43900
vae loss: 0.21728
kl loss: 0.00031
a decoder loss: 0.21697
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:24
train iter: 439
num of updates: 44000
vae loss: 0.21644
kl loss: 0.00031
a decoder loss: 0.21613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:25
train iter: 440
num of updates: 44100
vae loss: 0.21681
kl loss: 0.00031
a decoder loss: 0.21650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:26
train iter: 441
num of updates: 44200
vae loss: 0.21688
kl loss: 0.00030
a decoder loss: 0.21658
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:27
train iter: 442
num of updates: 44300
vae loss: 0.21579
kl loss: 0.00030
a decoder loss: 0.21549
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:28
train iter: 443
num of updates: 44400
vae loss: 0.21710
kl loss: 0.00030
a decoder loss: 0.21679
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:29
train iter: 444
num of updates: 44500
vae loss: 0.21601
kl loss: 0.00030
a decoder loss: 0.21571
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:30
train iter: 445
num of updates: 44600
vae loss: 0.21680
kl loss: 0.00030
a decoder loss: 0.21650
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:31
train iter: 446
num of updates: 44700
vae loss: 0.21607
kl loss: 0.00030
a decoder loss: 0.21577
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:32
train iter: 447
num of updates: 44800
vae loss: 0.21717
kl loss: 0.00029
a decoder loss: 0.21688
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:34
train iter: 448
num of updates: 44900
vae loss: 0.21643
kl loss: 0.00029
a decoder loss: 0.21613
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:35
train iter: 449
num of updates: 45000
vae loss: 0.21715
kl loss: 0.00029
a decoder loss: 0.21686
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:36
train iter: 450
num of updates: 45100
vae loss: 0.21619
kl loss: 0.00029
a decoder loss: 0.21590
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:37
train iter: 451
num of updates: 45200
vae loss: 0.21613
kl loss: 0.00029
a decoder loss: 0.21584
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:38
train iter: 452
num of updates: 45300
vae loss: 0.21575
kl loss: 0.00029
a decoder loss: 0.21546
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:39
train iter: 453
num of updates: 45400
vae loss: 0.21581
kl loss: 0.00028
a decoder loss: 0.21553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:40
train iter: 454
num of updates: 45500
vae loss: 0.21578
kl loss: 0.00028
a decoder loss: 0.21550
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:41
train iter: 455
num of updates: 45600
vae loss: 0.21581
kl loss: 0.00028
a decoder loss: 0.21553
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:42
train iter: 456
num of updates: 45700
vae loss: 0.21616
kl loss: 0.00028
a decoder loss: 0.21588
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:43
train iter: 457
num of updates: 45800
vae loss: 0.21529
kl loss: 0.00028
a decoder loss: 0.21501
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:44
train iter: 458
num of updates: 45900
vae loss: 0.21650
kl loss: 0.00028
a decoder loss: 0.21622
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:45
train iter: 459
num of updates: 46000
vae loss: 0.21536
kl loss: 0.00028
a decoder loss: 0.21508
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:46
train iter: 460
num of updates: 46100
vae loss: 0.21559
kl loss: 0.00028
a decoder loss: 0.21532
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:47
train iter: 461
num of updates: 46200
vae loss: 0.21538
kl loss: 0.00027
a decoder loss: 0.21510
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:48
train iter: 462
num of updates: 46300
vae loss: 0.21673
kl loss: 0.00027
a decoder loss: 0.21645
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:49
train iter: 463
num of updates: 46400
vae loss: 0.21479
kl loss: 0.00027
a decoder loss: 0.21452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:50
train iter: 464
num of updates: 46500
vae loss: 0.21623
kl loss: 0.00027
a decoder loss: 0.21596
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:51
train iter: 465
num of updates: 46600
vae loss: 0.21540
kl loss: 0.00027
a decoder loss: 0.21513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:52
train iter: 466
num of updates: 46700
vae loss: 0.21554
kl loss: 0.00027
a decoder loss: 0.21527
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:53
train iter: 467
num of updates: 46800
vae loss: 0.21496
kl loss: 0.00027
a decoder loss: 0.21469
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:54
train iter: 468
num of updates: 46900
vae loss: 0.21470
kl loss: 0.00027
a decoder loss: 0.21443
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:55
train iter: 469
num of updates: 47000
vae loss: 0.21470
kl loss: 0.00027
a decoder loss: 0.21444
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:56
train iter: 470
num of updates: 47100
vae loss: 0.21551
kl loss: 0.00027
a decoder loss: 0.21524
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:57
train iter: 471
num of updates: 47200
vae loss: 0.21590
kl loss: 0.00026
a decoder loss: 0.21563
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:58
train iter: 472
num of updates: 47300
vae loss: 0.21490
kl loss: 0.00026
a decoder loss: 0.21464
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:58:59
train iter: 473
num of updates: 47400
vae loss: 0.21581
kl loss: 0.00026
a decoder loss: 0.21555
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:00
train iter: 474
num of updates: 47500
vae loss: 0.21587
kl loss: 0.00026
a decoder loss: 0.21561
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:01
train iter: 475
num of updates: 47600
vae loss: 0.21540
kl loss: 0.00026
a decoder loss: 0.21514
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:02
train iter: 476
num of updates: 47700
vae loss: 0.21421
kl loss: 0.00026
a decoder loss: 0.21396
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:03
train iter: 477
num of updates: 47800
vae loss: 0.21466
kl loss: 0.00026
a decoder loss: 0.21440
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:04
train iter: 478
num of updates: 47900
vae loss: 0.21544
kl loss: 0.00026
a decoder loss: 0.21518
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:05
train iter: 479
num of updates: 48000
vae loss: 0.21534
kl loss: 0.00026
a decoder loss: 0.21509
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:06
train iter: 480
num of updates: 48100
vae loss: 0.21485
kl loss: 0.00025
a decoder loss: 0.21460
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:07
train iter: 481
num of updates: 48200
vae loss: 0.21422
kl loss: 0.00025
a decoder loss: 0.21397
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:08
train iter: 482
num of updates: 48300
vae loss: 0.21538
kl loss: 0.00025
a decoder loss: 0.21513
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:09
train iter: 483
num of updates: 48400
vae loss: 0.21507
kl loss: 0.00025
a decoder loss: 0.21482
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:10
train iter: 484
num of updates: 48500
vae loss: 0.21563
kl loss: 0.00025
a decoder loss: 0.21538
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:11
train iter: 485
num of updates: 48600
vae loss: 0.21352
kl loss: 0.00025
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:12
train iter: 486
num of updates: 48700
vae loss: 0.21529
kl loss: 0.00025
a decoder loss: 0.21504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:13
train iter: 487
num of updates: 48800
vae loss: 0.21497
kl loss: 0.00025
a decoder loss: 0.21472
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:14
train iter: 488
num of updates: 48900
vae loss: 0.21463
kl loss: 0.00024
a decoder loss: 0.21439
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:15
train iter: 489
num of updates: 49000
vae loss: 0.21523
kl loss: 0.00024
a decoder loss: 0.21499
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:16
train iter: 490
num of updates: 49100
vae loss: 0.21437
kl loss: 0.00024
a decoder loss: 0.21413
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:17
train iter: 491
num of updates: 49200
vae loss: 0.21473
kl loss: 0.00024
a decoder loss: 0.21449
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:18
train iter: 492
num of updates: 49300
vae loss: 0.21399
kl loss: 0.00024
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:19
train iter: 493
num of updates: 49400
vae loss: 0.21427
kl loss: 0.00024
a decoder loss: 0.21403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:20
train iter: 494
num of updates: 49500
vae loss: 0.21450
kl loss: 0.00024
a decoder loss: 0.21426
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:21
train iter: 495
num of updates: 49600
vae loss: 0.21495
kl loss: 0.00024
a decoder loss: 0.21471
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:22
train iter: 496
num of updates: 49700
vae loss: 0.21445
kl loss: 0.00024
a decoder loss: 0.21422
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:23
train iter: 497
num of updates: 49800
vae loss: 0.21442
kl loss: 0.00024
a decoder loss: 0.21418
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:24
train iter: 498
num of updates: 49900
vae loss: 0.21521
kl loss: 0.00023
a decoder loss: 0.21497
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:25
train iter: 499
num of updates: 50000
vae loss: 0.21475
kl loss: 0.00023
a decoder loss: 0.21452
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:26
train iter: 500
num of updates: 50100
vae loss: 0.21527
kl loss: 0.00023
a decoder loss: 0.21504
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:27
train iter: 501
num of updates: 50200
vae loss: 0.21417
kl loss: 0.00023
a decoder loss: 0.21394
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:28
train iter: 502
num of updates: 50300
vae loss: 0.21399
kl loss: 0.00023
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:29
train iter: 503
num of updates: 50400
vae loss: 0.21382
kl loss: 0.00023
a decoder loss: 0.21359
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:30
train iter: 504
num of updates: 50500
vae loss: 0.21359
kl loss: 0.00023
a decoder loss: 0.21336
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:32
train iter: 505
num of updates: 50600
vae loss: 0.21448
kl loss: 0.00023
a decoder loss: 0.21426
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:33
train iter: 506
num of updates: 50700
vae loss: 0.21294
kl loss: 0.00023
a decoder loss: 0.21271
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:34
train iter: 507
num of updates: 50800
vae loss: 0.21398
kl loss: 0.00023
a decoder loss: 0.21375
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:35
train iter: 508
num of updates: 50900
vae loss: 0.21469
kl loss: 0.00022
a decoder loss: 0.21446
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:36
train iter: 509
num of updates: 51000
vae loss: 0.21426
kl loss: 0.00022
a decoder loss: 0.21403
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:37
train iter: 510
num of updates: 51100
vae loss: 0.21442
kl loss: 0.00022
a decoder loss: 0.21420
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:38
train iter: 511
num of updates: 51200
vae loss: 0.21354
kl loss: 0.00022
a decoder loss: 0.21332
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:39
train iter: 512
num of updates: 51300
vae loss: 0.21374
kl loss: 0.00022
a decoder loss: 0.21351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:40
train iter: 513
num of updates: 51400
vae loss: 0.21336
kl loss: 0.00022
a decoder loss: 0.21314
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:41
train iter: 514
num of updates: 51500
vae loss: 0.21428
kl loss: 0.00022
a decoder loss: 0.21406
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:42
train iter: 515
num of updates: 51600
vae loss: 0.21463
kl loss: 0.00022
a decoder loss: 0.21441
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:43
train iter: 516
num of updates: 51700
vae loss: 0.21417
kl loss: 0.00022
a decoder loss: 0.21395
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:44
train iter: 517
num of updates: 51800
vae loss: 0.21323
kl loss: 0.00022
a decoder loss: 0.21302
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:45
train iter: 518
num of updates: 51900
vae loss: 0.21413
kl loss: 0.00022
a decoder loss: 0.21392
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:46
train iter: 519
num of updates: 52000
vae loss: 0.21363
kl loss: 0.00022
a decoder loss: 0.21341
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:47
train iter: 520
num of updates: 52100
vae loss: 0.21370
kl loss: 0.00022
a decoder loss: 0.21349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:48
train iter: 521
num of updates: 52200
vae loss: 0.21396
kl loss: 0.00022
a decoder loss: 0.21374
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:49
train iter: 522
num of updates: 52300
vae loss: 0.21359
kl loss: 0.00021
a decoder loss: 0.21338
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:50
train iter: 523
num of updates: 52400
vae loss: 0.21413
kl loss: 0.00022
a decoder loss: 0.21391
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:51
train iter: 524
num of updates: 52500
vae loss: 0.21365
kl loss: 0.00021
a decoder loss: 0.21344
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:52
train iter: 525
num of updates: 52600
vae loss: 0.21332
kl loss: 0.00021
a decoder loss: 0.21310
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:53
train iter: 526
num of updates: 52700
vae loss: 0.21364
kl loss: 0.00021
a decoder loss: 0.21343
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:54
train iter: 527
num of updates: 52800
vae loss: 0.21447
kl loss: 0.00021
a decoder loss: 0.21427
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:55
train iter: 528
num of updates: 52900
vae loss: 0.21363
kl loss: 0.00021
a decoder loss: 0.21342
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:56
train iter: 529
num of updates: 53000
vae loss: 0.21328
kl loss: 0.00021
a decoder loss: 0.21307
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:57
train iter: 530
num of updates: 53100
vae loss: 0.21317
kl loss: 0.00021
a decoder loss: 0.21296
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:58
train iter: 531
num of updates: 53200
vae loss: 0.21251
kl loss: 0.00021
a decoder loss: 0.21231
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 0:59:59
train iter: 532
num of updates: 53300
vae loss: 0.21338
kl loss: 0.00021
a decoder loss: 0.21317
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:00
train iter: 533
num of updates: 53400
vae loss: 0.21355
kl loss: 0.00021
a decoder loss: 0.21335
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:01
train iter: 534
num of updates: 53500
vae loss: 0.21405
kl loss: 0.00021
a decoder loss: 0.21384
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:02
train iter: 535
num of updates: 53600
vae loss: 0.21345
kl loss: 0.00020
a decoder loss: 0.21325
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:03
train iter: 536
num of updates: 53700
vae loss: 0.21311
kl loss: 0.00021
a decoder loss: 0.21291
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:04
train iter: 537
num of updates: 53800
vae loss: 0.21359
kl loss: 0.00020
a decoder loss: 0.21339
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:05
train iter: 538
num of updates: 53900
vae loss: 0.21341
kl loss: 0.00020
a decoder loss: 0.21321
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:06
train iter: 539
num of updates: 54000
vae loss: 0.21360
kl loss: 0.00020
a decoder loss: 0.21340
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:07
train iter: 540
num of updates: 54100
vae loss: 0.21399
kl loss: 0.00020
a decoder loss: 0.21379
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:08
train iter: 541
num of updates: 54200
vae loss: 0.21409
kl loss: 0.00020
a decoder loss: 0.21389
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:09
train iter: 542
num of updates: 54300
vae loss: 0.21281
kl loss: 0.00020
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:10
train iter: 543
num of updates: 54400
vae loss: 0.21329
kl loss: 0.00020
a decoder loss: 0.21309
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:11
train iter: 544
num of updates: 54500
vae loss: 0.21371
kl loss: 0.00020
a decoder loss: 0.21351
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:12
train iter: 545
num of updates: 54600
vae loss: 0.21308
kl loss: 0.00020
a decoder loss: 0.21289
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:13
train iter: 546
num of updates: 54700
vae loss: 0.21417
kl loss: 0.00020
a decoder loss: 0.21397
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:14
train iter: 547
num of updates: 54800
vae loss: 0.21346
kl loss: 0.00020
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:15
train iter: 548
num of updates: 54900
vae loss: 0.21247
kl loss: 0.00019
a decoder loss: 0.21227
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:16
train iter: 549
num of updates: 55000
vae loss: 0.21392
kl loss: 0.00020
a decoder loss: 0.21373
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:17
train iter: 550
num of updates: 55100
vae loss: 0.21326
kl loss: 0.00020
a decoder loss: 0.21306
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:18
train iter: 551
num of updates: 55200
vae loss: 0.21298
kl loss: 0.00019
a decoder loss: 0.21279
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:19
train iter: 552
num of updates: 55300
vae loss: 0.21239
kl loss: 0.00019
a decoder loss: 0.21220
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:20
train iter: 553
num of updates: 55400
vae loss: 0.21386
kl loss: 0.00019
a decoder loss: 0.21367
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:21
train iter: 554
num of updates: 55500
vae loss: 0.21273
kl loss: 0.00019
a decoder loss: 0.21254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:22
train iter: 555
num of updates: 55600
vae loss: 0.21381
kl loss: 0.00019
a decoder loss: 0.21362
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:23
train iter: 556
num of updates: 55700
vae loss: 0.21264
kl loss: 0.00019
a decoder loss: 0.21245
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:24
train iter: 557
num of updates: 55800
vae loss: 0.21314
kl loss: 0.00019
a decoder loss: 0.21295
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:25
train iter: 558
num of updates: 55900
vae loss: 0.21251
kl loss: 0.00019
a decoder loss: 0.21232
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:26
train iter: 559
num of updates: 56000
vae loss: 0.21327
kl loss: 0.00019
a decoder loss: 0.21309
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:28
train iter: 560
num of updates: 56100
vae loss: 0.21188
kl loss: 0.00019
a decoder loss: 0.21169
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:29
train iter: 561
num of updates: 56200
vae loss: 0.21339
kl loss: 0.00019
a decoder loss: 0.21320
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:30
train iter: 562
num of updates: 56300
vae loss: 0.21252
kl loss: 0.00019
a decoder loss: 0.21233
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:31
train iter: 563
num of updates: 56400
vae loss: 0.21273
kl loss: 0.00019
a decoder loss: 0.21254
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:32
train iter: 564
num of updates: 56500
vae loss: 0.21287
kl loss: 0.00019
a decoder loss: 0.21269
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:33
train iter: 565
num of updates: 56600
vae loss: 0.21220
kl loss: 0.00019
a decoder loss: 0.21202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:34
train iter: 566
num of updates: 56700
vae loss: 0.21236
kl loss: 0.00018
a decoder loss: 0.21218
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:35
train iter: 567
num of updates: 56800
vae loss: 0.21230
kl loss: 0.00018
a decoder loss: 0.21211
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:36
train iter: 568
num of updates: 56900
vae loss: 0.21309
kl loss: 0.00018
a decoder loss: 0.21290
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:37
train iter: 569
num of updates: 57000
vae loss: 0.21367
kl loss: 0.00018
a decoder loss: 0.21349
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:38
train iter: 570
num of updates: 57100
vae loss: 0.21273
kl loss: 0.00018
a decoder loss: 0.21255
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:39
train iter: 571
num of updates: 57200
vae loss: 0.21346
kl loss: 0.00018
a decoder loss: 0.21327
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:40
train iter: 572
num of updates: 57300
vae loss: 0.21232
kl loss: 0.00018
a decoder loss: 0.21214
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:41
train iter: 573
num of updates: 57400
vae loss: 0.21253
kl loss: 0.00018
a decoder loss: 0.21235
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:42
train iter: 574
num of updates: 57500
vae loss: 0.21303
kl loss: 0.00018
a decoder loss: 0.21285
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:43
train iter: 575
num of updates: 57600
vae loss: 0.21315
kl loss: 0.00018
a decoder loss: 0.21297
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:44
train iter: 576
num of updates: 57700
vae loss: 0.21299
kl loss: 0.00018
a decoder loss: 0.21281
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:45
train iter: 577
num of updates: 57800
vae loss: 0.21226
kl loss: 0.00018
a decoder loss: 0.21208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:46
train iter: 578
num of updates: 57900
vae loss: 0.21224
kl loss: 0.00018
a decoder loss: 0.21206
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:47
train iter: 579
num of updates: 58000
vae loss: 0.21220
kl loss: 0.00018
a decoder loss: 0.21202
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:48
train iter: 580
num of updates: 58100
vae loss: 0.21323
kl loss: 0.00018
a decoder loss: 0.21305
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:49
train iter: 581
num of updates: 58200
vae loss: 0.21256
kl loss: 0.00018
a decoder loss: 0.21238
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:50
train iter: 582
num of updates: 58300
vae loss: 0.21202
kl loss: 0.00018
a decoder loss: 0.21185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:51
train iter: 583
num of updates: 58400
vae loss: 0.21234
kl loss: 0.00018
a decoder loss: 0.21216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:52
train iter: 584
num of updates: 58500
vae loss: 0.21263
kl loss: 0.00017
a decoder loss: 0.21246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:53
train iter: 585
num of updates: 58600
vae loss: 0.21264
kl loss: 0.00017
a decoder loss: 0.21246
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:54
train iter: 586
num of updates: 58700
vae loss: 0.21195
kl loss: 0.00017
a decoder loss: 0.21178
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:55
train iter: 587
num of updates: 58800
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:56
train iter: 588
num of updates: 58900
vae loss: 0.21146
kl loss: 0.00017
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:57
train iter: 589
num of updates: 59000
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21261
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:58
train iter: 590
num of updates: 59100
vae loss: 0.21179
kl loss: 0.00017
a decoder loss: 0.21162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:00:59
train iter: 591
num of updates: 59200
vae loss: 0.21184
kl loss: 0.00017
a decoder loss: 0.21167
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:00
train iter: 592
num of updates: 59300
vae loss: 0.21233
kl loss: 0.00017
a decoder loss: 0.21215
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:01
train iter: 593
num of updates: 59400
vae loss: 0.21183
kl loss: 0.00017
a decoder loss: 0.21166
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:02
train iter: 594
num of updates: 59500
vae loss: 0.21186
kl loss: 0.00017
a decoder loss: 0.21169
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:03
train iter: 595
num of updates: 59600
vae loss: 0.21227
kl loss: 0.00017
a decoder loss: 0.21210
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:04
train iter: 596
num of updates: 59700
vae loss: 0.21265
kl loss: 0.00017
a decoder loss: 0.21248
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:05
train iter: 597
num of updates: 59800
vae loss: 0.21278
kl loss: 0.00017
a decoder loss: 0.21262
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:06
train iter: 598
num of updates: 59900
vae loss: 0.21212
kl loss: 0.00017
a decoder loss: 0.21195
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:07
train iter: 599
num of updates: 60000
vae loss: 0.21266
kl loss: 0.00017
a decoder loss: 0.21249
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:08
train iter: 600
num of updates: 60100
vae loss: 0.21215
kl loss: 0.00017
a decoder loss: 0.21198
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:09
train iter: 601
num of updates: 60200
vae loss: 0.21191
kl loss: 0.00017
a decoder loss: 0.21174
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:10
train iter: 602
num of updates: 60300
vae loss: 0.21222
kl loss: 0.00017
a decoder loss: 0.21205
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:11
train iter: 603
num of updates: 60400
vae loss: 0.21125
kl loss: 0.00016
a decoder loss: 0.21109
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:12
train iter: 604
num of updates: 60500
vae loss: 0.21234
kl loss: 0.00017
a decoder loss: 0.21217
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:13
train iter: 605
num of updates: 60600
vae loss: 0.21135
kl loss: 0.00016
a decoder loss: 0.21119
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:14
train iter: 606
num of updates: 60700
vae loss: 0.21258
kl loss: 0.00016
a decoder loss: 0.21242
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:15
train iter: 607
num of updates: 60800
vae loss: 0.21230
kl loss: 0.00016
a decoder loss: 0.21213
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:16
train iter: 608
num of updates: 60900
vae loss: 0.21141
kl loss: 0.00016
a decoder loss: 0.21125
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:17
train iter: 609
num of updates: 61000
vae loss: 0.21163
kl loss: 0.00016
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:18
train iter: 610
num of updates: 61100
vae loss: 0.21205
kl loss: 0.00016
a decoder loss: 0.21189
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:19
train iter: 611
num of updates: 61200
vae loss: 0.21294
kl loss: 0.00016
a decoder loss: 0.21278
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:20
train iter: 612
num of updates: 61300
vae loss: 0.21187
kl loss: 0.00016
a decoder loss: 0.21171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:21
train iter: 613
num of updates: 61400
vae loss: 0.21241
kl loss: 0.00016
a decoder loss: 0.21225
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:23
train iter: 614
num of updates: 61500
vae loss: 0.21210
kl loss: 0.00016
a decoder loss: 0.21194
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:24
train iter: 615
num of updates: 61600
vae loss: 0.21232
kl loss: 0.00016
a decoder loss: 0.21216
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:25
train iter: 616
num of updates: 61700
vae loss: 0.21177
kl loss: 0.00016
a decoder loss: 0.21161
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:26
train iter: 617
num of updates: 61800
vae loss: 0.21127
kl loss: 0.00016
a decoder loss: 0.21111
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:27
train iter: 618
num of updates: 61900
vae loss: 0.21257
kl loss: 0.00016
a decoder loss: 0.21241
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:28
train iter: 619
num of updates: 62000
vae loss: 0.21163
kl loss: 0.00016
a decoder loss: 0.21147
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:29
train iter: 620
num of updates: 62100
vae loss: 0.21083
kl loss: 0.00016
a decoder loss: 0.21067
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:30
train iter: 621
num of updates: 62200
vae loss: 0.21235
kl loss: 0.00016
a decoder loss: 0.21219
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:31
train iter: 622
num of updates: 62300
vae loss: 0.21112
kl loss: 0.00016
a decoder loss: 0.21096
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:32
train iter: 623
num of updates: 62400
vae loss: 0.21165
kl loss: 0.00016
a decoder loss: 0.21149
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:33
train iter: 624
num of updates: 62500
vae loss: 0.21158
kl loss: 0.00016
a decoder loss: 0.21142
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:34
train iter: 625
num of updates: 62600
vae loss: 0.21168
kl loss: 0.00015
a decoder loss: 0.21152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:35
train iter: 626
num of updates: 62700
vae loss: 0.21218
kl loss: 0.00015
a decoder loss: 0.21203
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:36
train iter: 627
num of updates: 62800
vae loss: 0.21200
kl loss: 0.00016
a decoder loss: 0.21185
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:37
train iter: 628
num of updates: 62900
vae loss: 0.21101
kl loss: 0.00015
a decoder loss: 0.21086
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:38
train iter: 629
num of updates: 63000
vae loss: 0.21094
kl loss: 0.00015
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:39
train iter: 630
num of updates: 63100
vae loss: 0.21168
kl loss: 0.00015
a decoder loss: 0.21152
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:40
train iter: 631
num of updates: 63200
vae loss: 0.21093
kl loss: 0.00015
a decoder loss: 0.21077
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:41
train iter: 632
num of updates: 63300
vae loss: 0.21148
kl loss: 0.00015
a decoder loss: 0.21133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:42
train iter: 633
num of updates: 63400
vae loss: 0.21190
kl loss: 0.00015
a decoder loss: 0.21175
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:43
train iter: 634
num of updates: 63500
vae loss: 0.21113
kl loss: 0.00015
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:44
train iter: 635
num of updates: 63600
vae loss: 0.21112
kl loss: 0.00015
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:45
train iter: 636
num of updates: 63700
vae loss: 0.21186
kl loss: 0.00015
a decoder loss: 0.21171
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:46
train iter: 637
num of updates: 63800
vae loss: 0.21193
kl loss: 0.00015
a decoder loss: 0.21178
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:47
train iter: 638
num of updates: 63900
vae loss: 0.21197
kl loss: 0.00015
a decoder loss: 0.21182
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:48
train iter: 639
num of updates: 64000
vae loss: 0.21219
kl loss: 0.00015
a decoder loss: 0.21204
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:49
train iter: 640
num of updates: 64100
vae loss: 0.21158
kl loss: 0.00015
a decoder loss: 0.21143
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:50
train iter: 641
num of updates: 64200
vae loss: 0.21081
kl loss: 0.00015
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:51
train iter: 642
num of updates: 64300
vae loss: 0.21129
kl loss: 0.00015
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:52
train iter: 643
num of updates: 64400
vae loss: 0.21155
kl loss: 0.00015
a decoder loss: 0.21140
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:53
train iter: 644
num of updates: 64500
vae loss: 0.21107
kl loss: 0.00015
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:54
train iter: 645
num of updates: 64600
vae loss: 0.21170
kl loss: 0.00015
a decoder loss: 0.21155
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:55
train iter: 646
num of updates: 64700
vae loss: 0.21222
kl loss: 0.00015
a decoder loss: 0.21208
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:56
train iter: 647
num of updates: 64800
vae loss: 0.21188
kl loss: 0.00015
a decoder loss: 0.21173
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:57
train iter: 648
num of updates: 64900
vae loss: 0.21106
kl loss: 0.00015
a decoder loss: 0.21091
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:58
train iter: 649
num of updates: 65000
vae loss: 0.21068
kl loss: 0.00015
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:01:59
train iter: 650
num of updates: 65100
vae loss: 0.21119
kl loss: 0.00015
a decoder loss: 0.21104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:00
train iter: 651
num of updates: 65200
vae loss: 0.21204
kl loss: 0.00014
a decoder loss: 0.21190
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:01
train iter: 652
num of updates: 65300
vae loss: 0.21083
kl loss: 0.00015
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:02
train iter: 653
num of updates: 65400
vae loss: 0.21115
kl loss: 0.00014
a decoder loss: 0.21100
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:03
train iter: 654
num of updates: 65500
vae loss: 0.21096
kl loss: 0.00014
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:04
train iter: 655
num of updates: 65600
vae loss: 0.21101
kl loss: 0.00014
a decoder loss: 0.21087
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:05
train iter: 656
num of updates: 65700
vae loss: 0.21175
kl loss: 0.00014
a decoder loss: 0.21160
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:06
train iter: 657
num of updates: 65800
vae loss: 0.21148
kl loss: 0.00014
a decoder loss: 0.21133
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:07
train iter: 658
num of updates: 65900
vae loss: 0.21132
kl loss: 0.00014
a decoder loss: 0.21118
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:08
train iter: 659
num of updates: 66000
vae loss: 0.21095
kl loss: 0.00014
a decoder loss: 0.21081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:09
train iter: 660
num of updates: 66100
vae loss: 0.21143
kl loss: 0.00014
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:10
train iter: 661
num of updates: 66200
vae loss: 0.21153
kl loss: 0.00014
a decoder loss: 0.21139
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:11
train iter: 662
num of updates: 66300
vae loss: 0.21035
kl loss: 0.00014
a decoder loss: 0.21020
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:12
train iter: 663
num of updates: 66400
vae loss: 0.21052
kl loss: 0.00014
a decoder loss: 0.21038
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:13
train iter: 664
num of updates: 66500
vae loss: 0.21138
kl loss: 0.00014
a decoder loss: 0.21124
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:14
train iter: 665
num of updates: 66600
vae loss: 0.21176
kl loss: 0.00014
a decoder loss: 0.21162
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:15
train iter: 666
num of updates: 66700
vae loss: 0.21130
kl loss: 0.00014
a decoder loss: 0.21116
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:16
train iter: 667
num of updates: 66800
vae loss: 0.21082
kl loss: 0.00014
a decoder loss: 0.21068
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:17
train iter: 668
num of updates: 66900
vae loss: 0.21108
kl loss: 0.00014
a decoder loss: 0.21094
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:18
train iter: 669
num of updates: 67000
vae loss: 0.21075
kl loss: 0.00014
a decoder loss: 0.21061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:19
train iter: 670
num of updates: 67100
vae loss: 0.21112
kl loss: 0.00014
a decoder loss: 0.21098
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:20
train iter: 671
num of updates: 67200
vae loss: 0.21111
kl loss: 0.00014
a decoder loss: 0.21097
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:21
train iter: 672
num of updates: 67300
vae loss: 0.21143
kl loss: 0.00014
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:23
train iter: 673
num of updates: 67400
vae loss: 0.21098
kl loss: 0.00014
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:24
train iter: 674
num of updates: 67500
vae loss: 0.21054
kl loss: 0.00014
a decoder loss: 0.21040
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:25
train iter: 675
num of updates: 67600
vae loss: 0.21078
kl loss: 0.00014
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:26
train iter: 676
num of updates: 67700
vae loss: 0.21092
kl loss: 0.00014
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:27
train iter: 677
num of updates: 67800
vae loss: 0.21079
kl loss: 0.00014
a decoder loss: 0.21066
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:28
train iter: 678
num of updates: 67900
vae loss: 0.21106
kl loss: 0.00014
a decoder loss: 0.21092
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:29
train iter: 679
num of updates: 68000
vae loss: 0.21159
kl loss: 0.00014
a decoder loss: 0.21146
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:30
train iter: 680
num of updates: 68100
vae loss: 0.21065
kl loss: 0.00014
a decoder loss: 0.21052
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:31
train iter: 681
num of updates: 68200
vae loss: 0.21130
kl loss: 0.00013
a decoder loss: 0.21117
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:32
train iter: 682
num of updates: 68300
vae loss: 0.21127
kl loss: 0.00013
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:33
train iter: 683
num of updates: 68400
vae loss: 0.21106
kl loss: 0.00013
a decoder loss: 0.21093
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:34
train iter: 684
num of updates: 68500
vae loss: 0.21030
kl loss: 0.00013
a decoder loss: 0.21016
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:35
train iter: 685
num of updates: 68600
vae loss: 0.21115
kl loss: 0.00013
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:36
train iter: 686
num of updates: 68700
vae loss: 0.21158
kl loss: 0.00014
a decoder loss: 0.21145
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:37
train iter: 687
num of updates: 68800
vae loss: 0.21117
kl loss: 0.00013
a decoder loss: 0.21104
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:38
train iter: 688
num of updates: 68900
vae loss: 0.21099
kl loss: 0.00013
a decoder loss: 0.21085
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:39
train iter: 689
num of updates: 69000
vae loss: 0.21095
kl loss: 0.00013
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:40
train iter: 690
num of updates: 69100
vae loss: 0.21045
kl loss: 0.00013
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:41
train iter: 691
num of updates: 69200
vae loss: 0.21084
kl loss: 0.00013
a decoder loss: 0.21071
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:42
train iter: 692
num of updates: 69300
vae loss: 0.21068
kl loss: 0.00013
a decoder loss: 0.21055
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:43
train iter: 693
num of updates: 69400
vae loss: 0.21071
kl loss: 0.00013
a decoder loss: 0.21058
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:44
train iter: 694
num of updates: 69500
vae loss: 0.21062
kl loss: 0.00013
a decoder loss: 0.21049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:45
train iter: 695
num of updates: 69600
vae loss: 0.21039
kl loss: 0.00013
a decoder loss: 0.21026
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:46
train iter: 696
num of updates: 69700
vae loss: 0.21214
kl loss: 0.00013
a decoder loss: 0.21201
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:47
train iter: 697
num of updates: 69800
vae loss: 0.21067
kl loss: 0.00013
a decoder loss: 0.21054
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:48
train iter: 698
num of updates: 69900
vae loss: 0.21087
kl loss: 0.00013
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:49
train iter: 699
num of updates: 70000
vae loss: 0.21102
kl loss: 0.00013
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:50
train iter: 700
num of updates: 70100
vae loss: 0.20980
kl loss: 0.00013
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:51
train iter: 701
num of updates: 70200
vae loss: 0.21077
kl loss: 0.00013
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:52
train iter: 702
num of updates: 70300
vae loss: 0.21125
kl loss: 0.00013
a decoder loss: 0.21112
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:53
train iter: 703
num of updates: 70400
vae loss: 0.21115
kl loss: 0.00013
a decoder loss: 0.21102
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:54
train iter: 704
num of updates: 70500
vae loss: 0.21127
kl loss: 0.00013
a decoder loss: 0.21114
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:55
train iter: 705
num of updates: 70600
vae loss: 0.21091
kl loss: 0.00013
a decoder loss: 0.21078
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:56
train iter: 706
num of updates: 70700
vae loss: 0.21007
kl loss: 0.00013
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:57
train iter: 707
num of updates: 70800
vae loss: 0.21055
kl loss: 0.00013
a decoder loss: 0.21043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:58
train iter: 708
num of updates: 70900
vae loss: 0.20956
kl loss: 0.00013
a decoder loss: 0.20943
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:02:59
train iter: 709
num of updates: 71000
vae loss: 0.20981
kl loss: 0.00013
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:00
train iter: 710
num of updates: 71100
vae loss: 0.21028
kl loss: 0.00013
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:01
train iter: 711
num of updates: 71200
vae loss: 0.21043
kl loss: 0.00013
a decoder loss: 0.21031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:02
train iter: 712
num of updates: 71300
vae loss: 0.21094
kl loss: 0.00013
a decoder loss: 0.21082
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:03
train iter: 713
num of updates: 71400
vae loss: 0.21017
kl loss: 0.00013
a decoder loss: 0.21004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:04
train iter: 714
num of updates: 71500
vae loss: 0.20995
kl loss: 0.00013
a decoder loss: 0.20983
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:05
train iter: 715
num of updates: 71600
vae loss: 0.21031
kl loss: 0.00013
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:06
train iter: 716
num of updates: 71700
vae loss: 0.21033
kl loss: 0.00012
a decoder loss: 0.21021
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:07
train iter: 717
num of updates: 71800
vae loss: 0.21015
kl loss: 0.00012
a decoder loss: 0.21003
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:08
train iter: 718
num of updates: 71900
vae loss: 0.21132
kl loss: 0.00012
a decoder loss: 0.21120
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:09
train iter: 719
num of updates: 72000
vae loss: 0.21081
kl loss: 0.00012
a decoder loss: 0.21069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:10
train iter: 720
num of updates: 72100
vae loss: 0.21084
kl loss: 0.00012
a decoder loss: 0.21072
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:11
train iter: 721
num of updates: 72200
vae loss: 0.21108
kl loss: 0.00012
a decoder loss: 0.21095
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:12
train iter: 722
num of updates: 72300
vae loss: 0.21042
kl loss: 0.00012
a decoder loss: 0.21029
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:13
train iter: 723
num of updates: 72400
vae loss: 0.21049
kl loss: 0.00012
a decoder loss: 0.21037
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:14
train iter: 724
num of updates: 72500
vae loss: 0.21054
kl loss: 0.00012
a decoder loss: 0.21042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:15
train iter: 725
num of updates: 72600
vae loss: 0.21086
kl loss: 0.00012
a decoder loss: 0.21074
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:16
train iter: 726
num of updates: 72700
vae loss: 0.20980
kl loss: 0.00012
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:17
train iter: 727
num of updates: 72800
vae loss: 0.21061
kl loss: 0.00012
a decoder loss: 0.21049
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:18
train iter: 728
num of updates: 72900
vae loss: 0.21056
kl loss: 0.00012
a decoder loss: 0.21044
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:19
train iter: 729
num of updates: 73000
vae loss: 0.21101
kl loss: 0.00012
a decoder loss: 0.21089
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:20
train iter: 730
num of updates: 73100
vae loss: 0.21091
kl loss: 0.00012
a decoder loss: 0.21079
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:21
train iter: 731
num of updates: 73200
vae loss: 0.21016
kl loss: 0.00012
a decoder loss: 0.21004
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:22
train iter: 732
num of updates: 73300
vae loss: 0.21141
kl loss: 0.00012
a decoder loss: 0.21129
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:23
train iter: 733
num of updates: 73400
vae loss: 0.21048
kl loss: 0.00012
a decoder loss: 0.21036
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:24
train iter: 734
num of updates: 73500
vae loss: 0.21034
kl loss: 0.00012
a decoder loss: 0.21022
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:26
train iter: 735
num of updates: 73600
vae loss: 0.21081
kl loss: 0.00012
a decoder loss: 0.21069
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:27
train iter: 736
num of updates: 73700
vae loss: 0.21008
kl loss: 0.00012
a decoder loss: 0.20996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:28
train iter: 737
num of updates: 73800
vae loss: 0.21000
kl loss: 0.00012
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:29
train iter: 738
num of updates: 73900
vae loss: 0.20994
kl loss: 0.00012
a decoder loss: 0.20982
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:30
train iter: 739
num of updates: 74000
vae loss: 0.20998
kl loss: 0.00012
a decoder loss: 0.20986
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:31
train iter: 740
num of updates: 74100
vae loss: 0.20991
kl loss: 0.00012
a decoder loss: 0.20979
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:32
train iter: 741
num of updates: 74200
vae loss: 0.21031
kl loss: 0.00012
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:33
train iter: 742
num of updates: 74300
vae loss: 0.21074
kl loss: 0.00012
a decoder loss: 0.21062
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:34
train iter: 743
num of updates: 74400
vae loss: 0.21053
kl loss: 0.00012
a decoder loss: 0.21042
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:35
train iter: 744
num of updates: 74500
vae loss: 0.21072
kl loss: 0.00012
a decoder loss: 0.21061
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:36
train iter: 745
num of updates: 74600
vae loss: 0.21027
kl loss: 0.00012
a decoder loss: 0.21015
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:37
train iter: 746
num of updates: 74700
vae loss: 0.21031
kl loss: 0.00012
a decoder loss: 0.21019
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:38
train iter: 747
num of updates: 74800
vae loss: 0.20951
kl loss: 0.00012
a decoder loss: 0.20939
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:39
train iter: 748
num of updates: 74900
vae loss: 0.20950
kl loss: 0.00012
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:40
train iter: 749
num of updates: 75000
vae loss: 0.20960
kl loss: 0.00012
a decoder loss: 0.20948
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:41
train iter: 750
num of updates: 75100
vae loss: 0.21092
kl loss: 0.00012
a decoder loss: 0.21080
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:42
train iter: 751
num of updates: 75200
vae loss: 0.21105
kl loss: 0.00012
a decoder loss: 0.21093
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:43
train iter: 752
num of updates: 75300
vae loss: 0.20931
kl loss: 0.00012
a decoder loss: 0.20920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:44
train iter: 753
num of updates: 75400
vae loss: 0.20972
kl loss: 0.00012
a decoder loss: 0.20961
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:45
train iter: 754
num of updates: 75500
vae loss: 0.20902
kl loss: 0.00012
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:46
train iter: 755
num of updates: 75600
vae loss: 0.20978
kl loss: 0.00011
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:47
train iter: 756
num of updates: 75700
vae loss: 0.21092
kl loss: 0.00011
a decoder loss: 0.21081
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:48
train iter: 757
num of updates: 75800
vae loss: 0.21094
kl loss: 0.00011
a decoder loss: 0.21083
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:49
train iter: 758
num of updates: 75900
vae loss: 0.20981
kl loss: 0.00011
a decoder loss: 0.20970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:50
train iter: 759
num of updates: 76000
vae loss: 0.20988
kl loss: 0.00011
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:51
train iter: 760
num of updates: 76100
vae loss: 0.21111
kl loss: 0.00011
a decoder loss: 0.21100
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:52
train iter: 761
num of updates: 76200
vae loss: 0.21008
kl loss: 0.00011
a decoder loss: 0.20997
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:53
train iter: 762
num of updates: 76300
vae loss: 0.21046
kl loss: 0.00011
a decoder loss: 0.21035
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:54
train iter: 763
num of updates: 76400
vae loss: 0.20895
kl loss: 0.00011
a decoder loss: 0.20884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:55
train iter: 764
num of updates: 76500
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:56
train iter: 765
num of updates: 76600
vae loss: 0.20950
kl loss: 0.00011
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:57
train iter: 766
num of updates: 76700
vae loss: 0.20948
kl loss: 0.00011
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:58
train iter: 767
num of updates: 76800
vae loss: 0.21075
kl loss: 0.00011
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:03:59
train iter: 768
num of updates: 76900
vae loss: 0.21003
kl loss: 0.00011
a decoder loss: 0.20992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:00
train iter: 769
num of updates: 77000
vae loss: 0.21058
kl loss: 0.00011
a decoder loss: 0.21047
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:01
train iter: 770
num of updates: 77100
vae loss: 0.20977
kl loss: 0.00011
a decoder loss: 0.20966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:02
train iter: 771
num of updates: 77200
vae loss: 0.21000
kl loss: 0.00011
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:03
train iter: 772
num of updates: 77300
vae loss: 0.21075
kl loss: 0.00011
a decoder loss: 0.21064
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:04
train iter: 773
num of updates: 77400
vae loss: 0.21009
kl loss: 0.00011
a decoder loss: 0.20998
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:05
train iter: 774
num of updates: 77500
vae loss: 0.20921
kl loss: 0.00011
a decoder loss: 0.20910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:06
train iter: 775
num of updates: 77600
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21030
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:07
train iter: 776
num of updates: 77700
vae loss: 0.20935
kl loss: 0.00011
a decoder loss: 0.20924
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:08
train iter: 777
num of updates: 77800
vae loss: 0.20977
kl loss: 0.00011
a decoder loss: 0.20966
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:09
train iter: 778
num of updates: 77900
vae loss: 0.21005
kl loss: 0.00011
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:10
train iter: 779
num of updates: 78000
vae loss: 0.20916
kl loss: 0.00011
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:11
train iter: 780
num of updates: 78100
vae loss: 0.20949
kl loss: 0.00011
a decoder loss: 0.20938
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:12
train iter: 781
num of updates: 78200
vae loss: 0.21064
kl loss: 0.00011
a decoder loss: 0.21053
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:13
train iter: 782
num of updates: 78300
vae loss: 0.20962
kl loss: 0.00011
a decoder loss: 0.20951
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:14
train iter: 783
num of updates: 78400
vae loss: 0.20933
kl loss: 0.00011
a decoder loss: 0.20922
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:15
train iter: 784
num of updates: 78500
vae loss: 0.20984
kl loss: 0.00011
a decoder loss: 0.20973
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:16
train iter: 785
num of updates: 78600
vae loss: 0.20957
kl loss: 0.00011
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:17
train iter: 786
num of updates: 78700
vae loss: 0.20948
kl loss: 0.00011
a decoder loss: 0.20937
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:18
train iter: 787
num of updates: 78800
vae loss: 0.20982
kl loss: 0.00011
a decoder loss: 0.20972
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:19
train iter: 788
num of updates: 78900
vae loss: 0.21041
kl loss: 0.00011
a decoder loss: 0.21031
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:20
train iter: 789
num of updates: 79000
vae loss: 0.20973
kl loss: 0.00011
a decoder loss: 0.20962
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:21
train iter: 790
num of updates: 79100
vae loss: 0.20991
kl loss: 0.00011
a decoder loss: 0.20980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:22
train iter: 791
num of updates: 79200
vae loss: 0.20955
kl loss: 0.00011
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:23
train iter: 792
num of updates: 79300
vae loss: 0.21007
kl loss: 0.00011
a decoder loss: 0.20996
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:24
train iter: 793
num of updates: 79400
vae loss: 0.20995
kl loss: 0.00011
a decoder loss: 0.20984
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:26
train iter: 794
num of updates: 79500
vae loss: 0.21054
kl loss: 0.00010
a decoder loss: 0.21043
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:27
train iter: 795
num of updates: 79600
vae loss: 0.20963
kl loss: 0.00011
a decoder loss: 0.20952
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:28
train iter: 796
num of updates: 79700
vae loss: 0.20908
kl loss: 0.00011
a decoder loss: 0.20898
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:29
train iter: 797
num of updates: 79800
vae loss: 0.21043
kl loss: 0.00011
a decoder loss: 0.21032
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:30
train iter: 798
num of updates: 79900
vae loss: 0.20945
kl loss: 0.00011
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:31
train iter: 799
num of updates: 80000
vae loss: 0.20913
kl loss: 0.00010
a decoder loss: 0.20902
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:32
train iter: 800
num of updates: 80100
vae loss: 0.21027
kl loss: 0.00010
a decoder loss: 0.21016
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:33
train iter: 801
num of updates: 80200
vae loss: 0.20951
kl loss: 0.00010
a decoder loss: 0.20941
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:34
train iter: 802
num of updates: 80300
vae loss: 0.21019
kl loss: 0.00010
a decoder loss: 0.21009
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:35
train iter: 803
num of updates: 80400
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20913
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:36
train iter: 804
num of updates: 80500
vae loss: 0.20966
kl loss: 0.00010
a decoder loss: 0.20955
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:37
train iter: 805
num of updates: 80600
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:38
train iter: 806
num of updates: 80700
vae loss: 0.21001
kl loss: 0.00010
a decoder loss: 0.20991
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:39
train iter: 807
num of updates: 80800
vae loss: 0.20943
kl loss: 0.00010
a decoder loss: 0.20933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:40
train iter: 808
num of updates: 80900
vae loss: 0.20937
kl loss: 0.00010
a decoder loss: 0.20927
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:41
train iter: 809
num of updates: 81000
vae loss: 0.20982
kl loss: 0.00010
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:42
train iter: 810
num of updates: 81100
vae loss: 0.21004
kl loss: 0.00010
a decoder loss: 0.20994
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:43
train iter: 811
num of updates: 81200
vae loss: 0.20981
kl loss: 0.00010
a decoder loss: 0.20970
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:44
train iter: 812
num of updates: 81300
vae loss: 0.21003
kl loss: 0.00010
a decoder loss: 0.20993
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:45
train iter: 813
num of updates: 81400
vae loss: 0.20938
kl loss: 0.00010
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:46
train iter: 814
num of updates: 81500
vae loss: 0.20991
kl loss: 0.00010
a decoder loss: 0.20980
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:47
train iter: 815
num of updates: 81600
vae loss: 0.21002
kl loss: 0.00010
a decoder loss: 0.20992
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:48
train iter: 816
num of updates: 81700
vae loss: 0.21010
kl loss: 0.00010
a decoder loss: 0.20999
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:49
train iter: 817
num of updates: 81800
vae loss: 0.21035
kl loss: 0.00010
a decoder loss: 0.21025
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:50
train iter: 818
num of updates: 81900
vae loss: 0.20965
kl loss: 0.00010
a decoder loss: 0.20954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:51
train iter: 819
num of updates: 82000
vae loss: 0.20964
kl loss: 0.00010
a decoder loss: 0.20954
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:52
train iter: 820
num of updates: 82100
vae loss: 0.20981
kl loss: 0.00010
a decoder loss: 0.20971
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:53
train iter: 821
num of updates: 82200
vae loss: 0.20835
kl loss: 0.00010
a decoder loss: 0.20825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:54
train iter: 822
num of updates: 82300
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:55
train iter: 823
num of updates: 82400
vae loss: 0.20956
kl loss: 0.00010
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:56
train iter: 824
num of updates: 82500
vae loss: 0.20918
kl loss: 0.00010
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:57
train iter: 825
num of updates: 82600
vae loss: 0.20938
kl loss: 0.00010
a decoder loss: 0.20928
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:58
train iter: 826
num of updates: 82700
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20935
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:04:59
train iter: 827
num of updates: 82800
vae loss: 0.20903
kl loss: 0.00010
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:00
train iter: 828
num of updates: 82900
vae loss: 0.20922
kl loss: 0.00010
a decoder loss: 0.20912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:01
train iter: 829
num of updates: 83000
vae loss: 0.20944
kl loss: 0.00010
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:02
train iter: 830
num of updates: 83100
vae loss: 0.20919
kl loss: 0.00010
a decoder loss: 0.20909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:03
train iter: 831
num of updates: 83200
vae loss: 0.20970
kl loss: 0.00010
a decoder loss: 0.20960
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:04
train iter: 832
num of updates: 83300
vae loss: 0.20946
kl loss: 0.00010
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:05
train iter: 833
num of updates: 83400
vae loss: 0.20943
kl loss: 0.00010
a decoder loss: 0.20933
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:06
train iter: 834
num of updates: 83500
vae loss: 0.20901
kl loss: 0.00010
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:07
train iter: 835
num of updates: 83600
vae loss: 0.20999
kl loss: 0.00010
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:08
train iter: 836
num of updates: 83700
vae loss: 0.20896
kl loss: 0.00010
a decoder loss: 0.20887
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:09
train iter: 837
num of updates: 83800
vae loss: 0.20978
kl loss: 0.00010
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:10
train iter: 838
num of updates: 83900
vae loss: 0.20830
kl loss: 0.00010
a decoder loss: 0.20820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:11
train iter: 839
num of updates: 84000
vae loss: 0.20950
kl loss: 0.00010
a decoder loss: 0.20940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:12
train iter: 840
num of updates: 84100
vae loss: 0.20966
kl loss: 0.00010
a decoder loss: 0.20956
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:13
train iter: 841
num of updates: 84200
vae loss: 0.20944
kl loss: 0.00010
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:14
train iter: 842
num of updates: 84300
vae loss: 0.20905
kl loss: 0.00010
a decoder loss: 0.20896
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:15
train iter: 843
num of updates: 84400
vae loss: 0.20863
kl loss: 0.00010
a decoder loss: 0.20854
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:16
train iter: 844
num of updates: 84500
vae loss: 0.20985
kl loss: 0.00010
a decoder loss: 0.20975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:17
train iter: 845
num of updates: 84600
vae loss: 0.20899
kl loss: 0.00010
a decoder loss: 0.20889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:18
train iter: 846
num of updates: 84700
vae loss: 0.20955
kl loss: 0.00010
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:19
train iter: 847
num of updates: 84800
vae loss: 0.20887
kl loss: 0.00010
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:20
train iter: 848
num of updates: 84900
vae loss: 0.20924
kl loss: 0.00010
a decoder loss: 0.20914
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:21
train iter: 849
num of updates: 85000
vae loss: 0.20913
kl loss: 0.00010
a decoder loss: 0.20903
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:22
train iter: 850
num of updates: 85100
vae loss: 0.20895
kl loss: 0.00010
a decoder loss: 0.20885
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:23
train iter: 851
num of updates: 85200
vae loss: 0.20954
kl loss: 0.00010
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:24
train iter: 852
num of updates: 85300
vae loss: 0.20893
kl loss: 0.00009
a decoder loss: 0.20884
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:25
train iter: 853
num of updates: 85400
vae loss: 0.20977
kl loss: 0.00009
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:26
train iter: 854
num of updates: 85500
vae loss: 0.20922
kl loss: 0.00010
a decoder loss: 0.20912
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:27
train iter: 855
num of updates: 85600
vae loss: 0.20941
kl loss: 0.00009
a decoder loss: 0.20932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:28
train iter: 856
num of updates: 85700
vae loss: 0.20985
kl loss: 0.00009
a decoder loss: 0.20975
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:29
train iter: 857
num of updates: 85800
vae loss: 0.20927
kl loss: 0.00010
a decoder loss: 0.20918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:31
train iter: 858
num of updates: 85900
vae loss: 0.20949
kl loss: 0.00009
a decoder loss: 0.20940
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:32
train iter: 859
num of updates: 86000
vae loss: 0.20945
kl loss: 0.00009
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:33
train iter: 860
num of updates: 86100
vae loss: 0.20916
kl loss: 0.00009
a decoder loss: 0.20907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:34
train iter: 861
num of updates: 86200
vae loss: 0.20930
kl loss: 0.00009
a decoder loss: 0.20921
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:35
train iter: 862
num of updates: 86300
vae loss: 0.20884
kl loss: 0.00009
a decoder loss: 0.20875
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:36
train iter: 863
num of updates: 86400
vae loss: 0.20997
kl loss: 0.00009
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:37
train iter: 864
num of updates: 86500
vae loss: 0.20866
kl loss: 0.00009
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:38
train iter: 865
num of updates: 86600
vae loss: 0.20986
kl loss: 0.00009
a decoder loss: 0.20977
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:39
train iter: 866
num of updates: 86700
vae loss: 0.20932
kl loss: 0.00009
a decoder loss: 0.20923
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:40
train iter: 867
num of updates: 86800
vae loss: 0.20918
kl loss: 0.00009
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:41
train iter: 868
num of updates: 86900
vae loss: 0.20920
kl loss: 0.00009
a decoder loss: 0.20911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:42
train iter: 869
num of updates: 87000
vae loss: 0.20906
kl loss: 0.00009
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:43
train iter: 870
num of updates: 87100
vae loss: 0.20899
kl loss: 0.00009
a decoder loss: 0.20889
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:44
train iter: 871
num of updates: 87200
vae loss: 0.20940
kl loss: 0.00009
a decoder loss: 0.20931
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:45
train iter: 872
num of updates: 87300
vae loss: 0.20832
kl loss: 0.00009
a decoder loss: 0.20823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:46
train iter: 873
num of updates: 87400
vae loss: 0.20897
kl loss: 0.00009
a decoder loss: 0.20888
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:47
train iter: 874
num of updates: 87500
vae loss: 0.20915
kl loss: 0.00009
a decoder loss: 0.20906
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:48
train iter: 875
num of updates: 87600
vae loss: 0.20901
kl loss: 0.00009
a decoder loss: 0.20891
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:49
train iter: 876
num of updates: 87700
vae loss: 0.20841
kl loss: 0.00009
a decoder loss: 0.20832
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:50
train iter: 877
num of updates: 87800
vae loss: 0.20997
kl loss: 0.00009
a decoder loss: 0.20988
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:51
train iter: 878
num of updates: 87900
vae loss: 0.20915
kl loss: 0.00009
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:52
train iter: 879
num of updates: 88000
vae loss: 0.20873
kl loss: 0.00009
a decoder loss: 0.20864
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:53
train iter: 880
num of updates: 88100
vae loss: 0.20854
kl loss: 0.00009
a decoder loss: 0.20845
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:54
train iter: 881
num of updates: 88200
vae loss: 0.20941
kl loss: 0.00009
a decoder loss: 0.20932
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:55
train iter: 882
num of updates: 88300
vae loss: 0.20918
kl loss: 0.00009
a decoder loss: 0.20909
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:56
train iter: 883
num of updates: 88400
vae loss: 0.20998
kl loss: 0.00009
a decoder loss: 0.20989
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:57
train iter: 884
num of updates: 88500
vae loss: 0.20870
kl loss: 0.00009
a decoder loss: 0.20861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:58
train iter: 885
num of updates: 88600
vae loss: 0.20926
kl loss: 0.00009
a decoder loss: 0.20917
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:05:59
train iter: 886
num of updates: 88700
vae loss: 0.20919
kl loss: 0.00009
a decoder loss: 0.20910
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:00
train iter: 887
num of updates: 88800
vae loss: 0.20914
kl loss: 0.00009
a decoder loss: 0.20905
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:01
train iter: 888
num of updates: 88900
vae loss: 0.20845
kl loss: 0.00009
a decoder loss: 0.20837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:02
train iter: 889
num of updates: 89000
vae loss: 0.20860
kl loss: 0.00009
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:03
train iter: 890
num of updates: 89100
vae loss: 0.20825
kl loss: 0.00009
a decoder loss: 0.20816
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:04
train iter: 891
num of updates: 89200
vae loss: 0.20943
kl loss: 0.00009
a decoder loss: 0.20934
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:05
train iter: 892
num of updates: 89300
vae loss: 0.20837
kl loss: 0.00009
a decoder loss: 0.20828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:06
train iter: 893
num of updates: 89400
vae loss: 0.20868
kl loss: 0.00009
a decoder loss: 0.20859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:07
train iter: 894
num of updates: 89500
vae loss: 0.20857
kl loss: 0.00009
a decoder loss: 0.20848
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:08
train iter: 895
num of updates: 89600
vae loss: 0.20926
kl loss: 0.00009
a decoder loss: 0.20917
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:09
train iter: 896
num of updates: 89700
vae loss: 0.20811
kl loss: 0.00009
a decoder loss: 0.20802
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:10
train iter: 897
num of updates: 89800
vae loss: 0.20976
kl loss: 0.00009
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:11
train iter: 898
num of updates: 89900
vae loss: 0.20909
kl loss: 0.00009
a decoder loss: 0.20900
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:12
train iter: 899
num of updates: 90000
vae loss: 0.20920
kl loss: 0.00009
a decoder loss: 0.20911
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:13
train iter: 900
num of updates: 90100
vae loss: 0.20822
kl loss: 0.00009
a decoder loss: 0.20813
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:14
train iter: 901
num of updates: 90200
vae loss: 0.20907
kl loss: 0.00009
a decoder loss: 0.20898
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:15
train iter: 902
num of updates: 90300
vae loss: 0.20869
kl loss: 0.00009
a decoder loss: 0.20860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:16
train iter: 903
num of updates: 90400
vae loss: 0.20878
kl loss: 0.00009
a decoder loss: 0.20869
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:17
train iter: 904
num of updates: 90500
vae loss: 0.20928
kl loss: 0.00009
a decoder loss: 0.20919
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:18
train iter: 905
num of updates: 90600
vae loss: 0.20752
kl loss: 0.00009
a decoder loss: 0.20744
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:19
train iter: 906
num of updates: 90700
vae loss: 0.20951
kl loss: 0.00009
a decoder loss: 0.20942
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:20
train iter: 907
num of updates: 90800
vae loss: 0.20860
kl loss: 0.00009
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:21
train iter: 908
num of updates: 90900
vae loss: 0.20832
kl loss: 0.00009
a decoder loss: 0.20823
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:22
train iter: 909
num of updates: 91000
vae loss: 0.20829
kl loss: 0.00009
a decoder loss: 0.20820
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:23
train iter: 910
num of updates: 91100
vae loss: 0.20929
kl loss: 0.00009
a decoder loss: 0.20920
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:24
train iter: 911
num of updates: 91200
vae loss: 0.20862
kl loss: 0.00009
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:25
train iter: 912
num of updates: 91300
vae loss: 0.20977
kl loss: 0.00009
a decoder loss: 0.20968
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:26
train iter: 913
num of updates: 91400
vae loss: 0.20837
kl loss: 0.00009
a decoder loss: 0.20828
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:27
train iter: 914
num of updates: 91500
vae loss: 0.20899
kl loss: 0.00009
a decoder loss: 0.20890
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:28
train iter: 915
num of updates: 91600
vae loss: 0.20865
kl loss: 0.00009
a decoder loss: 0.20856
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:29
train iter: 916
num of updates: 91700
vae loss: 0.20855
kl loss: 0.00009
a decoder loss: 0.20847
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:30
train iter: 917
num of updates: 91800
vae loss: 0.20901
kl loss: 0.00008
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:31
train iter: 918
num of updates: 91900
vae loss: 0.20945
kl loss: 0.00009
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:32
train iter: 919
num of updates: 92000
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:33
train iter: 920
num of updates: 92100
vae loss: 0.20861
kl loss: 0.00009
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:35
train iter: 921
num of updates: 92200
vae loss: 0.20876
kl loss: 0.00009
a decoder loss: 0.20868
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:36
train iter: 922
num of updates: 92300
vae loss: 0.20884
kl loss: 0.00008
a decoder loss: 0.20876
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:37
train iter: 923
num of updates: 92400
vae loss: 0.20880
kl loss: 0.00009
a decoder loss: 0.20871
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:38
train iter: 924
num of updates: 92500
vae loss: 0.20834
kl loss: 0.00008
a decoder loss: 0.20825
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:39
train iter: 925
num of updates: 92600
vae loss: 0.20916
kl loss: 0.00008
a decoder loss: 0.20908
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:40
train iter: 926
num of updates: 92700
vae loss: 0.20915
kl loss: 0.00008
a decoder loss: 0.20907
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:41
train iter: 927
num of updates: 92800
vae loss: 0.20846
kl loss: 0.00008
a decoder loss: 0.20838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:42
train iter: 928
num of updates: 92900
vae loss: 0.20846
kl loss: 0.00008
a decoder loss: 0.20838
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:43
train iter: 929
num of updates: 93000
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20852
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:44
train iter: 930
num of updates: 93100
vae loss: 0.20863
kl loss: 0.00008
a decoder loss: 0.20854
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:45
train iter: 931
num of updates: 93200
vae loss: 0.20875
kl loss: 0.00008
a decoder loss: 0.20867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:46
train iter: 932
num of updates: 93300
vae loss: 0.20823
kl loss: 0.00008
a decoder loss: 0.20815
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:47
train iter: 933
num of updates: 93400
vae loss: 0.20927
kl loss: 0.00008
a decoder loss: 0.20918
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:48
train iter: 934
num of updates: 93500
vae loss: 0.20827
kl loss: 0.00008
a decoder loss: 0.20819
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:49
train iter: 935
num of updates: 93600
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:50
train iter: 936
num of updates: 93700
vae loss: 0.20898
kl loss: 0.00008
a decoder loss: 0.20890
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:51
train iter: 937
num of updates: 93800
vae loss: 0.20792
kl loss: 0.00008
a decoder loss: 0.20784
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:52
train iter: 938
num of updates: 93900
vae loss: 0.20976
kl loss: 0.00008
a decoder loss: 0.20967
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:53
train iter: 939
num of updates: 94000
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20843
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:54
train iter: 940
num of updates: 94100
vae loss: 0.20882
kl loss: 0.00008
a decoder loss: 0.20874
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:55
train iter: 941
num of updates: 94200
vae loss: 0.20794
kl loss: 0.00008
a decoder loss: 0.20786
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:56
train iter: 942
num of updates: 94300
vae loss: 0.20865
kl loss: 0.00008
a decoder loss: 0.20856
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:57
train iter: 943
num of updates: 94400
vae loss: 0.20875
kl loss: 0.00008
a decoder loss: 0.20867
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:58
train iter: 944
num of updates: 94500
vae loss: 0.20954
kl loss: 0.00008
a decoder loss: 0.20946
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:06:59
train iter: 945
num of updates: 94600
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20842
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:00
train iter: 946
num of updates: 94700
vae loss: 0.20895
kl loss: 0.00008
a decoder loss: 0.20887
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:01
train iter: 947
num of updates: 94800
vae loss: 0.20814
kl loss: 0.00008
a decoder loss: 0.20806
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:02
train iter: 948
num of updates: 94900
vae loss: 0.20847
kl loss: 0.00008
a decoder loss: 0.20839
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:03
train iter: 949
num of updates: 95000
vae loss: 0.20835
kl loss: 0.00008
a decoder loss: 0.20827
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:04
train iter: 950
num of updates: 95100
vae loss: 0.20777
kl loss: 0.00008
a decoder loss: 0.20769
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:05
train iter: 951
num of updates: 95200
vae loss: 0.20923
kl loss: 0.00008
a decoder loss: 0.20915
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:06
train iter: 952
num of updates: 95300
vae loss: 0.20862
kl loss: 0.00008
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:07
train iter: 953
num of updates: 95400
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:08
train iter: 954
num of updates: 95500
vae loss: 0.20906
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:09
train iter: 955
num of updates: 95600
vae loss: 0.20812
kl loss: 0.00008
a decoder loss: 0.20804
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:10
train iter: 956
num of updates: 95700
vae loss: 0.20952
kl loss: 0.00008
a decoder loss: 0.20944
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:11
train iter: 957
num of updates: 95800
vae loss: 0.20867
kl loss: 0.00008
a decoder loss: 0.20859
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:12
train iter: 958
num of updates: 95900
vae loss: 0.20746
kl loss: 0.00008
a decoder loss: 0.20738
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:13
train iter: 959
num of updates: 96000
vae loss: 0.20838
kl loss: 0.00008
a decoder loss: 0.20830
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:14
train iter: 960
num of updates: 96100
vae loss: 0.20865
kl loss: 0.00008
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:15
train iter: 961
num of updates: 96200
vae loss: 0.20829
kl loss: 0.00008
a decoder loss: 0.20821
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:16
train iter: 962
num of updates: 96300
vae loss: 0.20857
kl loss: 0.00008
a decoder loss: 0.20849
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:17
train iter: 963
num of updates: 96400
vae loss: 0.20852
kl loss: 0.00008
a decoder loss: 0.20844
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:18
train iter: 964
num of updates: 96500
vae loss: 0.20825
kl loss: 0.00008
a decoder loss: 0.20817
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:19
train iter: 965
num of updates: 96600
vae loss: 0.20905
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:20
train iter: 966
num of updates: 96700
vae loss: 0.20820
kl loss: 0.00008
a decoder loss: 0.20812
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:21
train iter: 967
num of updates: 96800
vae loss: 0.20889
kl loss: 0.00008
a decoder loss: 0.20881
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:22
train iter: 968
num of updates: 96900
vae loss: 0.20888
kl loss: 0.00008
a decoder loss: 0.20880
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:23
train iter: 969
num of updates: 97000
vae loss: 0.20869
kl loss: 0.00008
a decoder loss: 0.20861
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:24
train iter: 970
num of updates: 97100
vae loss: 0.20817
kl loss: 0.00008
a decoder loss: 0.20809
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:25
train iter: 971
num of updates: 97200
vae loss: 0.20944
kl loss: 0.00008
a decoder loss: 0.20936
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:26
train iter: 972
num of updates: 97300
vae loss: 0.20902
kl loss: 0.00008
a decoder loss: 0.20894
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:27
train iter: 973
num of updates: 97400
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:28
train iter: 974
num of updates: 97500
vae loss: 0.20876
kl loss: 0.00008
a decoder loss: 0.20868
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:29
train iter: 975
num of updates: 97600
vae loss: 0.20901
kl loss: 0.00008
a decoder loss: 0.20893
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:30
train iter: 976
num of updates: 97700
vae loss: 0.20796
kl loss: 0.00008
a decoder loss: 0.20788
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:31
train iter: 977
num of updates: 97800
vae loss: 0.20815
kl loss: 0.00008
a decoder loss: 0.20807
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:32
train iter: 978
num of updates: 97900
vae loss: 0.20850
kl loss: 0.00008
a decoder loss: 0.20842
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:33
train iter: 979
num of updates: 98000
vae loss: 0.20905
kl loss: 0.00008
a decoder loss: 0.20897
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:34
train iter: 980
num of updates: 98100
vae loss: 0.20783
kl loss: 0.00008
a decoder loss: 0.20775
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:35
train iter: 981
num of updates: 98200
vae loss: 0.20880
kl loss: 0.00008
a decoder loss: 0.20872
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:36
train iter: 982
num of updates: 98300
vae loss: 0.20907
kl loss: 0.00008
a decoder loss: 0.20899
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:37
train iter: 983
num of updates: 98400
vae loss: 0.20890
kl loss: 0.00008
a decoder loss: 0.20882
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:38
train iter: 984
num of updates: 98500
vae loss: 0.20834
kl loss: 0.00008
a decoder loss: 0.20826
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:40
train iter: 985
num of updates: 98600
vae loss: 0.20821
kl loss: 0.00008
a decoder loss: 0.20813
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:41
train iter: 986
num of updates: 98700
vae loss: 0.20861
kl loss: 0.00008
a decoder loss: 0.20853
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:42
train iter: 987
num of updates: 98800
vae loss: 0.20886
kl loss: 0.00008
a decoder loss: 0.20878
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:43
train iter: 988
num of updates: 98900
vae loss: 0.20842
kl loss: 0.00008
a decoder loss: 0.20834
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:44
train iter: 989
num of updates: 99000
vae loss: 0.20867
kl loss: 0.00008
a decoder loss: 0.20860
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:45
train iter: 990
num of updates: 99100
vae loss: 0.20851
kl loss: 0.00008
a decoder loss: 0.20843
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:46
train iter: 991
num of updates: 99200
vae loss: 0.20858
kl loss: 0.00008
a decoder loss: 0.20851
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:47
train iter: 992
num of updates: 99300
vae loss: 0.20884
kl loss: 0.00008
a decoder loss: 0.20877
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:48
train iter: 993
num of updates: 99400
vae loss: 0.20811
kl loss: 0.00008
a decoder loss: 0.20803
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:49
train iter: 994
num of updates: 99500
vae loss: 0.20864
kl loss: 0.00008
a decoder loss: 0.20857
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:50
train iter: 995
num of updates: 99600
vae loss: 0.20830
kl loss: 0.00008
a decoder loss: 0.20822
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:51
train iter: 996
num of updates: 99700
vae loss: 0.20773
kl loss: 0.00008
a decoder loss: 0.20765
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:52
train iter: 997
num of updates: 99800
vae loss: 0.20845
kl loss: 0.00008
a decoder loss: 0.20837
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:53
train iter: 998
num of updates: 99900
vae loss: 0.20813
kl loss: 0.00007
a decoder loss: 0.20806
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

============================================================
time elapsed: 1:07:54
train iter: 999
num of updates: 100000
vae loss: 0.20890
kl loss: 0.00008
a decoder loss: 0.20883
y decoder loss: 0.00000
mean weights: 0.00000
mean disagreement losses: 0.00000

saving current model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/vae_model_100000.pt
============================================================
finished training vae!
============================================================
started training vae at: 25-09-28-00-54-25
finished training vae at: 25-09-28-02-02-31
total vae training time: 1:08:06
saved last updated model at: dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/vae_model.pt
============================================================
2025-09-28 02:02:33.840994: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:35.753133: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 16 bytes spill stores, 16 bytes spill loads

2025-09-28 02:02:36.721785: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 20 bytes spill stores, 20 bytes spill loads

2025-09-28 02:02:37.645571: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 40 bytes spill stores, 40 bytes spill loads

2025-09-28 02:02:38.674912: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:42.332555: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:02:43.055955: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:02:43.534825: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3', 24 bytes spill stores, 24 bytes spill loads

2025-09-28 02:02:45.001781: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:46.857999: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 404 bytes spill stores, 404 bytes spill loads

2025-09-28 02:02:48.121544: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 504 bytes spill stores, 460 bytes spill loads

2025-09-28 02:02:49.000180: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 908 bytes spill stores, 668 bytes spill loads

2025-09-28 02:02:49.733634: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 1868 bytes spill stores, 1352 bytes spill loads

2025-09-28 02:02:50.939958: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 236 bytes spill stores, 236 bytes spill loads

2025-09-28 02:02:51.789028: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-09-28 02:02:54.648144: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 24 bytes spill stores, 24 bytes spill loads

Error executing job with overrides: ['state_dep_prior=True', 'learn_dynamics_std=False', 'autonomous=False', 'n_dynamics_ensembles=5']
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/jax_dt/train_dt.py", line 1286, in train
    _vae_params = load_params(load_current_model_path)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 75, in load_params
    with File(path, 'rb') as fin:
         ^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/jax_dt/decision_transformer/dt/utils.py", line 59, in __init__
    self.f = open(fileName, mode)
             ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dt_runs/dt_relocate-expert-v1/seed_0/25-09-28-00-54-25/vae_model_1000000.pt'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrelocate-expert-v1-985440[0m at: [34mhttps://wandb.ai/james-gatsby/jax_dt/runs/vyerg8uv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250928_005517-vyerg8uv/logs[0m
Exception ignored in: <function OffScreenViewer.__del__ at 0x7bd89d1a0e00>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/platform/baseplatform.py", line 487, in __call__
    return self(*args, **named)
           ^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x7bd872b2f250>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7bd872b2f6d0>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x7bd8b9fb9440>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 133, in free
    EGL.eglDestroyContext(EGL_DISPLAY, self._context)
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglDestroyContext,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x7bd872b2f250>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7bd872b2f6d0>,
	),
	result = 0
)
Exception ignored in: <function OffScreenViewer.__del__ at 0x7bd89d1a0e00>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 204, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py", line 201, in free
    self.opengl_context.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x7bd872b2f250>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7bd8b9f65550>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7bd8b9f65550>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7bd8b9f652d0>,
	),
	result = 0
)
Exception ignored in: <function GLContext.__del__ at 0x7bd8b9fb9440>
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 138, in __del__
    self.free()
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/mujoco/egl/__init__.py", line 131, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE,
  File "/nfs/nhome/live/jheald/miniconda3/envs/jax_dt_py312/lib/python3.12/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x7bd872b2f250>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7bd8b9f65550>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7bd8b9f65550>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7bd8b9f652d0>,
	),
	result = 0
)
